{"version":3,"file":"index.rn.esm2017.js","sources":["../src/util/log.ts","../src/platform/browser/format_json.ts","../src/util/assert.ts","../src/platform/browser/random_bytes.ts","../src/util/misc.ts","../src/core/database_info.ts","../src/util/obj.ts","../src/util/obj_map.ts","../src/util/error.ts","../src/api/timestamp.ts","../src/core/snapshot_version.ts","../src/model/path.ts","../src/model/document_key.ts","../src/util/types.ts","../src/core/target.ts","../src/core/query.ts","../src/platform/rn/base64.ts","../src/util/byte_string.ts","../src/local/target_data.ts","../src/remote/existence_filter.ts","../src/remote/rpc_error.ts","../src/util/sorted_map.ts","../src/util/sorted_set.ts","../src/model/collections.ts","../src/model/document_set.ts","../src/core/view_snapshot.ts","../src/remote/remote_event.ts","../src/remote/watch_change.ts","../src/model/server_timestamps.ts","../src/model/values.ts","../src/remote/serializer.ts","../src/model/transform_operation.ts","../src/model/mutation.ts","../src/model/object_value.ts","../src/model/document.ts","../lite/src/api/util.ts","../src/model/mutation_batch.ts","../src/local/persistence_promise.ts","../src/local/remote_document_change_buffer.ts","../src/local/persistence.ts","../src/local/local_documents_view.ts","../src/local/local_view_changes.ts","../src/core/listen_sequence.ts","../src/util/promise.ts","../src/remote/backoff.ts","../src/local/simple_db.ts","../src/platform/browser/dom.ts","../src/util/async_queue.ts","../src/local/lru_garbage_collector.ts","../src/local/encoded_resource_path.ts","../src/local/local_serializer.ts","../src/local/indexeddb_mutation_queue.ts","../src/local/indexeddb_remote_document_cache.ts","../src/local/memory_index_manager.ts","../src/local/indexeddb_schema.ts","../src/local/indexeddb_index_manager.ts","../src/core/target_id_generator.ts","../src/local/indexeddb_target_cache.ts","../src/local/indexeddb_persistence.ts","../src/local/local_store.ts","../src/local/reference_set.ts","../src/auth/user.ts","../src/api/credentials.ts","../src/remote/persistent_stream.ts","../src/remote/datastore.ts","../src/remote/online_state_tracker.ts","../src/remote/remote_store.ts","../src/local/shared_client_state_schema.ts","../src/local/shared_client_state.ts","../src/core/view.ts","../src/core/sync_engine.ts","../src/core/event_manager.ts","../src/local/index_free_query_engine.ts","../src/local/memory_mutation_queue.ts","../src/local/memory_remote_document_cache.ts","../src/local/memory_target_cache.ts","../src/local/memory_persistence.ts","../src/remote/stream_bridge.ts","../src/remote/rest_connection.ts","../src/platform/browser/webchannel_connection.ts","../src/platform/browser/connectivity_monitor.ts","../src/remote/connectivity_monitor_noop.ts","../src/platform/browser/serializer.ts","../src/core/component_provider.ts","../src/platform/browser/connection.ts","../src/api/observer.ts","../src/util/async_observer.ts","../src/util/input_validation.ts","../src/api/blob.ts","../src/api/field_path.ts","../src/api/field_value.ts","../src/api/geo_point.ts","../src/api/user_data_reader.ts","../src/core/transaction.ts","../src/core/transaction_runner.ts","../src/core/firestore_client.ts","../src/api/user_data_writer.ts","../src/api/database.ts","../src/config.ts","../index.rn.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Logger, LogLevel, LogLevelString } from '@firebase/logger';\nimport { SDK_VERSION } from '../core/version';\nimport { formatJSON } from '../platform/format_json';\n\nexport { LogLevel };\n\nconst logClient = new Logger('@firebase/firestore');\n\n// Helper methods are needed because variables can't be exported as read/write\nexport function getLogLevel(): LogLevel {\n  return logClient.logLevel;\n}\n\nexport function setLogLevel(newLevel: LogLevelString | LogLevel): void {\n  logClient.setLogLevel(newLevel);\n}\n\nexport function logDebug(msg: string, ...obj: unknown[]): void {\n  if (logClient.logLevel <= LogLevel.DEBUG) {\n    const args = obj.map(argToString);\n    logClient.debug(`Firestore (${SDK_VERSION}): ${msg}`, ...args);\n  }\n}\n\nexport function logError(msg: string, ...obj: unknown[]): void {\n  if (logClient.logLevel <= LogLevel.ERROR) {\n    const args = obj.map(argToString);\n    logClient.error(`Firestore (${SDK_VERSION}): ${msg}`, ...args);\n  }\n}\n\nexport function logWarn(msg: string, ...obj: unknown[]): void {\n  if (logClient.logLevel <= LogLevel.WARN) {\n    const args = obj.map(argToString);\n    logClient.warn(`Firestore (${SDK_VERSION}): ${msg}`, ...args);\n  }\n}\n\n/**\n * Converts an additional log parameter to a string representation.\n */\nfunction argToString(obj: unknown): string | unknown {\n  if (typeof obj === 'string') {\n    return obj;\n  } else {\n    try {\n      return formatJSON(obj);\n    } catch (e) {\n      // Converting to JSON failed, just log the object directly\n      return obj;\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/** Formats an object as a JSON string, suitable for logging. */\nexport function formatJSON(value: unknown): string {\n  return JSON.stringify(value);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SDK_VERSION } from '../core/version';\nimport { logError } from './log';\n\n/**\n * Unconditionally fails, throwing an Error with the given message.\n * Messages are stripped in production builds.\n *\n * Returns `never` and can be used in expressions:\n * @example\n * let futureVar = fail('not implemented yet');\n */\nexport function fail(failure: string = 'Unexpected state'): never {\n  // Log the failure in addition to throw an exception, just in case the\n  // exception is swallowed.\n  const message =\n    `FIRESTORE (${SDK_VERSION}) INTERNAL ASSERTION FAILED: ` + failure;\n  logError(message);\n\n  // NOTE: We don't use FirestoreError here because these are internal failures\n  // that cannot be handled by the user. (Also it would create a circular\n  // dependency between the error and assert modules which doesn't work.)\n  throw new Error(message);\n}\n\n/**\n * Fails if the given assertion condition is false, throwing an Error with the\n * given message if it did.\n *\n * Messages are stripped in production builds.\n */\nexport function hardAssert(\n  assertion: boolean,\n  message?: string\n): asserts assertion {\n  if (!assertion) {\n    fail(message);\n  }\n}\n\n/**\n * Fails if the given assertion condition is false, throwing an Error with the\n * given message if it did.\n *\n * The code of callsites invoking this function are stripped out in production\n * builds. Any side-effects of code within the debugAssert() invocation will not\n * happen in this case.\n */\nexport function debugAssert(\n  assertion: boolean,\n  message: string\n): asserts assertion {\n  if (!assertion) {\n    fail(message);\n  }\n}\n\n/**\n * Casts `obj` to `T`. In non-production builds, verifies that `obj` is an\n * instance of `T` before casting.\n */\nexport function debugCast<T>(\n  obj: object,\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  constructor: { new (...args: any[]): T }\n): T | never {\n  debugAssert(\n    obj instanceof constructor,\n    `Expected type '${constructor.name}', but was '${obj.constructor.name}'`\n  );\n  return obj as T;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert } from '../../util/assert';\n\n/**\n * Generates `nBytes` of random bytes.\n *\n * If `nBytes < 0` , an error will be thrown.\n */\nexport function randomBytes(nBytes: number): Uint8Array {\n  debugAssert(nBytes >= 0, `Expecting non-negative nBytes, got: ${nBytes}`);\n\n  // Polyfills for IE and WebWorker by using `self` and `msCrypto` when `crypto` is not available.\n  const crypto =\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    typeof self !== 'undefined' && (self.crypto || (self as any)['msCrypto']);\n  const bytes = new Uint8Array(nBytes);\n  if (crypto) {\n    crypto.getRandomValues(bytes);\n  } else {\n    // Falls back to Math.random\n    for (let i = 0; i < nBytes; i++) {\n      bytes[i] = Math.floor(Math.random() * 256);\n    }\n  }\n  return bytes;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert } from './assert';\nimport { randomBytes } from '../platform/random_bytes';\n\nexport type EventHandler<E> = (value: E) => void;\nexport interface Indexable {\n  [k: string]: unknown;\n}\n\nexport class AutoId {\n  static newId(): string {\n    // Alphanumeric characters\n    const chars =\n      'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';\n    // The largest byte value that is a multiple of `char.length`.\n    const maxMultiple = Math.floor(256 / chars.length) * chars.length;\n    debugAssert(\n      0 < maxMultiple && maxMultiple < 256,\n      `Expect maxMultiple to be (0, 256), but got ${maxMultiple}`\n    );\n\n    let autoId = '';\n    const targetLength = 20;\n    while (autoId.length < targetLength) {\n      const bytes = randomBytes(40);\n      for (let i = 0; i < bytes.length; ++i) {\n        // Only accept values that are [0, maxMultiple), this ensures they can\n        // be evenly mapped to indices of `chars` via a modulo operation.\n        if (autoId.length < targetLength && bytes[i] < maxMultiple) {\n          autoId += chars.charAt(bytes[i] % chars.length);\n        }\n      }\n    }\n    debugAssert(autoId.length === targetLength, 'Invalid auto ID: ' + autoId);\n\n    return autoId;\n  }\n}\n\nexport function primitiveComparator<T>(left: T, right: T): number {\n  if (left < right) {\n    return -1;\n  }\n  if (left > right) {\n    return 1;\n  }\n  return 0;\n}\n\nexport interface Equatable<T> {\n  isEqual(other: T): boolean;\n}\n\n/** Helper to compare arrays using isEqual(). */\nexport function arrayEquals<T>(\n  left: T[],\n  right: T[],\n  comparator: (l: T, r: T) => boolean\n): boolean {\n  if (left.length !== right.length) {\n    return false;\n  }\n  return left.every((value, index) => comparator(value, right[index]));\n}\n/**\n * Returns the immediate lexicographically-following string. This is useful to\n * construct an inclusive range for indexeddb iterators.\n */\nexport function immediateSuccessor(s: string): string {\n  // Return the input string, with an additional NUL byte appended.\n  return s + '\\0';\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { primitiveComparator } from '../util/misc';\n\nexport class DatabaseInfo {\n  /**\n   * Constructs a DatabaseInfo using the provided host, databaseId and\n   * persistenceKey.\n   *\n   * @param databaseId The database to use.\n   * @param persistenceKey A unique identifier for this Firestore's local\n   * storage (used in conjunction with the databaseId).\n   * @param host The Firestore backend host to connect to.\n   * @param ssl Whether to use SSL when connecting.\n   * @param forceLongPolling Whether to use the forceLongPolling option\n   * when using WebChannel as the network transport.\n   */\n  constructor(\n    readonly databaseId: DatabaseId,\n    readonly persistenceKey: string,\n    readonly host: string,\n    readonly ssl: boolean,\n    readonly forceLongPolling: boolean\n  ) {}\n}\n\n/** The default database name for a project. */\nconst DEFAULT_DATABASE_NAME = '(default)';\n\n/** Represents the database ID a Firestore client is associated with. */\nexport class DatabaseId {\n  readonly database: string;\n  constructor(readonly projectId: string, database?: string) {\n    this.database = database ? database : DEFAULT_DATABASE_NAME;\n  }\n\n  get isDefaultDatabase(): boolean {\n    return this.database === DEFAULT_DATABASE_NAME;\n  }\n\n  isEqual(other: {}): boolean {\n    return (\n      other instanceof DatabaseId &&\n      other.projectId === this.projectId &&\n      other.database === this.database\n    );\n  }\n\n  compareTo(other: DatabaseId): number {\n    return (\n      primitiveComparator(this.projectId, other.projectId) ||\n      primitiveComparator(this.database, other.database)\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert } from './assert';\n\nexport interface Dict<V> {\n  [stringKey: string]: V;\n}\n\nexport function objectSize<V>(obj: object): number {\n  let count = 0;\n  for (const key in obj) {\n    if (Object.prototype.hasOwnProperty.call(obj, key)) {\n      count++;\n    }\n  }\n  return count;\n}\n\nexport function forEach<V>(\n  obj: Dict<V>,\n  fn: (key: string, val: V) => void\n): void {\n  for (const key in obj) {\n    if (Object.prototype.hasOwnProperty.call(obj, key)) {\n      fn(key, obj[key]);\n    }\n  }\n}\n\nexport function isEmpty<V>(obj: Dict<V>): boolean {\n  debugAssert(\n    obj != null && typeof obj === 'object',\n    'isEmpty() expects object parameter.'\n  );\n  for (const key in obj) {\n    if (Object.prototype.hasOwnProperty.call(obj, key)) {\n      return false;\n    }\n  }\n  return true;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { forEach, isEmpty } from './obj';\n\ntype Entry<K, V> = [K, V];\n\n/**\n * A map implementation that uses objects as keys. Objects must have an\n * associated equals function and must be immutable. Entries in the map are\n * stored together with the key being produced from the mapKeyFn. This map\n * automatically handles collisions of keys.\n */\nexport class ObjectMap<KeyType, ValueType> {\n  /**\n   * The inner map for a key -> value pair. Due to the possibility of\n   * collisions we keep a list of entries that we do a linear search through\n   * to find an actual match. Note that collisions should be rare, so we still\n   * expect near constant time lookups in practice.\n   */\n  private inner: {\n    [canonicalId: string]: Array<Entry<KeyType, ValueType>>;\n  } = {};\n\n  constructor(\n    private mapKeyFn: (key: KeyType) => string,\n    private equalsFn: (l: KeyType, r: KeyType) => boolean\n  ) {}\n\n  /** Get a value for this key, or undefined if it does not exist. */\n  get(key: KeyType): ValueType | undefined {\n    const id = this.mapKeyFn(key);\n    const matches = this.inner[id];\n    if (matches === undefined) {\n      return undefined;\n    }\n    for (const [otherKey, value] of matches) {\n      if (this.equalsFn(otherKey, key)) {\n        return value;\n      }\n    }\n    return undefined;\n  }\n\n  has(key: KeyType): boolean {\n    return this.get(key) !== undefined;\n  }\n\n  /** Put this key and value in the map. */\n  set(key: KeyType, value: ValueType): void {\n    const id = this.mapKeyFn(key);\n    const matches = this.inner[id];\n    if (matches === undefined) {\n      this.inner[id] = [[key, value]];\n      return;\n    }\n    for (let i = 0; i < matches.length; i++) {\n      if (this.equalsFn(matches[i][0], key)) {\n        matches[i] = [key, value];\n        return;\n      }\n    }\n    matches.push([key, value]);\n  }\n\n  /**\n   * Remove this key from the map. Returns a boolean if anything was deleted.\n   */\n  delete(key: KeyType): boolean {\n    const id = this.mapKeyFn(key);\n    const matches = this.inner[id];\n    if (matches === undefined) {\n      return false;\n    }\n    for (let i = 0; i < matches.length; i++) {\n      if (this.equalsFn(matches[i][0], key)) {\n        if (matches.length === 1) {\n          delete this.inner[id];\n        } else {\n          matches.splice(i, 1);\n        }\n        return true;\n      }\n    }\n    return false;\n  }\n\n  forEach(fn: (key: KeyType, val: ValueType) => void): void {\n    forEach(this.inner, (_, entries) => {\n      for (const [k, v] of entries) {\n        fn(k, v);\n      }\n    });\n  }\n\n  isEmpty(): boolean {\n    return isEmpty(this.inner);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as firestore from '@firebase/firestore-types';\n\n/**\n * Error Codes describing the different ways Firestore can fail. These come\n * directly from GRPC.\n */\nexport type Code = firestore.FirestoreErrorCode;\n\nexport const Code = {\n  // Causes are copied from:\n  // https://github.com/grpc/grpc/blob/bceec94ea4fc5f0085d81235d8e1c06798dc341a/include/grpc%2B%2B/impl/codegen/status_code_enum.h\n  /** Not an error; returned on success. */\n  OK: 'ok' as Code,\n\n  /** The operation was cancelled (typically by the caller). */\n  CANCELLED: 'cancelled' as Code,\n\n  /** Unknown error or an error from a different error domain. */\n  UNKNOWN: 'unknown' as Code,\n\n  /**\n   * Client specified an invalid argument. Note that this differs from\n   * FAILED_PRECONDITION. INVALID_ARGUMENT indicates arguments that are\n   * problematic regardless of the state of the system (e.g., a malformed file\n   * name).\n   */\n  INVALID_ARGUMENT: 'invalid-argument' as Code,\n\n  /**\n   * Deadline expired before operation could complete. For operations that\n   * change the state of the system, this error may be returned even if the\n   * operation has completed successfully. For example, a successful response\n   * from a server could have been delayed long enough for the deadline to\n   * expire.\n   */\n  DEADLINE_EXCEEDED: 'deadline-exceeded' as Code,\n\n  /** Some requested entity (e.g., file or directory) was not found. */\n  NOT_FOUND: 'not-found' as Code,\n\n  /**\n   * Some entity that we attempted to create (e.g., file or directory) already\n   * exists.\n   */\n  ALREADY_EXISTS: 'already-exists' as Code,\n\n  /**\n   * The caller does not have permission to execute the specified operation.\n   * PERMISSION_DENIED must not be used for rejections caused by exhausting\n   * some resource (use RESOURCE_EXHAUSTED instead for those errors).\n   * PERMISSION_DENIED must not be used if the caller can not be identified\n   * (use UNAUTHENTICATED instead for those errors).\n   */\n  PERMISSION_DENIED: 'permission-denied' as Code,\n\n  /**\n   * The request does not have valid authentication credentials for the\n   * operation.\n   */\n  UNAUTHENTICATED: 'unauthenticated' as Code,\n\n  /**\n   * Some resource has been exhausted, perhaps a per-user quota, or perhaps the\n   * entire file system is out of space.\n   */\n  RESOURCE_EXHAUSTED: 'resource-exhausted' as Code,\n\n  /**\n   * Operation was rejected because the system is not in a state required for\n   * the operation's execution. For example, directory to be deleted may be\n   * non-empty, an rmdir operation is applied to a non-directory, etc.\n   *\n   * A litmus test that may help a service implementor in deciding\n   * between FAILED_PRECONDITION, ABORTED, and UNAVAILABLE:\n   *  (a) Use UNAVAILABLE if the client can retry just the failing call.\n   *  (b) Use ABORTED if the client should retry at a higher-level\n   *      (e.g., restarting a read-modify-write sequence).\n   *  (c) Use FAILED_PRECONDITION if the client should not retry until\n   *      the system state has been explicitly fixed. E.g., if an \"rmdir\"\n   *      fails because the directory is non-empty, FAILED_PRECONDITION\n   *      should be returned since the client should not retry unless\n   *      they have first fixed up the directory by deleting files from it.\n   *  (d) Use FAILED_PRECONDITION if the client performs conditional\n   *      REST Get/Update/Delete on a resource and the resource on the\n   *      server does not match the condition. E.g., conflicting\n   *      read-modify-write on the same resource.\n   */\n  FAILED_PRECONDITION: 'failed-precondition' as Code,\n\n  /**\n   * The operation was aborted, typically due to a concurrency issue like\n   * sequencer check failures, transaction aborts, etc.\n   *\n   * See litmus test above for deciding between FAILED_PRECONDITION, ABORTED,\n   * and UNAVAILABLE.\n   */\n  ABORTED: 'aborted' as Code,\n\n  /**\n   * Operation was attempted past the valid range. E.g., seeking or reading\n   * past end of file.\n   *\n   * Unlike INVALID_ARGUMENT, this error indicates a problem that may be fixed\n   * if the system state changes. For example, a 32-bit file system will\n   * generate INVALID_ARGUMENT if asked to read at an offset that is not in the\n   * range [0,2^32-1], but it will generate OUT_OF_RANGE if asked to read from\n   * an offset past the current file size.\n   *\n   * There is a fair bit of overlap between FAILED_PRECONDITION and\n   * OUT_OF_RANGE. We recommend using OUT_OF_RANGE (the more specific error)\n   * when it applies so that callers who are iterating through a space can\n   * easily look for an OUT_OF_RANGE error to detect when they are done.\n   */\n  OUT_OF_RANGE: 'out-of-range' as Code,\n\n  /** Operation is not implemented or not supported/enabled in this service. */\n  UNIMPLEMENTED: 'unimplemented' as Code,\n\n  /**\n   * Internal errors. Means some invariants expected by underlying System has\n   * been broken. If you see one of these errors, Something is very broken.\n   */\n  INTERNAL: 'internal' as Code,\n\n  /**\n   * The service is currently unavailable. This is a most likely a transient\n   * condition and may be corrected by retrying with a backoff.\n   *\n   * See litmus test above for deciding between FAILED_PRECONDITION, ABORTED,\n   * and UNAVAILABLE.\n   */\n  UNAVAILABLE: 'unavailable' as Code,\n\n  /** Unrecoverable data loss or corruption. */\n  DATA_LOSS: 'data-loss' as Code\n};\n\n/**\n * An error class used for Firestore-generated errors. Ideally we should be\n * using FirebaseError, but integrating with it is overly arduous at the moment,\n * so we define our own compatible error class (with a `name` of 'FirebaseError'\n * and compatible `code` and `message` fields.)\n */\nexport class FirestoreError extends Error implements firestore.FirestoreError {\n  name = 'FirebaseError';\n  stack?: string;\n\n  constructor(readonly code: Code, readonly message: string) {\n    super(message);\n\n    // HACK: We write a toString property directly because Error is not a real\n    // class and so inheritance does not work correctly. We could alternatively\n    // do the same \"back-door inheritance\" trick that FirebaseError does.\n    this.toString = () => `${this.name}: [code=${this.code}]: ${this.message}`;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Code, FirestoreError } from '../util/error';\nimport { primitiveComparator } from '../util/misc';\n\n// The earlist date supported by Firestore timestamps (0001-01-01T00:00:00Z).\nconst MIN_SECONDS = -62135596800;\n\nexport class Timestamp {\n  static now(): Timestamp {\n    return Timestamp.fromMillis(Date.now());\n  }\n\n  static fromDate(date: Date): Timestamp {\n    return Timestamp.fromMillis(date.getTime());\n  }\n\n  static fromMillis(milliseconds: number): Timestamp {\n    const seconds = Math.floor(milliseconds / 1000);\n    const nanos = (milliseconds - seconds * 1000) * 1e6;\n    return new Timestamp(seconds, nanos);\n  }\n\n  constructor(readonly seconds: number, readonly nanoseconds: number) {\n    if (nanoseconds < 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Timestamp nanoseconds out of range: ' + nanoseconds\n      );\n    }\n    if (nanoseconds >= 1e9) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Timestamp nanoseconds out of range: ' + nanoseconds\n      );\n    }\n    if (seconds < MIN_SECONDS) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Timestamp seconds out of range: ' + seconds\n      );\n    }\n    // This will break in the year 10,000.\n    if (seconds >= 253402300800) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Timestamp seconds out of range: ' + seconds\n      );\n    }\n  }\n\n  toDate(): Date {\n    return new Date(this.toMillis());\n  }\n\n  toMillis(): number {\n    return this.seconds * 1000 + this.nanoseconds / 1e6;\n  }\n\n  _compareTo(other: Timestamp): number {\n    if (this.seconds === other.seconds) {\n      return primitiveComparator(this.nanoseconds, other.nanoseconds);\n    }\n    return primitiveComparator(this.seconds, other.seconds);\n  }\n\n  isEqual(other: Timestamp): boolean {\n    return (\n      other.seconds === this.seconds && other.nanoseconds === this.nanoseconds\n    );\n  }\n\n  toString(): string {\n    return (\n      'Timestamp(seconds=' +\n      this.seconds +\n      ', nanoseconds=' +\n      this.nanoseconds +\n      ')'\n    );\n  }\n\n  valueOf(): string {\n    // This method returns a string of the form <seconds>.<nanoseconds> where <seconds> is\n    // translated to have a non-negative value and both <seconds> and <nanoseconds> are left-padded\n    // with zeroes to be a consistent length. Strings with this format then have a lexiographical\n    // ordering that matches the expected ordering. The <seconds> translation is done to avoid\n    // having a leading negative sign (i.e. a leading '-' character) in its string representation,\n    // which would affect its lexiographical ordering.\n    const adjustedSeconds = this.seconds - MIN_SECONDS;\n    // Note: Up to 12 decimal digits are required to represent all valid 'seconds' values.\n    const formattedSeconds = String(adjustedSeconds).padStart(12, '0');\n    const formattedNanoseconds = String(this.nanoseconds).padStart(9, '0');\n    return formattedSeconds + '.' + formattedNanoseconds;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Timestamp } from '../api/timestamp';\n\n/**\n * A version of a document in Firestore. This corresponds to the version\n * timestamp, such as update_time or read_time.\n */\nexport class SnapshotVersion {\n  static fromTimestamp(value: Timestamp): SnapshotVersion {\n    return new SnapshotVersion(value);\n  }\n\n  static min(): SnapshotVersion {\n    return new SnapshotVersion(new Timestamp(0, 0));\n  }\n\n  private constructor(private timestamp: Timestamp) {}\n\n  compareTo(other: SnapshotVersion): number {\n    return this.timestamp._compareTo(other.timestamp);\n  }\n\n  isEqual(other: SnapshotVersion): boolean {\n    return this.timestamp.isEqual(other.timestamp);\n  }\n\n  /** Returns a number representation of the version for use in spec tests. */\n  toMicroseconds(): number {\n    // Convert to microseconds.\n    return this.timestamp.seconds * 1e6 + this.timestamp.nanoseconds / 1000;\n  }\n\n  toString(): string {\n    return 'SnapshotVersion(' + this.timestamp.toString() + ')';\n  }\n\n  toTimestamp(): Timestamp {\n    return this.timestamp;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert, fail } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\n\nexport const DOCUMENT_KEY_NAME = '__name__';\n\n/**\n * Path represents an ordered sequence of string segments.\n */\nabstract class BasePath<B extends BasePath<B>> {\n  private segments: string[];\n  private offset: number;\n  private len: number;\n\n  constructor(segments: string[], offset?: number, length?: number) {\n    if (offset === undefined) {\n      offset = 0;\n    } else if (offset > segments.length) {\n      fail('offset ' + offset + ' out of range ' + segments.length);\n    }\n\n    if (length === undefined) {\n      length = segments.length - offset;\n    } else if (length > segments.length - offset) {\n      fail('length ' + length + ' out of range ' + (segments.length - offset));\n    }\n    this.segments = segments;\n    this.offset = offset;\n    this.len = length;\n  }\n\n  /**\n   * Abstract constructor method to construct an instance of B with the given\n   * parameters.\n   */\n  protected abstract construct(\n    segments: string[],\n    offset?: number,\n    length?: number\n  ): B;\n\n  /**\n   * Returns a String representation.\n   *\n   * Implementing classes are required to provide deterministic implementations as\n   * the String representation is used to obtain canonical Query IDs.\n   */\n  abstract toString(): string;\n\n  get length(): number {\n    return this.len;\n  }\n\n  isEqual(other: B): boolean {\n    return BasePath.comparator(this, other) === 0;\n  }\n\n  child(nameOrPath: string | B): B {\n    const segments = this.segments.slice(this.offset, this.limit());\n    if (nameOrPath instanceof BasePath) {\n      nameOrPath.forEach(segment => {\n        segments.push(segment);\n      });\n    } else {\n      segments.push(nameOrPath);\n    }\n    return this.construct(segments);\n  }\n\n  /** The index of one past the last segment of the path. */\n  private limit(): number {\n    return this.offset + this.length;\n  }\n\n  popFirst(size?: number): B {\n    size = size === undefined ? 1 : size;\n    debugAssert(\n      this.length >= size,\n      \"Can't call popFirst() with less segments\"\n    );\n    return this.construct(\n      this.segments,\n      this.offset + size,\n      this.length - size\n    );\n  }\n\n  popLast(): B {\n    debugAssert(!this.isEmpty(), \"Can't call popLast() on empty path\");\n    return this.construct(this.segments, this.offset, this.length - 1);\n  }\n\n  firstSegment(): string {\n    debugAssert(!this.isEmpty(), \"Can't call firstSegment() on empty path\");\n    return this.segments[this.offset];\n  }\n\n  lastSegment(): string {\n    return this.get(this.length - 1);\n  }\n\n  get(index: number): string {\n    debugAssert(index < this.length, 'Index out of range');\n    return this.segments[this.offset + index];\n  }\n\n  isEmpty(): boolean {\n    return this.length === 0;\n  }\n\n  isPrefixOf(other: this): boolean {\n    if (other.length < this.length) {\n      return false;\n    }\n\n    for (let i = 0; i < this.length; i++) {\n      if (this.get(i) !== other.get(i)) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  isImmediateParentOf(potentialChild: this): boolean {\n    if (this.length + 1 !== potentialChild.length) {\n      return false;\n    }\n\n    for (let i = 0; i < this.length; i++) {\n      if (this.get(i) !== potentialChild.get(i)) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  forEach(fn: (segment: string) => void): void {\n    for (let i = this.offset, end = this.limit(); i < end; i++) {\n      fn(this.segments[i]);\n    }\n  }\n\n  toArray(): string[] {\n    return this.segments.slice(this.offset, this.limit());\n  }\n\n  static comparator<T extends BasePath<T>>(\n    p1: BasePath<T>,\n    p2: BasePath<T>\n  ): number {\n    const len = Math.min(p1.length, p2.length);\n    for (let i = 0; i < len; i++) {\n      const left = p1.get(i);\n      const right = p2.get(i);\n      if (left < right) {\n        return -1;\n      }\n      if (left > right) {\n        return 1;\n      }\n    }\n    if (p1.length < p2.length) {\n      return -1;\n    }\n    if (p1.length > p2.length) {\n      return 1;\n    }\n    return 0;\n  }\n}\n\n/**\n * A slash-separated path for navigating resources (documents and collections)\n * within Firestore.\n */\nexport class ResourcePath extends BasePath<ResourcePath> {\n  protected construct(\n    segments: string[],\n    offset?: number,\n    length?: number\n  ): ResourcePath {\n    return new ResourcePath(segments, offset, length);\n  }\n\n  canonicalString(): string {\n    // NOTE: The client is ignorant of any path segments containing escape\n    // sequences (e.g. __id123__) and just passes them through raw (they exist\n    // for legacy reasons and should not be used frequently).\n\n    return this.toArray().join('/');\n  }\n\n  toString(): string {\n    return this.canonicalString();\n  }\n\n  /**\n   * Creates a resource path from the given slash-delimited string.\n   */\n  static fromString(path: string): ResourcePath {\n    // NOTE: The client is ignorant of any path segments containing escape\n    // sequences (e.g. __id123__) and just passes them through raw (they exist\n    // for legacy reasons and should not be used frequently).\n\n    if (path.indexOf('//') >= 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid path (${path}). Paths must not contain // in them.`\n      );\n    }\n\n    // We may still have an empty segment at the beginning or end if they had a\n    // leading or trailing slash (which we allow).\n    const segments = path.split('/').filter(segment => segment.length > 0);\n\n    return new ResourcePath(segments);\n  }\n\n  static emptyPath(): ResourcePath {\n    return new ResourcePath([]);\n  }\n}\n\nconst identifierRegExp = /^[_a-zA-Z][_a-zA-Z0-9]*$/;\n\n/** A dot-separated path for navigating sub-objects within a document. */\nexport class FieldPath extends BasePath<FieldPath> {\n  protected construct(\n    segments: string[],\n    offset?: number,\n    length?: number\n  ): FieldPath {\n    return new FieldPath(segments, offset, length);\n  }\n\n  /**\n   * Returns true if the string could be used as a segment in a field path\n   * without escaping.\n   */\n  private static isValidIdentifier(segment: string): boolean {\n    return identifierRegExp.test(segment);\n  }\n\n  canonicalString(): string {\n    return this.toArray()\n      .map(str => {\n        str = str.replace('\\\\', '\\\\\\\\').replace('`', '\\\\`');\n        if (!FieldPath.isValidIdentifier(str)) {\n          str = '`' + str + '`';\n        }\n        return str;\n      })\n      .join('.');\n  }\n\n  toString(): string {\n    return this.canonicalString();\n  }\n\n  /**\n   * Returns true if this field references the key of a document.\n   */\n  isKeyField(): boolean {\n    return this.length === 1 && this.get(0) === DOCUMENT_KEY_NAME;\n  }\n\n  /**\n   * The field designating the key of a document.\n   */\n  static keyField(): FieldPath {\n    return new FieldPath([DOCUMENT_KEY_NAME]);\n  }\n\n  /**\n   * Parses a field string from the given server-formatted string.\n   *\n   * - Splitting the empty string is not allowed (for now at least).\n   * - Empty segments within the string (e.g. if there are two consecutive\n   *   separators) are not allowed.\n   *\n   * TODO(b/37244157): we should make this more strict. Right now, it allows\n   * non-identifier path components, even if they aren't escaped.\n   */\n  static fromServerFormat(path: string): FieldPath {\n    const segments: string[] = [];\n    let current = '';\n    let i = 0;\n\n    const addCurrentSegment = (): void => {\n      if (current.length === 0) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `Invalid field path (${path}). Paths must not be empty, begin ` +\n            `with '.', end with '.', or contain '..'`\n        );\n      }\n      segments.push(current);\n      current = '';\n    };\n\n    let inBackticks = false;\n\n    while (i < path.length) {\n      const c = path[i];\n      if (c === '\\\\') {\n        if (i + 1 === path.length) {\n          throw new FirestoreError(\n            Code.INVALID_ARGUMENT,\n            'Path has trailing escape character: ' + path\n          );\n        }\n        const next = path[i + 1];\n        if (!(next === '\\\\' || next === '.' || next === '`')) {\n          throw new FirestoreError(\n            Code.INVALID_ARGUMENT,\n            'Path has invalid escape sequence: ' + path\n          );\n        }\n        current += next;\n        i += 2;\n      } else if (c === '`') {\n        inBackticks = !inBackticks;\n        i++;\n      } else if (c === '.' && !inBackticks) {\n        addCurrentSegment();\n        i++;\n      } else {\n        current += c;\n        i++;\n      }\n    }\n    addCurrentSegment();\n\n    if (inBackticks) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Unterminated ` in path: ' + path\n      );\n    }\n\n    return new FieldPath(segments);\n  }\n\n  static emptyPath(): FieldPath {\n    return new FieldPath([]);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert } from '../util/assert';\n\nimport { ResourcePath } from './path';\n\nexport class DocumentKey {\n  constructor(readonly path: ResourcePath) {\n    debugAssert(\n      DocumentKey.isDocumentKey(path),\n      'Invalid DocumentKey with an odd number of segments: ' +\n        path.toArray().join('/')\n    );\n  }\n\n  static fromName(name: string): DocumentKey {\n    return new DocumentKey(ResourcePath.fromString(name).popFirst(5));\n  }\n\n  /** Returns true if the document is in the specified collectionId. */\n  hasCollectionId(collectionId: string): boolean {\n    return (\n      this.path.length >= 2 &&\n      this.path.get(this.path.length - 2) === collectionId\n    );\n  }\n\n  isEqual(other: DocumentKey | null): boolean {\n    return (\n      other !== null && ResourcePath.comparator(this.path, other.path) === 0\n    );\n  }\n\n  toString(): string {\n    return this.path.toString();\n  }\n\n  static comparator(k1: DocumentKey, k2: DocumentKey): number {\n    return ResourcePath.comparator(k1.path, k2.path);\n  }\n\n  static isDocumentKey(path: ResourcePath): boolean {\n    return path.length % 2 === 0;\n  }\n\n  /**\n   * Creates and returns a new document key with the given segments.\n   *\n   * @param segments The segments of the path to the document\n   * @return A new instance of DocumentKey\n   */\n  static fromSegments(segments: string[]): DocumentKey {\n    return new DocumentKey(new ResourcePath(segments.slice()));\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// An Object whose keys and values are strings.\nexport interface StringMap {\n  [key: string]: string;\n}\n\n/**\n * Returns whether a variable is either undefined or null.\n */\nexport function isNullOrUndefined(value: unknown): value is null | undefined {\n  return value === null || value === undefined;\n}\n\n/** Returns whether the value represents -0. */\nexport function isNegativeZero(value: number): boolean {\n  // Detect if the value is -0.0. Based on polyfill from\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is\n  return value === -0 && 1 / value === 1 / -0;\n}\n\n/**\n * Returns whether a value is an integer and in the safe integer range\n * @param value The value to test for being an integer and in the safe range\n */\nexport function isSafeInteger(value: unknown): boolean {\n  return (\n    typeof value === 'number' &&\n    Number.isInteger(value) &&\n    !isNegativeZero(value) &&\n    value <= Number.MAX_SAFE_INTEGER &&\n    value >= Number.MIN_SAFE_INTEGER\n  );\n}\n\n/** The subset of the browser's Window interface used by the SDK. */\nexport interface WindowLike {\n  readonly localStorage: Storage;\n  readonly indexedDB: IDBFactory | null;\n  addEventListener(type: string, listener: EventListener): void;\n  removeEventListener(type: string, listener: EventListener): void;\n}\n\n/** The subset of the browser's Document interface used by the SDK. */\nexport interface DocumentLike {\n  readonly visibilityState: VisibilityState;\n  addEventListener(type: string, listener: EventListener): void;\n  removeEventListener(type: string, listener: EventListener): void;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DocumentKey } from '../model/document_key';\nimport { ResourcePath } from '../model/path';\nimport { isNullOrUndefined } from '../util/types';\nimport {\n  Bound,\n  boundEquals,\n  canonifyBound,\n  canonifyFilter,\n  filterEquals,\n  stringifyFilter,\n  OrderBy,\n  orderByEquals,\n  stringifyOrderBy,\n  canonifyOrderBy,\n  Filter\n} from './query';\nimport { debugCast } from '../util/assert';\n\n/**\n * A Target represents the WatchTarget representation of a Query, which is used\n * by the LocalStore and the RemoteStore to keep track of and to execute\n * backend queries. While a Query can represent multiple Targets, each Targets\n * maps to a single WatchTarget in RemoteStore and a single TargetData entry\n * in persistence.\n */\nexport interface Target {\n  readonly path: ResourcePath;\n  readonly collectionGroup: string | null;\n  readonly orderBy: OrderBy[];\n  readonly filters: Filter[];\n  readonly limit: number | null;\n  readonly startAt: Bound | null;\n  readonly endAt: Bound | null;\n}\n\n// Visible for testing\nexport class TargetImpl implements Target {\n  memoizedCanonicalId: string | null = null;\n  constructor(\n    readonly path: ResourcePath,\n    readonly collectionGroup: string | null = null,\n    readonly orderBy: OrderBy[] = [],\n    readonly filters: Filter[] = [],\n    readonly limit: number | null = null,\n    readonly startAt: Bound | null = null,\n    readonly endAt: Bound | null = null\n  ) {}\n}\n\n/**\n * Initializes a Target with a path and optional additional query constraints.\n * Path must currently be empty if this is a collection group query.\n *\n * NOTE: you should always construct `Target` from `Query.toTarget` instead of\n * using this factory method, because `Query` provides an implicit `orderBy`\n * property.\n */\nexport function newTarget(\n  path: ResourcePath,\n  collectionGroup: string | null = null,\n  orderBy: OrderBy[] = [],\n  filters: Filter[] = [],\n  limit: number | null = null,\n  startAt: Bound | null = null,\n  endAt: Bound | null = null\n): Target {\n  return new TargetImpl(\n    path,\n    collectionGroup,\n    orderBy,\n    filters,\n    limit,\n    startAt,\n    endAt\n  );\n}\n\nexport function canonifyTarget(target: Target): string {\n  const targetImpl = debugCast(target, TargetImpl);\n\n  if (targetImpl.memoizedCanonicalId === null) {\n    let canonicalId = targetImpl.path.canonicalString();\n    if (targetImpl.collectionGroup !== null) {\n      canonicalId += '|cg:' + targetImpl.collectionGroup;\n    }\n    canonicalId += '|f:';\n    canonicalId += targetImpl.filters.map(f => canonifyFilter(f)).join(',');\n    canonicalId += '|ob:';\n    canonicalId += targetImpl.orderBy.map(o => canonifyOrderBy(o)).join(',');\n\n    if (!isNullOrUndefined(targetImpl.limit)) {\n      canonicalId += '|l:';\n      canonicalId += targetImpl.limit!;\n    }\n    if (targetImpl.startAt) {\n      canonicalId += '|lb:';\n      canonicalId += canonifyBound(targetImpl.startAt);\n    }\n    if (targetImpl.endAt) {\n      canonicalId += '|ub:';\n      canonicalId += canonifyBound(targetImpl.endAt);\n    }\n    targetImpl.memoizedCanonicalId = canonicalId;\n  }\n  return targetImpl.memoizedCanonicalId;\n}\n\nexport function stringifyTarget(target: Target): string {\n  let str = target.path.canonicalString();\n  if (target.collectionGroup !== null) {\n    str += ' collectionGroup=' + target.collectionGroup;\n  }\n  if (target.filters.length > 0) {\n    str += `, filters: [${target.filters\n      .map(f => stringifyFilter(f))\n      .join(', ')}]`;\n  }\n  if (!isNullOrUndefined(target.limit)) {\n    str += ', limit: ' + target.limit;\n  }\n  if (target.orderBy.length > 0) {\n    str += `, orderBy: [${target.orderBy\n      .map(o => stringifyOrderBy(o))\n      .join(', ')}]`;\n  }\n  if (target.startAt) {\n    str += ', startAt: ' + canonifyBound(target.startAt);\n  }\n  if (target.endAt) {\n    str += ', endAt: ' + canonifyBound(target.endAt);\n  }\n  return `Target(${str})`;\n}\n\nexport function targetEquals(left: Target, right: Target): boolean {\n  if (left.limit !== right.limit) {\n    return false;\n  }\n\n  if (left.orderBy.length !== right.orderBy.length) {\n    return false;\n  }\n\n  for (let i = 0; i < left.orderBy.length; i++) {\n    if (!orderByEquals(left.orderBy[i], right.orderBy[i])) {\n      return false;\n    }\n  }\n\n  if (left.filters.length !== right.filters.length) {\n    return false;\n  }\n\n  for (let i = 0; i < left.filters.length; i++) {\n    if (!filterEquals(left.filters[i], right.filters[i])) {\n      return false;\n    }\n  }\n\n  if (left.collectionGroup !== right.collectionGroup) {\n    return false;\n  }\n\n  if (!left.path.isEqual(right.path)) {\n    return false;\n  }\n\n  if (!boundEquals(left.startAt, right.startAt)) {\n    return false;\n  }\n\n  return boundEquals(left.endAt, right.endAt);\n}\n\nexport function isDocumentTarget(target: Target): boolean {\n  return (\n    DocumentKey.isDocumentKey(target.path) &&\n    target.collectionGroup === null &&\n    target.filters.length === 0\n  );\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { compareDocumentsByField, Document } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport {\n  arrayValueContains,\n  canonicalId,\n  isArray,\n  isNanValue,\n  isNullValue,\n  isReferenceValue,\n  typeOrder,\n  valueCompare,\n  valueEquals\n} from '../model/values';\nimport { FieldPath, ResourcePath } from '../model/path';\nimport { debugAssert, fail } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { isNullOrUndefined } from '../util/types';\nimport {\n  canonifyTarget,\n  newTarget,\n  stringifyTarget,\n  Target,\n  targetEquals\n} from './target';\nimport { cast } from '../../lite/src/api/util';\n\nexport const enum LimitType {\n  First = 'F',\n  Last = 'L'\n}\n\n/**\n * The Query interface defines all external properties of a query.\n *\n * QueryImpl implements this interface to provide memoization for `queryOrderBy`\n * and `queryToTarget`.\n */\nexport interface Query {\n  readonly path: ResourcePath;\n  readonly collectionGroup: string | null;\n  readonly explicitOrderBy: OrderBy[];\n  readonly filters: Filter[];\n  readonly limit: number | null;\n  readonly limitType: LimitType;\n  readonly startAt: Bound | null;\n  readonly endAt: Bound | null;\n\n  hasLimitToFirst(): boolean;\n  hasLimitToLast(): boolean;\n  getFirstOrderByField(): FieldPath | null;\n  getInequalityFilterField(): FieldPath | null;\n  asCollectionQueryAtPath(path: ResourcePath): Query;\n\n  /**\n   * Returns true if this query does not specify any query constraints that\n   * could remove results.\n   */\n  matchesAllDocuments(): boolean;\n\n  // Checks if any of the provided Operators are included in the query and\n  // returns the first one that is, or null if none are.\n  findFilterOperator(operators: Operator[]): Operator | null;\n}\n\n/**\n * Query encapsulates all the query attributes we support in the SDK. It can\n * be run against the LocalStore, as well as be converted to a `Target` to\n * query the RemoteStore results.\n *\n * Visible for testing.\n */\nexport class QueryImpl implements Query {\n  memoizedOrderBy: OrderBy[] | null = null;\n\n  // The corresponding `Target` of this `Query` instance.\n  memoizedTarget: Target | null = null;\n\n  /**\n   * Initializes a Query with a path and optional additional query constraints.\n   * Path must currently be empty if this is a collection group query.\n   */\n  constructor(\n    readonly path: ResourcePath,\n    readonly collectionGroup: string | null = null,\n    readonly explicitOrderBy: OrderBy[] = [],\n    readonly filters: Filter[] = [],\n    readonly limit: number | null = null,\n    readonly limitType: LimitType = LimitType.First,\n    readonly startAt: Bound | null = null,\n    readonly endAt: Bound | null = null\n  ) {\n    if (this.startAt) {\n      debugAssert(\n        this.startAt.position.length <= queryOrderBy(this).length,\n        'Bound is longer than orderBy'\n      );\n    }\n    if (this.endAt) {\n      debugAssert(\n        this.endAt.position.length <= queryOrderBy(this).length,\n        'Bound is longer than orderBy'\n      );\n    }\n  }\n\n  /**\n   * Helper to convert a collection group query into a collection query at a\n   * specific path. This is used when executing collection group queries, since\n   * we have to split the query into a set of collection queries at multiple\n   * paths.\n   */\n  asCollectionQueryAtPath(path: ResourcePath): Query {\n    return new QueryImpl(\n      path,\n      /*collectionGroup=*/ null,\n      this.explicitOrderBy.slice(),\n      this.filters.slice(),\n      this.limit,\n      this.limitType,\n      this.startAt,\n      this.endAt\n    );\n  }\n\n  matchesAllDocuments(): boolean {\n    return (\n      this.filters.length === 0 &&\n      this.limit === null &&\n      this.startAt == null &&\n      this.endAt == null &&\n      (this.explicitOrderBy.length === 0 ||\n        (this.explicitOrderBy.length === 1 &&\n          this.explicitOrderBy[0].field.isKeyField()))\n    );\n  }\n\n  hasLimitToFirst(): boolean {\n    return !isNullOrUndefined(this.limit) && this.limitType === LimitType.First;\n  }\n\n  hasLimitToLast(): boolean {\n    return !isNullOrUndefined(this.limit) && this.limitType === LimitType.Last;\n  }\n\n  getFirstOrderByField(): FieldPath | null {\n    return this.explicitOrderBy.length > 0\n      ? this.explicitOrderBy[0].field\n      : null;\n  }\n\n  getInequalityFilterField(): FieldPath | null {\n    for (const filter of this.filters) {\n      debugAssert(\n        filter instanceof FieldFilter,\n        'Only FieldFilters are supported'\n      );\n      if (filter.isInequality()) {\n        return filter.field;\n      }\n    }\n    return null;\n  }\n\n  findFilterOperator(operators: Operator[]): Operator | null {\n    for (const filter of this.filters) {\n      debugAssert(\n        filter instanceof FieldFilter,\n        'Only FieldFilters are supported'\n      );\n      if (operators.indexOf(filter.op) >= 0) {\n        return filter.op;\n      }\n    }\n    return null;\n  }\n}\n\n/** Creates a new Query instance with the options provided. */\nexport function newQuery(\n  path: ResourcePath,\n  collectionGroup: string | null,\n  explicitOrderBy: OrderBy[],\n  filters: Filter[],\n  limit: number | null,\n  limitType: LimitType,\n  startAt: Bound | null,\n  endAt: Bound | null\n): Query {\n  return new QueryImpl(\n    path,\n    collectionGroup,\n    explicitOrderBy,\n    filters,\n    limit,\n    limitType,\n    startAt,\n    endAt\n  );\n}\n\n/** Creates a new Query for a query that matches all documents at `path` */\nexport function newQueryForPath(path: ResourcePath): Query {\n  return new QueryImpl(path);\n}\n\n/**\n * Creates a new Query for a collection group query that matches all documents\n * within the provided collection group.\n */\nexport function newQueryForCollectionGroup(collectionId: string): Query {\n  return new QueryImpl(ResourcePath.emptyPath(), collectionId);\n}\n\n/**\n * Returns whether the query matches a single document by path (rather than a\n * collection).\n */\nexport function isDocumentQuery(query: Query): boolean {\n  return (\n    DocumentKey.isDocumentKey(query.path) &&\n    query.collectionGroup === null &&\n    query.filters.length === 0\n  );\n}\n\n/**\n * Returns whether the query matches a collection group rather than a specific\n * collection.\n */\nexport function isCollectionGroupQuery(query: Query): boolean {\n  return query.collectionGroup !== null;\n}\n\n/**\n * Returns the implicit order by constraint that is used to execute the Query,\n * which can be different from the order by constraints the user provided (e.g.\n * the SDK and backend always orders by `__name__`).\n */\nexport function queryOrderBy(query: Query): OrderBy[] {\n  const queryImpl = cast(query, QueryImpl);\n  if (queryImpl.memoizedOrderBy === null) {\n    queryImpl.memoizedOrderBy = [];\n\n    const inequalityField = queryImpl.getInequalityFilterField();\n    const firstOrderByField = queryImpl.getFirstOrderByField();\n    if (inequalityField !== null && firstOrderByField === null) {\n      // In order to implicitly add key ordering, we must also add the\n      // inequality filter field for it to be a valid query.\n      // Note that the default inequality field and key ordering is ascending.\n      if (!inequalityField.isKeyField()) {\n        queryImpl.memoizedOrderBy.push(new OrderBy(inequalityField));\n      }\n      queryImpl.memoizedOrderBy.push(\n        new OrderBy(FieldPath.keyField(), Direction.ASCENDING)\n      );\n    } else {\n      debugAssert(\n        inequalityField === null ||\n          (firstOrderByField !== null &&\n            inequalityField.isEqual(firstOrderByField)),\n        'First orderBy should match inequality field.'\n      );\n      let foundKeyOrdering = false;\n      for (const orderBy of queryImpl.explicitOrderBy) {\n        queryImpl.memoizedOrderBy.push(orderBy);\n        if (orderBy.field.isKeyField()) {\n          foundKeyOrdering = true;\n        }\n      }\n      if (!foundKeyOrdering) {\n        // The order of the implicit key ordering always matches the last\n        // explicit order by\n        const lastDirection =\n          queryImpl.explicitOrderBy.length > 0\n            ? queryImpl.explicitOrderBy[queryImpl.explicitOrderBy.length - 1]\n                .dir\n            : Direction.ASCENDING;\n        queryImpl.memoizedOrderBy.push(\n          new OrderBy(FieldPath.keyField(), lastDirection)\n        );\n      }\n    }\n  }\n  return queryImpl.memoizedOrderBy;\n}\n\n/**\n * Converts this `Query` instance to it's corresponding `Target` representation.\n */\nexport function queryToTarget(query: Query): Target {\n  const queryImpl = cast(query, QueryImpl);\n  if (!queryImpl.memoizedTarget) {\n    if (queryImpl.limitType === LimitType.First) {\n      queryImpl.memoizedTarget = newTarget(\n        queryImpl.path,\n        queryImpl.collectionGroup,\n        queryOrderBy(queryImpl),\n        queryImpl.filters,\n        queryImpl.limit,\n        queryImpl.startAt,\n        queryImpl.endAt\n      );\n    } else {\n      // Flip the orderBy directions since we want the last results\n      const orderBys = [] as OrderBy[];\n      for (const orderBy of queryOrderBy(queryImpl)) {\n        const dir =\n          orderBy.dir === Direction.DESCENDING\n            ? Direction.ASCENDING\n            : Direction.DESCENDING;\n        orderBys.push(new OrderBy(orderBy.field, dir));\n      }\n\n      // We need to swap the cursors to match the now-flipped query ordering.\n      const startAt = queryImpl.endAt\n        ? new Bound(queryImpl.endAt.position, !queryImpl.endAt.before)\n        : null;\n      const endAt = queryImpl.startAt\n        ? new Bound(queryImpl.startAt.position, !queryImpl.startAt.before)\n        : null;\n\n      // Now return as a LimitType.First query.\n      queryImpl.memoizedTarget = newTarget(\n        queryImpl.path,\n        queryImpl.collectionGroup,\n        orderBys,\n        queryImpl.filters,\n        queryImpl.limit,\n        startAt,\n        endAt\n      );\n    }\n  }\n  return queryImpl.memoizedTarget!;\n}\n\nexport function queryWithAddedFilter(query: Query, filter: Filter): Query {\n  debugAssert(\n    query.getInequalityFilterField() == null ||\n      !(filter instanceof FieldFilter) ||\n      !filter.isInequality() ||\n      filter.field.isEqual(query.getInequalityFilterField()!),\n    'Query must only have one inequality field.'\n  );\n\n  debugAssert(\n    !isDocumentQuery(query),\n    'No filtering allowed for document query'\n  );\n\n  const newFilters = query.filters.concat([filter]);\n  return new QueryImpl(\n    query.path,\n    query.collectionGroup,\n    query.explicitOrderBy.slice(),\n    newFilters,\n    query.limit,\n    query.limitType,\n    query.startAt,\n    query.endAt\n  );\n}\n\nexport function queryWithAddedOrderBy(query: Query, orderBy: OrderBy): Query {\n  debugAssert(\n    !query.startAt && !query.endAt,\n    'Bounds must be set after orderBy'\n  );\n  // TODO(dimond): validate that orderBy does not list the same key twice.\n  const newOrderBy = query.explicitOrderBy.concat([orderBy]);\n  return new QueryImpl(\n    query.path,\n    query.collectionGroup,\n    newOrderBy,\n    query.filters.slice(),\n    query.limit,\n    query.limitType,\n    query.startAt,\n    query.endAt\n  );\n}\n\nexport function queryWithLimit(\n  query: Query,\n  limit: number,\n  limitType: LimitType\n): Query {\n  return new QueryImpl(\n    query.path,\n    query.collectionGroup,\n    query.explicitOrderBy.slice(),\n    query.filters.slice(),\n    limit,\n    limitType,\n    query.startAt,\n    query.endAt\n  );\n}\n\nexport function queryWithStartAt(query: Query, bound: Bound): Query {\n  return new QueryImpl(\n    query.path,\n    query.collectionGroup,\n    query.explicitOrderBy.slice(),\n    query.filters.slice(),\n    query.limit,\n    query.limitType,\n    bound,\n    query.endAt\n  );\n}\n\nexport function queryWithEndAt(query: Query, bound: Bound): Query {\n  return new QueryImpl(\n    query.path,\n    query.collectionGroup,\n    query.explicitOrderBy.slice(),\n    query.filters.slice(),\n    query.limit,\n    query.limitType,\n    query.startAt,\n    bound\n  );\n}\n\nexport function queryEquals(left: Query, right: Query): boolean {\n  return (\n    targetEquals(queryToTarget(left), queryToTarget(right)) &&\n    left.limitType === right.limitType\n  );\n}\n\n// TODO(b/29183165): This is used to get a unique string from a query to, for\n// example, use as a dictionary key, but the implementation is subject to\n// collisions. Make it collision-free.\nexport function canonifyQuery(query: Query): string {\n  return `${canonifyTarget(queryToTarget(query))}|lt:${query.limitType}`;\n}\n\nexport function stringifyQuery(query: Query): string {\n  return `Query(target=${stringifyTarget(queryToTarget(query))}; limitType=${\n    query.limitType\n  })`;\n}\n\n/** Returns whether `doc` matches the constraints of `query`. */\nexport function queryMatches(query: Query, doc: Document): boolean {\n  return (\n    queryMatchesPathAndCollectionGroup(query, doc) &&\n    queryMatchesOrderBy(query, doc) &&\n    queryMatchesFilters(query, doc) &&\n    queryMatchesBounds(query, doc)\n  );\n}\n\nfunction queryMatchesPathAndCollectionGroup(\n  query: Query,\n  doc: Document\n): boolean {\n  const docPath = doc.key.path;\n  if (query.collectionGroup !== null) {\n    // NOTE: this.path is currently always empty since we don't expose Collection\n    // Group queries rooted at a document path yet.\n    return (\n      doc.key.hasCollectionId(query.collectionGroup) &&\n      query.path.isPrefixOf(docPath)\n    );\n  } else if (DocumentKey.isDocumentKey(query.path)) {\n    // exact match for document queries\n    return query.path.isEqual(docPath);\n  } else {\n    // shallow ancestor queries by default\n    return query.path.isImmediateParentOf(docPath);\n  }\n}\n\n/**\n * A document must have a value for every ordering clause in order to show up\n * in the results.\n */\nfunction queryMatchesOrderBy(query: Query, doc: Document): boolean {\n  for (const orderBy of query.explicitOrderBy) {\n    // order by key always matches\n    if (!orderBy.field.isKeyField() && doc.field(orderBy.field) === null) {\n      return false;\n    }\n  }\n  return true;\n}\n\nfunction queryMatchesFilters(query: Query, doc: Document): boolean {\n  for (const filter of query.filters) {\n    if (!filter.matches(doc)) {\n      return false;\n    }\n  }\n  return true;\n}\n\n/** Makes sure a document is within the bounds, if provided. */\nfunction queryMatchesBounds(query: Query, doc: Document): boolean {\n  if (\n    query.startAt &&\n    !sortsBeforeDocument(query.startAt, queryOrderBy(query), doc)\n  ) {\n    return false;\n  }\n  if (\n    query.endAt &&\n    sortsBeforeDocument(query.endAt, queryOrderBy(query), doc)\n  ) {\n    return false;\n  }\n  return true;\n}\n\n/**\n * Returns a new comparator function that can be used to compare two documents\n * based on the Query's ordering constraint.\n */\nexport function newQueryComparator(\n  query: Query\n): (d1: Document, d2: Document) => number {\n  return (d1: Document, d2: Document): number => {\n    let comparedOnKeyField = false;\n    for (const orderBy of queryOrderBy(query)) {\n      const comp = compareDocs(orderBy, d1, d2);\n      if (comp !== 0) {\n        return comp;\n      }\n      comparedOnKeyField = comparedOnKeyField || orderBy.field.isKeyField();\n    }\n    // Assert that we actually compared by key\n    debugAssert(\n      comparedOnKeyField,\n      \"orderBy used that doesn't compare on key field\"\n    );\n    return 0;\n  };\n}\n\nexport abstract class Filter {\n  abstract matches(doc: Document): boolean;\n}\n\nexport const enum Operator {\n  LESS_THAN = '<',\n  LESS_THAN_OR_EQUAL = '<=',\n  EQUAL = '==',\n  NOT_EQUAL = '!=',\n  GREATER_THAN = '>',\n  GREATER_THAN_OR_EQUAL = '>=',\n  ARRAY_CONTAINS = 'array-contains',\n  IN = 'in',\n  NOT_IN = 'not-in',\n  ARRAY_CONTAINS_ANY = 'array-contains-any'\n}\n\nexport class FieldFilter extends Filter {\n  protected constructor(\n    public field: FieldPath,\n    public op: Operator,\n    public value: api.Value\n  ) {\n    super();\n  }\n\n  /**\n   * Creates a filter based on the provided arguments.\n   */\n  static create(field: FieldPath, op: Operator, value: api.Value): FieldFilter {\n    if (field.isKeyField()) {\n      if (op === Operator.IN || op === Operator.NOT_IN) {\n        return this.createKeyFieldInFilter(field, op, value);\n      } else {\n        debugAssert(\n          isReferenceValue(value),\n          'Comparing on key, but filter value not a RefValue'\n        );\n        debugAssert(\n          op !== Operator.ARRAY_CONTAINS && op !== Operator.ARRAY_CONTAINS_ANY,\n          `'${op.toString()}' queries don't make sense on document keys.`\n        );\n        return new KeyFieldFilter(field, op, value);\n      }\n    } else if (isNullValue(value)) {\n      if (op !== Operator.EQUAL && op !== Operator.NOT_EQUAL) {\n        // TODO(ne-queries): Update error message to include != comparison.\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          'Invalid query. Null supports only equality comparisons.'\n        );\n      }\n      return new FieldFilter(field, op, value);\n    } else if (isNanValue(value)) {\n      if (op !== Operator.EQUAL && op !== Operator.NOT_EQUAL) {\n        // TODO(ne-queries): Update error message to include != comparison.\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          'Invalid query. NaN supports only equality comparisons.'\n        );\n      }\n      return new FieldFilter(field, op, value);\n    } else if (op === Operator.ARRAY_CONTAINS) {\n      return new ArrayContainsFilter(field, value);\n    } else if (op === Operator.IN) {\n      debugAssert(\n        isArray(value),\n        'IN filter has invalid value: ' + value.toString()\n      );\n      return new InFilter(field, value);\n    } else if (op === Operator.NOT_IN) {\n      debugAssert(\n        isArray(value),\n        'NOT_IN filter has invalid value: ' + value.toString()\n      );\n      return new NotInFilter(field, value);\n    } else if (op === Operator.ARRAY_CONTAINS_ANY) {\n      debugAssert(\n        isArray(value),\n        'ARRAY_CONTAINS_ANY filter has invalid value: ' + value.toString()\n      );\n      return new ArrayContainsAnyFilter(field, value);\n    } else {\n      return new FieldFilter(field, op, value);\n    }\n  }\n\n  private static createKeyFieldInFilter(\n    field: FieldPath,\n    op: Operator.IN | Operator.NOT_IN,\n    value: api.Value\n  ): FieldFilter {\n    debugAssert(\n      isArray(value),\n      `Comparing on key with ${op.toString()}` +\n        ', but filter value not an ArrayValue'\n    );\n    debugAssert(\n      (value.arrayValue.values || []).every(elem => isReferenceValue(elem)),\n      `Comparing on key with ${op.toString()}` +\n        ', but an array value was not a RefValue'\n    );\n\n    return op === Operator.IN\n      ? new KeyFieldInFilter(field, value)\n      : new KeyFieldNotInFilter(field, value);\n  }\n\n  matches(doc: Document): boolean {\n    const other = doc.field(this.field);\n    // Types do not have to match in NOT_EQUAL filters.\n    if (this.op === Operator.NOT_EQUAL) {\n      return (\n        other !== null &&\n        this.matchesComparison(valueCompare(other!, this.value))\n      );\n    }\n\n    // Only compare types with matching backend order (such as double and int).\n    return (\n      other !== null &&\n      typeOrder(this.value) === typeOrder(other) &&\n      this.matchesComparison(valueCompare(other, this.value))\n    );\n  }\n\n  protected matchesComparison(comparison: number): boolean {\n    switch (this.op) {\n      case Operator.LESS_THAN:\n        return comparison < 0;\n      case Operator.LESS_THAN_OR_EQUAL:\n        return comparison <= 0;\n      case Operator.EQUAL:\n        return comparison === 0;\n      case Operator.NOT_EQUAL:\n        return comparison !== 0;\n      case Operator.GREATER_THAN:\n        return comparison > 0;\n      case Operator.GREATER_THAN_OR_EQUAL:\n        return comparison >= 0;\n      default:\n        return fail('Unknown FieldFilter operator: ' + this.op);\n    }\n  }\n\n  isInequality(): boolean {\n    return (\n      [\n        Operator.LESS_THAN,\n        Operator.LESS_THAN_OR_EQUAL,\n        Operator.GREATER_THAN,\n        Operator.GREATER_THAN_OR_EQUAL,\n        Operator.NOT_EQUAL\n      ].indexOf(this.op) >= 0\n    );\n  }\n}\n\nexport function canonifyFilter(filter: Filter): string {\n  debugAssert(\n    filter instanceof FieldFilter,\n    'canonifyFilter() only supports FieldFilters'\n  );\n  // TODO(b/29183165): Technically, this won't be unique if two values have\n  // the same description, such as the int 3 and the string \"3\". So we should\n  // add the types in here somehow, too.\n  return (\n    filter.field.canonicalString() +\n    filter.op.toString() +\n    canonicalId(filter.value)\n  );\n}\n\nexport function filterEquals(f1: Filter, f2: Filter): boolean {\n  debugAssert(\n    f1 instanceof FieldFilter && f2 instanceof FieldFilter,\n    'Only FieldFilters can be compared'\n  );\n\n  return (\n    f1.op === f2.op &&\n    f1.field.isEqual(f2.field) &&\n    valueEquals(f1.value, f2.value)\n  );\n}\n\n/** Returns a debug description for `filter`. */\nexport function stringifyFilter(filter: Filter): string {\n  debugAssert(\n    filter instanceof FieldFilter,\n    'stringifyFilter() only supports FieldFilters'\n  );\n  return `${filter.field.canonicalString()} ${filter.op} ${canonicalId(\n    filter.value\n  )}`;\n}\n\n/** Filter that matches on key fields (i.e. '__name__'). */\nexport class KeyFieldFilter extends FieldFilter {\n  private readonly key: DocumentKey;\n\n  constructor(field: FieldPath, op: Operator, value: api.Value) {\n    super(field, op, value);\n    debugAssert(\n      isReferenceValue(value),\n      'KeyFieldFilter expects a ReferenceValue'\n    );\n    this.key = DocumentKey.fromName(value.referenceValue);\n  }\n\n  matches(doc: Document): boolean {\n    const comparison = DocumentKey.comparator(doc.key, this.key);\n    return this.matchesComparison(comparison);\n  }\n}\n\n/** Filter that matches on key fields within an array. */\nexport class KeyFieldInFilter extends FieldFilter {\n  private readonly keys: DocumentKey[];\n\n  constructor(field: FieldPath, value: api.Value) {\n    super(field, Operator.IN, value);\n    this.keys = extractDocumentKeysFromArrayValue(Operator.IN, value);\n  }\n\n  matches(doc: Document): boolean {\n    return this.keys.some(key => key.isEqual(doc.key));\n  }\n}\n\n/** Filter that matches on key fields not present within an array. */\nexport class KeyFieldNotInFilter extends FieldFilter {\n  private readonly keys: DocumentKey[];\n\n  constructor(field: FieldPath, value: api.Value) {\n    super(field, Operator.NOT_IN, value);\n    this.keys = extractDocumentKeysFromArrayValue(Operator.NOT_IN, value);\n  }\n\n  matches(doc: Document): boolean {\n    return !this.keys.some(key => key.isEqual(doc.key));\n  }\n}\n\nfunction extractDocumentKeysFromArrayValue(\n  op: Operator.IN | Operator.NOT_IN,\n  value: api.Value\n): DocumentKey[] {\n  debugAssert(\n    isArray(value),\n    'KeyFieldInFilter/KeyFieldNotInFilter expects an ArrayValue'\n  );\n  return (value.arrayValue?.values || []).map(v => {\n    debugAssert(\n      isReferenceValue(v),\n      `Comparing on key with ${op.toString()}, but an array value was not ` +\n        `a ReferenceValue`\n    );\n    return DocumentKey.fromName(v.referenceValue);\n  });\n}\n\n/** A Filter that implements the array-contains operator. */\nexport class ArrayContainsFilter extends FieldFilter {\n  constructor(field: FieldPath, value: api.Value) {\n    super(field, Operator.ARRAY_CONTAINS, value);\n  }\n\n  matches(doc: Document): boolean {\n    const other = doc.field(this.field);\n    return isArray(other) && arrayValueContains(other.arrayValue, this.value);\n  }\n}\n\n/** A Filter that implements the IN operator. */\nexport class InFilter extends FieldFilter {\n  constructor(field: FieldPath, value: api.Value) {\n    super(field, Operator.IN, value);\n    debugAssert(isArray(value), 'InFilter expects an ArrayValue');\n  }\n\n  matches(doc: Document): boolean {\n    const other = doc.field(this.field);\n    return other !== null && arrayValueContains(this.value.arrayValue!, other);\n  }\n}\n\n/** A Filter that implements the not-in operator. */\nexport class NotInFilter extends FieldFilter {\n  constructor(field: FieldPath, value: api.Value) {\n    super(field, Operator.NOT_IN, value);\n    debugAssert(isArray(value), 'NotInFilter expects an ArrayValue');\n  }\n\n  matches(doc: Document): boolean {\n    const other = doc.field(this.field);\n    return other !== null && !arrayValueContains(this.value.arrayValue!, other);\n  }\n}\n\n/** A Filter that implements the array-contains-any operator. */\nexport class ArrayContainsAnyFilter extends FieldFilter {\n  constructor(field: FieldPath, value: api.Value) {\n    super(field, Operator.ARRAY_CONTAINS_ANY, value);\n    debugAssert(isArray(value), 'ArrayContainsAnyFilter expects an ArrayValue');\n  }\n\n  matches(doc: Document): boolean {\n    const other = doc.field(this.field);\n    if (!isArray(other) || !other.arrayValue.values) {\n      return false;\n    }\n    return other.arrayValue.values.some(val =>\n      arrayValueContains(this.value.arrayValue!, val)\n    );\n  }\n}\n\n/**\n * The direction of sorting in an order by.\n */\nexport const enum Direction {\n  ASCENDING = 'asc',\n  DESCENDING = 'desc'\n}\n\n/**\n * Represents a bound of a query.\n *\n * The bound is specified with the given components representing a position and\n * whether it's just before or just after the position (relative to whatever the\n * query order is).\n *\n * The position represents a logical index position for a query. It's a prefix\n * of values for the (potentially implicit) order by clauses of a query.\n *\n * Bound provides a function to determine whether a document comes before or\n * after a bound. This is influenced by whether the position is just before or\n * just after the provided values.\n */\nexport class Bound {\n  constructor(readonly position: api.Value[], readonly before: boolean) {}\n}\n\nexport function canonifyBound(bound: Bound): string {\n  // TODO(b/29183165): Make this collision robust.\n  return `${bound.before ? 'b' : 'a'}:${bound.position\n    .map(p => canonicalId(p))\n    .join(',')}`;\n}\n\n/**\n * Returns true if a document sorts before a bound using the provided sort\n * order.\n */\nexport function sortsBeforeDocument(\n  bound: Bound,\n  orderBy: OrderBy[],\n  doc: Document\n): boolean {\n  debugAssert(\n    bound.position.length <= orderBy.length,\n    \"Bound has more components than query's orderBy\"\n  );\n  let comparison = 0;\n  for (let i = 0; i < bound.position.length; i++) {\n    const orderByComponent = orderBy[i];\n    const component = bound.position[i];\n    if (orderByComponent.field.isKeyField()) {\n      debugAssert(\n        isReferenceValue(component),\n        'Bound has a non-key value where the key path is being used.'\n      );\n      comparison = DocumentKey.comparator(\n        DocumentKey.fromName(component.referenceValue),\n        doc.key\n      );\n    } else {\n      const docValue = doc.field(orderByComponent.field);\n      debugAssert(\n        docValue !== null,\n        'Field should exist since document matched the orderBy already.'\n      );\n      comparison = valueCompare(component, docValue);\n    }\n    if (orderByComponent.dir === Direction.DESCENDING) {\n      comparison = comparison * -1;\n    }\n    if (comparison !== 0) {\n      break;\n    }\n  }\n  return bound.before ? comparison <= 0 : comparison < 0;\n}\n\nexport function boundEquals(left: Bound | null, right: Bound | null): boolean {\n  if (left === null) {\n    return right === null;\n  } else if (right === null) {\n    return false;\n  }\n\n  if (\n    left.before !== right.before ||\n    left.position.length !== right.position.length\n  ) {\n    return false;\n  }\n  for (let i = 0; i < left.position.length; i++) {\n    const leftPosition = left.position[i];\n    const rightPosition = right.position[i];\n    if (!valueEquals(leftPosition, rightPosition)) {\n      return false;\n    }\n  }\n  return true;\n}\n\n/**\n * An ordering on a field, in some Direction. Direction defaults to ASCENDING.\n */\nexport class OrderBy {\n  constructor(\n    readonly field: FieldPath,\n    readonly dir: Direction = Direction.ASCENDING\n  ) {}\n}\n\nexport function compareDocs(\n  orderBy: OrderBy,\n  d1: Document,\n  d2: Document\n): number {\n  const comparison = orderBy.field.isKeyField()\n    ? DocumentKey.comparator(d1.key, d2.key)\n    : compareDocumentsByField(orderBy.field, d1, d2);\n  switch (orderBy.dir) {\n    case Direction.ASCENDING:\n      return comparison;\n    case Direction.DESCENDING:\n      return -1 * comparison;\n    default:\n      return fail('Unknown direction: ' + orderBy.dir);\n  }\n}\n\nexport function canonifyOrderBy(orderBy: OrderBy): string {\n  // TODO(b/29183165): Make this collision robust.\n  return orderBy.field.canonicalString() + orderBy.dir;\n}\n\nexport function stringifyOrderBy(orderBy: OrderBy): string {\n  return `${orderBy.field.canonicalString()} (${orderBy.dir})`;\n}\n\nexport function orderByEquals(left: OrderBy, right: OrderBy): boolean {\n  return left.dir === right.dir && left.field.isEqual(right.field);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { base64 } from '@firebase/util';\n\n// WebSafe uses a different URL-encoding safe alphabet that doesn't match\n// the encoding used on the backend.\nconst WEB_SAFE = false;\n\n/** Converts a Base64 encoded string to a binary string. */\nexport function decodeBase64(encoded: string): string {\n  return String.fromCharCode.apply(\n    null,\n    // We use `decodeStringToByteArray()` instead of `decodeString()` since\n    // `decodeString()` returns Unicode strings, which doesn't match the values\n    // returned by `atob()`'s Latin1 representation.\n    base64.decodeStringToByteArray(encoded, WEB_SAFE)\n  );\n}\n\n/** Converts a binary string to a Base64 encoded string. */\nexport function encodeBase64(raw: string): string {\n  const bytes: number[] = [];\n  for (let i = 0; i < raw.length; i++) {\n    bytes[i] = raw.charCodeAt(i);\n  }\n  return base64.encodeByteArray(bytes, WEB_SAFE);\n}\n\n/** True if and only if the Base64 conversion functions are available. */\nexport function isBase64Available(): boolean {\n  return true;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { decodeBase64, encodeBase64 } from '../platform/base64';\nimport { primitiveComparator } from './misc';\n\n/**\n * Immutable class that represents a \"proto\" byte string.\n *\n * Proto byte strings can either be Base64-encoded strings or Uint8Arrays when\n * sent on the wire. This class abstracts away this differentiation by holding\n * the proto byte string in a common class that must be converted into a string\n * before being sent as a proto.\n */\nexport class ByteString {\n  static readonly EMPTY_BYTE_STRING = new ByteString('');\n\n  private constructor(private readonly binaryString: string) {}\n\n  static fromBase64String(base64: string): ByteString {\n    const binaryString = decodeBase64(base64);\n    return new ByteString(binaryString);\n  }\n\n  static fromUint8Array(array: Uint8Array): ByteString {\n    const binaryString = binaryStringFromUint8Array(array);\n    return new ByteString(binaryString);\n  }\n\n  toBase64(): string {\n    return encodeBase64(this.binaryString);\n  }\n\n  toUint8Array(): Uint8Array {\n    return uint8ArrayFromBinaryString(this.binaryString);\n  }\n\n  approximateByteSize(): number {\n    return this.binaryString.length * 2;\n  }\n\n  compareTo(other: ByteString): number {\n    return primitiveComparator(this.binaryString, other.binaryString);\n  }\n\n  isEqual(other: ByteString): boolean {\n    return this.binaryString === other.binaryString;\n  }\n}\n\n/**\n * Helper function to convert an Uint8array to a binary string.\n */\nexport function binaryStringFromUint8Array(array: Uint8Array): string {\n  let binaryString = '';\n  for (let i = 0; i < array.length; ++i) {\n    binaryString += String.fromCharCode(array[i]);\n  }\n  return binaryString;\n}\n\n/**\n * Helper function to convert a binary string to an Uint8Array.\n */\nexport function uint8ArrayFromBinaryString(binaryString: string): Uint8Array {\n  const buffer = new Uint8Array(binaryString.length);\n  for (let i = 0; i < binaryString.length; i++) {\n    buffer[i] = binaryString.charCodeAt(i);\n  }\n  return buffer;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { Target } from '../core/target';\nimport { ListenSequenceNumber, TargetId } from '../core/types';\nimport { ByteString } from '../util/byte_string';\n\n/** An enumeration of the different purposes we have for targets. */\nexport const enum TargetPurpose {\n  /** A regular, normal query target. */\n  Listen,\n\n  /**\n   * The query target was used to refill a query after an existence filter mismatch.\n   */\n  ExistenceFilterMismatch,\n\n  /** The query target was used to resolve a limbo document. */\n  LimboResolution\n}\n\n/**\n * An immutable set of metadata that the local store tracks for each target.\n */\nexport class TargetData {\n  constructor(\n    /** The target being listened to. */\n    readonly target: Target,\n    /**\n     * The target ID to which the target corresponds; Assigned by the\n     * LocalStore for user listens and by the SyncEngine for limbo watches.\n     */\n    readonly targetId: TargetId,\n    /** The purpose of the target. */\n    readonly purpose: TargetPurpose,\n    /**\n     * The sequence number of the last transaction during which this target data\n     * was modified.\n     */\n    readonly sequenceNumber: ListenSequenceNumber,\n    /** The latest snapshot version seen for this target. */\n    readonly snapshotVersion: SnapshotVersion = SnapshotVersion.min(),\n    /**\n     * The maximum snapshot version at which the associated view\n     * contained no limbo documents.\n     */\n    readonly lastLimboFreeSnapshotVersion: SnapshotVersion = SnapshotVersion.min(),\n    /**\n     * An opaque, server-assigned token that allows watching a target to be\n     * resumed after disconnecting without retransmitting all the data that\n     * matches the target. The resume token essentially identifies a point in\n     * time from which the server should resume sending results.\n     */\n    readonly resumeToken: ByteString = ByteString.EMPTY_BYTE_STRING\n  ) {}\n\n  /** Creates a new target data instance with an updated sequence number. */\n  withSequenceNumber(sequenceNumber: number): TargetData {\n    return new TargetData(\n      this.target,\n      this.targetId,\n      this.purpose,\n      sequenceNumber,\n      this.snapshotVersion,\n      this.lastLimboFreeSnapshotVersion,\n      this.resumeToken\n    );\n  }\n\n  /**\n   * Creates a new target data instance with an updated resume token and\n   * snapshot version.\n   */\n  withResumeToken(\n    resumeToken: ByteString,\n    snapshotVersion: SnapshotVersion\n  ): TargetData {\n    return new TargetData(\n      this.target,\n      this.targetId,\n      this.purpose,\n      this.sequenceNumber,\n      snapshotVersion,\n      this.lastLimboFreeSnapshotVersion,\n      resumeToken\n    );\n  }\n\n  /**\n   * Creates a new target data instance with an updated last limbo free\n   * snapshot version number.\n   */\n  withLastLimboFreeSnapshotVersion(\n    lastLimboFreeSnapshotVersion: SnapshotVersion\n  ): TargetData {\n    return new TargetData(\n      this.target,\n      this.targetId,\n      this.purpose,\n      this.sequenceNumber,\n      this.snapshotVersion,\n      lastLimboFreeSnapshotVersion,\n      this.resumeToken\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport class ExistenceFilter {\n  // TODO(b/33078163): just use simplest form of existence filter for now\n  constructor(public count: number) {}\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { fail } from '../util/assert';\nimport { Code } from '../util/error';\nimport { logError } from '../util/log';\n\n/**\n * Error Codes describing the different ways GRPC can fail. These are copied\n * directly from GRPC's sources here:\n *\n * https://github.com/grpc/grpc/blob/bceec94ea4fc5f0085d81235d8e1c06798dc341a/include/grpc%2B%2B/impl/codegen/status_code_enum.h\n *\n * Important! The names of these identifiers matter because the string forms\n * are used for reverse lookups from the webchannel stream. Do NOT change the\n * names of these identifiers or change this into a const enum.\n */\nenum RpcCode {\n  OK = 0,\n  CANCELLED = 1,\n  UNKNOWN = 2,\n  INVALID_ARGUMENT = 3,\n  DEADLINE_EXCEEDED = 4,\n  NOT_FOUND = 5,\n  ALREADY_EXISTS = 6,\n  PERMISSION_DENIED = 7,\n  UNAUTHENTICATED = 16,\n  RESOURCE_EXHAUSTED = 8,\n  FAILED_PRECONDITION = 9,\n  ABORTED = 10,\n  OUT_OF_RANGE = 11,\n  UNIMPLEMENTED = 12,\n  INTERNAL = 13,\n  UNAVAILABLE = 14,\n  DATA_LOSS = 15\n}\n\n/**\n * Determines whether an error code represents a permanent error when received\n * in response to a non-write operation.\n *\n * See isPermanentWriteError for classifying write errors.\n */\nexport function isPermanentError(code: Code): boolean {\n  switch (code) {\n    case Code.OK:\n      return fail('Treated status OK as error');\n    case Code.CANCELLED:\n    case Code.UNKNOWN:\n    case Code.DEADLINE_EXCEEDED:\n    case Code.RESOURCE_EXHAUSTED:\n    case Code.INTERNAL:\n    case Code.UNAVAILABLE:\n    // Unauthenticated means something went wrong with our token and we need\n    // to retry with new credentials which will happen automatically.\n    case Code.UNAUTHENTICATED:\n      return false;\n    case Code.INVALID_ARGUMENT:\n    case Code.NOT_FOUND:\n    case Code.ALREADY_EXISTS:\n    case Code.PERMISSION_DENIED:\n    case Code.FAILED_PRECONDITION:\n    // Aborted might be retried in some scenarios, but that is dependant on\n    // the context and should handled individually by the calling code.\n    // See https://cloud.google.com/apis/design/errors.\n    case Code.ABORTED:\n    case Code.OUT_OF_RANGE:\n    case Code.UNIMPLEMENTED:\n    case Code.DATA_LOSS:\n      return true;\n    default:\n      return fail('Unknown status code: ' + code);\n  }\n}\n\n/**\n * Determines whether an error code represents a permanent error when received\n * in response to a write operation.\n *\n * Write operations must be handled specially because as of b/119437764, ABORTED\n * errors on the write stream should be retried too (even though ABORTED errors\n * are not generally retryable).\n *\n * Note that during the initial handshake on the write stream an ABORTED error\n * signals that we should discard our stream token (i.e. it is permanent). This\n * means a handshake error should be classified with isPermanentError, above.\n */\nexport function isPermanentWriteError(code: Code): boolean {\n  return isPermanentError(code) && code !== Code.ABORTED;\n}\n\n/**\n * Maps an error Code from a GRPC status identifier like 'NOT_FOUND'.\n *\n * @returns The Code equivalent to the given status string or undefined if\n *     there is no match.\n */\nexport function mapCodeFromRpcStatus(status: string): Code | undefined {\n  // lookup by string\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  const code: RpcCode = RpcCode[status as any] as any;\n  if (code === undefined) {\n    return undefined;\n  }\n\n  return mapCodeFromRpcCode(code);\n}\n\n/**\n * Maps an error Code from GRPC status code number, like 0, 1, or 14. These\n * are not the same as HTTP status codes.\n *\n * @returns The Code equivalent to the given GRPC status code. Fails if there\n *     is no match.\n */\nexport function mapCodeFromRpcCode(code: number | undefined): Code {\n  if (code === undefined) {\n    // This shouldn't normally happen, but in certain error cases (like trying\n    // to send invalid proto messages) we may get an error with no GRPC code.\n    logError('GRPC error has no .code');\n    return Code.UNKNOWN;\n  }\n\n  switch (code) {\n    case RpcCode.OK:\n      return Code.OK;\n    case RpcCode.CANCELLED:\n      return Code.CANCELLED;\n    case RpcCode.UNKNOWN:\n      return Code.UNKNOWN;\n    case RpcCode.DEADLINE_EXCEEDED:\n      return Code.DEADLINE_EXCEEDED;\n    case RpcCode.RESOURCE_EXHAUSTED:\n      return Code.RESOURCE_EXHAUSTED;\n    case RpcCode.INTERNAL:\n      return Code.INTERNAL;\n    case RpcCode.UNAVAILABLE:\n      return Code.UNAVAILABLE;\n    case RpcCode.UNAUTHENTICATED:\n      return Code.UNAUTHENTICATED;\n    case RpcCode.INVALID_ARGUMENT:\n      return Code.INVALID_ARGUMENT;\n    case RpcCode.NOT_FOUND:\n      return Code.NOT_FOUND;\n    case RpcCode.ALREADY_EXISTS:\n      return Code.ALREADY_EXISTS;\n    case RpcCode.PERMISSION_DENIED:\n      return Code.PERMISSION_DENIED;\n    case RpcCode.FAILED_PRECONDITION:\n      return Code.FAILED_PRECONDITION;\n    case RpcCode.ABORTED:\n      return Code.ABORTED;\n    case RpcCode.OUT_OF_RANGE:\n      return Code.OUT_OF_RANGE;\n    case RpcCode.UNIMPLEMENTED:\n      return Code.UNIMPLEMENTED;\n    case RpcCode.DATA_LOSS:\n      return Code.DATA_LOSS;\n    default:\n      return fail('Unknown status code: ' + code);\n  }\n}\n\n/**\n * Maps an RPC code from a Code. This is the reverse operation from\n * mapCodeFromRpcCode and should really only be used in tests.\n */\nexport function mapRpcCodeFromCode(code: Code | undefined): number {\n  if (code === undefined) {\n    return RpcCode.OK;\n  }\n\n  switch (code) {\n    case Code.OK:\n      return RpcCode.OK;\n    case Code.CANCELLED:\n      return RpcCode.CANCELLED;\n    case Code.UNKNOWN:\n      return RpcCode.UNKNOWN;\n    case Code.DEADLINE_EXCEEDED:\n      return RpcCode.DEADLINE_EXCEEDED;\n    case Code.RESOURCE_EXHAUSTED:\n      return RpcCode.RESOURCE_EXHAUSTED;\n    case Code.INTERNAL:\n      return RpcCode.INTERNAL;\n    case Code.UNAVAILABLE:\n      return RpcCode.UNAVAILABLE;\n    case Code.UNAUTHENTICATED:\n      return RpcCode.UNAUTHENTICATED;\n    case Code.INVALID_ARGUMENT:\n      return RpcCode.INVALID_ARGUMENT;\n    case Code.NOT_FOUND:\n      return RpcCode.NOT_FOUND;\n    case Code.ALREADY_EXISTS:\n      return RpcCode.ALREADY_EXISTS;\n    case Code.PERMISSION_DENIED:\n      return RpcCode.PERMISSION_DENIED;\n    case Code.FAILED_PRECONDITION:\n      return RpcCode.FAILED_PRECONDITION;\n    case Code.ABORTED:\n      return RpcCode.ABORTED;\n    case Code.OUT_OF_RANGE:\n      return RpcCode.OUT_OF_RANGE;\n    case Code.UNIMPLEMENTED:\n      return RpcCode.UNIMPLEMENTED;\n    case Code.DATA_LOSS:\n      return RpcCode.DATA_LOSS;\n    default:\n      return fail('Unknown status code: ' + code);\n  }\n}\n\n/**\n * Converts an HTTP Status Code to the equivalent error code.\n *\n * @param status An HTTP Status Code, like 200, 404, 503, etc.\n * @returns The equivalent Code. Unknown status codes are mapped to\n *     Code.UNKNOWN.\n */\nexport function mapCodeFromHttpStatus(status?: number): Code {\n  if (status === undefined) {\n    logError('RPC_ERROR', 'HTTP error has no status');\n    return Code.UNKNOWN;\n  }\n\n  // The canonical error codes for Google APIs [1] specify mapping onto HTTP\n  // status codes but the mapping is not bijective. In each case of ambiguity\n  // this function chooses a primary error.\n  //\n  // [1]\n  // https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto\n  switch (status) {\n    case 200: // OK\n      return Code.OK;\n\n    case 400: // Bad Request\n      return Code.FAILED_PRECONDITION;\n    // Other possibilities based on the forward mapping\n    // return Code.INVALID_ARGUMENT;\n    // return Code.OUT_OF_RANGE;\n\n    case 401: // Unauthorized\n      return Code.UNAUTHENTICATED;\n\n    case 403: // Forbidden\n      return Code.PERMISSION_DENIED;\n\n    case 404: // Not Found\n      return Code.NOT_FOUND;\n\n    case 409: // Conflict\n      return Code.ABORTED;\n    // Other possibilities:\n    // return Code.ALREADY_EXISTS;\n\n    case 416: // Range Not Satisfiable\n      return Code.OUT_OF_RANGE;\n\n    case 429: // Too Many Requests\n      return Code.RESOURCE_EXHAUSTED;\n\n    case 499: // Client Closed Request\n      return Code.CANCELLED;\n\n    case 500: // Internal Server Error\n      return Code.UNKNOWN;\n    // Other possibilities:\n    // return Code.INTERNAL;\n    // return Code.DATA_LOSS;\n\n    case 501: // Unimplemented\n      return Code.UNIMPLEMENTED;\n\n    case 503: // Service Unavailable\n      return Code.UNAVAILABLE;\n\n    case 504: // Gateway Timeout\n      return Code.DEADLINE_EXCEEDED;\n\n    default:\n      if (status >= 200 && status < 300) {\n        return Code.OK;\n      }\n      if (status >= 400 && status < 500) {\n        return Code.FAILED_PRECONDITION;\n      }\n      if (status >= 500 && status < 600) {\n        return Code.INTERNAL;\n      }\n      return Code.UNKNOWN;\n  }\n}\n\n/**\n * Converts an HTTP response's error status to the equivalent error code.\n *\n * @param status An HTTP error response status (\"FAILED_PRECONDITION\",\n * \"UNKNOWN\", etc.)\n * @returns The equivalent Code. Non-matching responses are mapped to\n *     Code.UNKNOWN.\n */\nexport function mapCodeFromHttpResponseErrorStatus(status: string): Code {\n  const serverError = status.toLowerCase().replace('_', '-');\n  return Object.values(Code).indexOf(serverError as Code) >= 0\n    ? (serverError as Code)\n    : Code.UNKNOWN;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert, fail } from './assert';\n\n/*\n * Implementation of an immutable SortedMap using a Left-leaning\n * Red-Black Tree, adapted from the implementation in Mugs\n * (http://mads379.github.com/mugs/) by Mads Hartmann Jensen\n * (mads379@gmail.com).\n *\n * Original paper on Left-leaning Red-Black Trees:\n *   http://www.cs.princeton.edu/~rs/talks/LLRB/LLRB.pdf\n *\n * Invariant 1: No red node has a red child\n * Invariant 2: Every leaf path has the same number of black nodes\n * Invariant 3: Only the left child can be red (left leaning)\n */\n\nexport type Comparator<K> = (key1: K, key2: K) => number;\n\nexport interface Entry<K, V> {\n  key: K;\n  value: V;\n}\n\n// An immutable sorted map implementation, based on a Left-leaning Red-Black\n// tree.\nexport class SortedMap<K, V> {\n  // visible for testing\n  root: LLRBNode<K, V> | LLRBEmptyNode<K, V>;\n\n  constructor(\n    public comparator: Comparator<K>,\n    root?: LLRBNode<K, V> | LLRBEmptyNode<K, V>\n  ) {\n    this.root = root ? root : LLRBNode.EMPTY;\n  }\n\n  // Returns a copy of the map, with the specified key/value added or replaced.\n  insert(key: K, value: V): SortedMap<K, V> {\n    return new SortedMap<K, V>(\n      this.comparator,\n      this.root\n        .insert(key, value, this.comparator)\n        .copy(null, null, LLRBNode.BLACK, null, null)\n    );\n  }\n\n  // Returns a copy of the map, with the specified key removed.\n  remove(key: K): SortedMap<K, V> {\n    return new SortedMap<K, V>(\n      this.comparator,\n      this.root\n        .remove(key, this.comparator)\n        .copy(null, null, LLRBNode.BLACK, null, null)\n    );\n  }\n\n  // Returns the value of the node with the given key, or null.\n  get(key: K): V | null {\n    let node = this.root;\n    while (!node.isEmpty()) {\n      const cmp = this.comparator(key, node.key);\n      if (cmp === 0) {\n        return node.value;\n      } else if (cmp < 0) {\n        node = node.left;\n      } else if (cmp > 0) {\n        node = node.right;\n      }\n    }\n    return null;\n  }\n\n  // Returns the index of the element in this sorted map, or -1 if it doesn't\n  // exist.\n  indexOf(key: K): number {\n    // Number of nodes that were pruned when descending right\n    let prunedNodes = 0;\n    let node = this.root;\n    while (!node.isEmpty()) {\n      const cmp = this.comparator(key, node.key);\n      if (cmp === 0) {\n        return prunedNodes + node.left.size;\n      } else if (cmp < 0) {\n        node = node.left;\n      } else {\n        // Count all nodes left of the node plus the node itself\n        prunedNodes += node.left.size + 1;\n        node = node.right;\n      }\n    }\n    // Node not found\n    return -1;\n  }\n\n  isEmpty(): boolean {\n    return this.root.isEmpty();\n  }\n\n  // Returns the total number of nodes in the map.\n  get size(): number {\n    return this.root.size;\n  }\n\n  // Returns the minimum key in the map.\n  minKey(): K | null {\n    return this.root.minKey();\n  }\n\n  // Returns the maximum key in the map.\n  maxKey(): K | null {\n    return this.root.maxKey();\n  }\n\n  // Traverses the map in key order and calls the specified action function\n  // for each key/value pair. If action returns true, traversal is aborted.\n  // Returns the first truthy value returned by action, or the last falsey\n  // value returned by action.\n  inorderTraversal<T>(action: (k: K, v: V) => T): T {\n    return (this.root as LLRBNode<K, V>).inorderTraversal(action);\n  }\n\n  forEach(fn: (k: K, v: V) => void): void {\n    this.inorderTraversal((k, v) => {\n      fn(k, v);\n      return false;\n    });\n  }\n\n  toString(): string {\n    const descriptions: string[] = [];\n    this.inorderTraversal((k, v) => {\n      descriptions.push(`${k}:${v}`);\n      return false;\n    });\n    return `{${descriptions.join(', ')}}`;\n  }\n\n  // Traverses the map in reverse key order and calls the specified action\n  // function for each key/value pair. If action returns true, traversal is\n  // aborted.\n  // Returns the first truthy value returned by action, or the last falsey\n  // value returned by action.\n  reverseTraversal<T>(action: (k: K, v: V) => T): T {\n    return (this.root as LLRBNode<K, V>).reverseTraversal(action);\n  }\n\n  // Returns an iterator over the SortedMap.\n  getIterator(): SortedMapIterator<K, V> {\n    return new SortedMapIterator<K, V>(this.root, null, this.comparator, false);\n  }\n\n  getIteratorFrom(key: K): SortedMapIterator<K, V> {\n    return new SortedMapIterator<K, V>(this.root, key, this.comparator, false);\n  }\n\n  getReverseIterator(): SortedMapIterator<K, V> {\n    return new SortedMapIterator<K, V>(this.root, null, this.comparator, true);\n  }\n\n  getReverseIteratorFrom(key: K): SortedMapIterator<K, V> {\n    return new SortedMapIterator<K, V>(this.root, key, this.comparator, true);\n  }\n} // end SortedMap\n\n// An iterator over an LLRBNode.\nexport class SortedMapIterator<K, V> {\n  private isReverse: boolean;\n  private nodeStack: Array<LLRBNode<K, V> | LLRBEmptyNode<K, V>>;\n\n  constructor(\n    node: LLRBNode<K, V> | LLRBEmptyNode<K, V>,\n    startKey: K | null,\n    comparator: Comparator<K>,\n    isReverse: boolean\n  ) {\n    this.isReverse = isReverse;\n    this.nodeStack = [];\n\n    let cmp = 1;\n    while (!node.isEmpty()) {\n      cmp = startKey ? comparator(node.key, startKey) : 1;\n      // flip the comparison if we're going in reverse\n      if (isReverse) {\n        cmp *= -1;\n      }\n\n      if (cmp < 0) {\n        // This node is less than our start key. ignore it\n        if (this.isReverse) {\n          node = node.left;\n        } else {\n          node = node.right;\n        }\n      } else if (cmp === 0) {\n        // This node is exactly equal to our start key. Push it on the stack,\n        // but stop iterating;\n        this.nodeStack.push(node);\n        break;\n      } else {\n        // This node is greater than our start key, add it to the stack and move\n        // to the next one\n        this.nodeStack.push(node);\n        if (this.isReverse) {\n          node = node.right;\n        } else {\n          node = node.left;\n        }\n      }\n    }\n  }\n\n  getNext(): Entry<K, V> {\n    debugAssert(\n      this.nodeStack.length > 0,\n      'getNext() called on iterator when hasNext() is false.'\n    );\n\n    let node = this.nodeStack.pop()!;\n    const result = { key: node.key, value: node.value };\n\n    if (this.isReverse) {\n      node = node.left;\n      while (!node.isEmpty()) {\n        this.nodeStack.push(node);\n        node = node.right;\n      }\n    } else {\n      node = node.right;\n      while (!node.isEmpty()) {\n        this.nodeStack.push(node);\n        node = node.left;\n      }\n    }\n\n    return result;\n  }\n\n  hasNext(): boolean {\n    return this.nodeStack.length > 0;\n  }\n\n  peek(): Entry<K, V> | null {\n    if (this.nodeStack.length === 0) {\n      return null;\n    }\n\n    const node = this.nodeStack[this.nodeStack.length - 1];\n    return { key: node.key, value: node.value };\n  }\n} // end SortedMapIterator\n\n// Represents a node in a Left-leaning Red-Black tree.\nexport class LLRBNode<K, V> {\n  readonly color: boolean;\n  readonly left: LLRBNode<K, V> | LLRBEmptyNode<K, V>;\n  readonly right: LLRBNode<K, V> | LLRBEmptyNode<K, V>;\n  readonly size: number;\n\n  // Empty node is shared between all LLRB trees.\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  static EMPTY: LLRBEmptyNode<any, any> = null as any;\n\n  static RED = true;\n  static BLACK = false;\n\n  constructor(\n    public key: K,\n    public value: V,\n    color?: boolean,\n    left?: LLRBNode<K, V> | LLRBEmptyNode<K, V>,\n    right?: LLRBNode<K, V> | LLRBEmptyNode<K, V>\n  ) {\n    this.color = color != null ? color : LLRBNode.RED;\n    this.left = left != null ? left : LLRBNode.EMPTY;\n    this.right = right != null ? right : LLRBNode.EMPTY;\n    this.size = this.left.size + 1 + this.right.size;\n  }\n\n  // Returns a copy of the current node, optionally replacing pieces of it.\n  copy(\n    key: K | null,\n    value: V | null,\n    color: boolean | null,\n    left: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null,\n    right: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null\n  ): LLRBNode<K, V> {\n    return new LLRBNode<K, V>(\n      key != null ? key : this.key,\n      value != null ? value : this.value,\n      color != null ? color : this.color,\n      left != null ? left : this.left,\n      right != null ? right : this.right\n    );\n  }\n\n  isEmpty(): boolean {\n    return false;\n  }\n\n  // Traverses the tree in key order and calls the specified action function\n  // for each node. If action returns true, traversal is aborted.\n  // Returns the first truthy value returned by action, or the last falsey\n  // value returned by action.\n  inorderTraversal<T>(action: (k: K, v: V) => T): T {\n    return (\n      (this.left as LLRBNode<K, V>).inorderTraversal(action) ||\n      action(this.key, this.value) ||\n      (this.right as LLRBNode<K, V>).inorderTraversal(action)\n    );\n  }\n\n  // Traverses the tree in reverse key order and calls the specified action\n  // function for each node. If action returns true, traversal is aborted.\n  // Returns the first truthy value returned by action, or the last falsey\n  // value returned by action.\n  reverseTraversal<T>(action: (k: K, v: V) => T): T {\n    return (\n      (this.right as LLRBNode<K, V>).reverseTraversal(action) ||\n      action(this.key, this.value) ||\n      (this.left as LLRBNode<K, V>).reverseTraversal(action)\n    );\n  }\n\n  // Returns the minimum node in the tree.\n  private min(): LLRBNode<K, V> {\n    if (this.left.isEmpty()) {\n      return this;\n    } else {\n      return (this.left as LLRBNode<K, V>).min();\n    }\n  }\n\n  // Returns the maximum key in the tree.\n  minKey(): K | null {\n    return this.min().key;\n  }\n\n  // Returns the maximum key in the tree.\n  maxKey(): K | null {\n    if (this.right.isEmpty()) {\n      return this.key;\n    } else {\n      return this.right.maxKey();\n    }\n  }\n\n  // Returns new tree, with the key/value added.\n  insert(key: K, value: V, comparator: Comparator<K>): LLRBNode<K, V> {\n    let n: LLRBNode<K, V> = this;\n    const cmp = comparator(key, n.key);\n    if (cmp < 0) {\n      n = n.copy(null, null, null, n.left.insert(key, value, comparator), null);\n    } else if (cmp === 0) {\n      n = n.copy(null, value, null, null, null);\n    } else {\n      n = n.copy(\n        null,\n        null,\n        null,\n        null,\n        n.right.insert(key, value, comparator)\n      );\n    }\n    return n.fixUp();\n  }\n\n  private removeMin(): LLRBNode<K, V> | LLRBEmptyNode<K, V> {\n    if (this.left.isEmpty()) {\n      return LLRBNode.EMPTY;\n    }\n    let n: LLRBNode<K, V> = this;\n    if (!n.left.isRed() && !n.left.left.isRed()) {\n      n = n.moveRedLeft();\n    }\n    n = n.copy(null, null, null, (n.left as LLRBNode<K, V>).removeMin(), null);\n    return n.fixUp();\n  }\n\n  // Returns new tree, with the specified item removed.\n  remove(\n    key: K,\n    comparator: Comparator<K>\n  ): LLRBNode<K, V> | LLRBEmptyNode<K, V> {\n    let smallest: LLRBNode<K, V>;\n    let n: LLRBNode<K, V> = this;\n    if (comparator(key, n.key) < 0) {\n      if (!n.left.isEmpty() && !n.left.isRed() && !n.left.left.isRed()) {\n        n = n.moveRedLeft();\n      }\n      n = n.copy(null, null, null, n.left.remove(key, comparator), null);\n    } else {\n      if (n.left.isRed()) {\n        n = n.rotateRight();\n      }\n      if (!n.right.isEmpty() && !n.right.isRed() && !n.right.left.isRed()) {\n        n = n.moveRedRight();\n      }\n      if (comparator(key, n.key) === 0) {\n        if (n.right.isEmpty()) {\n          return LLRBNode.EMPTY;\n        } else {\n          smallest = (n.right as LLRBNode<K, V>).min();\n          n = n.copy(\n            smallest.key,\n            smallest.value,\n            null,\n            null,\n            (n.right as LLRBNode<K, V>).removeMin()\n          );\n        }\n      }\n      n = n.copy(null, null, null, null, n.right.remove(key, comparator));\n    }\n    return n.fixUp();\n  }\n\n  isRed(): boolean {\n    return this.color;\n  }\n\n  // Returns new tree after performing any needed rotations.\n  private fixUp(): LLRBNode<K, V> {\n    let n: LLRBNode<K, V> = this;\n    if (n.right.isRed() && !n.left.isRed()) {\n      n = n.rotateLeft();\n    }\n    if (n.left.isRed() && n.left.left.isRed()) {\n      n = n.rotateRight();\n    }\n    if (n.left.isRed() && n.right.isRed()) {\n      n = n.colorFlip();\n    }\n    return n;\n  }\n\n  private moveRedLeft(): LLRBNode<K, V> {\n    let n = this.colorFlip();\n    if (n.right.left.isRed()) {\n      n = n.copy(\n        null,\n        null,\n        null,\n        null,\n        (n.right as LLRBNode<K, V>).rotateRight()\n      );\n      n = n.rotateLeft();\n      n = n.colorFlip();\n    }\n    return n;\n  }\n\n  private moveRedRight(): LLRBNode<K, V> {\n    let n = this.colorFlip();\n    if (n.left.left.isRed()) {\n      n = n.rotateRight();\n      n = n.colorFlip();\n    }\n    return n;\n  }\n\n  private rotateLeft(): LLRBNode<K, V> {\n    const nl = this.copy(null, null, LLRBNode.RED, null, this.right.left);\n    return (this.right as LLRBNode<K, V>).copy(\n      null,\n      null,\n      this.color,\n      nl,\n      null\n    );\n  }\n\n  private rotateRight(): LLRBNode<K, V> {\n    const nr = this.copy(null, null, LLRBNode.RED, this.left.right, null);\n    return (this.left as LLRBNode<K, V>).copy(null, null, this.color, null, nr);\n  }\n\n  private colorFlip(): LLRBNode<K, V> {\n    const left = this.left.copy(null, null, !this.left.color, null, null);\n    const right = this.right.copy(null, null, !this.right.color, null, null);\n    return this.copy(null, null, !this.color, left, right);\n  }\n\n  // For testing.\n  checkMaxDepth(): boolean {\n    const blackDepth = this.check();\n    if (Math.pow(2.0, blackDepth) <= this.size + 1) {\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n  // In a balanced RB tree, the black-depth (number of black nodes) from root to\n  // leaves is equal on both sides.  This function verifies that or asserts.\n  protected check(): number {\n    if (this.isRed() && this.left.isRed()) {\n      throw fail('Red node has red child(' + this.key + ',' + this.value + ')');\n    }\n    if (this.right.isRed()) {\n      throw fail('Right child of (' + this.key + ',' + this.value + ') is red');\n    }\n    const blackDepth = (this.left as LLRBNode<K, V>).check();\n    if (blackDepth !== (this.right as LLRBNode<K, V>).check()) {\n      throw fail('Black depths differ');\n    } else {\n      return blackDepth + (this.isRed() ? 0 : 1);\n    }\n  }\n} // end LLRBNode\n\n// Represents an empty node (a leaf node in the Red-Black Tree).\nexport class LLRBEmptyNode<K, V> {\n  get key(): never {\n    throw fail('LLRBEmptyNode has no key.');\n  }\n  get value(): never {\n    throw fail('LLRBEmptyNode has no value.');\n  }\n  get color(): never {\n    throw fail('LLRBEmptyNode has no color.');\n  }\n  get left(): never {\n    throw fail('LLRBEmptyNode has no left child.');\n  }\n  get right(): never {\n    throw fail('LLRBEmptyNode has no right child.');\n  }\n  size = 0;\n\n  // Returns a copy of the current node.\n  copy(\n    key: K | null,\n    value: V | null,\n    color: boolean | null,\n    left: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null,\n    right: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null\n  ): LLRBEmptyNode<K, V> {\n    return this;\n  }\n\n  // Returns a copy of the tree, with the specified key/value added.\n  insert(key: K, value: V, comparator: Comparator<K>): LLRBNode<K, V> {\n    return new LLRBNode<K, V>(key, value);\n  }\n\n  // Returns a copy of the tree, with the specified key removed.\n  remove(key: K, comparator: Comparator<K>): LLRBEmptyNode<K, V> {\n    return this;\n  }\n\n  isEmpty(): boolean {\n    return true;\n  }\n\n  inorderTraversal(action: (k: K, v: V) => boolean): boolean {\n    return false;\n  }\n\n  reverseTraversal(action: (k: K, v: V) => boolean): boolean {\n    return false;\n  }\n\n  minKey(): K | null {\n    return null;\n  }\n\n  maxKey(): K | null {\n    return null;\n  }\n\n  isRed(): boolean {\n    return false;\n  }\n\n  // For testing.\n  checkMaxDepth(): boolean {\n    return true;\n  }\n\n  protected check(): 0 {\n    return 0;\n  }\n} // end LLRBEmptyNode\n\nLLRBNode.EMPTY = new LLRBEmptyNode<unknown, unknown>();\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SortedMap, SortedMapIterator } from './sorted_map';\n\n/**\n * SortedSet is an immutable (copy-on-write) collection that holds elements\n * in order specified by the provided comparator.\n *\n * NOTE: if provided comparator returns 0 for two elements, we consider them to\n * be equal!\n */\nexport class SortedSet<T> {\n  private data: SortedMap<T, boolean>;\n\n  constructor(private comparator: (left: T, right: T) => number) {\n    this.data = new SortedMap<T, boolean>(this.comparator);\n  }\n\n  has(elem: T): boolean {\n    return this.data.get(elem) !== null;\n  }\n\n  first(): T | null {\n    return this.data.minKey();\n  }\n\n  last(): T | null {\n    return this.data.maxKey();\n  }\n\n  get size(): number {\n    return this.data.size;\n  }\n\n  indexOf(elem: T): number {\n    return this.data.indexOf(elem);\n  }\n\n  /** Iterates elements in order defined by \"comparator\" */\n  forEach(cb: (elem: T) => void): void {\n    this.data.inorderTraversal((k: T, v: boolean) => {\n      cb(k);\n      return false;\n    });\n  }\n\n  /** Iterates over `elem`s such that: range[0] <= elem < range[1]. */\n  forEachInRange(range: [T, T], cb: (elem: T) => void): void {\n    const iter = this.data.getIteratorFrom(range[0]);\n    while (iter.hasNext()) {\n      const elem = iter.getNext();\n      if (this.comparator(elem.key, range[1]) >= 0) {\n        return;\n      }\n      cb(elem.key);\n    }\n  }\n\n  /**\n   * Iterates over `elem`s such that: start <= elem until false is returned.\n   */\n  forEachWhile(cb: (elem: T) => boolean, start?: T): void {\n    let iter: SortedMapIterator<T, boolean>;\n    if (start !== undefined) {\n      iter = this.data.getIteratorFrom(start);\n    } else {\n      iter = this.data.getIterator();\n    }\n    while (iter.hasNext()) {\n      const elem = iter.getNext();\n      const result = cb(elem.key);\n      if (!result) {\n        return;\n      }\n    }\n  }\n\n  /** Finds the least element greater than or equal to `elem`. */\n  firstAfterOrEqual(elem: T): T | null {\n    const iter = this.data.getIteratorFrom(elem);\n    return iter.hasNext() ? iter.getNext().key : null;\n  }\n\n  getIterator(): SortedSetIterator<T> {\n    return new SortedSetIterator<T>(this.data.getIterator());\n  }\n\n  getIteratorFrom(key: T): SortedSetIterator<T> {\n    return new SortedSetIterator<T>(this.data.getIteratorFrom(key));\n  }\n\n  /** Inserts or updates an element */\n  add(elem: T): SortedSet<T> {\n    return this.copy(this.data.remove(elem).insert(elem, true));\n  }\n\n  /** Deletes an element */\n  delete(elem: T): SortedSet<T> {\n    if (!this.has(elem)) {\n      return this;\n    }\n    return this.copy(this.data.remove(elem));\n  }\n\n  isEmpty(): boolean {\n    return this.data.isEmpty();\n  }\n\n  unionWith(other: SortedSet<T>): SortedSet<T> {\n    let result: SortedSet<T> = this;\n\n    // Make sure `result` always refers to the larger one of the two sets.\n    if (result.size < other.size) {\n      result = other;\n      other = this;\n    }\n\n    other.forEach(elem => {\n      result = result.add(elem);\n    });\n    return result;\n  }\n\n  isEqual(other: SortedSet<T>): boolean {\n    if (!(other instanceof SortedSet)) {\n      return false;\n    }\n    if (this.size !== other.size) {\n      return false;\n    }\n\n    const thisIt = this.data.getIterator();\n    const otherIt = other.data.getIterator();\n    while (thisIt.hasNext()) {\n      const thisElem = thisIt.getNext().key;\n      const otherElem = otherIt.getNext().key;\n      if (this.comparator(thisElem, otherElem) !== 0) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  toArray(): T[] {\n    const res: T[] = [];\n    this.forEach(targetId => {\n      res.push(targetId);\n    });\n    return res;\n  }\n\n  toString(): string {\n    const result: T[] = [];\n    this.forEach(elem => result.push(elem));\n    return 'SortedSet(' + result.toString() + ')';\n  }\n\n  private copy(data: SortedMap<T, boolean>): SortedSet<T> {\n    const result = new SortedSet(this.comparator);\n    result.data = data;\n    return result;\n  }\n}\n\nexport class SortedSetIterator<T> {\n  constructor(private iter: SortedMapIterator<T, boolean>) {}\n\n  getNext(): T {\n    return this.iter.getNext().key;\n  }\n\n  hasNext(): boolean {\n    return this.iter.hasNext();\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { SortedMap } from '../util/sorted_map';\nimport { SortedSet } from '../util/sorted_set';\n\nimport { TargetId } from '../core/types';\nimport { primitiveComparator } from '../util/misc';\nimport { Document, MaybeDocument } from './document';\nimport { DocumentKey } from './document_key';\n\n/** Miscellaneous collection types / constants. */\nexport interface DocumentSizeEntry {\n  maybeDocument: MaybeDocument;\n  size: number;\n}\n\nexport type MaybeDocumentMap = SortedMap<DocumentKey, MaybeDocument>;\nconst EMPTY_MAYBE_DOCUMENT_MAP = new SortedMap<DocumentKey, MaybeDocument>(\n  DocumentKey.comparator\n);\nexport function maybeDocumentMap(): MaybeDocumentMap {\n  return EMPTY_MAYBE_DOCUMENT_MAP;\n}\n\nexport type NullableMaybeDocumentMap = SortedMap<\n  DocumentKey,\n  MaybeDocument | null\n>;\n\nexport function nullableMaybeDocumentMap(): NullableMaybeDocumentMap {\n  return maybeDocumentMap();\n}\n\nexport interface DocumentSizeEntries {\n  maybeDocuments: NullableMaybeDocumentMap;\n  sizeMap: SortedMap<DocumentKey, number>;\n}\n\nexport type DocumentMap = SortedMap<DocumentKey, Document>;\nconst EMPTY_DOCUMENT_MAP = new SortedMap<DocumentKey, Document>(\n  DocumentKey.comparator\n);\nexport function documentMap(): DocumentMap {\n  return EMPTY_DOCUMENT_MAP;\n}\n\nexport type DocumentVersionMap = SortedMap<DocumentKey, SnapshotVersion>;\nconst EMPTY_DOCUMENT_VERSION_MAP = new SortedMap<DocumentKey, SnapshotVersion>(\n  DocumentKey.comparator\n);\nexport function documentVersionMap(): DocumentVersionMap {\n  return EMPTY_DOCUMENT_VERSION_MAP;\n}\n\nexport type DocumentKeySet = SortedSet<DocumentKey>;\nconst EMPTY_DOCUMENT_KEY_SET = new SortedSet(DocumentKey.comparator);\nexport function documentKeySet(...keys: DocumentKey[]): DocumentKeySet {\n  let set = EMPTY_DOCUMENT_KEY_SET;\n  for (const key of keys) {\n    set = set.add(key);\n  }\n  return set;\n}\n\nexport type TargetIdSet = SortedSet<TargetId>;\nconst EMPTY_TARGET_ID_SET = new SortedSet<TargetId>(primitiveComparator);\nexport function targetIdSet(): SortedSet<TargetId> {\n  return EMPTY_TARGET_ID_SET;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SortedMap } from '../util/sorted_map';\n\nimport { documentMap } from './collections';\nimport { Document } from './document';\nimport { DocumentComparator } from './document_comparator';\nimport { DocumentKey } from './document_key';\n\n/**\n * DocumentSet is an immutable (copy-on-write) collection that holds documents\n * in order specified by the provided comparator. We always add a document key\n * comparator on top of what is provided to guarantee document equality based on\n * the key.\n */\n\nexport class DocumentSet {\n  /**\n   * Returns an empty copy of the existing DocumentSet, using the same\n   * comparator.\n   */\n  static emptySet(oldSet: DocumentSet): DocumentSet {\n    return new DocumentSet(oldSet.comparator);\n  }\n\n  private comparator: DocumentComparator;\n  private keyedMap: SortedMap<DocumentKey, Document>;\n  private sortedSet: SortedMap<Document, null>;\n\n  /** The default ordering is by key if the comparator is omitted */\n  constructor(comp?: DocumentComparator) {\n    // We are adding document key comparator to the end as it's the only\n    // guaranteed unique property of a document.\n    if (comp) {\n      this.comparator = (d1: Document, d2: Document) =>\n        comp(d1, d2) || DocumentKey.comparator(d1.key, d2.key);\n    } else {\n      this.comparator = (d1: Document, d2: Document) =>\n        DocumentKey.comparator(d1.key, d2.key);\n    }\n\n    this.keyedMap = documentMap();\n    this.sortedSet = new SortedMap<Document, null>(this.comparator);\n  }\n\n  has(key: DocumentKey): boolean {\n    return this.keyedMap.get(key) != null;\n  }\n\n  get(key: DocumentKey): Document | null {\n    return this.keyedMap.get(key);\n  }\n\n  first(): Document | null {\n    return this.sortedSet.minKey();\n  }\n\n  last(): Document | null {\n    return this.sortedSet.maxKey();\n  }\n\n  isEmpty(): boolean {\n    return this.sortedSet.isEmpty();\n  }\n\n  /**\n   * Returns the index of the provided key in the document set, or -1 if the\n   * document key is not present in the set;\n   */\n  indexOf(key: DocumentKey): number {\n    const doc = this.keyedMap.get(key);\n    return doc ? this.sortedSet.indexOf(doc) : -1;\n  }\n\n  get size(): number {\n    return this.sortedSet.size;\n  }\n\n  /** Iterates documents in order defined by \"comparator\" */\n  forEach(cb: (doc: Document) => void): void {\n    this.sortedSet.inorderTraversal((k, v) => {\n      cb(k);\n      return false;\n    });\n  }\n\n  /** Inserts or updates a document with the same key */\n  add(doc: Document): DocumentSet {\n    // First remove the element if we have it.\n    const set = this.delete(doc.key);\n    return set.copy(\n      set.keyedMap.insert(doc.key, doc),\n      set.sortedSet.insert(doc, null)\n    );\n  }\n\n  /** Deletes a document with a given key */\n  delete(key: DocumentKey): DocumentSet {\n    const doc = this.get(key);\n    if (!doc) {\n      return this;\n    }\n\n    return this.copy(this.keyedMap.remove(key), this.sortedSet.remove(doc));\n  }\n\n  isEqual(other: DocumentSet | null | undefined): boolean {\n    if (!(other instanceof DocumentSet)) {\n      return false;\n    }\n    if (this.size !== other.size) {\n      return false;\n    }\n\n    const thisIt = this.sortedSet.getIterator();\n    const otherIt = other.sortedSet.getIterator();\n    while (thisIt.hasNext()) {\n      const thisDoc = thisIt.getNext().key;\n      const otherDoc = otherIt.getNext().key;\n      if (!thisDoc.isEqual(otherDoc)) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  toString(): string {\n    const docStrings: string[] = [];\n    this.forEach(doc => {\n      docStrings.push(doc.toString());\n    });\n    if (docStrings.length === 0) {\n      return 'DocumentSet ()';\n    } else {\n      return 'DocumentSet (\\n  ' + docStrings.join('  \\n') + '\\n)';\n    }\n  }\n\n  private copy(\n    keyedMap: SortedMap<DocumentKey, Document>,\n    sortedSet: SortedMap<Document, null>\n  ): DocumentSet {\n    const newSet = new DocumentSet();\n    newSet.comparator = this.comparator;\n    newSet.keyedMap = keyedMap;\n    newSet.sortedSet = sortedSet;\n    return newSet;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Document } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { DocumentSet } from '../model/document_set';\nimport { fail } from '../util/assert';\nimport { SortedMap } from '../util/sorted_map';\n\nimport { DocumentKeySet } from '../model/collections';\nimport { Query, queryEquals } from './query';\n\nexport const enum ChangeType {\n  Added,\n  Removed,\n  Modified,\n  Metadata\n}\n\nexport interface DocumentViewChange {\n  type: ChangeType;\n  doc: Document;\n}\n\nexport const enum SyncState {\n  Local,\n  Synced\n}\n\n/**\n * DocumentChangeSet keeps track of a set of changes to docs in a query, merging\n * duplicate events for the same doc.\n */\nexport class DocumentChangeSet {\n  private changeMap = new SortedMap<DocumentKey, DocumentViewChange>(\n    DocumentKey.comparator\n  );\n\n  track(change: DocumentViewChange): void {\n    const key = change.doc.key;\n    const oldChange = this.changeMap.get(key);\n    if (!oldChange) {\n      this.changeMap = this.changeMap.insert(key, change);\n      return;\n    }\n\n    // Merge the new change with the existing change.\n    if (\n      change.type !== ChangeType.Added &&\n      oldChange.type === ChangeType.Metadata\n    ) {\n      this.changeMap = this.changeMap.insert(key, change);\n    } else if (\n      change.type === ChangeType.Metadata &&\n      oldChange.type !== ChangeType.Removed\n    ) {\n      this.changeMap = this.changeMap.insert(key, {\n        type: oldChange.type,\n        doc: change.doc\n      });\n    } else if (\n      change.type === ChangeType.Modified &&\n      oldChange.type === ChangeType.Modified\n    ) {\n      this.changeMap = this.changeMap.insert(key, {\n        type: ChangeType.Modified,\n        doc: change.doc\n      });\n    } else if (\n      change.type === ChangeType.Modified &&\n      oldChange.type === ChangeType.Added\n    ) {\n      this.changeMap = this.changeMap.insert(key, {\n        type: ChangeType.Added,\n        doc: change.doc\n      });\n    } else if (\n      change.type === ChangeType.Removed &&\n      oldChange.type === ChangeType.Added\n    ) {\n      this.changeMap = this.changeMap.remove(key);\n    } else if (\n      change.type === ChangeType.Removed &&\n      oldChange.type === ChangeType.Modified\n    ) {\n      this.changeMap = this.changeMap.insert(key, {\n        type: ChangeType.Removed,\n        doc: oldChange.doc\n      });\n    } else if (\n      change.type === ChangeType.Added &&\n      oldChange.type === ChangeType.Removed\n    ) {\n      this.changeMap = this.changeMap.insert(key, {\n        type: ChangeType.Modified,\n        doc: change.doc\n      });\n    } else {\n      // This includes these cases, which don't make sense:\n      // Added->Added\n      // Removed->Removed\n      // Modified->Added\n      // Removed->Modified\n      // Metadata->Added\n      // Removed->Metadata\n      fail(\n        'unsupported combination of changes: ' +\n          JSON.stringify(change) +\n          ' after ' +\n          JSON.stringify(oldChange)\n      );\n    }\n  }\n\n  getChanges(): DocumentViewChange[] {\n    const changes: DocumentViewChange[] = [];\n    this.changeMap.inorderTraversal(\n      (key: DocumentKey, change: DocumentViewChange) => {\n        changes.push(change);\n      }\n    );\n    return changes;\n  }\n}\n\nexport class ViewSnapshot {\n  constructor(\n    readonly query: Query,\n    readonly docs: DocumentSet,\n    readonly oldDocs: DocumentSet,\n    readonly docChanges: DocumentViewChange[],\n    readonly mutatedKeys: DocumentKeySet,\n    readonly fromCache: boolean,\n    readonly syncStateChanged: boolean,\n    readonly excludesMetadataChanges: boolean\n  ) {}\n\n  /** Returns a view snapshot as if all documents in the snapshot were added. */\n  static fromInitialDocuments(\n    query: Query,\n    documents: DocumentSet,\n    mutatedKeys: DocumentKeySet,\n    fromCache: boolean\n  ): ViewSnapshot {\n    const changes: DocumentViewChange[] = [];\n    documents.forEach(doc => {\n      changes.push({ type: ChangeType.Added, doc });\n    });\n\n    return new ViewSnapshot(\n      query,\n      documents,\n      DocumentSet.emptySet(documents),\n      changes,\n      mutatedKeys,\n      fromCache,\n      /* syncStateChanged= */ true,\n      /* excludesMetadataChanges= */ false\n    );\n  }\n\n  get hasPendingWrites(): boolean {\n    return !this.mutatedKeys.isEmpty();\n  }\n\n  isEqual(other: ViewSnapshot): boolean {\n    if (\n      this.fromCache !== other.fromCache ||\n      this.syncStateChanged !== other.syncStateChanged ||\n      !this.mutatedKeys.isEqual(other.mutatedKeys) ||\n      !queryEquals(this.query, other.query) ||\n      !this.docs.isEqual(other.docs) ||\n      !this.oldDocs.isEqual(other.oldDocs)\n    ) {\n      return false;\n    }\n    const changes: DocumentViewChange[] = this.docChanges;\n    const otherChanges: DocumentViewChange[] = other.docChanges;\n    if (changes.length !== otherChanges.length) {\n      return false;\n    }\n    for (let i = 0; i < changes.length; i++) {\n      if (\n        changes[i].type !== otherChanges[i].type ||\n        !changes[i].doc.isEqual(otherChanges[i].doc)\n      ) {\n        return false;\n      }\n    }\n    return true;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { TargetId } from '../core/types';\nimport {\n  documentKeySet,\n  DocumentKeySet,\n  maybeDocumentMap,\n  MaybeDocumentMap,\n  targetIdSet\n} from '../model/collections';\nimport { SortedSet } from '../util/sorted_set';\nimport { ByteString } from '../util/byte_string';\n\n/**\n * An event from the RemoteStore. It is split into targetChanges (changes to the\n * state or the set of documents in our watched targets) and documentUpdates\n * (changes to the actual documents).\n */\nexport class RemoteEvent {\n  constructor(\n    /**\n     * The snapshot version this event brings us up to, or MIN if not set.\n     */\n    readonly snapshotVersion: SnapshotVersion,\n    /**\n     * A map from target to changes to the target. See TargetChange.\n     */\n    readonly targetChanges: Map<TargetId, TargetChange>,\n    /**\n     * A set of targets that is known to be inconsistent. Listens for these\n     * targets should be re-established without resume tokens.\n     */\n    readonly targetMismatches: SortedSet<TargetId>,\n    /**\n     * A set of which documents have changed or been deleted, along with the\n     * doc's new values (if not deleted).\n     */\n    readonly documentUpdates: MaybeDocumentMap,\n    /**\n     * A set of which document updates are due only to limbo resolution targets.\n     */\n    readonly resolvedLimboDocuments: DocumentKeySet\n  ) {}\n\n  /**\n   * HACK: Views require RemoteEvents in order to determine whether the view is\n   * CURRENT, but secondary tabs don't receive remote events. So this method is\n   * used to create a synthesized RemoteEvent that can be used to apply a\n   * CURRENT status change to a View, for queries executed in a different tab.\n   */\n  // PORTING NOTE: Multi-tab only\n  static createSynthesizedRemoteEventForCurrentChange(\n    targetId: TargetId,\n    current: boolean\n  ): RemoteEvent {\n    const targetChanges = new Map<TargetId, TargetChange>();\n    targetChanges.set(\n      targetId,\n      TargetChange.createSynthesizedTargetChangeForCurrentChange(\n        targetId,\n        current\n      )\n    );\n    return new RemoteEvent(\n      SnapshotVersion.min(),\n      targetChanges,\n      targetIdSet(),\n      maybeDocumentMap(),\n      documentKeySet()\n    );\n  }\n}\n\n/**\n * A TargetChange specifies the set of changes for a specific target as part of\n * a RemoteEvent. These changes track which documents are added, modified or\n * removed, as well as the target's resume token and whether the target is\n * marked CURRENT.\n * The actual changes *to* documents are not part of the TargetChange since\n * documents may be part of multiple targets.\n */\nexport class TargetChange {\n  constructor(\n    /**\n     * An opaque, server-assigned token that allows watching a query to be resumed\n     * after disconnecting without retransmitting all the data that matches the\n     * query. The resume token essentially identifies a point in time from which\n     * the server should resume sending results.\n     */\n    readonly resumeToken: ByteString,\n    /**\n     * The \"current\" (synced) status of this target. Note that \"current\"\n     * has special meaning in the RPC protocol that implies that a target is\n     * both up-to-date and consistent with the rest of the watch stream.\n     */\n    readonly current: boolean,\n    /**\n     * The set of documents that were newly assigned to this target as part of\n     * this remote event.\n     */\n    readonly addedDocuments: DocumentKeySet,\n    /**\n     * The set of documents that were already assigned to this target but received\n     * an update during this remote event.\n     */\n    readonly modifiedDocuments: DocumentKeySet,\n    /**\n     * The set of documents that were removed from this target as part of this\n     * remote event.\n     */\n    readonly removedDocuments: DocumentKeySet\n  ) {}\n\n  /**\n   * This method is used to create a synthesized TargetChanges that can be used to\n   * apply a CURRENT status change to a View (for queries executed in a different\n   * tab) or for new queries (to raise snapshots with correct CURRENT status).\n   */\n  static createSynthesizedTargetChangeForCurrentChange(\n    targetId: TargetId,\n    current: boolean\n  ): TargetChange {\n    return new TargetChange(\n      ByteString.EMPTY_BYTE_STRING,\n      current,\n      documentKeySet(),\n      documentKeySet(),\n      documentKeySet()\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { TargetId } from '../core/types';\nimport { ChangeType } from '../core/view_snapshot';\nimport { TargetData, TargetPurpose } from '../local/target_data';\nimport {\n  documentKeySet,\n  DocumentKeySet,\n  maybeDocumentMap\n} from '../model/collections';\nimport { Document, MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { debugAssert, fail, hardAssert } from '../util/assert';\nimport { FirestoreError } from '../util/error';\nimport { logDebug } from '../util/log';\nimport { primitiveComparator } from '../util/misc';\nimport { SortedMap } from '../util/sorted_map';\nimport { SortedSet } from '../util/sorted_set';\nimport { ExistenceFilter } from './existence_filter';\nimport { RemoteEvent, TargetChange } from './remote_event';\nimport { ByteString } from '../util/byte_string';\nimport { isDocumentTarget } from '../core/target';\n\n/**\n * Internal representation of the watcher API protocol buffers.\n */\nexport type WatchChange =\n  | DocumentWatchChange\n  | WatchTargetChange\n  | ExistenceFilterChange;\n\n/**\n * Represents a changed document and a list of target ids to which this change\n * applies.\n *\n * If document has been deleted NoDocument will be provided.\n */\nexport class DocumentWatchChange {\n  constructor(\n    /** The new document applies to all of these targets. */\n    public updatedTargetIds: TargetId[],\n    /** The new document is removed from all of these targets. */\n    public removedTargetIds: TargetId[],\n    /** The key of the document for this change. */\n    public key: DocumentKey,\n    /**\n     * The new document or NoDocument if it was deleted. Is null if the\n     * document went out of view without the server sending a new document.\n     */\n    public newDoc: MaybeDocument | null\n  ) {}\n}\n\nexport class ExistenceFilterChange {\n  constructor(\n    public targetId: TargetId,\n    public existenceFilter: ExistenceFilter\n  ) {}\n}\n\nexport const enum WatchTargetChangeState {\n  NoChange,\n  Added,\n  Removed,\n  Current,\n  Reset\n}\n\nexport class WatchTargetChange {\n  constructor(\n    /** What kind of change occurred to the watch target. */\n    public state: WatchTargetChangeState,\n    /** The target IDs that were added/removed/set. */\n    public targetIds: TargetId[],\n    /**\n     * An opaque, server-assigned token that allows watching a target to be\n     * resumed after disconnecting without retransmitting all the data that\n     * matches the target. The resume token essentially identifies a point in\n     * time from which the server should resume sending results.\n     */\n    public resumeToken: ByteString = ByteString.EMPTY_BYTE_STRING,\n    /** An RPC error indicating why the watch failed. */\n    public cause: FirestoreError | null = null\n  ) {}\n}\n\n/** Tracks the internal state of a Watch target. */\nclass TargetState {\n  /**\n   * The number of pending responses (adds or removes) that we are waiting on.\n   * We only consider targets active that have no pending responses.\n   */\n  private pendingResponses = 0;\n\n  /**\n   * Keeps track of the document changes since the last raised snapshot.\n   *\n   * These changes are continuously updated as we receive document updates and\n   * always reflect the current set of changes against the last issued snapshot.\n   */\n  private documentChanges: SortedMap<\n    DocumentKey,\n    ChangeType\n  > = snapshotChangesMap();\n\n  /** See public getters for explanations of these fields. */\n  private _resumeToken: ByteString = ByteString.EMPTY_BYTE_STRING;\n  private _current = false;\n\n  /**\n   * Whether this target state should be included in the next snapshot. We\n   * initialize to true so that newly-added targets are included in the next\n   * RemoteEvent.\n   */\n  private _hasPendingChanges = true;\n\n  /**\n   * Whether this target has been marked 'current'.\n   *\n   * 'Current' has special meaning in the RPC protocol: It implies that the\n   * Watch backend has sent us all changes up to the point at which the target\n   * was added and that the target is consistent with the rest of the watch\n   * stream.\n   */\n  get current(): boolean {\n    return this._current;\n  }\n\n  /** The last resume token sent to us for this target. */\n  get resumeToken(): ByteString {\n    return this._resumeToken;\n  }\n\n  /** Whether this target has pending target adds or target removes. */\n  get isPending(): boolean {\n    return this.pendingResponses !== 0;\n  }\n\n  /** Whether we have modified any state that should trigger a snapshot. */\n  get hasPendingChanges(): boolean {\n    return this._hasPendingChanges;\n  }\n\n  /**\n   * Applies the resume token to the TargetChange, but only when it has a new\n   * value. Empty resumeTokens are discarded.\n   */\n  updateResumeToken(resumeToken: ByteString): void {\n    if (resumeToken.approximateByteSize() > 0) {\n      this._hasPendingChanges = true;\n      this._resumeToken = resumeToken;\n    }\n  }\n\n  /**\n   * Creates a target change from the current set of changes.\n   *\n   * To reset the document changes after raising this snapshot, call\n   * `clearPendingChanges()`.\n   */\n  toTargetChange(): TargetChange {\n    let addedDocuments = documentKeySet();\n    let modifiedDocuments = documentKeySet();\n    let removedDocuments = documentKeySet();\n\n    this.documentChanges.forEach((key, changeType) => {\n      switch (changeType) {\n        case ChangeType.Added:\n          addedDocuments = addedDocuments.add(key);\n          break;\n        case ChangeType.Modified:\n          modifiedDocuments = modifiedDocuments.add(key);\n          break;\n        case ChangeType.Removed:\n          removedDocuments = removedDocuments.add(key);\n          break;\n        default:\n          fail('Encountered invalid change type: ' + changeType);\n      }\n    });\n\n    return new TargetChange(\n      this._resumeToken,\n      this._current,\n      addedDocuments,\n      modifiedDocuments,\n      removedDocuments\n    );\n  }\n\n  /**\n   * Resets the document changes and sets `hasPendingChanges` to false.\n   */\n  clearPendingChanges(): void {\n    this._hasPendingChanges = false;\n    this.documentChanges = snapshotChangesMap();\n  }\n\n  addDocumentChange(key: DocumentKey, changeType: ChangeType): void {\n    this._hasPendingChanges = true;\n    this.documentChanges = this.documentChanges.insert(key, changeType);\n  }\n\n  removeDocumentChange(key: DocumentKey): void {\n    this._hasPendingChanges = true;\n    this.documentChanges = this.documentChanges.remove(key);\n  }\n\n  recordPendingTargetRequest(): void {\n    this.pendingResponses += 1;\n  }\n\n  recordTargetResponse(): void {\n    this.pendingResponses -= 1;\n  }\n\n  markCurrent(): void {\n    this._hasPendingChanges = true;\n    this._current = true;\n  }\n}\n\n/**\n * Interface implemented by RemoteStore to expose target metadata to the\n * WatchChangeAggregator.\n */\nexport interface TargetMetadataProvider {\n  /**\n   * Returns the set of remote document keys for the given target ID as of the\n   * last raised snapshot.\n   */\n  getRemoteKeysForTarget(targetId: TargetId): DocumentKeySet;\n\n  /**\n   * Returns the TargetData for an active target ID or 'null' if this target\n   * has become inactive\n   */\n  getTargetDataForTarget(targetId: TargetId): TargetData | null;\n}\n\nconst LOG_TAG = 'WatchChangeAggregator';\n\n/**\n * A helper class to accumulate watch changes into a RemoteEvent.\n */\nexport class WatchChangeAggregator {\n  constructor(private metadataProvider: TargetMetadataProvider) {}\n\n  /** The internal state of all tracked targets. */\n  private targetStates = new Map<TargetId, TargetState>();\n\n  /** Keeps track of the documents to update since the last raised snapshot. */\n  private pendingDocumentUpdates = maybeDocumentMap();\n\n  /** A mapping of document keys to their set of target IDs. */\n  private pendingDocumentTargetMapping = documentTargetMap();\n\n  /**\n   * A list of targets with existence filter mismatches. These targets are\n   * known to be inconsistent and their listens needs to be re-established by\n   * RemoteStore.\n   */\n  private pendingTargetResets = new SortedSet<TargetId>(primitiveComparator);\n\n  /**\n   * Processes and adds the DocumentWatchChange to the current set of changes.\n   */\n  handleDocumentChange(docChange: DocumentWatchChange): void {\n    for (const targetId of docChange.updatedTargetIds) {\n      if (docChange.newDoc instanceof Document) {\n        this.addDocumentToTarget(targetId, docChange.newDoc);\n      } else if (docChange.newDoc instanceof NoDocument) {\n        this.removeDocumentFromTarget(\n          targetId,\n          docChange.key,\n          docChange.newDoc\n        );\n      }\n    }\n\n    for (const targetId of docChange.removedTargetIds) {\n      this.removeDocumentFromTarget(targetId, docChange.key, docChange.newDoc);\n    }\n  }\n\n  /** Processes and adds the WatchTargetChange to the current set of changes. */\n  handleTargetChange(targetChange: WatchTargetChange): void {\n    this.forEachTarget(targetChange, targetId => {\n      const targetState = this.ensureTargetState(targetId);\n      switch (targetChange.state) {\n        case WatchTargetChangeState.NoChange:\n          if (this.isActiveTarget(targetId)) {\n            targetState.updateResumeToken(targetChange.resumeToken);\n          }\n          break;\n        case WatchTargetChangeState.Added:\n          // We need to decrement the number of pending acks needed from watch\n          // for this targetId.\n          targetState.recordTargetResponse();\n          if (!targetState.isPending) {\n            // We have a freshly added target, so we need to reset any state\n            // that we had previously. This can happen e.g. when remove and add\n            // back a target for existence filter mismatches.\n            targetState.clearPendingChanges();\n          }\n          targetState.updateResumeToken(targetChange.resumeToken);\n          break;\n        case WatchTargetChangeState.Removed:\n          // We need to keep track of removed targets to we can post-filter and\n          // remove any target changes.\n          // We need to decrement the number of pending acks needed from watch\n          // for this targetId.\n          targetState.recordTargetResponse();\n          if (!targetState.isPending) {\n            this.removeTarget(targetId);\n          }\n          debugAssert(\n            !targetChange.cause,\n            'WatchChangeAggregator does not handle errored targets'\n          );\n          break;\n        case WatchTargetChangeState.Current:\n          if (this.isActiveTarget(targetId)) {\n            targetState.markCurrent();\n            targetState.updateResumeToken(targetChange.resumeToken);\n          }\n          break;\n        case WatchTargetChangeState.Reset:\n          if (this.isActiveTarget(targetId)) {\n            // Reset the target and synthesizes removes for all existing\n            // documents. The backend will re-add any documents that still\n            // match the target before it sends the next global snapshot.\n            this.resetTarget(targetId);\n            targetState.updateResumeToken(targetChange.resumeToken);\n          }\n          break;\n        default:\n          fail('Unknown target watch change state: ' + targetChange.state);\n      }\n    });\n  }\n\n  /**\n   * Iterates over all targetIds that the watch change applies to: either the\n   * targetIds explicitly listed in the change or the targetIds of all currently\n   * active targets.\n   */\n  forEachTarget(\n    targetChange: WatchTargetChange,\n    fn: (targetId: TargetId) => void\n  ): void {\n    if (targetChange.targetIds.length > 0) {\n      targetChange.targetIds.forEach(fn);\n    } else {\n      this.targetStates.forEach((_, targetId) => {\n        if (this.isActiveTarget(targetId)) {\n          fn(targetId);\n        }\n      });\n    }\n  }\n\n  /**\n   * Handles existence filters and synthesizes deletes for filter mismatches.\n   * Targets that are invalidated by filter mismatches are added to\n   * `pendingTargetResets`.\n   */\n  handleExistenceFilter(watchChange: ExistenceFilterChange): void {\n    const targetId = watchChange.targetId;\n    const expectedCount = watchChange.existenceFilter.count;\n\n    const targetData = this.targetDataForActiveTarget(targetId);\n    if (targetData) {\n      const target = targetData.target;\n      if (isDocumentTarget(target)) {\n        if (expectedCount === 0) {\n          // The existence filter told us the document does not exist. We deduce\n          // that this document does not exist and apply a deleted document to\n          // our updates. Without applying this deleted document there might be\n          // another query that will raise this document as part of a snapshot\n          // until it is resolved, essentially exposing inconsistency between\n          // queries.\n          const key = new DocumentKey(target.path);\n          this.removeDocumentFromTarget(\n            targetId,\n            key,\n            new NoDocument(key, SnapshotVersion.min())\n          );\n        } else {\n          hardAssert(\n            expectedCount === 1,\n            'Single document existence filter with count: ' + expectedCount\n          );\n        }\n      } else {\n        const currentSize = this.getCurrentDocumentCountForTarget(targetId);\n        if (currentSize !== expectedCount) {\n          // Existence filter mismatch: We reset the mapping and raise a new\n          // snapshot with `isFromCache:true`.\n          this.resetTarget(targetId);\n          this.pendingTargetResets = this.pendingTargetResets.add(targetId);\n        }\n      }\n    }\n  }\n\n  /**\n   * Converts the currently accumulated state into a remote event at the\n   * provided snapshot version. Resets the accumulated changes before returning.\n   */\n  createRemoteEvent(snapshotVersion: SnapshotVersion): RemoteEvent {\n    const targetChanges = new Map<TargetId, TargetChange>();\n\n    this.targetStates.forEach((targetState, targetId) => {\n      const targetData = this.targetDataForActiveTarget(targetId);\n      if (targetData) {\n        if (targetState.current && isDocumentTarget(targetData.target)) {\n          // Document queries for document that don't exist can produce an empty\n          // result set. To update our local cache, we synthesize a document\n          // delete if we have not previously received the document. This\n          // resolves the limbo state of the document, removing it from\n          // limboDocumentRefs.\n          //\n          // TODO(dimond): Ideally we would have an explicit lookup target\n          // instead resulting in an explicit delete message and we could\n          // remove this special logic.\n          const key = new DocumentKey(targetData.target.path);\n          if (\n            this.pendingDocumentUpdates.get(key) === null &&\n            !this.targetContainsDocument(targetId, key)\n          ) {\n            this.removeDocumentFromTarget(\n              targetId,\n              key,\n              new NoDocument(key, snapshotVersion)\n            );\n          }\n        }\n\n        if (targetState.hasPendingChanges) {\n          targetChanges.set(targetId, targetState.toTargetChange());\n          targetState.clearPendingChanges();\n        }\n      }\n    });\n\n    let resolvedLimboDocuments = documentKeySet();\n\n    // We extract the set of limbo-only document updates as the GC logic\n    // special-cases documents that do not appear in the target cache.\n    //\n    // TODO(gsoltis): Expand on this comment once GC is available in the JS\n    // client.\n    this.pendingDocumentTargetMapping.forEach((key, targets) => {\n      let isOnlyLimboTarget = true;\n\n      targets.forEachWhile(targetId => {\n        const targetData = this.targetDataForActiveTarget(targetId);\n        if (\n          targetData &&\n          targetData.purpose !== TargetPurpose.LimboResolution\n        ) {\n          isOnlyLimboTarget = false;\n          return false;\n        }\n\n        return true;\n      });\n\n      if (isOnlyLimboTarget) {\n        resolvedLimboDocuments = resolvedLimboDocuments.add(key);\n      }\n    });\n\n    const remoteEvent = new RemoteEvent(\n      snapshotVersion,\n      targetChanges,\n      this.pendingTargetResets,\n      this.pendingDocumentUpdates,\n      resolvedLimboDocuments\n    );\n\n    this.pendingDocumentUpdates = maybeDocumentMap();\n    this.pendingDocumentTargetMapping = documentTargetMap();\n    this.pendingTargetResets = new SortedSet<TargetId>(primitiveComparator);\n\n    return remoteEvent;\n  }\n\n  /**\n   * Adds the provided document to the internal list of document updates and\n   * its document key to the given target's mapping.\n   */\n  // Visible for testing.\n  addDocumentToTarget(targetId: TargetId, document: MaybeDocument): void {\n    if (!this.isActiveTarget(targetId)) {\n      return;\n    }\n\n    const changeType = this.targetContainsDocument(targetId, document.key)\n      ? ChangeType.Modified\n      : ChangeType.Added;\n\n    const targetState = this.ensureTargetState(targetId);\n    targetState.addDocumentChange(document.key, changeType);\n\n    this.pendingDocumentUpdates = this.pendingDocumentUpdates.insert(\n      document.key,\n      document\n    );\n\n    this.pendingDocumentTargetMapping = this.pendingDocumentTargetMapping.insert(\n      document.key,\n      this.ensureDocumentTargetMapping(document.key).add(targetId)\n    );\n  }\n\n  /**\n   * Removes the provided document from the target mapping. If the\n   * document no longer matches the target, but the document's state is still\n   * known (e.g. we know that the document was deleted or we received the change\n   * that caused the filter mismatch), the new document can be provided\n   * to update the remote document cache.\n   */\n  // Visible for testing.\n  removeDocumentFromTarget(\n    targetId: TargetId,\n    key: DocumentKey,\n    updatedDocument: MaybeDocument | null\n  ): void {\n    if (!this.isActiveTarget(targetId)) {\n      return;\n    }\n\n    const targetState = this.ensureTargetState(targetId);\n    if (this.targetContainsDocument(targetId, key)) {\n      targetState.addDocumentChange(key, ChangeType.Removed);\n    } else {\n      // The document may have entered and left the target before we raised a\n      // snapshot, so we can just ignore the change.\n      targetState.removeDocumentChange(key);\n    }\n\n    this.pendingDocumentTargetMapping = this.pendingDocumentTargetMapping.insert(\n      key,\n      this.ensureDocumentTargetMapping(key).delete(targetId)\n    );\n\n    if (updatedDocument) {\n      this.pendingDocumentUpdates = this.pendingDocumentUpdates.insert(\n        key,\n        updatedDocument\n      );\n    }\n  }\n\n  removeTarget(targetId: TargetId): void {\n    this.targetStates.delete(targetId);\n  }\n\n  /**\n   * Returns the current count of documents in the target. This includes both\n   * the number of documents that the LocalStore considers to be part of the\n   * target as well as any accumulated changes.\n   */\n  private getCurrentDocumentCountForTarget(targetId: TargetId): number {\n    const targetState = this.ensureTargetState(targetId);\n    const targetChange = targetState.toTargetChange();\n    return (\n      this.metadataProvider.getRemoteKeysForTarget(targetId).size +\n      targetChange.addedDocuments.size -\n      targetChange.removedDocuments.size\n    );\n  }\n\n  /**\n   * Increment the number of acks needed from watch before we can consider the\n   * server to be 'in-sync' with the client's active targets.\n   */\n  recordPendingTargetRequest(targetId: TargetId): void {\n    // For each request we get we need to record we need a response for it.\n    const targetState = this.ensureTargetState(targetId);\n    targetState.recordPendingTargetRequest();\n  }\n\n  private ensureTargetState(targetId: TargetId): TargetState {\n    let result = this.targetStates.get(targetId);\n    if (!result) {\n      result = new TargetState();\n      this.targetStates.set(targetId, result);\n    }\n    return result;\n  }\n\n  private ensureDocumentTargetMapping(key: DocumentKey): SortedSet<TargetId> {\n    let targetMapping = this.pendingDocumentTargetMapping.get(key);\n\n    if (!targetMapping) {\n      targetMapping = new SortedSet<TargetId>(primitiveComparator);\n      this.pendingDocumentTargetMapping = this.pendingDocumentTargetMapping.insert(\n        key,\n        targetMapping\n      );\n    }\n\n    return targetMapping;\n  }\n\n  /**\n   * Verifies that the user is still interested in this target (by calling\n   * `getTargetDataForTarget()`) and that we are not waiting for pending ADDs\n   * from watch.\n   */\n  protected isActiveTarget(targetId: TargetId): boolean {\n    const targetActive = this.targetDataForActiveTarget(targetId) !== null;\n    if (!targetActive) {\n      logDebug(LOG_TAG, 'Detected inactive target', targetId);\n    }\n    return targetActive;\n  }\n\n  /**\n   * Returns the TargetData for an active target (i.e. a target that the user\n   * is still interested in that has no outstanding target change requests).\n   */\n  protected targetDataForActiveTarget(targetId: TargetId): TargetData | null {\n    const targetState = this.targetStates.get(targetId);\n    return targetState && targetState.isPending\n      ? null\n      : this.metadataProvider.getTargetDataForTarget(targetId);\n  }\n\n  /**\n   * Resets the state of a Watch target to its initial state (e.g. sets\n   * 'current' to false, clears the resume token and removes its target mapping\n   * from all documents).\n   */\n  private resetTarget(targetId: TargetId): void {\n    debugAssert(\n      !this.targetStates.get(targetId)!.isPending,\n      'Should only reset active targets'\n    );\n    this.targetStates.set(targetId, new TargetState());\n\n    // Trigger removal for any documents currently mapped to this target.\n    // These removals will be part of the initial snapshot if Watch does not\n    // resend these documents.\n    const existingKeys = this.metadataProvider.getRemoteKeysForTarget(targetId);\n    existingKeys.forEach(key => {\n      this.removeDocumentFromTarget(targetId, key, /*updatedDocument=*/ null);\n    });\n  }\n  /**\n   * Returns whether the LocalStore considers the document to be part of the\n   * specified target.\n   */\n  private targetContainsDocument(\n    targetId: TargetId,\n    key: DocumentKey\n  ): boolean {\n    const existingKeys = this.metadataProvider.getRemoteKeysForTarget(targetId);\n    return existingKeys.has(key);\n  }\n}\n\nfunction documentTargetMap(): SortedMap<DocumentKey, SortedSet<TargetId>> {\n  return new SortedMap<DocumentKey, SortedSet<TargetId>>(\n    DocumentKey.comparator\n  );\n}\n\nfunction snapshotChangesMap(): SortedMap<DocumentKey, ChangeType> {\n  return new SortedMap<DocumentKey, ChangeType>(DocumentKey.comparator);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\nimport { Timestamp } from '../api/timestamp';\nimport { normalizeTimestamp } from './values';\n\n/**\n * Represents a locally-applied ServerTimestamp.\n *\n * Server Timestamps are backed by MapValues that contain an internal field\n * `__type__` with a value of `server_timestamp`. The previous value and local\n * write time are stored in its `__previous_value__` and `__local_write_time__`\n * fields respectively.\n *\n * Notes:\n * - ServerTimestampValue instances are created as the result of applying a\n *   TransformMutation (see TransformMutation.applyTo()). They can only exist in\n *   the local view of a document. Therefore they do not need to be parsed or\n *   serialized.\n * - When evaluated locally (e.g. for snapshot.data()), they by default\n *   evaluate to `null`. This behavior can be configured by passing custom\n *   FieldValueOptions to value().\n * - With respect to other ServerTimestampValues, they sort by their\n *   localWriteTime.\n */\n\nconst SERVER_TIMESTAMP_SENTINEL = 'server_timestamp';\nconst TYPE_KEY = '__type__';\nconst PREVIOUS_VALUE_KEY = '__previous_value__';\nconst LOCAL_WRITE_TIME_KEY = '__local_write_time__';\n\nexport function isServerTimestamp(value: api.Value | null): boolean {\n  const type = (value?.mapValue?.fields || {})[TYPE_KEY]?.stringValue;\n  return type === SERVER_TIMESTAMP_SENTINEL;\n}\n\n/**\n * Creates a new ServerTimestamp proto value (using the internal format).\n */\nexport function serverTimestamp(\n  localWriteTime: Timestamp,\n  previousValue: api.Value | null\n): api.Value {\n  const mapValue: api.MapValue = {\n    fields: {\n      [TYPE_KEY]: {\n        stringValue: SERVER_TIMESTAMP_SENTINEL\n      },\n      [LOCAL_WRITE_TIME_KEY]: {\n        timestampValue: {\n          seconds: localWriteTime.seconds,\n          nanos: localWriteTime.nanoseconds\n        }\n      }\n    }\n  };\n\n  if (previousValue) {\n    mapValue.fields![PREVIOUS_VALUE_KEY] = previousValue;\n  }\n\n  return { mapValue };\n}\n\n/**\n * Returns the value of the field before this ServerTimestamp was set.\n *\n * Preserving the previous values allows the user to display the last resoled\n * value until the backend responds with the timestamp.\n */\nexport function getPreviousValue(value: api.Value): api.Value | null {\n  const previousValue = value.mapValue!.fields![PREVIOUS_VALUE_KEY];\n\n  if (isServerTimestamp(previousValue)) {\n    return getPreviousValue(previousValue);\n  }\n  return previousValue;\n}\n\n/**\n * Returns the local time at which this timestamp was first set.\n */\nexport function getLocalWriteTime(value: api.Value): Timestamp {\n  const localWriteTime = normalizeTimestamp(\n    value.mapValue!.fields![LOCAL_WRITE_TIME_KEY].timestampValue!\n  );\n  return new Timestamp(localWriteTime.seconds, localWriteTime.nanos);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { TypeOrder } from './object_value';\nimport { fail, hardAssert } from '../util/assert';\nimport { forEach, objectSize } from '../util/obj';\nimport { ByteString } from '../util/byte_string';\nimport { isNegativeZero } from '../util/types';\nimport { DocumentKey } from './document_key';\nimport { arrayEquals, primitiveComparator } from '../util/misc';\nimport { DatabaseId } from '../core/database_info';\nimport {\n  getLocalWriteTime,\n  getPreviousValue,\n  isServerTimestamp\n} from './server_timestamps';\n\n// A RegExp matching ISO 8601 UTC timestamps with optional fraction.\nconst ISO_TIMESTAMP_REG_EXP = new RegExp(\n  /^\\d{4}-\\d\\d-\\d\\dT\\d\\d:\\d\\d:\\d\\d(?:\\.(\\d+))?Z$/\n);\n\n/** Extracts the backend's type order for the provided value. */\nexport function typeOrder(value: api.Value): TypeOrder {\n  if ('nullValue' in value) {\n    return TypeOrder.NullValue;\n  } else if ('booleanValue' in value) {\n    return TypeOrder.BooleanValue;\n  } else if ('integerValue' in value || 'doubleValue' in value) {\n    return TypeOrder.NumberValue;\n  } else if ('timestampValue' in value) {\n    return TypeOrder.TimestampValue;\n  } else if ('stringValue' in value) {\n    return TypeOrder.StringValue;\n  } else if ('bytesValue' in value) {\n    return TypeOrder.BlobValue;\n  } else if ('referenceValue' in value) {\n    return TypeOrder.RefValue;\n  } else if ('geoPointValue' in value) {\n    return TypeOrder.GeoPointValue;\n  } else if ('arrayValue' in value) {\n    return TypeOrder.ArrayValue;\n  } else if ('mapValue' in value) {\n    if (isServerTimestamp(value)) {\n      return TypeOrder.ServerTimestampValue;\n    }\n    return TypeOrder.ObjectValue;\n  } else {\n    return fail('Invalid value type: ' + JSON.stringify(value));\n  }\n}\n\n/** Tests `left` and `right` for equality based on the backend semantics. */\nexport function valueEquals(left: api.Value, right: api.Value): boolean {\n  const leftType = typeOrder(left);\n  const rightType = typeOrder(right);\n  if (leftType !== rightType) {\n    return false;\n  }\n\n  switch (leftType) {\n    case TypeOrder.NullValue:\n      return true;\n    case TypeOrder.BooleanValue:\n      return left.booleanValue === right.booleanValue;\n    case TypeOrder.ServerTimestampValue:\n      return getLocalWriteTime(left).isEqual(getLocalWriteTime(right));\n    case TypeOrder.TimestampValue:\n      return timestampEquals(left, right);\n    case TypeOrder.StringValue:\n      return left.stringValue === right.stringValue;\n    case TypeOrder.BlobValue:\n      return blobEquals(left, right);\n    case TypeOrder.RefValue:\n      return left.referenceValue === right.referenceValue;\n    case TypeOrder.GeoPointValue:\n      return geoPointEquals(left, right);\n    case TypeOrder.NumberValue:\n      return numberEquals(left, right);\n    case TypeOrder.ArrayValue:\n      return arrayEquals(\n        left.arrayValue!.values || [],\n        right.arrayValue!.values || [],\n        valueEquals\n      );\n    case TypeOrder.ObjectValue:\n      return objectEquals(left, right);\n    default:\n      return fail('Unexpected value type: ' + JSON.stringify(left));\n  }\n}\n\nfunction timestampEquals(left: api.Value, right: api.Value): boolean {\n  if (\n    typeof left.timestampValue === 'string' &&\n    typeof right.timestampValue === 'string' &&\n    left.timestampValue.length === right.timestampValue.length\n  ) {\n    // Use string equality for ISO 8601 timestamps\n    return left.timestampValue === right.timestampValue;\n  }\n\n  const leftTimestamp = normalizeTimestamp(left.timestampValue!);\n  const rightTimestamp = normalizeTimestamp(right.timestampValue!);\n  return (\n    leftTimestamp.seconds === rightTimestamp.seconds &&\n    leftTimestamp.nanos === rightTimestamp.nanos\n  );\n}\n\nfunction geoPointEquals(left: api.Value, right: api.Value): boolean {\n  return (\n    normalizeNumber(left.geoPointValue!.latitude) ===\n      normalizeNumber(right.geoPointValue!.latitude) &&\n    normalizeNumber(left.geoPointValue!.longitude) ===\n      normalizeNumber(right.geoPointValue!.longitude)\n  );\n}\n\nfunction blobEquals(left: api.Value, right: api.Value): boolean {\n  return normalizeByteString(left.bytesValue!).isEqual(\n    normalizeByteString(right.bytesValue!)\n  );\n}\n\nexport function numberEquals(left: api.Value, right: api.Value): boolean {\n  if ('integerValue' in left && 'integerValue' in right) {\n    return (\n      normalizeNumber(left.integerValue) === normalizeNumber(right.integerValue)\n    );\n  } else if ('doubleValue' in left && 'doubleValue' in right) {\n    const n1 = normalizeNumber(left.doubleValue!);\n    const n2 = normalizeNumber(right.doubleValue!);\n\n    if (n1 === n2) {\n      return isNegativeZero(n1) === isNegativeZero(n2);\n    } else {\n      return isNaN(n1) && isNaN(n2);\n    }\n  }\n\n  return false;\n}\n\nfunction objectEquals(left: api.Value, right: api.Value): boolean {\n  const leftMap = left.mapValue!.fields || {};\n  const rightMap = right.mapValue!.fields || {};\n\n  if (objectSize(leftMap) !== objectSize(rightMap)) {\n    return false;\n  }\n\n  for (const key in leftMap) {\n    if (leftMap.hasOwnProperty(key)) {\n      if (\n        rightMap[key] === undefined ||\n        !valueEquals(leftMap[key], rightMap[key])\n      ) {\n        return false;\n      }\n    }\n  }\n  return true;\n}\n\n/** Returns true if the ArrayValue contains the specified element. */\nexport function arrayValueContains(\n  haystack: api.ArrayValue,\n  needle: api.Value\n): boolean {\n  return (\n    (haystack.values || []).find(v => valueEquals(v, needle)) !== undefined\n  );\n}\n\nexport function valueCompare(left: api.Value, right: api.Value): number {\n  const leftType = typeOrder(left);\n  const rightType = typeOrder(right);\n\n  if (leftType !== rightType) {\n    return primitiveComparator(leftType, rightType);\n  }\n\n  switch (leftType) {\n    case TypeOrder.NullValue:\n      return 0;\n    case TypeOrder.BooleanValue:\n      return primitiveComparator(left.booleanValue!, right.booleanValue!);\n    case TypeOrder.NumberValue:\n      return compareNumbers(left, right);\n    case TypeOrder.TimestampValue:\n      return compareTimestamps(left.timestampValue!, right.timestampValue!);\n    case TypeOrder.ServerTimestampValue:\n      return compareTimestamps(\n        getLocalWriteTime(left),\n        getLocalWriteTime(right)\n      );\n    case TypeOrder.StringValue:\n      return primitiveComparator(left.stringValue!, right.stringValue!);\n    case TypeOrder.BlobValue:\n      return compareBlobs(left.bytesValue!, right.bytesValue!);\n    case TypeOrder.RefValue:\n      return compareReferences(left.referenceValue!, right.referenceValue!);\n    case TypeOrder.GeoPointValue:\n      return compareGeoPoints(left.geoPointValue!, right.geoPointValue!);\n    case TypeOrder.ArrayValue:\n      return compareArrays(left.arrayValue!, right.arrayValue!);\n    case TypeOrder.ObjectValue:\n      return compareMaps(left.mapValue!, right.mapValue!);\n    default:\n      throw fail('Invalid value type: ' + leftType);\n  }\n}\n\nfunction compareNumbers(left: api.Value, right: api.Value): number {\n  const leftNumber = normalizeNumber(left.integerValue || left.doubleValue);\n  const rightNumber = normalizeNumber(right.integerValue || right.doubleValue);\n\n  if (leftNumber < rightNumber) {\n    return -1;\n  } else if (leftNumber > rightNumber) {\n    return 1;\n  } else if (leftNumber === rightNumber) {\n    return 0;\n  } else {\n    // one or both are NaN.\n    if (isNaN(leftNumber)) {\n      return isNaN(rightNumber) ? 0 : -1;\n    } else {\n      return 1;\n    }\n  }\n}\n\nfunction compareTimestamps(left: api.Timestamp, right: api.Timestamp): number {\n  if (\n    typeof left === 'string' &&\n    typeof right === 'string' &&\n    left.length === right.length\n  ) {\n    return primitiveComparator(left, right);\n  }\n\n  const leftTimestamp = normalizeTimestamp(left);\n  const rightTimestamp = normalizeTimestamp(right);\n\n  const comparison = primitiveComparator(\n    leftTimestamp.seconds,\n    rightTimestamp.seconds\n  );\n  if (comparison !== 0) {\n    return comparison;\n  }\n  return primitiveComparator(leftTimestamp.nanos, rightTimestamp.nanos);\n}\n\nfunction compareReferences(leftPath: string, rightPath: string): number {\n  const leftSegments = leftPath.split('/');\n  const rightSegments = rightPath.split('/');\n  for (let i = 0; i < leftSegments.length && i < rightSegments.length; i++) {\n    const comparison = primitiveComparator(leftSegments[i], rightSegments[i]);\n    if (comparison !== 0) {\n      return comparison;\n    }\n  }\n  return primitiveComparator(leftSegments.length, rightSegments.length);\n}\n\nfunction compareGeoPoints(left: api.LatLng, right: api.LatLng): number {\n  const comparison = primitiveComparator(\n    normalizeNumber(left.latitude),\n    normalizeNumber(right.latitude)\n  );\n  if (comparison !== 0) {\n    return comparison;\n  }\n  return primitiveComparator(\n    normalizeNumber(left.longitude),\n    normalizeNumber(right.longitude)\n  );\n}\n\nfunction compareBlobs(\n  left: string | Uint8Array,\n  right: string | Uint8Array\n): number {\n  const leftBytes = normalizeByteString(left);\n  const rightBytes = normalizeByteString(right);\n  return leftBytes.compareTo(rightBytes);\n}\n\nfunction compareArrays(left: api.ArrayValue, right: api.ArrayValue): number {\n  const leftArray = left.values || [];\n  const rightArray = right.values || [];\n\n  for (let i = 0; i < leftArray.length && i < rightArray.length; ++i) {\n    const compare = valueCompare(leftArray[i], rightArray[i]);\n    if (compare) {\n      return compare;\n    }\n  }\n  return primitiveComparator(leftArray.length, rightArray.length);\n}\n\nfunction compareMaps(left: api.MapValue, right: api.MapValue): number {\n  const leftMap = left.fields || {};\n  const leftKeys = Object.keys(leftMap);\n  const rightMap = right.fields || {};\n  const rightKeys = Object.keys(rightMap);\n\n  // Even though MapValues are likely sorted correctly based on their insertion\n  // order (e.g. when received from the backend), local modifications can bring\n  // elements out of order. We need to re-sort the elements to ensure that\n  // canonical IDs are independent of insertion order.\n  leftKeys.sort();\n  rightKeys.sort();\n\n  for (let i = 0; i < leftKeys.length && i < rightKeys.length; ++i) {\n    const keyCompare = primitiveComparator(leftKeys[i], rightKeys[i]);\n    if (keyCompare !== 0) {\n      return keyCompare;\n    }\n    const compare = valueCompare(leftMap[leftKeys[i]], rightMap[rightKeys[i]]);\n    if (compare !== 0) {\n      return compare;\n    }\n  }\n\n  return primitiveComparator(leftKeys.length, rightKeys.length);\n}\n\n/**\n * Generates the canonical ID for the provided field value (as used in Target\n * serialization).\n */\nexport function canonicalId(value: api.Value): string {\n  return canonifyValue(value);\n}\n\nfunction canonifyValue(value: api.Value): string {\n  if ('nullValue' in value) {\n    return 'null';\n  } else if ('booleanValue' in value) {\n    return '' + value.booleanValue!;\n  } else if ('integerValue' in value) {\n    return '' + value.integerValue!;\n  } else if ('doubleValue' in value) {\n    return '' + value.doubleValue!;\n  } else if ('timestampValue' in value) {\n    return canonifyTimestamp(value.timestampValue!);\n  } else if ('stringValue' in value) {\n    return value.stringValue!;\n  } else if ('bytesValue' in value) {\n    return canonifyByteString(value.bytesValue!);\n  } else if ('referenceValue' in value) {\n    return canonifyReference(value.referenceValue!);\n  } else if ('geoPointValue' in value) {\n    return canonifyGeoPoint(value.geoPointValue!);\n  } else if ('arrayValue' in value) {\n    return canonifyArray(value.arrayValue!);\n  } else if ('mapValue' in value) {\n    return canonifyMap(value.mapValue!);\n  } else {\n    return fail('Invalid value type: ' + JSON.stringify(value));\n  }\n}\n\nfunction canonifyByteString(byteString: string | Uint8Array): string {\n  return normalizeByteString(byteString).toBase64();\n}\n\nfunction canonifyTimestamp(timestamp: api.Timestamp): string {\n  const normalizedTimestamp = normalizeTimestamp(timestamp);\n  return `time(${normalizedTimestamp.seconds},${normalizedTimestamp.nanos})`;\n}\n\nfunction canonifyGeoPoint(geoPoint: api.LatLng): string {\n  return `geo(${geoPoint.latitude},${geoPoint.longitude})`;\n}\n\nfunction canonifyReference(referenceValue: string): string {\n  return DocumentKey.fromName(referenceValue).toString();\n}\n\nfunction canonifyMap(mapValue: api.MapValue): string {\n  // Iteration order in JavaScript is not guaranteed. To ensure that we generate\n  // matching canonical IDs for identical maps, we need to sort the keys.\n  const sortedKeys = Object.keys(mapValue.fields || {}).sort();\n\n  let result = '{';\n  let first = true;\n  for (const key of sortedKeys) {\n    if (!first) {\n      result += ',';\n    } else {\n      first = false;\n    }\n    result += `${key}:${canonifyValue(mapValue.fields![key])}`;\n  }\n  return result + '}';\n}\n\nfunction canonifyArray(arrayValue: api.ArrayValue): string {\n  let result = '[';\n  let first = true;\n  for (const value of arrayValue.values || []) {\n    if (!first) {\n      result += ',';\n    } else {\n      first = false;\n    }\n    result += canonifyValue(value);\n  }\n  return result + ']';\n}\n\n/**\n * Returns an approximate (and wildly inaccurate) in-memory size for the field\n * value.\n *\n * The memory size takes into account only the actual user data as it resides\n * in memory and ignores object overhead.\n */\nexport function estimateByteSize(value: api.Value): number {\n  switch (typeOrder(value)) {\n    case TypeOrder.NullValue:\n      return 4;\n    case TypeOrder.BooleanValue:\n      return 4;\n    case TypeOrder.NumberValue:\n      return 8;\n    case TypeOrder.TimestampValue:\n      // Timestamps are made up of two distinct numbers (seconds + nanoseconds)\n      return 16;\n    case TypeOrder.ServerTimestampValue:\n      const previousValue = getPreviousValue(value);\n      return previousValue ? 16 + estimateByteSize(previousValue) : 16;\n    case TypeOrder.StringValue:\n      // See https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures:\n      // \"JavaScript's String type is [...] a set of elements of 16-bit unsigned\n      // integer values\"\n      return value.stringValue!.length * 2;\n    case TypeOrder.BlobValue:\n      return normalizeByteString(value.bytesValue!).approximateByteSize();\n    case TypeOrder.RefValue:\n      return value.referenceValue!.length;\n    case TypeOrder.GeoPointValue:\n      // GeoPoints are made up of two distinct numbers (latitude + longitude)\n      return 16;\n    case TypeOrder.ArrayValue:\n      return estimateArrayByteSize(value.arrayValue!);\n    case TypeOrder.ObjectValue:\n      return estimateMapByteSize(value.mapValue!);\n    default:\n      throw fail('Invalid value type: ' + JSON.stringify(value));\n  }\n}\n\nfunction estimateMapByteSize(mapValue: api.MapValue): number {\n  let size = 0;\n  forEach(mapValue.fields || {}, (key, val) => {\n    size += key.length + estimateByteSize(val);\n  });\n  return size;\n}\n\nfunction estimateArrayByteSize(arrayValue: api.ArrayValue): number {\n  return (arrayValue.values || []).reduce(\n    (previousSize, value) => previousSize + estimateByteSize(value),\n    0\n  );\n}\n\n/**\n * Converts the possible Proto values for a timestamp value into a \"seconds and\n * nanos\" representation.\n */\nexport function normalizeTimestamp(\n  date: api.Timestamp\n): { seconds: number; nanos: number } {\n  hardAssert(!!date, 'Cannot normalize null or undefined timestamp.');\n\n  // The json interface (for the browser) will return an iso timestamp string,\n  // while the proto js library (for node) will return a\n  // google.protobuf.Timestamp instance.\n  if (typeof date === 'string') {\n    // The date string can have higher precision (nanos) than the Date class\n    // (millis), so we do some custom parsing here.\n\n    // Parse the nanos right out of the string.\n    let nanos = 0;\n    const fraction = ISO_TIMESTAMP_REG_EXP.exec(date);\n    hardAssert(!!fraction, 'invalid timestamp: ' + date);\n    if (fraction[1]) {\n      // Pad the fraction out to 9 digits (nanos).\n      let nanoStr = fraction[1];\n      nanoStr = (nanoStr + '000000000').substr(0, 9);\n      nanos = Number(nanoStr);\n    }\n\n    // Parse the date to get the seconds.\n    const parsedDate = new Date(date);\n    const seconds = Math.floor(parsedDate.getTime() / 1000);\n\n    return { seconds, nanos };\n  } else {\n    // TODO(b/37282237): Use strings for Proto3 timestamps\n    // assert(!this.options.useProto3Json,\n    //   'The timestamp instance format requires Proto JS.');\n    const seconds = normalizeNumber(date.seconds);\n    const nanos = normalizeNumber(date.nanos);\n    return { seconds, nanos };\n  }\n}\n\n/**\n * Converts the possible Proto types for numbers into a JavaScript number.\n * Returns 0 if the value is not numeric.\n */\nexport function normalizeNumber(value: number | string | undefined): number {\n  // TODO(bjornick): Handle int64 greater than 53 bits.\n  if (typeof value === 'number') {\n    return value;\n  } else if (typeof value === 'string') {\n    return Number(value);\n  } else {\n    return 0;\n  }\n}\n\n/** Converts the possible Proto types for Blobs into a ByteString. */\nexport function normalizeByteString(blob: string | Uint8Array): ByteString {\n  if (typeof blob === 'string') {\n    return ByteString.fromBase64String(blob);\n  } else {\n    return ByteString.fromUint8Array(blob);\n  }\n}\n\n/** Returns a reference value for the provided database and key. */\nexport function refValue(databaseId: DatabaseId, key: DocumentKey): api.Value {\n  return {\n    referenceValue: `projects/${databaseId.projectId}/databases/${\n      databaseId.database\n    }/documents/${key.path.canonicalString()}`\n  };\n}\n\n/** Returns true if `value` is an IntegerValue . */\nexport function isInteger(\n  value?: api.Value | null\n): value is { integerValue: string | number } {\n  return !!value && 'integerValue' in value;\n}\n\n/** Returns true if `value` is a DoubleValue. */\nexport function isDouble(\n  value?: api.Value | null\n): value is { doubleValue: string | number } {\n  return !!value && 'doubleValue' in value;\n}\n\n/** Returns true if `value` is either an IntegerValue or a DoubleValue. */\nexport function isNumber(value?: api.Value | null): boolean {\n  return isInteger(value) || isDouble(value);\n}\n\n/** Returns true if `value` is an ArrayValue. */\nexport function isArray(\n  value?: api.Value | null\n): value is { arrayValue: api.ArrayValue } {\n  return !!value && 'arrayValue' in value;\n}\n\n/** Returns true if `value` is a ReferenceValue. */\nexport function isReferenceValue(\n  value?: api.Value | null\n): value is { referenceValue: string } {\n  return !!value && 'referenceValue' in value;\n}\n\n/** Returns true if `value` is a NullValue. */\nexport function isNullValue(\n  value?: api.Value | null\n): value is { nullValue: 'NULL_VALUE' } {\n  return !!value && 'nullValue' in value;\n}\n\n/** Returns true if `value` is NaN. */\nexport function isNanValue(\n  value?: api.Value | null\n): value is { doubleValue: 'NaN' | number } {\n  return !!value && 'doubleValue' in value && isNaN(Number(value.doubleValue));\n}\n\n/** Returns true if `value` is a MapValue. */\nexport function isMapValue(\n  value?: api.Value | null\n): value is { mapValue: api.MapValue } {\n  return !!value && 'mapValue' in value;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Blob } from '../api/blob';\nimport { Timestamp } from '../api/timestamp';\nimport { DatabaseId } from '../core/database_info';\nimport {\n  Bound,\n  Direction,\n  FieldFilter,\n  Filter,\n  LimitType,\n  newQuery,\n  newQueryForPath,\n  Operator,\n  OrderBy,\n  queryToTarget\n} from '../core/query';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { isDocumentTarget, Target } from '../core/target';\nimport { TargetId } from '../core/types';\nimport { TargetData, TargetPurpose } from '../local/target_data';\nimport { Document, MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { ObjectValue } from '../model/object_value';\nimport {\n  DeleteMutation,\n  FieldMask,\n  FieldTransform,\n  Mutation,\n  MutationResult,\n  PatchMutation,\n  Precondition,\n  SetMutation,\n  TransformMutation,\n  VerifyMutation\n} from '../model/mutation';\nimport { FieldPath, ResourcePath } from '../model/path';\nimport * as api from '../protos/firestore_proto_api';\nimport { debugAssert, fail, hardAssert } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { ByteString } from '../util/byte_string';\nimport {\n  isNegativeZero,\n  isNullOrUndefined,\n  isSafeInteger\n} from '../util/types';\nimport {\n  ArrayRemoveTransformOperation,\n  ArrayUnionTransformOperation,\n  NumericIncrementTransformOperation,\n  ServerTimestampTransform,\n  TransformOperation\n} from '../model/transform_operation';\nimport { ExistenceFilter } from './existence_filter';\nimport { mapCodeFromRpcCode } from './rpc_error';\nimport {\n  DocumentWatchChange,\n  ExistenceFilterChange,\n  WatchChange,\n  WatchTargetChange,\n  WatchTargetChangeState\n} from './watch_change';\nimport { isNanValue, isNullValue, normalizeTimestamp } from '../model/values';\nimport {\n  TargetChangeTargetChangeType,\n  WriteResult\n} from '../protos/firestore_proto_api';\n\nconst DIRECTIONS = (() => {\n  const dirs: { [dir: string]: api.OrderDirection } = {};\n  dirs[Direction.ASCENDING] = 'ASCENDING';\n  dirs[Direction.DESCENDING] = 'DESCENDING';\n  return dirs;\n})();\n\nconst OPERATORS = (() => {\n  const ops: { [op: string]: api.FieldFilterOp } = {};\n  ops[Operator.LESS_THAN] = 'LESS_THAN';\n  ops[Operator.LESS_THAN_OR_EQUAL] = 'LESS_THAN_OR_EQUAL';\n  ops[Operator.GREATER_THAN] = 'GREATER_THAN';\n  ops[Operator.GREATER_THAN_OR_EQUAL] = 'GREATER_THAN_OR_EQUAL';\n  ops[Operator.EQUAL] = 'EQUAL';\n  ops[Operator.NOT_EQUAL] = 'NOT_EQUAL';\n  ops[Operator.ARRAY_CONTAINS] = 'ARRAY_CONTAINS';\n  ops[Operator.IN] = 'IN';\n  ops[Operator.NOT_IN] = 'NOT_IN';\n  ops[Operator.ARRAY_CONTAINS_ANY] = 'ARRAY_CONTAINS_ANY';\n  return ops;\n})();\n\nfunction assertPresent(value: unknown, description: string): asserts value {\n  debugAssert(!isNullOrUndefined(value), description + ' is missing');\n}\n\n/**\n * This class generates JsonObject values for the Datastore API suitable for\n * sending to either GRPC stub methods or via the JSON/HTTP REST API.\n *\n * The serializer supports both Protobuf.js and Proto3 JSON formats. By\n * setting `useProto3Json` to true, the serializer will use the Proto3 JSON\n * format.\n *\n * For a description of the Proto3 JSON format check\n * https://developers.google.com/protocol-buffers/docs/proto3#json\n *\n * TODO(klimt): We can remove the databaseId argument if we keep the full\n * resource name in documents.\n */\nexport class JsonProtoSerializer {\n  constructor(\n    readonly databaseId: DatabaseId,\n    readonly useProto3Json: boolean\n  ) {}\n}\n\nfunction fromRpcStatus(status: api.Status): FirestoreError {\n  const code =\n    status.code === undefined ? Code.UNKNOWN : mapCodeFromRpcCode(status.code);\n  return new FirestoreError(code, status.message || '');\n}\n\n/**\n * Returns a value for a number (or null) that's appropriate to put into\n * a google.protobuf.Int32Value proto.\n * DO NOT USE THIS FOR ANYTHING ELSE.\n * This method cheats. It's typed as returning \"number\" because that's what\n * our generated proto interfaces say Int32Value must be. But GRPC actually\n * expects a { value: <number> } struct.\n */\nfunction toInt32Proto(\n  serializer: JsonProtoSerializer,\n  val: number | null\n): number | { value: number } | null {\n  if (serializer.useProto3Json || isNullOrUndefined(val)) {\n    return val;\n  } else {\n    return { value: val };\n  }\n}\n\n/**\n * Returns a number (or null) from a google.protobuf.Int32Value proto.\n */\nfunction fromInt32Proto(\n  val: number | { value: number } | undefined\n): number | null {\n  let result;\n  if (typeof val === 'object') {\n    result = val.value;\n  } else {\n    result = val;\n  }\n  return isNullOrUndefined(result) ? null : result;\n}\n\n/**\n * Returns an IntegerValue for `value`.\n */\nexport function toInteger(value: number): api.Value {\n  return { integerValue: '' + value };\n}\n\n/**\n * Returns an DoubleValue for `value` that is encoded based the serializer's\n * `useProto3Json` setting.\n */\nexport function toDouble(\n  serializer: JsonProtoSerializer,\n  value: number\n): api.Value {\n  if (serializer.useProto3Json) {\n    if (isNaN(value)) {\n      return { doubleValue: 'NaN' };\n    } else if (value === Infinity) {\n      return { doubleValue: 'Infinity' };\n    } else if (value === -Infinity) {\n      return { doubleValue: '-Infinity' };\n    }\n  }\n  return { doubleValue: isNegativeZero(value) ? '-0' : value };\n}\n\n/**\n * Returns a value for a number that's appropriate to put into a proto.\n * The return value is an IntegerValue if it can safely represent the value,\n * otherwise a DoubleValue is returned.\n */\nexport function toNumber(\n  serializer: JsonProtoSerializer,\n  value: number\n): api.Value {\n  return isSafeInteger(value) ? toInteger(value) : toDouble(serializer, value);\n}\n\n/**\n * Returns a value for a Date that's appropriate to put into a proto.\n */\nexport function toTimestamp(\n  serializer: JsonProtoSerializer,\n  timestamp: Timestamp\n): api.Timestamp {\n  if (serializer.useProto3Json) {\n    // Serialize to ISO-8601 date format, but with full nano resolution.\n    // Since JS Date has only millis, let's only use it for the seconds and\n    // then manually add the fractions to the end.\n    const jsDateStr = new Date(timestamp.seconds * 1000).toISOString();\n    // Remove .xxx frac part and Z in the end.\n    const strUntilSeconds = jsDateStr.replace(/\\.\\d*/, '').replace('Z', '');\n    // Pad the fraction out to 9 digits (nanos).\n    const nanoStr = ('000000000' + timestamp.nanoseconds).slice(-9);\n\n    return `${strUntilSeconds}.${nanoStr}Z`;\n  } else {\n    return {\n      seconds: '' + timestamp.seconds,\n      nanos: timestamp.nanoseconds\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    } as any;\n  }\n}\n\nfunction fromTimestamp(date: api.Timestamp): Timestamp {\n  const timestamp = normalizeTimestamp(date);\n  return new Timestamp(timestamp.seconds, timestamp.nanos);\n}\n\n/**\n * Returns a value for bytes that's appropriate to put in a proto.\n *\n * Visible for testing.\n */\nexport function toBytes(\n  serializer: JsonProtoSerializer,\n  bytes: Blob | ByteString\n): string | Uint8Array {\n  if (serializer.useProto3Json) {\n    return bytes.toBase64();\n  } else {\n    return bytes.toUint8Array();\n  }\n}\n\n/**\n * Returns a ByteString based on the proto string value.\n */\nexport function fromBytes(\n  serializer: JsonProtoSerializer,\n  value: string | Uint8Array | undefined\n): ByteString {\n  if (serializer.useProto3Json) {\n    hardAssert(\n      value === undefined || typeof value === 'string',\n      'value must be undefined or a string when using proto3 Json'\n    );\n    return ByteString.fromBase64String(value ? value : '');\n  } else {\n    hardAssert(\n      value === undefined || value instanceof Uint8Array,\n      'value must be undefined or Uint8Array'\n    );\n    return ByteString.fromUint8Array(value ? value : new Uint8Array());\n  }\n}\n\nexport function toVersion(\n  serializer: JsonProtoSerializer,\n  version: SnapshotVersion\n): api.Timestamp {\n  return toTimestamp(serializer, version.toTimestamp());\n}\n\nexport function fromVersion(version: api.Timestamp): SnapshotVersion {\n  hardAssert(!!version, \"Trying to deserialize version that isn't set\");\n  return SnapshotVersion.fromTimestamp(fromTimestamp(version));\n}\n\nexport function toResourceName(\n  databaseId: DatabaseId,\n  path: ResourcePath\n): string {\n  return fullyQualifiedPrefixPath(databaseId)\n    .child('documents')\n    .child(path)\n    .canonicalString();\n}\n\nfunction fromResourceName(name: string): ResourcePath {\n  const resource = ResourcePath.fromString(name);\n  hardAssert(\n    isValidResourceName(resource),\n    'Tried to deserialize invalid key ' + resource.toString()\n  );\n  return resource;\n}\n\nexport function toName(\n  serializer: JsonProtoSerializer,\n  key: DocumentKey\n): string {\n  return toResourceName(serializer.databaseId, key.path);\n}\n\nexport function fromName(\n  serializer: JsonProtoSerializer,\n  name: string\n): DocumentKey {\n  const resource = fromResourceName(name);\n  hardAssert(\n    resource.get(1) === serializer.databaseId.projectId,\n    'Tried to deserialize key from different project: ' +\n      resource.get(1) +\n      ' vs ' +\n      serializer.databaseId.projectId\n  );\n  hardAssert(\n    (!resource.get(3) && !serializer.databaseId.database) ||\n      resource.get(3) === serializer.databaseId.database,\n    'Tried to deserialize key from different database: ' +\n      resource.get(3) +\n      ' vs ' +\n      serializer.databaseId.database\n  );\n  return new DocumentKey(extractLocalPathFromResourceName(resource));\n}\n\nfunction toQueryPath(\n  serializer: JsonProtoSerializer,\n  path: ResourcePath\n): string {\n  return toResourceName(serializer.databaseId, path);\n}\n\nfunction fromQueryPath(name: string): ResourcePath {\n  const resourceName = fromResourceName(name);\n  // In v1beta1 queries for collections at the root did not have a trailing\n  // \"/documents\". In v1 all resource paths contain \"/documents\". Preserve the\n  // ability to read the v1beta1 form for compatibility with queries persisted\n  // in the local target cache.\n  if (resourceName.length === 4) {\n    return ResourcePath.emptyPath();\n  }\n  return extractLocalPathFromResourceName(resourceName);\n}\n\nexport function getEncodedDatabaseId(serializer: JsonProtoSerializer): string {\n  const path = new ResourcePath([\n    'projects',\n    serializer.databaseId.projectId,\n    'databases',\n    serializer.databaseId.database\n  ]);\n  return path.canonicalString();\n}\n\nfunction fullyQualifiedPrefixPath(databaseId: DatabaseId): ResourcePath {\n  return new ResourcePath([\n    'projects',\n    databaseId.projectId,\n    'databases',\n    databaseId.database\n  ]);\n}\n\nfunction extractLocalPathFromResourceName(\n  resourceName: ResourcePath\n): ResourcePath {\n  hardAssert(\n    resourceName.length > 4 && resourceName.get(4) === 'documents',\n    'tried to deserialize invalid key ' + resourceName.toString()\n  );\n  return resourceName.popFirst(5);\n}\n\n/** Creates an api.Document from key and fields (but no create/update time) */\nexport function toMutationDocument(\n  serializer: JsonProtoSerializer,\n  key: DocumentKey,\n  fields: ObjectValue\n): api.Document {\n  return {\n    name: toName(serializer, key),\n    fields: fields.proto.mapValue.fields\n  };\n}\n\nexport function toDocument(\n  serializer: JsonProtoSerializer,\n  document: Document\n): api.Document {\n  debugAssert(\n    !document.hasLocalMutations,\n    \"Can't serialize documents with mutations.\"\n  );\n  return {\n    name: toName(serializer, document.key),\n    fields: document.toProto().mapValue.fields,\n    updateTime: toTimestamp(serializer, document.version.toTimestamp())\n  };\n}\n\nexport function fromDocument(\n  serializer: JsonProtoSerializer,\n  document: api.Document,\n  hasCommittedMutations?: boolean\n): Document {\n  const key = fromName(serializer, document.name!);\n  const version = fromVersion(document.updateTime!);\n  const data = new ObjectValue({ mapValue: { fields: document.fields } });\n  return new Document(key, version, data, {\n    hasCommittedMutations: !!hasCommittedMutations\n  });\n}\n\nfunction fromFound(\n  serializer: JsonProtoSerializer,\n  doc: api.BatchGetDocumentsResponse\n): Document {\n  hardAssert(\n    !!doc.found,\n    'Tried to deserialize a found document from a missing document.'\n  );\n  assertPresent(doc.found.name, 'doc.found.name');\n  assertPresent(doc.found.updateTime, 'doc.found.updateTime');\n  const key = fromName(serializer, doc.found.name);\n  const version = fromVersion(doc.found.updateTime);\n  const data = new ObjectValue({ mapValue: { fields: doc.found.fields } });\n  return new Document(key, version, data, {});\n}\n\nfunction fromMissing(\n  serializer: JsonProtoSerializer,\n  result: api.BatchGetDocumentsResponse\n): NoDocument {\n  hardAssert(\n    !!result.missing,\n    'Tried to deserialize a missing document from a found document.'\n  );\n  hardAssert(\n    !!result.readTime,\n    'Tried to deserialize a missing document without a read time.'\n  );\n  const key = fromName(serializer, result.missing);\n  const version = fromVersion(result.readTime);\n  return new NoDocument(key, version);\n}\n\nexport function fromMaybeDocument(\n  serializer: JsonProtoSerializer,\n  result: api.BatchGetDocumentsResponse\n): MaybeDocument {\n  if ('found' in result) {\n    return fromFound(serializer, result);\n  } else if ('missing' in result) {\n    return fromMissing(serializer, result);\n  }\n  return fail('invalid batch get response: ' + JSON.stringify(result));\n}\n\nexport function fromWatchChange(\n  serializer: JsonProtoSerializer,\n  change: api.ListenResponse\n): WatchChange {\n  let watchChange: WatchChange;\n  if ('targetChange' in change) {\n    assertPresent(change.targetChange, 'targetChange');\n    // proto3 default value is unset in JSON (undefined), so use 'NO_CHANGE'\n    // if unset\n    const state = fromWatchTargetChangeState(\n      change.targetChange.targetChangeType || 'NO_CHANGE'\n    );\n    const targetIds: TargetId[] = change.targetChange.targetIds || [];\n\n    const resumeToken = fromBytes(serializer, change.targetChange.resumeToken);\n    const causeProto = change.targetChange!.cause;\n    const cause = causeProto && fromRpcStatus(causeProto);\n    watchChange = new WatchTargetChange(\n      state,\n      targetIds,\n      resumeToken,\n      cause || null\n    );\n  } else if ('documentChange' in change) {\n    assertPresent(change.documentChange, 'documentChange');\n    const entityChange = change.documentChange;\n    assertPresent(entityChange.document, 'documentChange.name');\n    assertPresent(entityChange.document.name, 'documentChange.document.name');\n    assertPresent(\n      entityChange.document.updateTime,\n      'documentChange.document.updateTime'\n    );\n    const key = fromName(serializer, entityChange.document.name);\n    const version = fromVersion(entityChange.document.updateTime);\n    const data = new ObjectValue({\n      mapValue: { fields: entityChange.document.fields }\n    });\n    const doc = new Document(key, version, data, {});\n    const updatedTargetIds = entityChange.targetIds || [];\n    const removedTargetIds = entityChange.removedTargetIds || [];\n    watchChange = new DocumentWatchChange(\n      updatedTargetIds,\n      removedTargetIds,\n      doc.key,\n      doc\n    );\n  } else if ('documentDelete' in change) {\n    assertPresent(change.documentDelete, 'documentDelete');\n    const docDelete = change.documentDelete;\n    assertPresent(docDelete.document, 'documentDelete.document');\n    const key = fromName(serializer, docDelete.document);\n    const version = docDelete.readTime\n      ? fromVersion(docDelete.readTime)\n      : SnapshotVersion.min();\n    const doc = new NoDocument(key, version);\n    const removedTargetIds = docDelete.removedTargetIds || [];\n    watchChange = new DocumentWatchChange([], removedTargetIds, doc.key, doc);\n  } else if ('documentRemove' in change) {\n    assertPresent(change.documentRemove, 'documentRemove');\n    const docRemove = change.documentRemove;\n    assertPresent(docRemove.document, 'documentRemove');\n    const key = fromName(serializer, docRemove.document);\n    const removedTargetIds = docRemove.removedTargetIds || [];\n    watchChange = new DocumentWatchChange([], removedTargetIds, key, null);\n  } else if ('filter' in change) {\n    // TODO(dimond): implement existence filter parsing with strategy.\n    assertPresent(change.filter, 'filter');\n    const filter = change.filter;\n    assertPresent(filter.targetId, 'filter.targetId');\n    const count = filter.count || 0;\n    const existenceFilter = new ExistenceFilter(count);\n    const targetId = filter.targetId;\n    watchChange = new ExistenceFilterChange(targetId, existenceFilter);\n  } else {\n    return fail('Unknown change type ' + JSON.stringify(change));\n  }\n  return watchChange;\n}\n\nfunction fromWatchTargetChangeState(\n  state: TargetChangeTargetChangeType\n): WatchTargetChangeState {\n  if (state === 'NO_CHANGE') {\n    return WatchTargetChangeState.NoChange;\n  } else if (state === 'ADD') {\n    return WatchTargetChangeState.Added;\n  } else if (state === 'REMOVE') {\n    return WatchTargetChangeState.Removed;\n  } else if (state === 'CURRENT') {\n    return WatchTargetChangeState.Current;\n  } else if (state === 'RESET') {\n    return WatchTargetChangeState.Reset;\n  } else {\n    return fail('Got unexpected TargetChange.state: ' + state);\n  }\n}\n\nexport function versionFromListenResponse(\n  change: api.ListenResponse\n): SnapshotVersion {\n  // We have only reached a consistent snapshot for the entire stream if there\n  // is a read_time set and it applies to all targets (i.e. the list of\n  // targets is empty). The backend is guaranteed to send such responses.\n  if (!('targetChange' in change)) {\n    return SnapshotVersion.min();\n  }\n  const targetChange = change.targetChange!;\n  if (targetChange.targetIds && targetChange.targetIds.length) {\n    return SnapshotVersion.min();\n  }\n  if (!targetChange.readTime) {\n    return SnapshotVersion.min();\n  }\n  return fromVersion(targetChange.readTime);\n}\n\nexport function toMutation(\n  serializer: JsonProtoSerializer,\n  mutation: Mutation\n): api.Write {\n  let result: api.Write;\n  if (mutation instanceof SetMutation) {\n    result = {\n      update: toMutationDocument(serializer, mutation.key, mutation.value)\n    };\n  } else if (mutation instanceof DeleteMutation) {\n    result = { delete: toName(serializer, mutation.key) };\n  } else if (mutation instanceof PatchMutation) {\n    result = {\n      update: toMutationDocument(serializer, mutation.key, mutation.data),\n      updateMask: toDocumentMask(mutation.fieldMask)\n    };\n  } else if (mutation instanceof TransformMutation) {\n    result = {\n      transform: {\n        document: toName(serializer, mutation.key),\n        fieldTransforms: mutation.fieldTransforms.map(transform =>\n          toFieldTransform(serializer, transform)\n        )\n      }\n    };\n  } else if (mutation instanceof VerifyMutation) {\n    result = {\n      verify: toName(serializer, mutation.key)\n    };\n  } else {\n    return fail('Unknown mutation type ' + mutation.type);\n  }\n\n  if (!mutation.precondition.isNone) {\n    result.currentDocument = toPrecondition(serializer, mutation.precondition);\n  }\n\n  return result;\n}\n\nexport function fromMutation(\n  serializer: JsonProtoSerializer,\n  proto: api.Write\n): Mutation {\n  const precondition = proto.currentDocument\n    ? fromPrecondition(proto.currentDocument)\n    : Precondition.none();\n\n  if (proto.update) {\n    assertPresent(proto.update.name, 'name');\n    const key = fromName(serializer, proto.update.name);\n    const value = new ObjectValue({\n      mapValue: { fields: proto.update.fields }\n    });\n    if (proto.updateMask) {\n      const fieldMask = fromDocumentMask(proto.updateMask);\n      return new PatchMutation(key, value, fieldMask, precondition);\n    } else {\n      return new SetMutation(key, value, precondition);\n    }\n  } else if (proto.delete) {\n    const key = fromName(serializer, proto.delete);\n    return new DeleteMutation(key, precondition);\n  } else if (proto.transform) {\n    const key = fromName(serializer, proto.transform.document!);\n    const fieldTransforms = proto.transform.fieldTransforms!.map(transform =>\n      fromFieldTransform(serializer, transform)\n    );\n    hardAssert(\n      precondition.exists === true,\n      'Transforms only support precondition \"exists == true\"'\n    );\n    return new TransformMutation(key, fieldTransforms);\n  } else if (proto.verify) {\n    const key = fromName(serializer, proto.verify);\n    return new VerifyMutation(key, precondition);\n  } else {\n    return fail('unknown mutation proto: ' + JSON.stringify(proto));\n  }\n}\n\nfunction toPrecondition(\n  serializer: JsonProtoSerializer,\n  precondition: Precondition\n): api.Precondition {\n  debugAssert(!precondition.isNone, \"Can't serialize an empty precondition\");\n  if (precondition.updateTime !== undefined) {\n    return {\n      updateTime: toVersion(serializer, precondition.updateTime)\n    };\n  } else if (precondition.exists !== undefined) {\n    return { exists: precondition.exists };\n  } else {\n    return fail('Unknown precondition');\n  }\n}\n\nfunction fromPrecondition(precondition: api.Precondition): Precondition {\n  if (precondition.updateTime !== undefined) {\n    return Precondition.updateTime(fromVersion(precondition.updateTime));\n  } else if (precondition.exists !== undefined) {\n    return Precondition.exists(precondition.exists);\n  } else {\n    return Precondition.none();\n  }\n}\n\nfunction fromWriteResult(\n  proto: WriteResult,\n  commitTime: api.Timestamp\n): MutationResult {\n  // NOTE: Deletes don't have an updateTime.\n  let version = proto.updateTime\n    ? fromVersion(proto.updateTime)\n    : fromVersion(commitTime);\n\n  if (version.isEqual(SnapshotVersion.min())) {\n    // The Firestore Emulator currently returns an update time of 0 for\n    // deletes of non-existing documents (rather than null). This breaks the\n    // test \"get deleted doc while offline with source=cache\" as NoDocuments\n    // with version 0 are filtered by IndexedDb's RemoteDocumentCache.\n    // TODO(#2149): Remove this when Emulator is fixed\n    version = fromVersion(commitTime);\n  }\n\n  let transformResults: api.Value[] | null = null;\n  if (proto.transformResults && proto.transformResults.length > 0) {\n    transformResults = proto.transformResults;\n  }\n  return new MutationResult(version, transformResults);\n}\n\nexport function fromWriteResults(\n  protos: WriteResult[] | undefined,\n  commitTime?: api.Timestamp\n): MutationResult[] {\n  if (protos && protos.length > 0) {\n    hardAssert(\n      commitTime !== undefined,\n      'Received a write result without a commit time'\n    );\n    return protos.map(proto => fromWriteResult(proto, commitTime));\n  } else {\n    return [];\n  }\n}\n\nfunction toFieldTransform(\n  serializer: JsonProtoSerializer,\n  fieldTransform: FieldTransform\n): api.FieldTransform {\n  const transform = fieldTransform.transform;\n  if (transform instanceof ServerTimestampTransform) {\n    return {\n      fieldPath: fieldTransform.field.canonicalString(),\n      setToServerValue: 'REQUEST_TIME'\n    };\n  } else if (transform instanceof ArrayUnionTransformOperation) {\n    return {\n      fieldPath: fieldTransform.field.canonicalString(),\n      appendMissingElements: {\n        values: transform.elements\n      }\n    };\n  } else if (transform instanceof ArrayRemoveTransformOperation) {\n    return {\n      fieldPath: fieldTransform.field.canonicalString(),\n      removeAllFromArray: {\n        values: transform.elements\n      }\n    };\n  } else if (transform instanceof NumericIncrementTransformOperation) {\n    return {\n      fieldPath: fieldTransform.field.canonicalString(),\n      increment: transform.operand\n    };\n  } else {\n    throw fail('Unknown transform: ' + fieldTransform.transform);\n  }\n}\n\nfunction fromFieldTransform(\n  serializer: JsonProtoSerializer,\n  proto: api.FieldTransform\n): FieldTransform {\n  let transform: TransformOperation | null = null;\n  if ('setToServerValue' in proto) {\n    hardAssert(\n      proto.setToServerValue === 'REQUEST_TIME',\n      'Unknown server value transform proto: ' + JSON.stringify(proto)\n    );\n    transform = new ServerTimestampTransform();\n  } else if ('appendMissingElements' in proto) {\n    const values = proto.appendMissingElements!.values || [];\n    transform = new ArrayUnionTransformOperation(values);\n  } else if ('removeAllFromArray' in proto) {\n    const values = proto.removeAllFromArray!.values || [];\n    transform = new ArrayRemoveTransformOperation(values);\n  } else if ('increment' in proto) {\n    transform = new NumericIncrementTransformOperation(\n      serializer,\n      proto.increment!\n    );\n  } else {\n    fail('Unknown transform proto: ' + JSON.stringify(proto));\n  }\n  const fieldPath = FieldPath.fromServerFormat(proto.fieldPath!);\n  return new FieldTransform(fieldPath, transform!);\n}\n\nexport function toDocumentsTarget(\n  serializer: JsonProtoSerializer,\n  target: Target\n): api.DocumentsTarget {\n  return { documents: [toQueryPath(serializer, target.path)] };\n}\n\nexport function fromDocumentsTarget(\n  documentsTarget: api.DocumentsTarget\n): Target {\n  const count = documentsTarget.documents!.length;\n  hardAssert(\n    count === 1,\n    'DocumentsTarget contained other than 1 document: ' + count\n  );\n  const name = documentsTarget.documents![0];\n  return queryToTarget(newQueryForPath(fromQueryPath(name)));\n}\n\nexport function toQueryTarget(\n  serializer: JsonProtoSerializer,\n  target: Target\n): api.QueryTarget {\n  // Dissect the path into parent, collectionId, and optional key filter.\n  const result: api.QueryTarget = { structuredQuery: {} };\n  const path = target.path;\n  if (target.collectionGroup !== null) {\n    debugAssert(\n      path.length % 2 === 0,\n      'Collection Group queries should be within a document path or root.'\n    );\n    result.parent = toQueryPath(serializer, path);\n    result.structuredQuery!.from = [\n      {\n        collectionId: target.collectionGroup,\n        allDescendants: true\n      }\n    ];\n  } else {\n    debugAssert(\n      path.length % 2 !== 0,\n      'Document queries with filters are not supported.'\n    );\n    result.parent = toQueryPath(serializer, path.popLast());\n    result.structuredQuery!.from = [{ collectionId: path.lastSegment() }];\n  }\n\n  const where = toFilter(target.filters);\n  if (where) {\n    result.structuredQuery!.where = where;\n  }\n\n  const orderBy = toOrder(target.orderBy);\n  if (orderBy) {\n    result.structuredQuery!.orderBy = orderBy;\n  }\n\n  const limit = toInt32Proto(serializer, target.limit);\n  if (limit !== null) {\n    result.structuredQuery!.limit = limit;\n  }\n\n  if (target.startAt) {\n    result.structuredQuery!.startAt = toCursor(target.startAt);\n  }\n  if (target.endAt) {\n    result.structuredQuery!.endAt = toCursor(target.endAt);\n  }\n\n  return result;\n}\n\nexport function fromQueryTarget(target: api.QueryTarget): Target {\n  let path = fromQueryPath(target.parent!);\n\n  const query = target.structuredQuery!;\n  const fromCount = query.from ? query.from.length : 0;\n  let collectionGroup: string | null = null;\n  if (fromCount > 0) {\n    hardAssert(\n      fromCount === 1,\n      'StructuredQuery.from with more than one collection is not supported.'\n    );\n    const from = query.from![0];\n    if (from.allDescendants) {\n      collectionGroup = from.collectionId!;\n    } else {\n      path = path.child(from.collectionId!);\n    }\n  }\n\n  let filterBy: Filter[] = [];\n  if (query.where) {\n    filterBy = fromFilter(query.where);\n  }\n\n  let orderBy: OrderBy[] = [];\n  if (query.orderBy) {\n    orderBy = fromOrder(query.orderBy);\n  }\n\n  let limit: number | null = null;\n  if (query.limit) {\n    limit = fromInt32Proto(query.limit);\n  }\n\n  let startAt: Bound | null = null;\n  if (query.startAt) {\n    startAt = fromCursor(query.startAt);\n  }\n\n  let endAt: Bound | null = null;\n  if (query.endAt) {\n    endAt = fromCursor(query.endAt);\n  }\n\n  return queryToTarget(\n    newQuery(\n      path,\n      collectionGroup,\n      orderBy,\n      filterBy,\n      limit,\n      LimitType.First,\n      startAt,\n      endAt\n    )\n  );\n}\n\nexport function toListenRequestLabels(\n  serializer: JsonProtoSerializer,\n  targetData: TargetData\n): api.ApiClientObjectMap<string> | null {\n  const value = toLabel(serializer, targetData.purpose);\n  if (value == null) {\n    return null;\n  } else {\n    return {\n      'goog-listen-tags': value\n    };\n  }\n}\n\nfunction toLabel(\n  serializer: JsonProtoSerializer,\n  purpose: TargetPurpose\n): string | null {\n  switch (purpose) {\n    case TargetPurpose.Listen:\n      return null;\n    case TargetPurpose.ExistenceFilterMismatch:\n      return 'existence-filter-mismatch';\n    case TargetPurpose.LimboResolution:\n      return 'limbo-document';\n    default:\n      return fail('Unrecognized query purpose: ' + purpose);\n  }\n}\n\nexport function toTarget(\n  serializer: JsonProtoSerializer,\n  targetData: TargetData\n): api.Target {\n  let result: api.Target;\n  const target = targetData.target;\n\n  if (isDocumentTarget(target)) {\n    result = { documents: toDocumentsTarget(serializer, target) };\n  } else {\n    result = { query: toQueryTarget(serializer, target) };\n  }\n\n  result.targetId = targetData.targetId;\n\n  if (targetData.resumeToken.approximateByteSize() > 0) {\n    result.resumeToken = toBytes(serializer, targetData.resumeToken);\n  }\n\n  return result;\n}\n\nfunction toFilter(filters: Filter[]): api.Filter | undefined {\n  if (filters.length === 0) {\n    return;\n  }\n  const protos = filters.map(filter => {\n    debugAssert(\n      filter instanceof FieldFilter,\n      'Only FieldFilters are supported'\n    );\n    return toUnaryOrFieldFilter(filter);\n  });\n  if (protos.length === 1) {\n    return protos[0];\n  }\n  return { compositeFilter: { op: 'AND', filters: protos } };\n}\n\nfunction fromFilter(filter: api.Filter | undefined): Filter[] {\n  if (!filter) {\n    return [];\n  } else if (filter.unaryFilter !== undefined) {\n    return [fromUnaryFilter(filter)];\n  } else if (filter.fieldFilter !== undefined) {\n    return [fromFieldFilter(filter)];\n  } else if (filter.compositeFilter !== undefined) {\n    return filter.compositeFilter\n      .filters!.map(f => fromFilter(f))\n      .reduce((accum, current) => accum.concat(current));\n  } else {\n    return fail('Unknown filter: ' + JSON.stringify(filter));\n  }\n}\n\nfunction toOrder(orderBys: OrderBy[]): api.Order[] | undefined {\n  if (orderBys.length === 0) {\n    return;\n  }\n  return orderBys.map(order => toPropertyOrder(order));\n}\n\nfunction fromOrder(orderBys: api.Order[]): OrderBy[] {\n  return orderBys.map(order => fromPropertyOrder(order));\n}\n\nfunction toCursor(cursor: Bound): api.Cursor {\n  return {\n    before: cursor.before,\n    values: cursor.position\n  };\n}\n\nfunction fromCursor(cursor: api.Cursor): Bound {\n  const before = !!cursor.before;\n  const position = cursor.values || [];\n  return new Bound(position, before);\n}\n\n// visible for testing\nexport function toDirection(dir: Direction): api.OrderDirection {\n  return DIRECTIONS[dir];\n}\n\n// visible for testing\nexport function fromDirection(\n  dir: api.OrderDirection | undefined\n): Direction | undefined {\n  switch (dir) {\n    case 'ASCENDING':\n      return Direction.ASCENDING;\n    case 'DESCENDING':\n      return Direction.DESCENDING;\n    default:\n      return undefined;\n  }\n}\n\n// visible for testing\nexport function toOperatorName(op: Operator): api.FieldFilterOp {\n  return OPERATORS[op];\n}\n\nexport function fromOperatorName(op: api.FieldFilterOp): Operator {\n  switch (op) {\n    case 'EQUAL':\n      return Operator.EQUAL;\n    case 'NOT_EQUAL':\n      return Operator.NOT_EQUAL;\n    case 'GREATER_THAN':\n      return Operator.GREATER_THAN;\n    case 'GREATER_THAN_OR_EQUAL':\n      return Operator.GREATER_THAN_OR_EQUAL;\n    case 'LESS_THAN':\n      return Operator.LESS_THAN;\n    case 'LESS_THAN_OR_EQUAL':\n      return Operator.LESS_THAN_OR_EQUAL;\n    case 'ARRAY_CONTAINS':\n      return Operator.ARRAY_CONTAINS;\n    case 'IN':\n      return Operator.IN;\n    case 'NOT_IN':\n      return Operator.NOT_IN;\n    case 'ARRAY_CONTAINS_ANY':\n      return Operator.ARRAY_CONTAINS_ANY;\n    case 'OPERATOR_UNSPECIFIED':\n      return fail('Unspecified operator');\n    default:\n      return fail('Unknown operator');\n  }\n}\n\nexport function toFieldPathReference(path: FieldPath): api.FieldReference {\n  return { fieldPath: path.canonicalString() };\n}\n\nexport function fromFieldPathReference(\n  fieldReference: api.FieldReference\n): FieldPath {\n  return FieldPath.fromServerFormat(fieldReference.fieldPath!);\n}\n\n// visible for testing\nexport function toPropertyOrder(orderBy: OrderBy): api.Order {\n  return {\n    field: toFieldPathReference(orderBy.field),\n    direction: toDirection(orderBy.dir)\n  };\n}\n\nexport function fromPropertyOrder(orderBy: api.Order): OrderBy {\n  return new OrderBy(\n    fromFieldPathReference(orderBy.field!),\n    fromDirection(orderBy.direction)\n  );\n}\n\nexport function fromFieldFilter(filter: api.Filter): Filter {\n  return FieldFilter.create(\n    fromFieldPathReference(filter.fieldFilter!.field!),\n    fromOperatorName(filter.fieldFilter!.op!),\n    filter.fieldFilter!.value!\n  );\n}\n\n// visible for testing\nexport function toUnaryOrFieldFilter(filter: FieldFilter): api.Filter {\n  if (filter.op === Operator.EQUAL) {\n    if (isNanValue(filter.value)) {\n      return {\n        unaryFilter: {\n          field: toFieldPathReference(filter.field),\n          op: 'IS_NAN'\n        }\n      };\n    } else if (isNullValue(filter.value)) {\n      return {\n        unaryFilter: {\n          field: toFieldPathReference(filter.field),\n          op: 'IS_NULL'\n        }\n      };\n    }\n  } else if (filter.op === Operator.NOT_EQUAL) {\n    if (isNanValue(filter.value)) {\n      return {\n        unaryFilter: {\n          field: toFieldPathReference(filter.field),\n          op: 'IS_NOT_NAN'\n        }\n      };\n    } else if (isNullValue(filter.value)) {\n      return {\n        unaryFilter: {\n          field: toFieldPathReference(filter.field),\n          op: 'IS_NOT_NULL'\n        }\n      };\n    }\n  }\n  return {\n    fieldFilter: {\n      field: toFieldPathReference(filter.field),\n      op: toOperatorName(filter.op),\n      value: filter.value\n    }\n  };\n}\n\nexport function fromUnaryFilter(filter: api.Filter): Filter {\n  switch (filter.unaryFilter!.op!) {\n    case 'IS_NAN':\n      const nanField = fromFieldPathReference(filter.unaryFilter!.field!);\n      return FieldFilter.create(nanField, Operator.EQUAL, {\n        doubleValue: NaN\n      });\n    case 'IS_NULL':\n      const nullField = fromFieldPathReference(filter.unaryFilter!.field!);\n      return FieldFilter.create(nullField, Operator.EQUAL, {\n        nullValue: 'NULL_VALUE'\n      });\n    case 'IS_NOT_NAN':\n      const notNanField = fromFieldPathReference(filter.unaryFilter!.field!);\n      return FieldFilter.create(notNanField, Operator.NOT_EQUAL, {\n        doubleValue: NaN\n      });\n    case 'IS_NOT_NULL':\n      const notNullField = fromFieldPathReference(filter.unaryFilter!.field!);\n      return FieldFilter.create(notNullField, Operator.NOT_EQUAL, {\n        nullValue: 'NULL_VALUE'\n      });\n    case 'OPERATOR_UNSPECIFIED':\n      return fail('Unspecified filter');\n    default:\n      return fail('Unknown filter');\n  }\n}\n\nexport function toDocumentMask(fieldMask: FieldMask): api.DocumentMask {\n  const canonicalFields: string[] = [];\n  fieldMask.fields.forEach(field =>\n    canonicalFields.push(field.canonicalString())\n  );\n  return {\n    fieldPaths: canonicalFields\n  };\n}\n\nexport function fromDocumentMask(proto: api.DocumentMask): FieldMask {\n  const paths = proto.fieldPaths || [];\n  return new FieldMask(paths.map(path => FieldPath.fromServerFormat(path)));\n}\n\nexport function isValidResourceName(path: ResourcePath): boolean {\n  // Resource names have at least 4 components (project ID, database ID)\n  return (\n    path.length >= 4 &&\n    path.get(0) === 'projects' &&\n    path.get(2) === 'databases'\n  );\n}\n","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { Timestamp } from '../api/timestamp';\nimport { debugAssert } from '../util/assert';\nimport { JsonProtoSerializer, toDouble, toInteger } from '../remote/serializer';\nimport {\n  isArray,\n  isInteger,\n  isNumber,\n  normalizeNumber,\n  valueEquals\n} from './values';\nimport { serverTimestamp } from './server_timestamps';\nimport { arrayEquals } from '../util/misc';\n\n/** Represents a transform within a TransformMutation. */\nexport class TransformOperation {\n  // Make sure that the structural type of `TransformOperation` is unique.\n  // See https://github.com/microsoft/TypeScript/issues/5451\n  private _ = undefined;\n}\n\n/**\n * Computes the local transform result against the provided `previousValue`,\n * optionally using the provided localWriteTime.\n */\nexport function applyTransformOperationToLocalView(\n  transform: TransformOperation,\n  previousValue: api.Value | null,\n  localWriteTime: Timestamp\n): api.Value {\n  if (transform instanceof ServerTimestampTransform) {\n    return serverTimestamp(localWriteTime, previousValue);\n  } else if (transform instanceof ArrayUnionTransformOperation) {\n    return applyArrayUnionTransformOperation(transform, previousValue);\n  } else if (transform instanceof ArrayRemoveTransformOperation) {\n    return applyArrayRemoveTransformOperation(transform, previousValue);\n  } else {\n    debugAssert(\n      transform instanceof NumericIncrementTransformOperation,\n      'Expected NumericIncrementTransformOperation but was: ' + transform\n    );\n    return applyNumericIncrementTransformOperationToLocalView(\n      transform,\n      previousValue\n    );\n  }\n}\n\n/**\n * Computes a final transform result after the transform has been acknowledged\n * by the server, potentially using the server-provided transformResult.\n */\nexport function applyTransformOperationToRemoteDocument(\n  transform: TransformOperation,\n  previousValue: api.Value | null,\n  transformResult: api.Value | null\n): api.Value {\n  // The server just sends null as the transform result for array operations,\n  // so we have to calculate a result the same as we do for local\n  // applications.\n  if (transform instanceof ArrayUnionTransformOperation) {\n    return applyArrayUnionTransformOperation(transform, previousValue);\n  } else if (transform instanceof ArrayRemoveTransformOperation) {\n    return applyArrayRemoveTransformOperation(transform, previousValue);\n  }\n\n  debugAssert(\n    transformResult !== null,\n    \"Didn't receive transformResult for non-array transform\"\n  );\n  return transformResult;\n}\n\n/**\n * If this transform operation is not idempotent, returns the base value to\n * persist for this transform. If a base value is returned, the transform\n * operation is always applied to this base value, even if document has\n * already been updated.\n *\n * Base values provide consistent behavior for non-idempotent transforms and\n * allow us to return the same latency-compensated value even if the backend\n * has already applied the transform operation. The base value is null for\n * idempotent transforms, as they can be re-played even if the backend has\n * already applied them.\n *\n * @return a base value to store along with the mutation, or null for\n * idempotent transforms.\n */\nexport function computeTransformOperationBaseValue(\n  transform: TransformOperation,\n  previousValue: api.Value | null\n): api.Value | null {\n  if (transform instanceof NumericIncrementTransformOperation) {\n    return isNumber(previousValue) ? previousValue! : { integerValue: 0 };\n  }\n  return null;\n}\n\nexport function transformOperationEquals(\n  left: TransformOperation,\n  right: TransformOperation\n): boolean {\n  if (\n    left instanceof ArrayUnionTransformOperation &&\n    right instanceof ArrayUnionTransformOperation\n  ) {\n    return arrayEquals(left.elements, right.elements, valueEquals);\n  } else if (\n    left instanceof ArrayRemoveTransformOperation &&\n    right instanceof ArrayRemoveTransformOperation\n  ) {\n    return arrayEquals(left.elements, right.elements, valueEquals);\n  } else if (\n    left instanceof NumericIncrementTransformOperation &&\n    right instanceof NumericIncrementTransformOperation\n  ) {\n    return valueEquals(left.operand, right.operand);\n  }\n\n  return (\n    left instanceof ServerTimestampTransform &&\n    right instanceof ServerTimestampTransform\n  );\n}\n\n/** Transforms a value into a server-generated timestamp. */\nexport class ServerTimestampTransform extends TransformOperation {}\n\n/** Transforms an array value via a union operation. */\nexport class ArrayUnionTransformOperation extends TransformOperation {\n  constructor(readonly elements: api.Value[]) {\n    super();\n  }\n}\n\nfunction applyArrayUnionTransformOperation(\n  transform: ArrayUnionTransformOperation,\n  previousValue: api.Value | null\n): api.Value {\n  const values = coercedFieldValuesArray(previousValue);\n  for (const toUnion of transform.elements) {\n    if (!values.some(element => valueEquals(element, toUnion))) {\n      values.push(toUnion);\n    }\n  }\n  return { arrayValue: { values } };\n}\n\n/** Transforms an array value via a remove operation. */\nexport class ArrayRemoveTransformOperation extends TransformOperation {\n  constructor(readonly elements: api.Value[]) {\n    super();\n  }\n}\n\nfunction applyArrayRemoveTransformOperation(\n  transform: ArrayRemoveTransformOperation,\n  previousValue: api.Value | null\n): api.Value {\n  let values = coercedFieldValuesArray(previousValue);\n  for (const toRemove of transform.elements) {\n    values = values.filter(element => !valueEquals(element, toRemove));\n  }\n  return { arrayValue: { values } };\n}\n\n/**\n * Implements the backend semantics for locally computed NUMERIC_ADD (increment)\n * transforms. Converts all field values to integers or doubles, but unlike the\n * backend does not cap integer values at 2^63. Instead, JavaScript number\n * arithmetic is used and precision loss can occur for values greater than 2^53.\n */\nexport class NumericIncrementTransformOperation extends TransformOperation {\n  constructor(\n    readonly serializer: JsonProtoSerializer,\n    readonly operand: api.Value\n  ) {\n    super();\n    debugAssert(\n      isNumber(operand),\n      'NumericIncrementTransform transform requires a NumberValue'\n    );\n  }\n}\n\nexport function applyNumericIncrementTransformOperationToLocalView(\n  transform: NumericIncrementTransformOperation,\n  previousValue: api.Value | null\n): api.Value {\n  // PORTING NOTE: Since JavaScript's integer arithmetic is limited to 53 bit\n  // precision and resolves overflows by reducing precision, we do not\n  // manually cap overflows at 2^63.\n  const baseValue = computeTransformOperationBaseValue(\n    transform,\n    previousValue\n  )!;\n  const sum = asNumber(baseValue) + asNumber(transform.operand);\n  if (isInteger(baseValue) && isInteger(transform.operand)) {\n    return toInteger(sum);\n  } else {\n    return toDouble(transform.serializer, sum);\n  }\n}\n\nfunction asNumber(value: api.Value): number {\n  return normalizeNumber(value.integerValue || value.doubleValue);\n}\n\nfunction coercedFieldValuesArray(value: api.Value | null): api.Value[] {\n  return isArray(value) && value.arrayValue.values\n    ? value.arrayValue.values.slice()\n    : [];\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { Timestamp } from '../api/timestamp';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { debugAssert, hardAssert } from '../util/assert';\n\nimport {\n  Document,\n  MaybeDocument,\n  NoDocument,\n  UnknownDocument\n} from './document';\nimport { DocumentKey } from './document_key';\nimport { ObjectValue, ObjectValueBuilder } from './object_value';\nimport { FieldPath } from './path';\nimport {\n  applyTransformOperationToLocalView,\n  applyTransformOperationToRemoteDocument,\n  computeTransformOperationBaseValue,\n  TransformOperation,\n  transformOperationEquals\n} from './transform_operation';\nimport { arrayEquals } from '../util/misc';\n\n/**\n * Provides a set of fields that can be used to partially patch a document.\n * FieldMask is used in conjunction with ObjectValue.\n * Examples:\n *   foo - Overwrites foo entirely with the provided value. If foo is not\n *         present in the companion ObjectValue, the field is deleted.\n *   foo.bar - Overwrites only the field bar of the object foo.\n *             If foo is not an object, foo is replaced with an object\n *             containing foo\n */\nexport class FieldMask {\n  constructor(readonly fields: FieldPath[]) {\n    // TODO(dimond): validation of FieldMask\n    // Sort the field mask to support `FieldMask.isEqual()` and assert below.\n    fields.sort(FieldPath.comparator);\n    debugAssert(\n      !fields.some((v, i) => i !== 0 && v.isEqual(fields[i - 1])),\n      'FieldMask contains field that is not unique: ' +\n        fields.find((v, i) => i !== 0 && v.isEqual(fields[i - 1]))!\n    );\n  }\n\n  /**\n   * Verifies that `fieldPath` is included by at least one field in this field\n   * mask.\n   *\n   * This is an O(n) operation, where `n` is the size of the field mask.\n   */\n  covers(fieldPath: FieldPath): boolean {\n    for (const fieldMaskPath of this.fields) {\n      if (fieldMaskPath.isPrefixOf(fieldPath)) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  isEqual(other: FieldMask): boolean {\n    return arrayEquals(this.fields, other.fields, (l, r) => l.isEqual(r));\n  }\n}\n\n/** A field path and the TransformOperation to perform upon it. */\nexport class FieldTransform {\n  constructor(\n    readonly field: FieldPath,\n    readonly transform: TransformOperation\n  ) {}\n}\n\nexport function fieldTransformEquals(\n  left: FieldTransform,\n  right: FieldTransform\n): boolean {\n  return (\n    left.field.isEqual(right.field) &&\n    transformOperationEquals(left.transform, right.transform)\n  );\n}\n\n/** The result of successfully applying a mutation to the backend. */\nexport class MutationResult {\n  constructor(\n    /**\n     * The version at which the mutation was committed:\n     *\n     * - For most operations, this is the updateTime in the WriteResult.\n     * - For deletes, the commitTime of the WriteResponse (because deletes are\n     *   not stored and have no updateTime).\n     *\n     * Note that these versions can be different: No-op writes will not change\n     * the updateTime even though the commitTime advances.\n     */\n    readonly version: SnapshotVersion,\n    /**\n     * The resulting fields returned from the backend after a\n     * TransformMutation has been committed. Contains one FieldValue for each\n     * FieldTransform that was in the mutation.\n     *\n     * Will be null if the mutation was not a TransformMutation.\n     */\n    readonly transformResults: Array<api.Value | null> | null\n  ) {}\n}\n\nexport const enum MutationType {\n  Set,\n  Patch,\n  Transform,\n  Delete,\n  Verify\n}\n\n/**\n * Encodes a precondition for a mutation. This follows the model that the\n * backend accepts with the special case of an explicit \"empty\" precondition\n * (meaning no precondition).\n */\nexport class Precondition {\n  private constructor(\n    readonly updateTime?: SnapshotVersion,\n    readonly exists?: boolean\n  ) {\n    debugAssert(\n      updateTime === undefined || exists === undefined,\n      'Precondition can specify \"exists\" or \"updateTime\" but not both'\n    );\n  }\n\n  /** Creates a new empty Precondition. */\n  static none(): Precondition {\n    return new Precondition();\n  }\n\n  /** Creates a new Precondition with an exists flag. */\n  static exists(exists: boolean): Precondition {\n    return new Precondition(undefined, exists);\n  }\n\n  /** Creates a new Precondition based on a version a document exists at. */\n  static updateTime(version: SnapshotVersion): Precondition {\n    return new Precondition(version);\n  }\n\n  /** Returns whether this Precondition is empty. */\n  get isNone(): boolean {\n    return this.updateTime === undefined && this.exists === undefined;\n  }\n\n  isEqual(other: Precondition): boolean {\n    return (\n      this.exists === other.exists &&\n      (this.updateTime\n        ? !!other.updateTime && this.updateTime.isEqual(other.updateTime)\n        : !other.updateTime)\n    );\n  }\n}\n\n/**\n * Returns true if the preconditions is valid for the given document\n * (or null if no document is available).\n */\nexport function preconditionIsValidForDocument(\n  precondition: Precondition,\n  maybeDoc: MaybeDocument | null\n): boolean {\n  if (precondition.updateTime !== undefined) {\n    return (\n      maybeDoc instanceof Document &&\n      maybeDoc.version.isEqual(precondition.updateTime)\n    );\n  } else if (precondition.exists !== undefined) {\n    return precondition.exists === maybeDoc instanceof Document;\n  } else {\n    debugAssert(precondition.isNone, 'Precondition should be empty');\n    return true;\n  }\n}\n\n/**\n * A mutation describes a self-contained change to a document. Mutations can\n * create, replace, delete, and update subsets of documents.\n *\n * Mutations not only act on the value of the document but also its version.\n *\n * For local mutations (mutations that haven't been committed yet), we preserve\n * the existing version for Set, Patch, and Transform mutations. For Delete\n * mutations, we reset the version to 0.\n *\n * Here's the expected transition table.\n *\n * MUTATION           APPLIED TO            RESULTS IN\n *\n * SetMutation        Document(v3)          Document(v3)\n * SetMutation        NoDocument(v3)        Document(v0)\n * SetMutation        null                  Document(v0)\n * PatchMutation      Document(v3)          Document(v3)\n * PatchMutation      NoDocument(v3)        NoDocument(v3)\n * PatchMutation      null                  null\n * TransformMutation  Document(v3)          Document(v3)\n * TransformMutation  NoDocument(v3)        NoDocument(v3)\n * TransformMutation  null                  null\n * DeleteMutation     Document(v3)          NoDocument(v0)\n * DeleteMutation     NoDocument(v3)        NoDocument(v0)\n * DeleteMutation     null                  NoDocument(v0)\n *\n * For acknowledged mutations, we use the updateTime of the WriteResponse as\n * the resulting version for Set, Patch, and Transform mutations. As deletes\n * have no explicit update time, we use the commitTime of the WriteResponse for\n * Delete mutations.\n *\n * If a mutation is acknowledged by the backend but fails the precondition check\n * locally, we return an `UnknownDocument` and rely on Watch to send us the\n * updated version.\n *\n * Note that TransformMutations don't create Documents (in the case of being\n * applied to a NoDocument), even though they would on the backend. This is\n * because the client always combines the TransformMutation with a SetMutation\n * or PatchMutation and we only want to apply the transform if the prior\n * mutation resulted in a Document (always true for a SetMutation, but not\n * necessarily for a PatchMutation).\n *\n * ## Subclassing Notes\n *\n * Subclasses of Mutation need to implement applyToRemoteDocument() and\n * applyToLocalView() to implement the actual behavior of applying the mutation\n * to some source document.\n */\nexport abstract class Mutation {\n  abstract readonly type: MutationType;\n  abstract readonly key: DocumentKey;\n  abstract readonly precondition: Precondition;\n}\n\n/**\n * Applies this mutation to the given MaybeDocument or null for the purposes\n * of computing a new remote document. If the input document doesn't match the\n * expected state (e.g. it is null or outdated), an `UnknownDocument` can be\n * returned.\n *\n * @param mutation The mutation to apply.\n * @param maybeDoc The document to mutate. The input document can be null if\n *     the client has no knowledge of the pre-mutation state of the document.\n * @param mutationResult The result of applying the mutation from the backend.\n * @return The mutated document. The returned document may be an\n *     UnknownDocument if the mutation could not be applied to the locally\n *     cached base document.\n */\nexport function applyMutationToRemoteDocument(\n  mutation: Mutation,\n  maybeDoc: MaybeDocument | null,\n  mutationResult: MutationResult\n): MaybeDocument {\n  verifyMutationKeyMatches(mutation, maybeDoc);\n  if (mutation instanceof SetMutation) {\n    return applySetMutationToRemoteDocument(mutation, maybeDoc, mutationResult);\n  } else if (mutation instanceof PatchMutation) {\n    return applyPatchMutationToRemoteDocument(\n      mutation,\n      maybeDoc,\n      mutationResult\n    );\n  } else if (mutation instanceof TransformMutation) {\n    return applyTransformMutationToRemoteDocument(\n      mutation,\n      maybeDoc,\n      mutationResult\n    );\n  } else {\n    debugAssert(\n      mutation instanceof DeleteMutation,\n      'Unexpected mutation type: ' + mutation\n    );\n    return applyDeleteMutationToRemoteDocument(\n      mutation,\n      maybeDoc,\n      mutationResult\n    );\n  }\n}\n\n/**\n * Applies this mutation to the given MaybeDocument or null for the purposes\n * of computing the new local view of a document. Both the input and returned\n * documents can be null.\n *\n * @param mutation The mutation to apply.\n * @param maybeDoc The document to mutate. The input document can be null if\n *     the client has no knowledge of the pre-mutation state of the document.\n * @param baseDoc The state of the document prior to this mutation batch. The\n *     input document can be null if the client has no knowledge of the\n *     pre-mutation state of the document.\n * @param localWriteTime A timestamp indicating the local write time of the\n *     batch this mutation is a part of.\n * @return The mutated document. The returned document may be null, but only\n *     if maybeDoc was null and the mutation would not create a new document.\n */\nexport function applyMutationToLocalView(\n  mutation: Mutation,\n  maybeDoc: MaybeDocument | null,\n  baseDoc: MaybeDocument | null,\n  localWriteTime: Timestamp\n): MaybeDocument | null {\n  verifyMutationKeyMatches(mutation, maybeDoc);\n\n  if (mutation instanceof SetMutation) {\n    return applySetMutationToLocalView(mutation, maybeDoc);\n  } else if (mutation instanceof PatchMutation) {\n    return applyPatchMutationToLocalView(mutation, maybeDoc);\n  } else if (mutation instanceof TransformMutation) {\n    return applyTransformMutationToLocalView(\n      mutation,\n      maybeDoc,\n      localWriteTime,\n      baseDoc\n    );\n  } else {\n    debugAssert(\n      mutation instanceof DeleteMutation,\n      'Unexpected mutation type: ' + mutation\n    );\n    return applyDeleteMutationToLocalView(mutation, maybeDoc);\n  }\n}\n\n/**\n * If this mutation is not idempotent, returns the base value to persist with\n * this mutation. If a base value is returned, the mutation is always applied\n * to this base value, even if document has already been updated.\n *\n * The base value is a sparse object that consists of only the document\n * fields for which this mutation contains a non-idempotent transformation\n * (e.g. a numeric increment). The provided value guarantees consistent\n * behavior for non-idempotent transforms and allow us to return the same\n * latency-compensated value even if the backend has already applied the\n * mutation. The base value is null for idempotent mutations, as they can be\n * re-played even if the backend has already applied them.\n *\n * @return a base value to store along with the mutation, or null for\n * idempotent mutations.\n */\nexport function extractMutationBaseValue(\n  mutation: Mutation,\n  maybeDoc: MaybeDocument | null\n): ObjectValue | null {\n  if (mutation instanceof TransformMutation) {\n    return extractTransformMutationBaseValue(mutation, maybeDoc);\n  }\n  return null;\n}\n\nexport function mutationEquals(left: Mutation, right: Mutation): boolean {\n  if (left.type !== right.type) {\n    return false;\n  }\n\n  if (!left.key.isEqual(right.key)) {\n    return false;\n  }\n\n  if (!left.precondition.isEqual(right.precondition)) {\n    return false;\n  }\n\n  if (left.type === MutationType.Set) {\n    return (left as SetMutation).value.isEqual((right as SetMutation).value);\n  }\n\n  if (left.type === MutationType.Patch) {\n    return (\n      (left as PatchMutation).data.isEqual((right as PatchMutation).data) &&\n      (left as PatchMutation).fieldMask.isEqual(\n        (right as PatchMutation).fieldMask\n      )\n    );\n  }\n\n  if (left.type === MutationType.Transform) {\n    return arrayEquals(\n      (left as TransformMutation).fieldTransforms,\n      (left as TransformMutation).fieldTransforms,\n      (l, r) => fieldTransformEquals(l, r)\n    );\n  }\n\n  return true;\n}\n\nfunction verifyMutationKeyMatches(\n  mutation: Mutation,\n  maybeDoc: MaybeDocument | null\n): void {\n  if (maybeDoc != null) {\n    debugAssert(\n      maybeDoc.key.isEqual(mutation.key),\n      'Can only apply a mutation to a document with the same key'\n    );\n  }\n}\n\n/**\n * Returns the version from the given document for use as the result of a\n * mutation. Mutations are defined to return the version of the base document\n * only if it is an existing document. Deleted and unknown documents have a\n * post-mutation version of SnapshotVersion.min().\n */\nfunction getPostMutationVersion(\n  maybeDoc: MaybeDocument | null\n): SnapshotVersion {\n  if (maybeDoc instanceof Document) {\n    return maybeDoc.version;\n  } else {\n    return SnapshotVersion.min();\n  }\n}\n\n/**\n * A mutation that creates or replaces the document at the given key with the\n * object value contents.\n */\nexport class SetMutation extends Mutation {\n  constructor(\n    readonly key: DocumentKey,\n    readonly value: ObjectValue,\n    readonly precondition: Precondition\n  ) {\n    super();\n  }\n\n  readonly type: MutationType = MutationType.Set;\n}\n\nfunction applySetMutationToRemoteDocument(\n  mutation: SetMutation,\n  maybeDoc: MaybeDocument | null,\n  mutationResult: MutationResult\n): Document {\n  debugAssert(\n    mutationResult.transformResults == null,\n    'Transform results received by SetMutation.'\n  );\n\n  // Unlike applySetMutationToLocalView, if we're applying a mutation to a\n  // remote document the server has accepted the mutation so the precondition\n  // must have held.\n  return new Document(mutation.key, mutationResult.version, mutation.value, {\n    hasCommittedMutations: true\n  });\n}\n\nfunction applySetMutationToLocalView(\n  mutation: SetMutation,\n  maybeDoc: MaybeDocument | null\n): MaybeDocument | null {\n  if (!preconditionIsValidForDocument(mutation.precondition, maybeDoc)) {\n    return maybeDoc;\n  }\n\n  const version = getPostMutationVersion(maybeDoc);\n  return new Document(mutation.key, version, mutation.value, {\n    hasLocalMutations: true\n  });\n}\n\n/**\n * A mutation that modifies fields of the document at the given key with the\n * given values. The values are applied through a field mask:\n *\n *  * When a field is in both the mask and the values, the corresponding field\n *    is updated.\n *  * When a field is in neither the mask nor the values, the corresponding\n *    field is unmodified.\n *  * When a field is in the mask but not in the values, the corresponding field\n *    is deleted.\n *  * When a field is not in the mask but is in the values, the values map is\n *    ignored.\n */\nexport class PatchMutation extends Mutation {\n  constructor(\n    readonly key: DocumentKey,\n    readonly data: ObjectValue,\n    readonly fieldMask: FieldMask,\n    readonly precondition: Precondition\n  ) {\n    super();\n  }\n\n  readonly type: MutationType = MutationType.Patch;\n}\n\nfunction applyPatchMutationToRemoteDocument(\n  mutation: PatchMutation,\n  maybeDoc: MaybeDocument | null,\n  mutationResult: MutationResult\n): MaybeDocument {\n  debugAssert(\n    mutationResult.transformResults == null,\n    'Transform results received by PatchMutation.'\n  );\n\n  if (!preconditionIsValidForDocument(mutation.precondition, maybeDoc)) {\n    // Since the mutation was not rejected, we know that the  precondition\n    // matched on the backend. We therefore must not have the expected version\n    // of the document in our cache and return an UnknownDocument with the\n    // known updateTime.\n    return new UnknownDocument(mutation.key, mutationResult.version);\n  }\n\n  const newData = patchDocument(mutation, maybeDoc);\n  return new Document(mutation.key, mutationResult.version, newData, {\n    hasCommittedMutations: true\n  });\n}\n\nfunction applyPatchMutationToLocalView(\n  mutation: PatchMutation,\n  maybeDoc: MaybeDocument | null\n): MaybeDocument | null {\n  if (!preconditionIsValidForDocument(mutation.precondition, maybeDoc)) {\n    return maybeDoc;\n  }\n\n  const version = getPostMutationVersion(maybeDoc);\n  const newData = patchDocument(mutation, maybeDoc);\n  return new Document(mutation.key, version, newData, {\n    hasLocalMutations: true\n  });\n}\n\n/**\n * Patches the data of document if available or creates a new document. Note\n * that this does not check whether or not the precondition of this patch\n * holds.\n */\nfunction patchDocument(\n  mutation: PatchMutation,\n  maybeDoc: MaybeDocument | null\n): ObjectValue {\n  let data: ObjectValue;\n  if (maybeDoc instanceof Document) {\n    data = maybeDoc.data();\n  } else {\n    data = ObjectValue.empty();\n  }\n  return patchObject(mutation, data);\n}\n\nfunction patchObject(mutation: PatchMutation, data: ObjectValue): ObjectValue {\n  const builder = new ObjectValueBuilder(data);\n  mutation.fieldMask.fields.forEach(fieldPath => {\n    if (!fieldPath.isEmpty()) {\n      const newValue = mutation.data.field(fieldPath);\n      if (newValue !== null) {\n        builder.set(fieldPath, newValue);\n      } else {\n        builder.delete(fieldPath);\n      }\n    }\n  });\n  return builder.build();\n}\n\n/**\n * A mutation that modifies specific fields of the document with transform\n * operations. Currently the only supported transform is a server timestamp, but\n * IP Address, increment(n), etc. could be supported in the future.\n *\n * It is somewhat similar to a PatchMutation in that it patches specific fields\n * and has no effect when applied to a null or NoDocument (see comment on\n * Mutation for rationale).\n */\nexport class TransformMutation extends Mutation {\n  readonly type: MutationType = MutationType.Transform;\n\n  // NOTE: We set a precondition of exists: true as a safety-check, since we\n  // always combine TransformMutations with a SetMutation or PatchMutation which\n  // (if successful) should end up with an existing document.\n  readonly precondition = Precondition.exists(true);\n\n  constructor(\n    readonly key: DocumentKey,\n    readonly fieldTransforms: FieldTransform[]\n  ) {\n    super();\n  }\n}\n\nfunction applyTransformMutationToRemoteDocument(\n  mutation: TransformMutation,\n  maybeDoc: MaybeDocument | null,\n  mutationResult: MutationResult\n): Document | UnknownDocument {\n  hardAssert(\n    mutationResult.transformResults != null,\n    'Transform results missing for TransformMutation.'\n  );\n\n  if (!preconditionIsValidForDocument(mutation.precondition, maybeDoc)) {\n    // Since the mutation was not rejected, we know that the  precondition\n    // matched on the backend. We therefore must not have the expected version\n    // of the document in our cache and return an UnknownDocument with the\n    // known updateTime.\n    return new UnknownDocument(mutation.key, mutationResult.version);\n  }\n\n  const doc = requireDocument(mutation, maybeDoc);\n  const transformResults = serverTransformResults(\n    mutation.fieldTransforms,\n    maybeDoc,\n    mutationResult.transformResults!\n  );\n\n  const version = mutationResult.version;\n  const newData = transformObject(mutation, doc.data(), transformResults);\n  return new Document(mutation.key, version, newData, {\n    hasCommittedMutations: true\n  });\n}\n\nfunction applyTransformMutationToLocalView(\n  mutation: TransformMutation,\n  maybeDoc: MaybeDocument | null,\n  localWriteTime: Timestamp,\n  baseDoc: MaybeDocument | null\n): MaybeDocument | null {\n  if (!preconditionIsValidForDocument(mutation.precondition, maybeDoc)) {\n    return maybeDoc;\n  }\n\n  const doc = requireDocument(mutation, maybeDoc);\n  const transformResults = localTransformResults(\n    mutation.fieldTransforms,\n    localWriteTime,\n    maybeDoc,\n    baseDoc\n  );\n  const newData = transformObject(mutation, doc.data(), transformResults);\n  return new Document(mutation.key, doc.version, newData, {\n    hasLocalMutations: true\n  });\n}\n\nfunction extractTransformMutationBaseValue(\n  mutation: TransformMutation,\n  maybeDoc: MaybeDocument | null | Document\n): ObjectValue | null {\n  let baseObject: ObjectValueBuilder | null = null;\n  for (const fieldTransform of mutation.fieldTransforms) {\n    const existingValue =\n      maybeDoc instanceof Document\n        ? maybeDoc.field(fieldTransform.field)\n        : undefined;\n    const coercedValue = computeTransformOperationBaseValue(\n      fieldTransform.transform,\n      existingValue || null\n    );\n\n    if (coercedValue != null) {\n      if (baseObject == null) {\n        baseObject = new ObjectValueBuilder().set(\n          fieldTransform.field,\n          coercedValue\n        );\n      } else {\n        baseObject = baseObject.set(fieldTransform.field, coercedValue);\n      }\n    }\n  }\n  return baseObject ? baseObject.build() : null;\n}\n\n/**\n * Asserts that the given MaybeDocument is actually a Document and verifies\n * that it matches the key for this mutation. Since we only support\n * transformations with precondition exists this method is guaranteed to be\n * safe.\n */\nfunction requireDocument(\n  mutation: Mutation,\n  maybeDoc: MaybeDocument | null\n): Document {\n  debugAssert(\n    maybeDoc instanceof Document,\n    'Unknown MaybeDocument type ' + maybeDoc\n  );\n  debugAssert(\n    maybeDoc.key.isEqual(mutation.key),\n    'Can only transform a document with the same key'\n  );\n  return maybeDoc;\n}\n\n/**\n * Creates a list of \"transform results\" (a transform result is a field value\n * representing the result of applying a transform) for use after a\n * TransformMutation has been acknowledged by the server.\n *\n * @param fieldTransforms The field transforms to apply the result to.\n * @param baseDoc The document prior to applying this mutation batch.\n * @param serverTransformResults The transform results received by the server.\n * @return The transform results list.\n */\nfunction serverTransformResults(\n  fieldTransforms: FieldTransform[],\n  baseDoc: MaybeDocument | null,\n  serverTransformResults: Array<api.Value | null>\n): api.Value[] {\n  const transformResults: api.Value[] = [];\n  hardAssert(\n    fieldTransforms.length === serverTransformResults.length,\n    `server transform result count (${serverTransformResults.length}) ` +\n      `should match field transform count (${fieldTransforms.length})`\n  );\n\n  for (let i = 0; i < serverTransformResults.length; i++) {\n    const fieldTransform = fieldTransforms[i];\n    const transform = fieldTransform.transform;\n    let previousValue: api.Value | null = null;\n    if (baseDoc instanceof Document) {\n      previousValue = baseDoc.field(fieldTransform.field);\n    }\n    transformResults.push(\n      applyTransformOperationToRemoteDocument(\n        transform,\n        previousValue,\n        serverTransformResults[i]\n      )\n    );\n  }\n  return transformResults;\n}\n\n/**\n * Creates a list of \"transform results\" (a transform result is a field value\n * representing the result of applying a transform) for use when applying a\n * TransformMutation locally.\n *\n * @param fieldTransforms The field transforms to apply the result to.\n * @param localWriteTime The local time of the transform mutation (used to\n *     generate ServerTimestampValues).\n * @param maybeDoc The current state of the document after applying all\n *     previous mutations.\n * @param baseDoc The document prior to applying this mutation batch.\n * @return The transform results list.\n */\nfunction localTransformResults(\n  fieldTransforms: FieldTransform[],\n  localWriteTime: Timestamp,\n  maybeDoc: MaybeDocument | null,\n  baseDoc: MaybeDocument | null\n): api.Value[] {\n  const transformResults: api.Value[] = [];\n  for (const fieldTransform of fieldTransforms) {\n    const transform = fieldTransform.transform;\n\n    let previousValue: api.Value | null = null;\n    if (maybeDoc instanceof Document) {\n      previousValue = maybeDoc.field(fieldTransform.field);\n    }\n\n    if (previousValue === null && baseDoc instanceof Document) {\n      // If the current document does not contain a value for the mutated\n      // field, use the value that existed before applying this mutation\n      // batch. This solves an edge case where a PatchMutation clears the\n      // values in a nested map before the TransformMutation is applied.\n      previousValue = baseDoc.field(fieldTransform.field);\n    }\n\n    transformResults.push(\n      applyTransformOperationToLocalView(\n        transform,\n        previousValue,\n        localWriteTime\n      )\n    );\n  }\n  return transformResults;\n}\n\nfunction transformObject(\n  mutation: TransformMutation,\n  data: ObjectValue,\n  transformResults: api.Value[]\n): ObjectValue {\n  debugAssert(\n    transformResults.length === mutation.fieldTransforms.length,\n    'TransformResults length mismatch.'\n  );\n\n  const builder = new ObjectValueBuilder(data);\n  for (let i = 0; i < mutation.fieldTransforms.length; i++) {\n    const fieldTransform = mutation.fieldTransforms[i];\n    builder.set(fieldTransform.field, transformResults[i]);\n  }\n  return builder.build();\n}\n\n/** A mutation that deletes the document at the given key. */\nexport class DeleteMutation extends Mutation {\n  constructor(readonly key: DocumentKey, readonly precondition: Precondition) {\n    super();\n  }\n\n  readonly type: MutationType = MutationType.Delete;\n}\n\nfunction applyDeleteMutationToRemoteDocument(\n  mutation: DeleteMutation,\n  maybeDoc: MaybeDocument | null,\n  mutationResult: MutationResult\n): NoDocument {\n  debugAssert(\n    mutationResult.transformResults == null,\n    'Transform results received by DeleteMutation.'\n  );\n\n  // Unlike applyToLocalView, if we're applying a mutation to a remote\n  // document the server has accepted the mutation so the precondition must\n  // have held.\n\n  return new NoDocument(mutation.key, mutationResult.version, {\n    hasCommittedMutations: true\n  });\n}\n\nfunction applyDeleteMutationToLocalView(\n  mutation: DeleteMutation,\n  maybeDoc: MaybeDocument | null\n): MaybeDocument | null {\n  if (!preconditionIsValidForDocument(mutation.precondition, maybeDoc)) {\n    return maybeDoc;\n  }\n\n  if (maybeDoc) {\n    debugAssert(\n      maybeDoc.key.isEqual(mutation.key),\n      'Can only apply mutation to document with same key'\n    );\n  }\n  return new NoDocument(mutation.key, SnapshotVersion.min());\n}\n\n/**\n * A mutation that verifies the existence of the document at the given key with\n * the provided precondition.\n *\n * The `verify` operation is only used in Transactions, and this class serves\n * primarily to facilitate serialization into protos.\n */\nexport class VerifyMutation extends Mutation {\n  constructor(readonly key: DocumentKey, readonly precondition: Precondition) {\n    super();\n  }\n\n  readonly type: MutationType = MutationType.Verify;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { debugAssert } from '../util/assert';\nimport { FieldMask } from './mutation';\nimport { FieldPath } from './path';\nimport { isServerTimestamp } from './server_timestamps';\nimport { valueEquals, isMapValue, typeOrder } from './values';\nimport { forEach } from '../util/obj';\n\nexport interface JsonObject<T> {\n  [name: string]: T;\n}\n\nexport const enum TypeOrder {\n  // This order is based on the backend's ordering, but modified to support\n  // server timestamps.\n  NullValue = 0,\n  BooleanValue = 1,\n  NumberValue = 2,\n  TimestampValue = 3,\n  ServerTimestampValue = 4,\n  StringValue = 5,\n  BlobValue = 6,\n  RefValue = 7,\n  GeoPointValue = 8,\n  ArrayValue = 9,\n  ObjectValue = 10\n}\n\n/**\n * An ObjectValue represents a MapValue in the Firestore Proto and offers the\n * ability to add and remove fields (via the ObjectValueBuilder).\n */\nexport class ObjectValue {\n  constructor(readonly proto: { mapValue: api.MapValue }) {\n    debugAssert(\n      !isServerTimestamp(proto),\n      'ServerTimestamps should be converted to ServerTimestampValue'\n    );\n  }\n\n  static empty(): ObjectValue {\n    return new ObjectValue({ mapValue: {} });\n  }\n\n  /**\n   * Returns the value at the given path or null.\n   *\n   * @param path the path to search\n   * @return The value at the path or if there it doesn't exist.\n   */\n  field(path: FieldPath): api.Value | null {\n    if (path.isEmpty()) {\n      return this.proto;\n    } else {\n      let value: api.Value = this.proto;\n      for (let i = 0; i < path.length - 1; ++i) {\n        if (!value.mapValue!.fields) {\n          return null;\n        }\n        value = value.mapValue!.fields[path.get(i)];\n        if (!isMapValue(value)) {\n          return null;\n        }\n      }\n\n      value = (value.mapValue!.fields || {})[path.lastSegment()];\n      return value || null;\n    }\n  }\n\n  isEqual(other: ObjectValue): boolean {\n    return valueEquals(this.proto, other.proto);\n  }\n}\n\n/**\n * An Overlay, which contains an update to apply. Can either be Value proto, a\n * map of Overlay values (to represent additional nesting at the given key) or\n * `null` (to represent field deletes).\n */\ntype Overlay = Map<string, Overlay> | api.Value | null;\n\n/**\n * An ObjectValueBuilder provides APIs to set and delete fields from an\n * ObjectValue.\n */\nexport class ObjectValueBuilder {\n  /** A map that contains the accumulated changes in this builder. */\n  private overlayMap = new Map<string, Overlay>();\n\n  /**\n   * @param baseObject The object to mutate.\n   */\n  constructor(private readonly baseObject: ObjectValue = ObjectValue.empty()) {}\n\n  /**\n   * Sets the field to the provided value.\n   *\n   * @param path The field path to set.\n   * @param value The value to set.\n   * @return The current Builder instance.\n   */\n  set(path: FieldPath, value: api.Value): ObjectValueBuilder {\n    debugAssert(\n      !path.isEmpty(),\n      'Cannot set field for empty path on ObjectValue'\n    );\n    this.setOverlay(path, value);\n    return this;\n  }\n\n  /**\n   * Removes the field at the specified path. If there is no field at the\n   * specified path, nothing is changed.\n   *\n   * @param path The field path to remove.\n   * @return The current Builder instance.\n   */\n  delete(path: FieldPath): ObjectValueBuilder {\n    debugAssert(\n      !path.isEmpty(),\n      'Cannot delete field for empty path on ObjectValue'\n    );\n    this.setOverlay(path, null);\n    return this;\n  }\n\n  /**\n   * Adds `value` to the overlay map at `path`. Creates nested map entries if\n   * needed.\n   */\n  private setOverlay(path: FieldPath, value: api.Value | null): void {\n    let currentLevel = this.overlayMap;\n\n    for (let i = 0; i < path.length - 1; ++i) {\n      const currentSegment = path.get(i);\n      let currentValue = currentLevel.get(currentSegment);\n\n      if (currentValue instanceof Map) {\n        // Re-use a previously created map\n        currentLevel = currentValue;\n      } else if (\n        currentValue &&\n        typeOrder(currentValue) === TypeOrder.ObjectValue\n      ) {\n        // Convert the existing Protobuf MapValue into a map\n        currentValue = new Map<string, Overlay>(\n          Object.entries(currentValue.mapValue!.fields || {})\n        );\n        currentLevel.set(currentSegment, currentValue);\n        currentLevel = currentValue;\n      } else {\n        // Create an empty map to represent the current nesting level\n        currentValue = new Map<string, Overlay>();\n        currentLevel.set(currentSegment, currentValue);\n        currentLevel = currentValue;\n      }\n    }\n\n    currentLevel.set(path.lastSegment(), value);\n  }\n\n  /** Returns an ObjectValue with all mutations applied. */\n  build(): ObjectValue {\n    const mergedResult = this.applyOverlay(\n      FieldPath.emptyPath(),\n      this.overlayMap\n    );\n    if (mergedResult != null) {\n      return new ObjectValue(mergedResult);\n    } else {\n      return this.baseObject;\n    }\n  }\n\n  /**\n   * Applies any overlays from `currentOverlays` that exist at `currentPath`\n   * and returns the merged data at `currentPath` (or null if there were no\n   * changes).\n   *\n   * @param currentPath The path at the current nesting level. Can be set to\n   * FieldValue.emptyPath() to represent the root.\n   * @param currentOverlays The overlays at the current nesting level in the\n   * same format as `overlayMap`.\n   * @return The merged data at `currentPath` or null if no modifications\n   * were applied.\n   */\n  private applyOverlay(\n    currentPath: FieldPath,\n    currentOverlays: Map<string, Overlay>\n  ): { mapValue: api.MapValue } | null {\n    let modified = false;\n\n    const existingValue = this.baseObject.field(currentPath);\n    const resultAtPath = isMapValue(existingValue)\n      ? // If there is already data at the current path, base our\n        // modifications on top of the existing data.\n        { ...existingValue.mapValue.fields }\n      : {};\n\n    currentOverlays.forEach((value, pathSegment) => {\n      if (value instanceof Map) {\n        const nested = this.applyOverlay(currentPath.child(pathSegment), value);\n        if (nested != null) {\n          resultAtPath[pathSegment] = nested;\n          modified = true;\n        }\n      } else if (value !== null) {\n        resultAtPath[pathSegment] = value;\n        modified = true;\n      } else if (resultAtPath.hasOwnProperty(pathSegment)) {\n        delete resultAtPath[pathSegment];\n        modified = true;\n      }\n    });\n\n    return modified ? { mapValue: { fields: resultAtPath } } : null;\n  }\n}\n\n/**\n * Returns a FieldMask built from all fields in a MapValue.\n */\nexport function extractFieldMask(value: api.MapValue): FieldMask {\n  const fields: FieldPath[] = [];\n  forEach(value!.fields || {}, (key, value) => {\n    const currentPath = new FieldPath([key]);\n    if (isMapValue(value)) {\n      const nestedMask = extractFieldMask(value.mapValue!);\n      const nestedFields = nestedMask.fields;\n      if (nestedFields.length === 0) {\n        // Preserve the empty map by adding it to the FieldMask.\n        fields.push(currentPath);\n      } else {\n        // For nested and non-empty ObjectValues, add the FieldPath of the\n        // leaf nodes.\n        for (const nestedPath of nestedFields) {\n          fields.push(currentPath.child(nestedPath));\n        }\n      }\n    } else {\n      // For nested and non-empty ObjectValues, add the FieldPath of the leaf\n      // nodes.\n      fields.push(currentPath);\n    }\n  });\n  return new FieldMask(fields);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { fail } from '../util/assert';\n\nimport { DocumentKey } from './document_key';\nimport { ObjectValue } from './object_value';\nimport { FieldPath } from './path';\nimport { valueCompare } from './values';\n\nexport interface DocumentOptions {\n  hasLocalMutations?: boolean;\n  hasCommittedMutations?: boolean;\n}\n\n/**\n * The result of a lookup for a given path may be an existing document or a\n * marker that this document does not exist at a given version.\n */\nexport abstract class MaybeDocument {\n  constructor(readonly key: DocumentKey, readonly version: SnapshotVersion) {}\n\n  /**\n   * Whether this document had a local mutation applied that has not yet been\n   * acknowledged by Watch.\n   */\n  abstract get hasPendingWrites(): boolean;\n\n  abstract isEqual(other: MaybeDocument | null | undefined): boolean;\n\n  abstract toString(): string;\n}\n\n/**\n * Represents a document in Firestore with a key, version, data and whether the\n * data has local mutations applied to it.\n */\nexport class Document extends MaybeDocument {\n  readonly hasLocalMutations: boolean;\n  readonly hasCommittedMutations: boolean;\n\n  constructor(\n    key: DocumentKey,\n    version: SnapshotVersion,\n    private readonly objectValue: ObjectValue,\n    options: DocumentOptions\n  ) {\n    super(key, version);\n    this.hasLocalMutations = !!options.hasLocalMutations;\n    this.hasCommittedMutations = !!options.hasCommittedMutations;\n  }\n\n  field(path: FieldPath): api.Value | null {\n    return this.objectValue.field(path);\n  }\n\n  data(): ObjectValue {\n    return this.objectValue;\n  }\n\n  toProto(): { mapValue: api.MapValue } {\n    return this.objectValue.proto;\n  }\n\n  isEqual(other: MaybeDocument | null | undefined): boolean {\n    return (\n      other instanceof Document &&\n      this.key.isEqual(other.key) &&\n      this.version.isEqual(other.version) &&\n      this.hasLocalMutations === other.hasLocalMutations &&\n      this.hasCommittedMutations === other.hasCommittedMutations &&\n      this.objectValue.isEqual(other.objectValue)\n    );\n  }\n\n  toString(): string {\n    return (\n      `Document(${this.key}, ${\n        this.version\n      }, ${this.objectValue.toString()}, ` +\n      `{hasLocalMutations: ${this.hasLocalMutations}}), ` +\n      `{hasCommittedMutations: ${this.hasCommittedMutations}})`\n    );\n  }\n\n  get hasPendingWrites(): boolean {\n    return this.hasLocalMutations || this.hasCommittedMutations;\n  }\n}\n\n/**\n * Compares the value for field `field` in the provided documents. Throws if\n * the field does not exist in both documents.\n */\nexport function compareDocumentsByField(\n  field: FieldPath,\n  d1: Document,\n  d2: Document\n): number {\n  const v1 = d1.field(field);\n  const v2 = d2.field(field);\n  if (v1 !== null && v2 !== null) {\n    return valueCompare(v1, v2);\n  } else {\n    return fail(\"Trying to compare documents on fields that don't exist\");\n  }\n}\n\n/**\n * A class representing a deleted document.\n * Version is set to 0 if we don't point to any specific time, otherwise it\n * denotes time we know it didn't exist at.\n */\nexport class NoDocument extends MaybeDocument {\n  readonly hasCommittedMutations: boolean;\n\n  constructor(\n    key: DocumentKey,\n    version: SnapshotVersion,\n    options?: DocumentOptions\n  ) {\n    super(key, version);\n    this.hasCommittedMutations = !!(options && options.hasCommittedMutations);\n  }\n\n  toString(): string {\n    return `NoDocument(${this.key}, ${this.version})`;\n  }\n\n  get hasPendingWrites(): boolean {\n    return this.hasCommittedMutations;\n  }\n\n  isEqual(other: MaybeDocument | null | undefined): boolean {\n    return (\n      other instanceof NoDocument &&\n      other.hasCommittedMutations === this.hasCommittedMutations &&\n      other.version.isEqual(this.version) &&\n      other.key.isEqual(this.key)\n    );\n  }\n}\n\n/**\n * A class representing an existing document whose data is unknown (e.g. a\n * document that was updated without a known base document).\n */\nexport class UnknownDocument extends MaybeDocument {\n  toString(): string {\n    return `UnknownDocument(${this.key}, ${this.version})`;\n  }\n\n  get hasPendingWrites(): boolean {\n    return true;\n  }\n\n  isEqual(other: MaybeDocument | null | undefined): boolean {\n    return (\n      other instanceof UnknownDocument &&\n      other.version.isEqual(this.version) &&\n      other.key.isEqual(this.key)\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Code, FirestoreError } from '../../../src/util/error';\n\n/**\n * Casts `obj` to `T`. Throws if  `obj` is not an instance of `T`.\n *\n * This cast is used in the Lite and Full SDK to verify instance types for\n * arguments passed to the public API.\n */\nexport function cast<T>(\n  obj: object,\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  constructor: { new (...args: any[]): T }\n): T | never {\n  if (!(obj instanceof constructor)) {\n    if (constructor.name === obj.constructor.name) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Type does not match the expected instance. Did you pass ' +\n          `'${constructor.name}' from a different Firestore SDK?`\n      );\n    } else {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Expected type '${constructor.name}', but was '${obj.constructor.name}'`\n      );\n    }\n  }\n  return obj as T;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Timestamp } from '../api/timestamp';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { BatchId } from '../core/types';\nimport { debugAssert, hardAssert } from '../util/assert';\nimport { arrayEquals } from '../util/misc';\nimport {\n  documentKeySet,\n  DocumentKeySet,\n  DocumentVersionMap,\n  documentVersionMap,\n  MaybeDocumentMap\n} from './collections';\nimport { MaybeDocument } from './document';\nimport { DocumentKey } from './document_key';\nimport {\n  applyMutationToLocalView,\n  applyMutationToRemoteDocument,\n  Mutation,\n  mutationEquals,\n  MutationResult\n} from './mutation';\n\nexport const BATCHID_UNKNOWN = -1;\n\n/**\n * A batch of mutations that will be sent as one unit to the backend.\n */\nexport class MutationBatch {\n  /**\n   * @param batchId The unique ID of this mutation batch.\n   * @param localWriteTime The original write time of this mutation.\n   * @param baseMutations Mutations that are used to populate the base\n   * values when this mutation is applied locally. This can be used to locally\n   * overwrite values that are persisted in the remote document cache. Base\n   * mutations are never sent to the backend.\n   * @param mutations The user-provided mutations in this mutation batch.\n   * User-provided mutations are applied both locally and remotely on the\n   * backend.\n   */\n  constructor(\n    public batchId: BatchId,\n    public localWriteTime: Timestamp,\n    public baseMutations: Mutation[],\n    public mutations: Mutation[]\n  ) {\n    debugAssert(mutations.length > 0, 'Cannot create an empty mutation batch');\n  }\n\n  /**\n   * Applies all the mutations in this MutationBatch to the specified document\n   * to create a new remote document\n   *\n   * @param docKey The key of the document to apply mutations to.\n   * @param maybeDoc The document to apply mutations to.\n   * @param batchResult The result of applying the MutationBatch to the\n   * backend.\n   */\n  applyToRemoteDocument(\n    docKey: DocumentKey,\n    maybeDoc: MaybeDocument | null,\n    batchResult: MutationBatchResult\n  ): MaybeDocument | null {\n    if (maybeDoc) {\n      debugAssert(\n        maybeDoc.key.isEqual(docKey),\n        `applyToRemoteDocument: key ${docKey} should match maybeDoc key\n        ${maybeDoc.key}`\n      );\n    }\n\n    const mutationResults = batchResult.mutationResults;\n    debugAssert(\n      mutationResults.length === this.mutations.length,\n      `Mismatch between mutations length\n      (${this.mutations.length}) and mutation results length\n      (${mutationResults.length}).`\n    );\n\n    for (let i = 0; i < this.mutations.length; i++) {\n      const mutation = this.mutations[i];\n      if (mutation.key.isEqual(docKey)) {\n        const mutationResult = mutationResults[i];\n        maybeDoc = applyMutationToRemoteDocument(\n          mutation,\n          maybeDoc,\n          mutationResult\n        );\n      }\n    }\n    return maybeDoc;\n  }\n\n  /**\n   * Computes the local view of a document given all the mutations in this\n   * batch.\n   *\n   * @param docKey The key of the document to apply mutations to.\n   * @param maybeDoc The document to apply mutations to.\n   */\n  applyToLocalView(\n    docKey: DocumentKey,\n    maybeDoc: MaybeDocument | null\n  ): MaybeDocument | null {\n    if (maybeDoc) {\n      debugAssert(\n        maybeDoc.key.isEqual(docKey),\n        `applyToLocalDocument: key ${docKey} should match maybeDoc key\n        ${maybeDoc.key}`\n      );\n    }\n\n    // First, apply the base state. This allows us to apply non-idempotent\n    // transform against a consistent set of values.\n    for (const mutation of this.baseMutations) {\n      if (mutation.key.isEqual(docKey)) {\n        maybeDoc = applyMutationToLocalView(\n          mutation,\n          maybeDoc,\n          maybeDoc,\n          this.localWriteTime\n        );\n      }\n    }\n\n    const baseDoc = maybeDoc;\n\n    // Second, apply all user-provided mutations.\n    for (const mutation of this.mutations) {\n      if (mutation.key.isEqual(docKey)) {\n        maybeDoc = applyMutationToLocalView(\n          mutation,\n          maybeDoc,\n          baseDoc,\n          this.localWriteTime\n        );\n      }\n    }\n    return maybeDoc;\n  }\n\n  /**\n   * Computes the local view for all provided documents given the mutations in\n   * this batch.\n   */\n  applyToLocalDocumentSet(maybeDocs: MaybeDocumentMap): MaybeDocumentMap {\n    // TODO(mrschmidt): This implementation is O(n^2). If we apply the mutations\n    // directly (as done in `applyToLocalView()`), we can reduce the complexity\n    // to O(n).\n    let mutatedDocuments = maybeDocs;\n    this.mutations.forEach(m => {\n      const mutatedDocument = this.applyToLocalView(\n        m.key,\n        maybeDocs.get(m.key)\n      );\n      if (mutatedDocument) {\n        mutatedDocuments = mutatedDocuments.insert(m.key, mutatedDocument);\n      }\n    });\n    return mutatedDocuments;\n  }\n\n  keys(): DocumentKeySet {\n    return this.mutations.reduce(\n      (keys, m) => keys.add(m.key),\n      documentKeySet()\n    );\n  }\n\n  isEqual(other: MutationBatch): boolean {\n    return (\n      this.batchId === other.batchId &&\n      arrayEquals(this.mutations, other.mutations, (l, r) =>\n        mutationEquals(l, r)\n      ) &&\n      arrayEquals(this.baseMutations, other.baseMutations, (l, r) =>\n        mutationEquals(l, r)\n      )\n    );\n  }\n}\n\n/** The result of applying a mutation batch to the backend. */\nexport class MutationBatchResult {\n  private constructor(\n    readonly batch: MutationBatch,\n    readonly commitVersion: SnapshotVersion,\n    readonly mutationResults: MutationResult[],\n    /**\n     * A pre-computed mapping from each mutated document to the resulting\n     * version.\n     */\n    readonly docVersions: DocumentVersionMap\n  ) {}\n\n  /**\n   * Creates a new MutationBatchResult for the given batch and results. There\n   * must be one result for each mutation in the batch. This static factory\n   * caches a document=>version mapping (docVersions).\n   */\n  static from(\n    batch: MutationBatch,\n    commitVersion: SnapshotVersion,\n    results: MutationResult[]\n  ): MutationBatchResult {\n    hardAssert(\n      batch.mutations.length === results.length,\n      'Mutations sent ' +\n        batch.mutations.length +\n        ' must equal results received ' +\n        results.length\n    );\n\n    let versionMap = documentVersionMap();\n    const mutations = batch.mutations;\n    for (let i = 0; i < mutations.length; i++) {\n      versionMap = versionMap.insert(mutations[i].key, results[i].version);\n    }\n\n    return new MutationBatchResult(batch, commitVersion, results, versionMap);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { fail } from '../util/assert';\n\nexport type FulfilledHandler<T, R> =\n  | ((result: T) => R | PersistencePromise<R>)\n  | null;\nexport type RejectedHandler<R> =\n  | ((reason: Error) => R | PersistencePromise<R>)\n  | null;\nexport type Resolver<T> = (value?: T) => void;\nexport type Rejector = (error: Error) => void;\n\n/**\n * PersistencePromise<> is essentially a re-implementation of Promise<> except\n * it has a .next() method instead of .then() and .next() and .catch() callbacks\n * are executed synchronously when a PersistencePromise resolves rather than\n * asynchronously (Promise<> implementations use setImmediate() or similar).\n *\n * This is necessary to interoperate with IndexedDB which will automatically\n * commit transactions if control is returned to the event loop without\n * synchronously initiating another operation on the transaction.\n *\n * NOTE: .then() and .catch() only allow a single consumer, unlike normal\n * Promises.\n */\nexport class PersistencePromise<T> {\n  // NOTE: next/catchCallback will always point to our own wrapper functions,\n  // not the user's raw next() or catch() callbacks.\n  private nextCallback: FulfilledHandler<T, unknown> = null;\n  private catchCallback: RejectedHandler<unknown> = null;\n\n  // When the operation resolves, we'll set result or error and mark isDone.\n  private result: T | undefined = undefined;\n  private error: Error | undefined = undefined;\n  private isDone = false;\n\n  // Set to true when .then() or .catch() are called and prevents additional\n  // chaining.\n  private callbackAttached = false;\n\n  constructor(callback: (resolve: Resolver<T>, reject: Rejector) => void) {\n    callback(\n      value => {\n        this.isDone = true;\n        this.result = value;\n        if (this.nextCallback) {\n          // value should be defined unless T is Void, but we can't express\n          // that in the type system.\n          this.nextCallback(value!);\n        }\n      },\n      error => {\n        this.isDone = true;\n        this.error = error;\n        if (this.catchCallback) {\n          this.catchCallback(error);\n        }\n      }\n    );\n  }\n\n  catch<R>(\n    fn: (error: Error) => R | PersistencePromise<R>\n  ): PersistencePromise<R> {\n    return this.next(undefined, fn);\n  }\n\n  next<R>(\n    nextFn?: FulfilledHandler<T, R>,\n    catchFn?: RejectedHandler<R>\n  ): PersistencePromise<R> {\n    if (this.callbackAttached) {\n      fail('Called next() or catch() twice for PersistencePromise');\n    }\n    this.callbackAttached = true;\n    if (this.isDone) {\n      if (!this.error) {\n        return this.wrapSuccess(nextFn, this.result!);\n      } else {\n        return this.wrapFailure(catchFn, this.error);\n      }\n    } else {\n      return new PersistencePromise<R>((resolve, reject) => {\n        this.nextCallback = (value: T) => {\n          this.wrapSuccess(nextFn, value).next(resolve, reject);\n        };\n        this.catchCallback = (error: Error) => {\n          this.wrapFailure(catchFn, error).next(resolve, reject);\n        };\n      });\n    }\n  }\n\n  toPromise(): Promise<T> {\n    return new Promise((resolve, reject) => {\n      this.next(resolve, reject);\n    });\n  }\n\n  private wrapUserFunction<R>(\n    fn: () => R | PersistencePromise<R>\n  ): PersistencePromise<R> {\n    try {\n      const result = fn();\n      if (result instanceof PersistencePromise) {\n        return result;\n      } else {\n        return PersistencePromise.resolve(result);\n      }\n    } catch (e) {\n      return PersistencePromise.reject<R>(e);\n    }\n  }\n\n  private wrapSuccess<R>(\n    nextFn: FulfilledHandler<T, R> | undefined,\n    value: T\n  ): PersistencePromise<R> {\n    if (nextFn) {\n      return this.wrapUserFunction(() => nextFn(value));\n    } else {\n      // If there's no nextFn, then R must be the same as T\n      return PersistencePromise.resolve<R>((value as unknown) as R);\n    }\n  }\n\n  private wrapFailure<R>(\n    catchFn: RejectedHandler<R> | undefined,\n    error: Error\n  ): PersistencePromise<R> {\n    if (catchFn) {\n      return this.wrapUserFunction(() => catchFn(error));\n    } else {\n      return PersistencePromise.reject<R>(error);\n    }\n  }\n\n  static resolve(): PersistencePromise<void>;\n  static resolve<R>(result: R): PersistencePromise<R>;\n  static resolve<R>(result?: R): PersistencePromise<R | void> {\n    return new PersistencePromise<R | void>((resolve, reject) => {\n      resolve(result);\n    });\n  }\n\n  static reject<R>(error: Error): PersistencePromise<R> {\n    return new PersistencePromise<R>((resolve, reject) => {\n      reject(error);\n    });\n  }\n\n  static waitFor(\n    // Accept all Promise types in waitFor().\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    all: { forEach: (cb: (el: PersistencePromise<any>) => void) => void }\n  ): PersistencePromise<void> {\n    return new PersistencePromise<void>((resolve, reject) => {\n      let expectedCount = 0;\n      let resolvedCount = 0;\n      let done = false;\n\n      all.forEach(element => {\n        ++expectedCount;\n        element.next(\n          () => {\n            ++resolvedCount;\n            if (done && resolvedCount === expectedCount) {\n              resolve();\n            }\n          },\n          err => reject(err)\n        );\n      });\n\n      done = true;\n      if (resolvedCount === expectedCount) {\n        resolve();\n      }\n    });\n  }\n\n  /**\n   * Given an array of predicate functions that asynchronously evaluate to a\n   * boolean, implements a short-circuiting `or` between the results. Predicates\n   * will be evaluated until one of them returns `true`, then stop. The final\n   * result will be whether any of them returned `true`.\n   */\n  static or(\n    predicates: Array<() => PersistencePromise<boolean>>\n  ): PersistencePromise<boolean> {\n    let p: PersistencePromise<boolean> = PersistencePromise.resolve<boolean>(\n      false\n    );\n    for (const predicate of predicates) {\n      p = p.next(isTrue => {\n        if (isTrue) {\n          return PersistencePromise.resolve<boolean>(isTrue);\n        } else {\n          return predicate();\n        }\n      });\n    }\n    return p;\n  }\n\n  /**\n   * Given an iterable, call the given function on each element in the\n   * collection and wait for all of the resulting concurrent PersistencePromises\n   * to resolve.\n   */\n  static forEach<R, S>(\n    collection: { forEach: (cb: (r: R, s: S) => void) => void },\n    f:\n      | ((r: R, s: S) => PersistencePromise<void>)\n      | ((r: R) => PersistencePromise<void>)\n  ): PersistencePromise<void>;\n  static forEach<R>(\n    collection: { forEach: (cb: (r: R) => void) => void },\n    f: (r: R) => PersistencePromise<void>\n  ): PersistencePromise<void>;\n  static forEach<R, S>(\n    collection: { forEach: (cb: (r: R, s?: S) => void) => void },\n    f: (r: R, s?: S) => PersistencePromise<void>\n  ): PersistencePromise<void> {\n    const promises: Array<PersistencePromise<void>> = [];\n    collection.forEach((r, s) => {\n      promises.push(f.call(this, r, s));\n    });\n    return this.waitFor(promises);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DocumentKeySet, NullableMaybeDocumentMap } from '../model/collections';\nimport { MaybeDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { debugAssert } from '../util/assert';\nimport { ObjectMap } from '../util/obj_map';\n\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { SnapshotVersion } from '../core/snapshot_version';\n\n/**\n * An in-memory buffer of entries to be written to a RemoteDocumentCache.\n * It can be used to batch up a set of changes to be written to the cache, but\n * additionally supports reading entries back with the `getEntry()` method,\n * falling back to the underlying RemoteDocumentCache if no entry is\n * buffered.\n *\n * Entries added to the cache *must* be read first. This is to facilitate\n * calculating the size delta of the pending changes.\n *\n * PORTING NOTE: This class was implemented then removed from other platforms.\n * If byte-counting ends up being needed on the other platforms, consider\n * porting this class as part of that implementation work.\n */\nexport abstract class RemoteDocumentChangeBuffer {\n  // A mapping of document key to the new cache entry that should be written (or null if any\n  // existing cache entry should be removed).\n  protected changes: ObjectMap<\n    DocumentKey,\n    MaybeDocument | null\n  > = new ObjectMap(\n    key => key.toString(),\n    (l, r) => l.isEqual(r)\n  );\n\n  // The read time to use for all added documents in this change buffer.\n  private _readTime: SnapshotVersion | undefined;\n\n  private changesApplied = false;\n\n  protected abstract getFromCache(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<MaybeDocument | null>;\n\n  protected abstract getAllFromCache(\n    transaction: PersistenceTransaction,\n    documentKeys: DocumentKeySet\n  ): PersistencePromise<NullableMaybeDocumentMap>;\n\n  protected abstract applyChanges(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<void>;\n\n  protected set readTime(value: SnapshotVersion) {\n    // Right now (for simplicity) we just track a single readTime for all the\n    // added entries since we expect them to all be the same, but we could\n    // rework to store per-entry readTimes if necessary.\n    debugAssert(\n      this._readTime === undefined || this._readTime.isEqual(value),\n      'All changes in a RemoteDocumentChangeBuffer must have the same read time'\n    );\n    this._readTime = value;\n  }\n\n  protected get readTime(): SnapshotVersion {\n    debugAssert(\n      this._readTime !== undefined,\n      'Read time is not set. All removeEntry() calls must include a readTime if `trackRemovals` is used.'\n    );\n    return this._readTime;\n  }\n\n  /**\n   * Buffers a `RemoteDocumentCache.addEntry()` call.\n   *\n   * You can only modify documents that have already been retrieved via\n   * `getEntry()/getEntries()` (enforced via IndexedDbs `apply()`).\n   */\n  addEntry(maybeDocument: MaybeDocument, readTime: SnapshotVersion): void {\n    this.assertNotApplied();\n    this.readTime = readTime;\n    this.changes.set(maybeDocument.key, maybeDocument);\n  }\n\n  /**\n   * Buffers a `RemoteDocumentCache.removeEntry()` call.\n   *\n   * You can only remove documents that have already been retrieved via\n   * `getEntry()/getEntries()` (enforced via IndexedDbs `apply()`).\n   */\n  removeEntry(key: DocumentKey, readTime?: SnapshotVersion): void {\n    this.assertNotApplied();\n    if (readTime) {\n      this.readTime = readTime;\n    }\n    this.changes.set(key, null);\n  }\n\n  /**\n   * Looks up an entry in the cache. The buffered changes will first be checked,\n   * and if no buffered change applies, this will forward to\n   * `RemoteDocumentCache.getEntry()`.\n   *\n   * @param transaction The transaction in which to perform any persistence\n   *     operations.\n   * @param documentKey The key of the entry to look up.\n   * @return The cached Document or NoDocument entry, or null if we have nothing\n   * cached.\n   */\n  getEntry(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<MaybeDocument | null> {\n    this.assertNotApplied();\n    const bufferedEntry = this.changes.get(documentKey);\n    if (bufferedEntry !== undefined) {\n      return PersistencePromise.resolve<MaybeDocument | null>(bufferedEntry);\n    } else {\n      return this.getFromCache(transaction, documentKey);\n    }\n  }\n\n  /**\n   * Looks up several entries in the cache, forwarding to\n   * `RemoteDocumentCache.getEntry()`.\n   *\n   * @param transaction The transaction in which to perform any persistence\n   *     operations.\n   * @param documentKeys The keys of the entries to look up.\n   * @return A map of cached `Document`s or `NoDocument`s, indexed by key. If an\n   *     entry cannot be found, the corresponding key will be mapped to a null\n   *     value.\n   */\n  getEntries(\n    transaction: PersistenceTransaction,\n    documentKeys: DocumentKeySet\n  ): PersistencePromise<NullableMaybeDocumentMap> {\n    return this.getAllFromCache(transaction, documentKeys);\n  }\n\n  /**\n   * Applies buffered changes to the underlying RemoteDocumentCache, using\n   * the provided transaction.\n   */\n  apply(transaction: PersistenceTransaction): PersistencePromise<void> {\n    this.assertNotApplied();\n    this.changesApplied = true;\n    return this.applyChanges(transaction);\n  }\n\n  /** Helper to assert this.changes is not null  */\n  protected assertNotApplied(): void {\n    debugAssert(!this.changesApplied, 'Changes have already been applied.');\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { User } from '../auth/user';\nimport { ListenSequenceNumber, TargetId } from '../core/types';\nimport { DocumentKey } from '../model/document_key';\nimport { IndexManager } from './index_manager';\nimport { LocalStore } from './local_store';\nimport { MutationQueue } from './mutation_queue';\nimport { PersistencePromise } from './persistence_promise';\nimport { TargetCache } from './target_cache';\nimport { RemoteDocumentCache } from './remote_document_cache';\nimport { TargetData } from './target_data';\n\nexport const PRIMARY_LEASE_LOST_ERROR_MSG =\n  'The current tab is not in the required state to perform this operation. ' +\n  'It might be necessary to refresh the browser tab.';\n\n/**\n * A base class representing a persistence transaction, encapsulating both the\n * transaction's sequence numbers as well as a list of onCommitted listeners.\n *\n * When you call Persistence.runTransaction(), it will create a transaction and\n * pass it to your callback. You then pass it to any method that operates\n * on persistence.\n */\nexport abstract class PersistenceTransaction {\n  private readonly onCommittedListeners: Array<() => void> = [];\n\n  abstract readonly currentSequenceNumber: ListenSequenceNumber;\n\n  addOnCommittedListener(listener: () => void): void {\n    this.onCommittedListeners.push(listener);\n  }\n\n  raiseOnCommittedEvent(): void {\n    this.onCommittedListeners.forEach(listener => listener());\n  }\n}\n\n/** The different modes supported by `IndexedDbPersistence.runTransaction()`. */\nexport type PersistenceTransactionMode =\n  | 'readonly'\n  | 'readwrite'\n  | 'readwrite-primary';\n\n/**\n * Callback type for primary state notifications. This callback can be\n * registered with the persistence layer to get notified when we transition from\n * primary to secondary state and vice versa.\n *\n * Note: Instances can only toggle between Primary and Secondary state if\n * IndexedDB persistence is enabled and multiple clients are active. If this\n * listener is registered with MemoryPersistence, the callback will be called\n * exactly once marking the current instance as Primary.\n */\nexport type PrimaryStateListener = (isPrimary: boolean) => Promise<void>;\n\n/**\n * A ReferenceDelegate instance handles all of the hooks into the document-reference lifecycle. This\n * includes being added to a target, being removed from a target, being subject to mutation, and\n * being mutated by the user.\n *\n * Different implementations may do different things with each of these events. Not every\n * implementation needs to do something with every lifecycle hook.\n *\n * PORTING NOTE: since sequence numbers are attached to transactions in this\n * client, the ReferenceDelegate does not need to deal in transactional\n * semantics (onTransactionStarted/Committed()), nor does it need to track and\n * generate sequence numbers (getCurrentSequenceNumber()).\n */\nexport interface ReferenceDelegate {\n  /** Notify the delegate that the given document was added to a target. */\n  addReference(\n    txn: PersistenceTransaction,\n    targetId: TargetId,\n    doc: DocumentKey\n  ): PersistencePromise<void>;\n\n  /** Notify the delegate that the given document was removed from a target. */\n  removeReference(\n    txn: PersistenceTransaction,\n    targetId: TargetId,\n    doc: DocumentKey\n  ): PersistencePromise<void>;\n\n  /**\n   * Notify the delegate that a target was removed. The delegate may, but is not obligated to,\n   * actually delete the target and associated data.\n   */\n  removeTarget(\n    txn: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void>;\n\n  /**\n   * Notify the delegate that a document may no longer be part of any views or\n   * have any mutations associated.\n   */\n  markPotentiallyOrphaned(\n    txn: PersistenceTransaction,\n    doc: DocumentKey\n  ): PersistencePromise<void>;\n\n  /** Notify the delegate that a limbo document was updated. */\n  updateLimboDocument(\n    txn: PersistenceTransaction,\n    doc: DocumentKey\n  ): PersistencePromise<void>;\n}\n\n/**\n * Persistence is the lowest-level shared interface to persistent storage in\n * Firestore.\n *\n * Persistence is used to create MutationQueue and RemoteDocumentCache\n * instances backed by persistence (which might be in-memory or LevelDB).\n *\n * Persistence also exposes an API to create and run PersistenceTransactions\n * against persistence. All read / write operations must be wrapped in a\n * transaction. Implementations of PersistenceTransaction / Persistence only\n * need to guarantee that writes made against the transaction are not made to\n * durable storage until the transaction resolves its PersistencePromise.\n * Since memory-only storage components do not alter durable storage, they are\n * free to ignore the transaction.\n *\n * This contract is enough to allow the LocalStore be be written\n * independently of whether or not the stored state actually is durably\n * persisted. If persistent storage is enabled, writes are grouped together to\n * avoid inconsistent state that could cause crashes.\n *\n * Concretely, when persistent storage is enabled, the persistent versions of\n * MutationQueue, RemoteDocumentCache, and others (the mutators) will\n * defer their writes into a transaction. Once the local store has completed\n * one logical operation, it commits the transaction.\n *\n * When persistent storage is disabled, the non-persistent versions of the\n * mutators ignore the transaction. This short-cut is allowed because\n * memory-only storage leaves no state so it cannot be inconsistent.\n *\n * This simplifies the implementations of the mutators and allows memory-only\n * implementations to supplement the persistent ones without requiring any\n * special dual-store implementation of Persistence. The cost is that the\n * LocalStore needs to be slightly careful about the order of its reads and\n * writes in order to avoid relying on being able to read back uncommitted\n * writes.\n */\nexport interface Persistence {\n  /**\n   * Whether or not this persistence instance has been started.\n   */\n  readonly started: boolean;\n\n  readonly referenceDelegate: ReferenceDelegate;\n\n  /** Starts persistence. */\n  start(): Promise<void>;\n\n  /**\n   * Releases any resources held during eager shutdown.\n   */\n  shutdown(): Promise<void>;\n\n  /**\n   * Registers a listener that gets called when the database receives a\n   * version change event indicating that it has deleted.\n   *\n   * PORTING NOTE: This is only used for Web multi-tab.\n   */\n  setDatabaseDeletedListener(\n    databaseDeletedListener: () => Promise<void>\n  ): void;\n\n  /**\n   * Adjusts the current network state in the client's metadata, potentially\n   * affecting the primary lease.\n   *\n   * PORTING NOTE: This is only used for Web multi-tab.\n   */\n  setNetworkEnabled(networkEnabled: boolean): void;\n\n  /**\n   * Returns a MutationQueue representing the persisted mutations for the\n   * given user.\n   *\n   * Note: The implementation is free to return the same instance every time\n   * this is called for a given user. In particular, the memory-backed\n   * implementation does this to emulate the persisted implementation to the\n   * extent possible (e.g. in the case of uid switching from\n   * sally=>jack=>sally, sally's mutation queue will be preserved).\n   */\n  getMutationQueue(user: User): MutationQueue;\n\n  /**\n   * Returns a TargetCache representing the persisted cache of targets.\n   *\n   * Note: The implementation is free to return the same instance every time\n   * this is called. In particular, the memory-backed implementation does this\n   * to emulate the persisted implementation to the extent possible.\n   */\n  getTargetCache(): TargetCache;\n\n  /**\n   * Returns a RemoteDocumentCache representing the persisted cache of remote\n   * documents.\n   *\n   * Note: The implementation is free to return the same instance every time\n   * this is called. In particular, the memory-backed implementation does this\n   * to emulate the persisted implementation to the extent possible.\n   */\n  getRemoteDocumentCache(): RemoteDocumentCache;\n\n  /**\n   * Returns an IndexManager instance that manages our persisted query indexes.\n   *\n   * Note: The implementation is free to return the same instance every time\n   * this is called. In particular, the memory-backed implementation does this\n   * to emulate the persisted implementation to the extent possible.\n   */\n  getIndexManager(): IndexManager;\n\n  /**\n   * Performs an operation inside a persistence transaction. Any reads or writes\n   * against persistence must be performed within a transaction. Writes will be\n   * committed atomically once the transaction completes.\n   *\n   * Persistence operations are asynchronous and therefore the provided\n   * transactionOperation must return a PersistencePromise. When it is resolved,\n   * the transaction will be committed and the Promise returned by this method\n   * will resolve.\n   *\n   * @param action A description of the action performed by this transaction,\n   * used for logging.\n   * @param mode The underlying mode of the IndexedDb transaction. Can be\n   * 'readonly`, 'readwrite' or 'readwrite-primary'. Transactions marked\n   * 'readwrite-primary' can only be executed by the primary client. In this\n   * mode, the transactionOperation will not be run if the primary lease cannot\n   * be acquired and the returned promise will be rejected with a\n   * FAILED_PRECONDITION error.\n   * @param transactionOperation The operation to run inside a transaction.\n   * @return A promise that is resolved once the transaction completes.\n   */\n  runTransaction<T>(\n    action: string,\n    mode: PersistenceTransactionMode,\n    transactionOperation: (\n      transaction: PersistenceTransaction\n    ) => PersistencePromise<T>\n  ): Promise<T>;\n}\n\n/**\n * Interface implemented by the LRU scheduler to start(), stop() and restart\n * garbage collection.\n */\nexport interface GarbageCollectionScheduler {\n  readonly started: boolean;\n  start(localStore: LocalStore): void;\n  stop(): void;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  isCollectionGroupQuery,\n  isDocumentQuery,\n  Query,\n  queryMatches\n} from '../core/query';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport {\n  DocumentKeySet,\n  documentKeySet,\n  DocumentMap,\n  documentMap,\n  MaybeDocumentMap,\n  maybeDocumentMap,\n  NullableMaybeDocumentMap,\n  nullableMaybeDocumentMap\n} from '../model/collections';\nimport { Document, MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { MutationBatch } from '../model/mutation_batch';\nimport { ResourcePath } from '../model/path';\n\nimport { debugAssert } from '../util/assert';\nimport { IndexManager } from './index_manager';\nimport { MutationQueue } from './mutation_queue';\nimport { applyMutationToLocalView, PatchMutation } from '../model/mutation';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { RemoteDocumentCache } from './remote_document_cache';\n\n/**\n * A readonly view of the local state of all documents we're tracking (i.e. we\n * have a cached version in remoteDocumentCache or local mutations for the\n * document). The view is computed by applying the mutations in the\n * MutationQueue to the RemoteDocumentCache.\n */\nexport class LocalDocumentsView {\n  constructor(\n    readonly remoteDocumentCache: RemoteDocumentCache,\n    readonly mutationQueue: MutationQueue,\n    readonly indexManager: IndexManager\n  ) {}\n\n  /**\n   * Get the local view of the document identified by `key`.\n   *\n   * @return Local view of the document or null if we don't have any cached\n   * state for it.\n   */\n  getDocument(\n    transaction: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<MaybeDocument | null> {\n    return this.mutationQueue\n      .getAllMutationBatchesAffectingDocumentKey(transaction, key)\n      .next(batches => this.getDocumentInternal(transaction, key, batches));\n  }\n\n  /** Internal version of `getDocument` that allows reusing batches. */\n  private getDocumentInternal(\n    transaction: PersistenceTransaction,\n    key: DocumentKey,\n    inBatches: MutationBatch[]\n  ): PersistencePromise<MaybeDocument | null> {\n    return this.remoteDocumentCache.getEntry(transaction, key).next(doc => {\n      for (const batch of inBatches) {\n        doc = batch.applyToLocalView(key, doc);\n      }\n      return doc;\n    });\n  }\n\n  // Returns the view of the given `docs` as they would appear after applying\n  // all mutations in the given `batches`.\n  private applyLocalMutationsToDocuments(\n    transaction: PersistenceTransaction,\n    docs: NullableMaybeDocumentMap,\n    batches: MutationBatch[]\n  ): NullableMaybeDocumentMap {\n    let results = nullableMaybeDocumentMap();\n    docs.forEach((key, localView) => {\n      for (const batch of batches) {\n        localView = batch.applyToLocalView(key, localView);\n      }\n      results = results.insert(key, localView);\n    });\n    return results;\n  }\n\n  /**\n   * Gets the local view of the documents identified by `keys`.\n   *\n   * If we don't have cached state for a document in `keys`, a NoDocument will\n   * be stored for that key in the resulting set.\n   */\n  getDocuments(\n    transaction: PersistenceTransaction,\n    keys: DocumentKeySet\n  ): PersistencePromise<MaybeDocumentMap> {\n    return this.remoteDocumentCache\n      .getEntries(transaction, keys)\n      .next(docs => this.getLocalViewOfDocuments(transaction, docs));\n  }\n\n  /**\n   * Similar to `getDocuments`, but creates the local view from the given\n   * `baseDocs` without retrieving documents from the local store.\n   */\n  getLocalViewOfDocuments(\n    transaction: PersistenceTransaction,\n    baseDocs: NullableMaybeDocumentMap\n  ): PersistencePromise<MaybeDocumentMap> {\n    return this.mutationQueue\n      .getAllMutationBatchesAffectingDocumentKeys(transaction, baseDocs)\n      .next(batches => {\n        const docs = this.applyLocalMutationsToDocuments(\n          transaction,\n          baseDocs,\n          batches\n        );\n        let results = maybeDocumentMap();\n        docs.forEach((key, maybeDoc) => {\n          // TODO(http://b/32275378): Don't conflate missing / deleted.\n          if (!maybeDoc) {\n            maybeDoc = new NoDocument(key, SnapshotVersion.min());\n          }\n          results = results.insert(key, maybeDoc);\n        });\n\n        return results;\n      });\n  }\n\n  /**\n   * Performs a query against the local view of all documents.\n   *\n   * @param transaction The persistence transaction.\n   * @param query The query to match documents against.\n   * @param sinceReadTime If not set to SnapshotVersion.min(), return only\n   *     documents that have been read since this snapshot version (exclusive).\n   */\n  getDocumentsMatchingQuery(\n    transaction: PersistenceTransaction,\n    query: Query,\n    sinceReadTime: SnapshotVersion\n  ): PersistencePromise<DocumentMap> {\n    if (isDocumentQuery(query)) {\n      return this.getDocumentsMatchingDocumentQuery(transaction, query.path);\n    } else if (isCollectionGroupQuery(query)) {\n      return this.getDocumentsMatchingCollectionGroupQuery(\n        transaction,\n        query,\n        sinceReadTime\n      );\n    } else {\n      return this.getDocumentsMatchingCollectionQuery(\n        transaction,\n        query,\n        sinceReadTime\n      );\n    }\n  }\n\n  private getDocumentsMatchingDocumentQuery(\n    transaction: PersistenceTransaction,\n    docPath: ResourcePath\n  ): PersistencePromise<DocumentMap> {\n    // Just do a simple document lookup.\n    return this.getDocument(transaction, new DocumentKey(docPath)).next(\n      maybeDoc => {\n        let result = documentMap();\n        if (maybeDoc instanceof Document) {\n          result = result.insert(maybeDoc.key, maybeDoc);\n        }\n        return result;\n      }\n    );\n  }\n\n  private getDocumentsMatchingCollectionGroupQuery(\n    transaction: PersistenceTransaction,\n    query: Query,\n    sinceReadTime: SnapshotVersion\n  ): PersistencePromise<DocumentMap> {\n    debugAssert(\n      query.path.isEmpty(),\n      'Currently we only support collection group queries at the root.'\n    );\n    const collectionId = query.collectionGroup!;\n    let results = documentMap();\n    return this.indexManager\n      .getCollectionParents(transaction, collectionId)\n      .next(parents => {\n        // Perform a collection query against each parent that contains the\n        // collectionId and aggregate the results.\n        return PersistencePromise.forEach(parents, (parent: ResourcePath) => {\n          const collectionQuery = query.asCollectionQueryAtPath(\n            parent.child(collectionId)\n          );\n          return this.getDocumentsMatchingCollectionQuery(\n            transaction,\n            collectionQuery,\n            sinceReadTime\n          ).next(r => {\n            r.forEach((key, doc) => {\n              results = results.insert(key, doc);\n            });\n          });\n        }).next(() => results);\n      });\n  }\n\n  private getDocumentsMatchingCollectionQuery(\n    transaction: PersistenceTransaction,\n    query: Query,\n    sinceReadTime: SnapshotVersion\n  ): PersistencePromise<DocumentMap> {\n    // Query the remote documents and overlay mutations.\n    let results: DocumentMap;\n    let mutationBatches: MutationBatch[];\n    return this.remoteDocumentCache\n      .getDocumentsMatchingQuery(transaction, query, sinceReadTime)\n      .next(queryResults => {\n        results = queryResults;\n        return this.mutationQueue.getAllMutationBatchesAffectingQuery(\n          transaction,\n          query\n        );\n      })\n      .next(matchingMutationBatches => {\n        mutationBatches = matchingMutationBatches;\n        // It is possible that a PatchMutation can make a document match a query, even if\n        // the version in the RemoteDocumentCache is not a match yet (waiting for server\n        // to ack). To handle this, we find all document keys affected by the PatchMutations\n        // that are not in `result` yet, and back fill them via `remoteDocumentCache.getEntries`,\n        // otherwise those `PatchMutations` will be ignored because no base document can be found,\n        // and lead to missing result for the query.\n        return this.addMissingBaseDocuments(\n          transaction,\n          mutationBatches,\n          results\n        ).next(mergedDocuments => {\n          results = mergedDocuments;\n\n          for (const batch of mutationBatches) {\n            for (const mutation of batch.mutations) {\n              const key = mutation.key;\n              const baseDoc = results.get(key);\n              const mutatedDoc = applyMutationToLocalView(\n                mutation,\n                baseDoc,\n                baseDoc,\n                batch.localWriteTime\n              );\n              if (mutatedDoc instanceof Document) {\n                results = results.insert(key, mutatedDoc);\n              } else {\n                results = results.remove(key);\n              }\n            }\n          }\n        });\n      })\n      .next(() => {\n        // Finally, filter out any documents that don't actually match\n        // the query.\n        results.forEach((key, doc) => {\n          if (!queryMatches(query, doc)) {\n            results = results.remove(key);\n          }\n        });\n\n        return results;\n      });\n  }\n\n  private addMissingBaseDocuments(\n    transaction: PersistenceTransaction,\n    matchingMutationBatches: MutationBatch[],\n    existingDocuments: DocumentMap\n  ): PersistencePromise<DocumentMap> {\n    let missingBaseDocEntriesForPatching = documentKeySet();\n    for (const batch of matchingMutationBatches) {\n      for (const mutation of batch.mutations) {\n        if (\n          mutation instanceof PatchMutation &&\n          existingDocuments.get(mutation.key) === null\n        ) {\n          missingBaseDocEntriesForPatching = missingBaseDocEntriesForPatching.add(\n            mutation.key\n          );\n        }\n      }\n    }\n\n    let mergedDocuments = existingDocuments;\n    return this.remoteDocumentCache\n      .getEntries(transaction, missingBaseDocEntriesForPatching)\n      .next(missingBaseDocs => {\n        missingBaseDocs.forEach((key, doc) => {\n          if (doc !== null && doc instanceof Document) {\n            mergedDocuments = mergedDocuments.insert(key, doc);\n          }\n        });\n        return mergedDocuments;\n      });\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { TargetId } from '../core/types';\nimport { ChangeType, ViewSnapshot } from '../core/view_snapshot';\nimport { documentKeySet, DocumentKeySet } from '../model/collections';\n\n/**\n * A set of changes to what documents are currently in view and out of view for\n * a given query. These changes are sent to the LocalStore by the View (via\n * the SyncEngine) and are used to pin / unpin documents as appropriate.\n */\nexport class LocalViewChanges {\n  constructor(\n    readonly targetId: TargetId,\n    readonly fromCache: boolean,\n    readonly addedKeys: DocumentKeySet,\n    readonly removedKeys: DocumentKeySet\n  ) {}\n\n  static fromSnapshot(\n    targetId: TargetId,\n    viewSnapshot: ViewSnapshot\n  ): LocalViewChanges {\n    let addedKeys = documentKeySet();\n    let removedKeys = documentKeySet();\n\n    for (const docChange of viewSnapshot.docChanges) {\n      switch (docChange.type) {\n        case ChangeType.Added:\n          addedKeys = addedKeys.add(docChange.doc.key);\n          break;\n        case ChangeType.Removed:\n          removedKeys = removedKeys.add(docChange.doc.key);\n          break;\n        default:\n        // do nothing\n      }\n    }\n\n    return new LocalViewChanges(\n      targetId,\n      viewSnapshot.fromCache,\n      addedKeys,\n      removedKeys\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ListenSequenceNumber } from './types';\n\n/**\n * `SequenceNumberSyncer` defines the methods required to keep multiple instances of a\n * `ListenSequence` in sync.\n */\nexport interface SequenceNumberSyncer {\n  // Notify the syncer that a new sequence number has been used.\n  writeSequenceNumber(sequenceNumber: ListenSequenceNumber): void;\n  // Setting this property allows the syncer to notify when a sequence number has been used, and\n  // and lets the ListenSequence adjust its internal previous value accordingly.\n  sequenceNumberHandler:\n    | ((sequenceNumber: ListenSequenceNumber) => void)\n    | null;\n}\n\n/**\n * `ListenSequence` is a monotonic sequence. It is initialized with a minimum value to\n * exceed. All subsequent calls to next will return increasing values. If provided with a\n * `SequenceNumberSyncer`, it will additionally bump its next value when told of a new value, as\n * well as write out sequence numbers that it produces via `next()`.\n */\nexport class ListenSequence {\n  static readonly INVALID: ListenSequenceNumber = -1;\n\n  private writeNewSequenceNumber?: (\n    newSequenceNumber: ListenSequenceNumber\n  ) => void;\n\n  constructor(\n    private previousValue: ListenSequenceNumber,\n    sequenceNumberSyncer?: SequenceNumberSyncer\n  ) {\n    if (sequenceNumberSyncer) {\n      sequenceNumberSyncer.sequenceNumberHandler = sequenceNumber =>\n        this.setPreviousValue(sequenceNumber);\n      this.writeNewSequenceNumber = sequenceNumber =>\n        sequenceNumberSyncer.writeSequenceNumber(sequenceNumber);\n    }\n  }\n\n  private setPreviousValue(\n    externalPreviousValue: ListenSequenceNumber\n  ): ListenSequenceNumber {\n    this.previousValue = Math.max(externalPreviousValue, this.previousValue);\n    return this.previousValue;\n  }\n\n  next(): ListenSequenceNumber {\n    const nextValue = ++this.previousValue;\n    if (this.writeNewSequenceNumber) {\n      this.writeNewSequenceNumber(nextValue);\n    }\n    return nextValue;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport interface Resolver<R> {\n  (value?: R | Promise<R>): void;\n}\n\nexport interface Rejecter {\n  (reason?: Error): void;\n}\n\nexport class Deferred<R = void> {\n  promise: Promise<R>;\n  // Assigned synchronously in constructor by Promise constructor callback.\n  resolve!: Resolver<R>;\n  reject!: Rejecter;\n\n  constructor() {\n    this.promise = new Promise((resolve: Resolver<R>, reject: Rejecter) => {\n      this.resolve = resolve;\n      this.reject = reject;\n    });\n  }\n}\n\n/**\n * Takes an array of values and a function from a value to a Promise. The function is run on each\n * value sequentially, waiting for the previous promise to resolve before starting the next one.\n * The returned promise resolves once the function has been run on all values.\n */\nexport function sequence<T>(\n  values: T[],\n  fn: (value: T) => Promise<void>\n): Promise<void> {\n  let p = Promise.resolve();\n  for (const value of values) {\n    p = p.then(() => fn(value));\n  }\n  return p;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AsyncQueue, DelayedOperation, TimerId } from '../util/async_queue';\nimport { logDebug } from '../util/log';\n\nconst LOG_TAG = 'ExponentialBackoff';\n\n/**\n * Initial backoff time in milliseconds after an error.\n * Set to 1s according to https://cloud.google.com/apis/design/errors.\n */\nconst DEFAULT_BACKOFF_INITIAL_DELAY_MS = 1000;\n\nconst DEFAULT_BACKOFF_FACTOR = 1.5;\n\n/** Maximum backoff time in milliseconds */\nconst DEFAULT_BACKOFF_MAX_DELAY_MS = 60 * 1000;\n\n/**\n * A helper for running delayed tasks following an exponential backoff curve\n * between attempts.\n *\n * Each delay is made up of a \"base\" delay which follows the exponential\n * backoff curve, and a +/- 50% \"jitter\" that is calculated and added to the\n * base delay. This prevents clients from accidentally synchronizing their\n * delays causing spikes of load to the backend.\n */\nexport class ExponentialBackoff {\n  private currentBaseMs: number = 0;\n  private timerPromise: DelayedOperation<void> | null = null;\n  /** The last backoff attempt, as epoch milliseconds. */\n  private lastAttemptTime = Date.now();\n\n  constructor(\n    /**\n     * The AsyncQueue to run backoff operations on.\n     */\n    private readonly queue: AsyncQueue,\n    /**\n     * The ID to use when scheduling backoff operations on the AsyncQueue.\n     */\n    private readonly timerId: TimerId,\n    /**\n     * The initial delay (used as the base delay on the first retry attempt).\n     * Note that jitter will still be applied, so the actual delay could be as\n     * little as 0.5*initialDelayMs.\n     */\n    private readonly initialDelayMs: number = DEFAULT_BACKOFF_INITIAL_DELAY_MS,\n    /**\n     * The multiplier to use to determine the extended base delay after each\n     * attempt.\n     */\n    private readonly backoffFactor: number = DEFAULT_BACKOFF_FACTOR,\n    /**\n     * The maximum base delay after which no further backoff is performed.\n     * Note that jitter will still be applied, so the actual delay could be as\n     * much as 1.5*maxDelayMs.\n     */\n    private readonly maxDelayMs: number = DEFAULT_BACKOFF_MAX_DELAY_MS\n  ) {\n    this.reset();\n  }\n\n  /**\n   * Resets the backoff delay.\n   *\n   * The very next backoffAndWait() will have no delay. If it is called again\n   * (i.e. due to an error), initialDelayMs (plus jitter) will be used, and\n   * subsequent ones will increase according to the backoffFactor.\n   */\n  reset(): void {\n    this.currentBaseMs = 0;\n  }\n\n  /**\n   * Resets the backoff delay to the maximum delay (e.g. for use after a\n   * RESOURCE_EXHAUSTED error).\n   */\n  resetToMax(): void {\n    this.currentBaseMs = this.maxDelayMs;\n  }\n\n  /**\n   * Returns a promise that resolves after currentDelayMs, and increases the\n   * delay for any subsequent attempts. If there was a pending backoff operation\n   * already, it will be canceled.\n   */\n  backoffAndRun(op: () => Promise<void>): void {\n    // Cancel any pending backoff operation.\n    this.cancel();\n\n    // First schedule using the current base (which may be 0 and should be\n    // honored as such).\n    const desiredDelayWithJitterMs = Math.floor(\n      this.currentBaseMs + this.jitterDelayMs()\n    );\n\n    // Guard against lastAttemptTime being in the future due to a clock change.\n    const delaySoFarMs = Math.max(0, Date.now() - this.lastAttemptTime);\n\n    // Guard against the backoff delay already being past.\n    const remainingDelayMs = Math.max(\n      0,\n      desiredDelayWithJitterMs - delaySoFarMs\n    );\n\n    if (remainingDelayMs > 0) {\n      logDebug(\n        LOG_TAG,\n        `Backing off for ${remainingDelayMs} ms ` +\n          `(base delay: ${this.currentBaseMs} ms, ` +\n          `delay with jitter: ${desiredDelayWithJitterMs} ms, ` +\n          `last attempt: ${delaySoFarMs} ms ago)`\n      );\n    }\n\n    this.timerPromise = this.queue.enqueueAfterDelay(\n      this.timerId,\n      remainingDelayMs,\n      () => {\n        this.lastAttemptTime = Date.now();\n        return op();\n      }\n    );\n\n    // Apply backoff factor to determine next delay and ensure it is within\n    // bounds.\n    this.currentBaseMs *= this.backoffFactor;\n    if (this.currentBaseMs < this.initialDelayMs) {\n      this.currentBaseMs = this.initialDelayMs;\n    }\n    if (this.currentBaseMs > this.maxDelayMs) {\n      this.currentBaseMs = this.maxDelayMs;\n    }\n  }\n\n  skipBackoff(): void {\n    if (this.timerPromise !== null) {\n      this.timerPromise.skipDelay();\n      this.timerPromise = null;\n    }\n  }\n\n  cancel(): void {\n    if (this.timerPromise !== null) {\n      this.timerPromise.cancel();\n      this.timerPromise = null;\n    }\n  }\n\n  /** Returns a random value in the range [-currentBaseMs/2, currentBaseMs/2] */\n  private jitterDelayMs(): number {\n    return (Math.random() - 0.5) * this.currentBaseMs;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { getUA } from '@firebase/util';\nimport { debugAssert } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { logDebug, logError } from '../util/log';\nimport { Deferred } from '../util/promise';\nimport { PersistencePromise } from './persistence_promise';\n\n// References to `window` are guarded by SimpleDb.isAvailable()\n/* eslint-disable no-restricted-globals */\n\nconst LOG_TAG = 'SimpleDb';\n\n/**\n * The maximum number of retry attempts for an IndexedDb transaction that fails\n * with a DOMException.\n */\nconst TRANSACTION_RETRY_COUNT = 3;\n\n// The different modes supported by `SimpleDb.runTransaction()`\ntype SimpleDbTransactionMode = 'readonly' | 'readwrite';\n\nexport interface SimpleDbSchemaConverter {\n  createOrUpgrade(\n    db: IDBDatabase,\n    txn: IDBTransaction,\n    fromVersion: number,\n    toVersion: number\n  ): PersistencePromise<void>;\n}\n\n/**\n * Provides a wrapper around IndexedDb with a simplified interface that uses\n * Promise-like return values to chain operations. Real promises cannot be used\n * since .then() continuations are executed asynchronously (e.g. via\n * .setImmediate), which would cause IndexedDB to end the transaction.\n * See PersistencePromise for more details.\n */\nexport class SimpleDb {\n  private db?: IDBDatabase;\n  private versionchangelistener?: (event: IDBVersionChangeEvent) => void;\n\n  /** Deletes the specified database. */\n  static delete(name: string): Promise<void> {\n    logDebug(LOG_TAG, 'Removing database:', name);\n    return wrapRequest<void>(window.indexedDB.deleteDatabase(name)).toPromise();\n  }\n\n  /** Returns true if IndexedDB is available in the current environment. */\n  static isAvailable(): boolean {\n    if (typeof indexedDB === 'undefined') {\n      return false;\n    }\n\n    if (SimpleDb.isMockPersistence()) {\n      return true;\n    }\n\n    // We extensively use indexed array values and compound keys,\n    // which IE and Edge do not support. However, they still have indexedDB\n    // defined on the window, so we need to check for them here and make sure\n    // to return that persistence is not enabled for those browsers.\n    // For tracking support of this feature, see here:\n    // https://developer.microsoft.com/en-us/microsoft-edge/platform/status/indexeddbarraysandmultientrysupport/\n\n    // Check the UA string to find out the browser.\n    const ua = getUA();\n\n    // IE 10\n    // ua = 'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Trident/6.0)';\n\n    // IE 11\n    // ua = 'Mozilla/5.0 (Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko';\n\n    // Edge\n    // ua = 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML,\n    // like Gecko) Chrome/39.0.2171.71 Safari/537.36 Edge/12.0';\n\n    // iOS Safari: Disable for users running iOS version < 10.\n    const iOSVersion = SimpleDb.getIOSVersion(ua);\n    const isUnsupportedIOS = 0 < iOSVersion && iOSVersion < 10;\n\n    // Android browser: Disable for userse running version < 4.5.\n    const androidVersion = SimpleDb.getAndroidVersion(ua);\n    const isUnsupportedAndroid = 0 < androidVersion && androidVersion < 4.5;\n\n    if (\n      ua.indexOf('MSIE ') > 0 ||\n      ua.indexOf('Trident/') > 0 ||\n      ua.indexOf('Edge/') > 0 ||\n      isUnsupportedIOS ||\n      isUnsupportedAndroid\n    ) {\n      return false;\n    } else {\n      return true;\n    }\n  }\n\n  /**\n   * Returns true if the backing IndexedDB store is the Node IndexedDBShim\n   * (see https://github.com/axemclion/IndexedDBShim).\n   */\n  static isMockPersistence(): boolean {\n    return (\n      typeof process !== 'undefined' &&\n      process.env?.USE_MOCK_PERSISTENCE === 'YES'\n    );\n  }\n\n  /** Helper to get a typed SimpleDbStore from a transaction. */\n  static getStore<KeyType extends IDBValidKey, ValueType extends unknown>(\n    txn: SimpleDbTransaction,\n    store: string\n  ): SimpleDbStore<KeyType, ValueType> {\n    return txn.store<KeyType, ValueType>(store);\n  }\n\n  // visible for testing\n  /** Parse User Agent to determine iOS version. Returns -1 if not found. */\n  static getIOSVersion(ua: string): number {\n    const iOSVersionRegex = ua.match(/i(?:phone|pad|pod) os ([\\d_]+)/i);\n    const version = iOSVersionRegex\n      ? iOSVersionRegex[1].split('_').slice(0, 2).join('.')\n      : '-1';\n    return Number(version);\n  }\n\n  // visible for testing\n  /** Parse User Agent to determine Android version. Returns -1 if not found. */\n  static getAndroidVersion(ua: string): number {\n    const androidVersionRegex = ua.match(/Android ([\\d.]+)/i);\n    const version = androidVersionRegex\n      ? androidVersionRegex[1].split('.').slice(0, 2).join('.')\n      : '-1';\n    return Number(version);\n  }\n\n  /*\n   * Creates a new SimpleDb wrapper for IndexedDb database `name`.\n   *\n   * Note that `version` must not be a downgrade. IndexedDB does not support\n   * downgrading the schema version. We currently do not support any way to do\n   * versioning outside of IndexedDB's versioning mechanism, as only\n   * version-upgrade transactions are allowed to do things like create\n   * objectstores.\n   */\n  constructor(\n    private readonly name: string,\n    private readonly version: number,\n    private readonly schemaConverter: SimpleDbSchemaConverter\n  ) {\n    debugAssert(\n      SimpleDb.isAvailable(),\n      'IndexedDB not supported in current environment.'\n    );\n\n    const iOSVersion = SimpleDb.getIOSVersion(getUA());\n    // NOTE: According to https://bugs.webkit.org/show_bug.cgi?id=197050, the\n    // bug we're checking for should exist in iOS >= 12.2 and < 13, but for\n    // whatever reason it's much harder to hit after 12.2 so we only proactively\n    // log on 12.2.\n    if (iOSVersion === 12.2) {\n      logError(\n        'Firestore persistence suffers from a bug in iOS 12.2 ' +\n          'Safari that may cause your app to stop working. See ' +\n          'https://stackoverflow.com/q/56496296/110915 for details ' +\n          'and a potential workaround.'\n      );\n    }\n  }\n\n  /**\n   * Opens the specified database, creating or upgrading it if necessary.\n   */\n  async ensureDb(): Promise<IDBDatabase> {\n    if (!this.db) {\n      logDebug(LOG_TAG, 'Opening database:', this.name);\n      this.db = await new Promise<IDBDatabase>((resolve, reject) => {\n        // TODO(mikelehen): Investigate browser compatibility.\n        // https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API/Using_IndexedDB\n        // suggests IE9 and older WebKit browsers handle upgrade\n        // differently. They expect setVersion, as described here:\n        // https://developer.mozilla.org/en-US/docs/Web/API/IDBVersionChangeRequest/setVersion\n        const request = indexedDB.open(this.name, this.version);\n\n        request.onsuccess = (event: Event) => {\n          const db = (event.target as IDBOpenDBRequest).result;\n          resolve(db);\n        };\n\n        request.onblocked = () => {\n          reject(\n            new IndexedDbTransactionError(\n              'Cannot upgrade IndexedDB schema while another tab is open. ' +\n                'Close all tabs that access Firestore and reload this page to proceed.'\n            )\n          );\n        };\n\n        request.onerror = (event: Event) => {\n          const error: DOMException = (event.target as IDBOpenDBRequest).error!;\n          if (error.name === 'VersionError') {\n            reject(\n              new FirestoreError(\n                Code.FAILED_PRECONDITION,\n                'A newer version of the Firestore SDK was previously used and so the persisted ' +\n                  'data is not compatible with the version of the SDK you are now using. The SDK ' +\n                  'will operate with persistence disabled. If you need persistence, please ' +\n                  're-upgrade to a newer version of the SDK or else clear the persisted IndexedDB ' +\n                  'data for your app to start fresh.'\n              )\n            );\n          } else {\n            reject(new IndexedDbTransactionError(error));\n          }\n        };\n\n        request.onupgradeneeded = (event: IDBVersionChangeEvent) => {\n          logDebug(\n            LOG_TAG,\n            'Database \"' + this.name + '\" requires upgrade from version:',\n            event.oldVersion\n          );\n          const db = (event.target as IDBOpenDBRequest).result;\n          this.schemaConverter\n            .createOrUpgrade(\n              db,\n              request.transaction!,\n              event.oldVersion,\n              this.version\n            )\n            .next(() => {\n              logDebug(\n                LOG_TAG,\n                'Database upgrade to version ' + this.version + ' complete'\n              );\n            });\n        };\n      });\n    }\n\n    if (this.versionchangelistener) {\n      this.db.onversionchange = event => this.versionchangelistener!(event);\n    }\n    return this.db;\n  }\n\n  setVersionChangeListener(\n    versionChangeListener: (event: IDBVersionChangeEvent) => void\n  ): void {\n    this.versionchangelistener = versionChangeListener;\n    if (this.db) {\n      this.db.onversionchange = (event: IDBVersionChangeEvent) => {\n        return versionChangeListener(event);\n      };\n    }\n  }\n\n  async runTransaction<T>(\n    mode: SimpleDbTransactionMode,\n    objectStores: string[],\n    transactionFn: (transaction: SimpleDbTransaction) => PersistencePromise<T>\n  ): Promise<T> {\n    const readonly = mode === 'readonly';\n    let attemptNumber = 0;\n\n    while (true) {\n      ++attemptNumber;\n\n      try {\n        this.db = await this.ensureDb();\n\n        const transaction = SimpleDbTransaction.open(\n          this.db,\n          readonly ? 'readonly' : 'readwrite',\n          objectStores\n        );\n        const transactionFnResult = transactionFn(transaction)\n          .catch(error => {\n            // Abort the transaction if there was an error.\n            transaction.abort(error);\n            // We cannot actually recover, and calling `abort()` will cause the transaction's\n            // completion promise to be rejected. This in turn means that we won't use\n            // `transactionFnResult` below. We return a rejection here so that we don't add the\n            // possibility of returning `void` to the type of `transactionFnResult`.\n            return PersistencePromise.reject<T>(error);\n          })\n          .toPromise();\n\n        // As noted above, errors are propagated by aborting the transaction. So\n        // we swallow any error here to avoid the browser logging it as unhandled.\n        transactionFnResult.catch(() => {});\n\n        // Wait for the transaction to complete (i.e. IndexedDb's onsuccess event to\n        // fire), but still return the original transactionFnResult back to the\n        // caller.\n        await transaction.completionPromise;\n        return transactionFnResult;\n      } catch (error) {\n        // TODO(schmidt-sebastian): We could probably be smarter about this and\n        // not retry exceptions that are likely unrecoverable (such as quota\n        // exceeded errors).\n\n        // Note: We cannot use an instanceof check for FirestoreException, since the\n        // exception is wrapped in a generic error by our async/await handling.\n        const retryable =\n          error.name !== 'FirebaseError' &&\n          attemptNumber < TRANSACTION_RETRY_COUNT;\n        logDebug(\n          LOG_TAG,\n          'Transaction failed with error: %s. Retrying: %s.',\n          error.message,\n          retryable\n        );\n\n        this.close();\n\n        if (!retryable) {\n          return Promise.reject(error);\n        }\n      }\n    }\n  }\n\n  close(): void {\n    if (this.db) {\n      this.db.close();\n    }\n    this.db = undefined;\n  }\n}\n\n/**\n * A controller for iterating over a key range or index. It allows an iterate\n * callback to delete the currently-referenced object, or jump to a new key\n * within the key range or index.\n */\nexport class IterationController {\n  private shouldStop = false;\n  private nextKey: IDBValidKey | null = null;\n\n  constructor(private dbCursor: IDBCursorWithValue) {}\n\n  get isDone(): boolean {\n    return this.shouldStop;\n  }\n\n  get skipToKey(): IDBValidKey | null {\n    return this.nextKey;\n  }\n\n  set cursor(value: IDBCursorWithValue) {\n    this.dbCursor = value;\n  }\n\n  /**\n   * This function can be called to stop iteration at any point.\n   */\n  done(): void {\n    this.shouldStop = true;\n  }\n\n  /**\n   * This function can be called to skip to that next key, which could be\n   * an index or a primary key.\n   */\n  skip(key: IDBValidKey): void {\n    this.nextKey = key;\n  }\n\n  /**\n   * Delete the current cursor value from the object store.\n   *\n   * NOTE: You CANNOT do this with a keysOnly query.\n   */\n  delete(): PersistencePromise<void> {\n    return wrapRequest<void>(this.dbCursor.delete());\n  }\n}\n\n/**\n * Callback used with iterate() method.\n */\nexport type IterateCallback<KeyType, ValueType> = (\n  key: KeyType,\n  value: ValueType,\n  control: IterationController\n) => void | PersistencePromise<void>;\n\n/** Options available to the iterate() method. */\nexport interface IterateOptions {\n  /** Index to iterate over (else primary keys will be iterated) */\n  index?: string;\n\n  /** IndxedDB Range to iterate over (else entire store will be iterated) */\n  range?: IDBKeyRange;\n\n  /** If true, values aren't read while iterating. */\n  keysOnly?: boolean;\n\n  /** If true, iterate over the store in reverse. */\n  reverse?: boolean;\n}\n\n/** An error that wraps exceptions that thrown during IndexedDB execution. */\nexport class IndexedDbTransactionError extends FirestoreError {\n  name = 'IndexedDbTransactionError';\n\n  constructor(cause: Error | string) {\n    super(Code.UNAVAILABLE, 'IndexedDB transaction failed: ' + cause);\n  }\n}\n\n/** Verifies whether `e` is an IndexedDbTransactionError. */\nexport function isIndexedDbTransactionError(e: Error): boolean {\n  // Use name equality, as instanceof checks on errors don't work with errors\n  // that wrap other errors.\n  return e.name === 'IndexedDbTransactionError';\n}\n\n/**\n * Wraps an IDBTransaction and exposes a store() method to get a handle to a\n * specific object store.\n */\nexport class SimpleDbTransaction {\n  private aborted = false;\n\n  /**\n   * A promise that resolves with the result of the IndexedDb transaction.\n   */\n  private readonly completionDeferred = new Deferred<void>();\n\n  static open(\n    db: IDBDatabase,\n    mode: IDBTransactionMode,\n    objectStoreNames: string[]\n  ): SimpleDbTransaction {\n    try {\n      return new SimpleDbTransaction(db.transaction(objectStoreNames, mode));\n    } catch (e) {\n      throw new IndexedDbTransactionError(e);\n    }\n  }\n\n  constructor(private readonly transaction: IDBTransaction) {\n    this.transaction.oncomplete = () => {\n      this.completionDeferred.resolve();\n    };\n    this.transaction.onabort = () => {\n      if (transaction.error) {\n        this.completionDeferred.reject(\n          new IndexedDbTransactionError(transaction.error)\n        );\n      } else {\n        this.completionDeferred.resolve();\n      }\n    };\n    this.transaction.onerror = (event: Event) => {\n      const error = checkForAndReportiOSError(\n        (event.target as IDBRequest).error!\n      );\n      this.completionDeferred.reject(new IndexedDbTransactionError(error));\n    };\n  }\n\n  get completionPromise(): Promise<void> {\n    return this.completionDeferred.promise;\n  }\n\n  abort(error?: Error): void {\n    if (error) {\n      this.completionDeferred.reject(error);\n    }\n\n    if (!this.aborted) {\n      logDebug(\n        LOG_TAG,\n        'Aborting transaction:',\n        error ? error.message : 'Client-initiated abort'\n      );\n      this.aborted = true;\n      this.transaction.abort();\n    }\n  }\n\n  /**\n   * Returns a SimpleDbStore<KeyType, ValueType> for the specified store. All\n   * operations performed on the SimpleDbStore happen within the context of this\n   * transaction and it cannot be used anymore once the transaction is\n   * completed.\n   *\n   * Note that we can't actually enforce that the KeyType and ValueType are\n   * correct, but they allow type safety through the rest of the consuming code.\n   */\n  store<KeyType extends IDBValidKey, ValueType extends unknown>(\n    storeName: string\n  ): SimpleDbStore<KeyType, ValueType> {\n    const store = this.transaction.objectStore(storeName);\n    debugAssert(!!store, 'Object store not part of transaction: ' + storeName);\n    return new SimpleDbStore<KeyType, ValueType>(store);\n  }\n}\n\n/**\n * A wrapper around an IDBObjectStore providing an API that:\n *\n * 1) Has generic KeyType / ValueType parameters to provide strongly-typed\n * methods for acting against the object store.\n * 2) Deals with IndexedDB's onsuccess / onerror event callbacks, making every\n * method return a PersistencePromise instead.\n * 3) Provides a higher-level API to avoid needing to do excessive wrapping of\n * intermediate IndexedDB types (IDBCursorWithValue, etc.)\n */\nexport class SimpleDbStore<\n  KeyType extends IDBValidKey,\n  ValueType extends unknown\n> {\n  constructor(private store: IDBObjectStore) {}\n\n  /**\n   * Writes a value into the Object Store.\n   *\n   * @param key Optional explicit key to use when writing the object, else the\n   * key will be auto-assigned (e.g. via the defined keyPath for the store).\n   * @param value The object to write.\n   */\n  put(value: ValueType): PersistencePromise<void>;\n  put(key: KeyType, value: ValueType): PersistencePromise<void>;\n  put(\n    keyOrValue: KeyType | ValueType,\n    value?: ValueType\n  ): PersistencePromise<void> {\n    let request;\n    if (value !== undefined) {\n      logDebug(LOG_TAG, 'PUT', this.store.name, keyOrValue, value);\n      request = this.store.put(value, keyOrValue as KeyType);\n    } else {\n      logDebug(LOG_TAG, 'PUT', this.store.name, '<auto-key>', keyOrValue);\n      request = this.store.put(keyOrValue as ValueType);\n    }\n    return wrapRequest<void>(request);\n  }\n\n  /**\n   * Adds a new value into an Object Store and returns the new key. Similar to\n   * IndexedDb's `add()`, this method will fail on primary key collisions.\n   *\n   * @param value The object to write.\n   * @return The key of the value to add.\n   */\n  add(value: ValueType): PersistencePromise<KeyType> {\n    logDebug(LOG_TAG, 'ADD', this.store.name, value, value);\n    const request = this.store.add(value as ValueType);\n    return wrapRequest<KeyType>(request);\n  }\n\n  /**\n   * Gets the object with the specified key from the specified store, or null\n   * if no object exists with the specified key.\n   *\n   * @key The key of the object to get.\n   * @return The object with the specified key or null if no object exists.\n   */\n  get(key: KeyType): PersistencePromise<ValueType | null> {\n    const request = this.store.get(key);\n    // We're doing an unsafe cast to ValueType.\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return wrapRequest<any>(request).next(result => {\n      // Normalize nonexistence to null.\n      if (result === undefined) {\n        result = null;\n      }\n      logDebug(LOG_TAG, 'GET', this.store.name, key, result);\n      return result;\n    });\n  }\n\n  delete(key: KeyType | IDBKeyRange): PersistencePromise<void> {\n    logDebug(LOG_TAG, 'DELETE', this.store.name, key);\n    const request = this.store.delete(key);\n    return wrapRequest<void>(request);\n  }\n\n  /**\n   * If we ever need more of the count variants, we can add overloads. For now,\n   * all we need is to count everything in a store.\n   *\n   * Returns the number of rows in the store.\n   */\n  count(): PersistencePromise<number> {\n    logDebug(LOG_TAG, 'COUNT', this.store.name);\n    const request = this.store.count();\n    return wrapRequest<number>(request);\n  }\n\n  loadAll(): PersistencePromise<ValueType[]>;\n  loadAll(range: IDBKeyRange): PersistencePromise<ValueType[]>;\n  loadAll(index: string, range: IDBKeyRange): PersistencePromise<ValueType[]>;\n  loadAll(\n    indexOrRange?: string | IDBKeyRange,\n    range?: IDBKeyRange\n  ): PersistencePromise<ValueType[]> {\n    const cursor = this.cursor(this.options(indexOrRange, range));\n    const results: ValueType[] = [];\n    return this.iterateCursor(cursor, (key, value) => {\n      results.push(value);\n    }).next(() => {\n      return results;\n    });\n  }\n\n  deleteAll(): PersistencePromise<void>;\n  deleteAll(range: IDBKeyRange): PersistencePromise<void>;\n  deleteAll(index: string, range: IDBKeyRange): PersistencePromise<void>;\n  deleteAll(\n    indexOrRange?: string | IDBKeyRange,\n    range?: IDBKeyRange\n  ): PersistencePromise<void> {\n    logDebug(LOG_TAG, 'DELETE ALL', this.store.name);\n    const options = this.options(indexOrRange, range);\n    options.keysOnly = false;\n    const cursor = this.cursor(options);\n    return this.iterateCursor(cursor, (key, value, control) => {\n      // NOTE: Calling delete() on a cursor is documented as more efficient than\n      // calling delete() on an object store with a single key\n      // (https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore/delete),\n      // however, this requires us *not* to use a keysOnly cursor\n      // (https://developer.mozilla.org/en-US/docs/Web/API/IDBCursor/delete). We\n      // may want to compare the performance of each method.\n      return control.delete();\n    });\n  }\n\n  /**\n   * Iterates over keys and values in an object store.\n   *\n   * @param options Options specifying how to iterate the objects in the store.\n   * @param callback will be called for each iterated object. Iteration can be\n   * canceled at any point by calling the doneFn passed to the callback.\n   * The callback can return a PersistencePromise if it performs async\n   * operations but note that iteration will continue without waiting for them\n   * to complete.\n   * @returns A PersistencePromise that resolves once all PersistencePromises\n   * returned by callbacks resolve.\n   */\n  iterate(\n    callback: IterateCallback<KeyType, ValueType>\n  ): PersistencePromise<void>;\n  iterate(\n    options: IterateOptions,\n    callback: IterateCallback<KeyType, ValueType>\n  ): PersistencePromise<void>;\n  iterate(\n    optionsOrCallback: IterateOptions | IterateCallback<KeyType, ValueType>,\n    callback?: IterateCallback<KeyType, ValueType>\n  ): PersistencePromise<void> {\n    let options;\n    if (!callback) {\n      options = {};\n      callback = optionsOrCallback as IterateCallback<KeyType, ValueType>;\n    } else {\n      options = optionsOrCallback as IterateOptions;\n    }\n    const cursor = this.cursor(options);\n    return this.iterateCursor(cursor, callback);\n  }\n\n  /**\n   * Iterates over a store, but waits for the given callback to complete for\n   * each entry before iterating the next entry. This allows the callback to do\n   * asynchronous work to determine if this iteration should continue.\n   *\n   * The provided callback should return `true` to continue iteration, and\n   * `false` otherwise.\n   */\n  iterateSerial(\n    callback: (k: KeyType, v: ValueType) => PersistencePromise<boolean>\n  ): PersistencePromise<void> {\n    const cursorRequest = this.cursor({});\n    return new PersistencePromise((resolve, reject) => {\n      cursorRequest.onerror = (event: Event) => {\n        const error = checkForAndReportiOSError(\n          (event.target as IDBRequest).error!\n        );\n        reject(error);\n      };\n      cursorRequest.onsuccess = (event: Event) => {\n        const cursor: IDBCursorWithValue = (event.target as IDBRequest).result;\n        if (!cursor) {\n          resolve();\n          return;\n        }\n\n        callback(cursor.primaryKey as KeyType, cursor.value).next(\n          shouldContinue => {\n            if (shouldContinue) {\n              cursor.continue();\n            } else {\n              resolve();\n            }\n          }\n        );\n      };\n    });\n  }\n\n  private iterateCursor(\n    cursorRequest: IDBRequest,\n    fn: IterateCallback<KeyType, ValueType>\n  ): PersistencePromise<void> {\n    const results: Array<PersistencePromise<void>> = [];\n    return new PersistencePromise((resolve, reject) => {\n      cursorRequest.onerror = (event: Event) => {\n        reject((event.target as IDBRequest).error!);\n      };\n      cursorRequest.onsuccess = (event: Event) => {\n        const cursor: IDBCursorWithValue = (event.target as IDBRequest).result;\n        if (!cursor) {\n          resolve();\n          return;\n        }\n        const controller = new IterationController(cursor);\n        const userResult = fn(\n          cursor.primaryKey as KeyType,\n          cursor.value,\n          controller\n        );\n        if (userResult instanceof PersistencePromise) {\n          const userPromise: PersistencePromise<void> = userResult.catch(\n            err => {\n              controller.done();\n              return PersistencePromise.reject(err);\n            }\n          );\n          results.push(userPromise);\n        }\n        if (controller.isDone) {\n          resolve();\n        } else if (controller.skipToKey === null) {\n          cursor.continue();\n        } else {\n          cursor.continue(controller.skipToKey);\n        }\n      };\n    }).next(() => {\n      return PersistencePromise.waitFor(results);\n    });\n  }\n\n  private options(\n    indexOrRange?: string | IDBKeyRange,\n    range?: IDBKeyRange\n  ): IterateOptions {\n    let indexName: string | undefined = undefined;\n    if (indexOrRange !== undefined) {\n      if (typeof indexOrRange === 'string') {\n        indexName = indexOrRange;\n      } else {\n        debugAssert(\n          range === undefined,\n          '3rd argument must not be defined if 2nd is a range.'\n        );\n        range = indexOrRange;\n      }\n    }\n    return { index: indexName, range };\n  }\n\n  private cursor(options: IterateOptions): IDBRequest {\n    let direction: IDBCursorDirection = 'next';\n    if (options.reverse) {\n      direction = 'prev';\n    }\n    if (options.index) {\n      const index = this.store.index(options.index);\n      if (options.keysOnly) {\n        return index.openKeyCursor(options.range, direction);\n      } else {\n        return index.openCursor(options.range, direction);\n      }\n    } else {\n      return this.store.openCursor(options.range, direction);\n    }\n  }\n}\n\n/**\n * Wraps an IDBRequest in a PersistencePromise, using the onsuccess / onerror\n * handlers to resolve / reject the PersistencePromise as appropriate.\n */\nfunction wrapRequest<R>(request: IDBRequest): PersistencePromise<R> {\n  return new PersistencePromise<R>((resolve, reject) => {\n    request.onsuccess = (event: Event) => {\n      const result = (event.target as IDBRequest).result;\n      resolve(result);\n    };\n\n    request.onerror = (event: Event) => {\n      const error = checkForAndReportiOSError(\n        (event.target as IDBRequest).error!\n      );\n      reject(error);\n    };\n  });\n}\n\n// Guard so we only report the error once.\nlet reportedIOSError = false;\nfunction checkForAndReportiOSError(error: DOMException): Error {\n  const iOSVersion = SimpleDb.getIOSVersion(getUA());\n  if (iOSVersion >= 12.2 && iOSVersion < 13) {\n    const IOS_ERROR =\n      'An internal error was encountered in the Indexed Database server';\n    if (error.message.indexOf(IOS_ERROR) >= 0) {\n      // Wrap error in a more descriptive one.\n      const newError = new FirestoreError(\n        'internal',\n        `IOS_INDEXEDDB_BUG1: IndexedDb has thrown '${IOS_ERROR}'. This is likely ` +\n          `due to an unavoidable bug in iOS. See https://stackoverflow.com/q/56496296/110915 ` +\n          `for details and a potential workaround.`\n      );\n      if (!reportedIOSError) {\n        reportedIOSError = true;\n        // Throw a global exception outside of this promise chain, for the user to\n        // potentially catch.\n        setTimeout(() => {\n          throw newError;\n        }, 0);\n      }\n      return newError;\n    }\n  }\n  return error;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/** The Platform's 'window' implementation or null if not available. */\nexport function getWindow(): Window | null {\n  // `window` is not always available, e.g. in ReactNative and WebWorkers.\n  // eslint-disable-next-line no-restricted-globals\n  return typeof window !== 'undefined' ? window : null;\n}\n\n/** The Platform's 'document' implementation or null if not available. */\nexport function getDocument(): Document | null {\n  // `document` is not always available, e.g. in ReactNative and WebWorkers.\n  // eslint-disable-next-line no-restricted-globals\n  return typeof document !== 'undefined' ? document : null;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert, fail } from './assert';\nimport { Code, FirestoreError } from './error';\nimport { logDebug, logError } from './log';\nimport { Deferred } from './promise';\nimport { ExponentialBackoff } from '../remote/backoff';\nimport { isIndexedDbTransactionError } from '../local/simple_db';\nimport { getDocument } from '../platform/dom';\n\nconst LOG_TAG = 'AsyncQueue';\n\n// Accept any return type from setTimeout().\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\ntype TimerHandle = any;\n\n/**\n * Wellknown \"timer\" IDs used when scheduling delayed operations on the\n * AsyncQueue. These IDs can then be used from tests to check for the presence\n * of operations or to run them early.\n *\n * The string values are used when encoding these timer IDs in JSON spec tests.\n */\nexport const enum TimerId {\n  /** All can be used with runDelayedOperationsEarly() to run all timers. */\n  All = 'all',\n\n  /**\n   * The following 4 timers are used in persistent_stream.ts for the listen and\n   * write streams. The \"Idle\" timer is used to close the stream due to\n   * inactivity. The \"ConnectionBackoff\" timer is used to restart a stream once\n   * the appropriate backoff delay has elapsed.\n   */\n  ListenStreamIdle = 'listen_stream_idle',\n  ListenStreamConnectionBackoff = 'listen_stream_connection_backoff',\n  WriteStreamIdle = 'write_stream_idle',\n  WriteStreamConnectionBackoff = 'write_stream_connection_backoff',\n\n  /**\n   * A timer used in online_state_tracker.ts to transition from\n   * OnlineState.Unknown to Offline after a set timeout, rather than waiting\n   * indefinitely for success or failure.\n   */\n  OnlineStateTimeout = 'online_state_timeout',\n\n  /**\n   * A timer used to update the client metadata in IndexedDb, which is used\n   * to determine the primary leaseholder.\n   */\n  ClientMetadataRefresh = 'client_metadata_refresh',\n\n  /** A timer used to periodically attempt LRU Garbage collection */\n  LruGarbageCollection = 'lru_garbage_collection',\n\n  /**\n   * A timer used to retry transactions. Since there can be multiple concurrent\n   * transactions, multiple of these may be in the queue at a given time.\n   */\n  TransactionRetry = 'transaction_retry',\n\n  /**\n   * A timer used to retry operations scheduled via retryable AsyncQueue\n   * operations.\n   */\n  AsyncQueueRetry = 'async_queue_retry'\n}\n\n/**\n * Represents an operation scheduled to be run in the future on an AsyncQueue.\n *\n * It is created via DelayedOperation.createAndSchedule().\n *\n * Supports cancellation (via cancel()) and early execution (via skipDelay()).\n *\n * Note: We implement `PromiseLike` instead of `Promise`, as the `Promise` type\n * in newer versions of TypeScript defines `finally`, which is not available in\n * IE.\n */\nexport class DelayedOperation<T extends unknown> implements PromiseLike<T> {\n  // handle for use with clearTimeout(), or null if the operation has been\n  // executed or canceled already.\n  private timerHandle: TimerHandle | null;\n\n  private readonly deferred = new Deferred<T>();\n\n  private constructor(\n    private readonly asyncQueue: AsyncQueue,\n    readonly timerId: TimerId,\n    readonly targetTimeMs: number,\n    private readonly op: () => Promise<T>,\n    private readonly removalCallback: (op: DelayedOperation<T>) => void\n  ) {\n    // It's normal for the deferred promise to be canceled (due to cancellation)\n    // and so we attach a dummy catch callback to avoid\n    // 'UnhandledPromiseRejectionWarning' log spam.\n    this.deferred.promise.catch(err => {});\n  }\n\n  /**\n   * Creates and returns a DelayedOperation that has been scheduled to be\n   * executed on the provided asyncQueue after the provided delayMs.\n   *\n   * @param asyncQueue The queue to schedule the operation on.\n   * @param id A Timer ID identifying the type of operation this is.\n   * @param delayMs The delay (ms) before the operation should be scheduled.\n   * @param op The operation to run.\n   * @param removalCallback A callback to be called synchronously once the\n   *   operation is executed or canceled, notifying the AsyncQueue to remove it\n   *   from its delayedOperations list.\n   *   PORTING NOTE: This exists to prevent making removeDelayedOperation() and\n   *   the DelayedOperation class public.\n   */\n  static createAndSchedule<R extends unknown>(\n    asyncQueue: AsyncQueue,\n    timerId: TimerId,\n    delayMs: number,\n    op: () => Promise<R>,\n    removalCallback: (op: DelayedOperation<R>) => void\n  ): DelayedOperation<R> {\n    const targetTime = Date.now() + delayMs;\n    const delayedOp = new DelayedOperation(\n      asyncQueue,\n      timerId,\n      targetTime,\n      op,\n      removalCallback\n    );\n    delayedOp.start(delayMs);\n    return delayedOp;\n  }\n\n  /**\n   * Starts the timer. This is called immediately after construction by\n   * createAndSchedule().\n   */\n  private start(delayMs: number): void {\n    this.timerHandle = setTimeout(() => this.handleDelayElapsed(), delayMs);\n  }\n\n  /**\n   * Queues the operation to run immediately (if it hasn't already been run or\n   * canceled).\n   */\n  skipDelay(): void {\n    return this.handleDelayElapsed();\n  }\n\n  /**\n   * Cancels the operation if it hasn't already been executed or canceled. The\n   * promise will be rejected.\n   *\n   * As long as the operation has not yet been run, calling cancel() provides a\n   * guarantee that the operation will not be run.\n   */\n  cancel(reason?: string): void {\n    if (this.timerHandle !== null) {\n      this.clearTimeout();\n      this.deferred.reject(\n        new FirestoreError(\n          Code.CANCELLED,\n          'Operation cancelled' + (reason ? ': ' + reason : '')\n        )\n      );\n    }\n  }\n\n  then = this.deferred.promise.then.bind(this.deferred.promise);\n\n  private handleDelayElapsed(): void {\n    this.asyncQueue.enqueueAndForget(() => {\n      if (this.timerHandle !== null) {\n        this.clearTimeout();\n        return this.op().then(result => {\n          return this.deferred.resolve(result);\n        });\n      } else {\n        return Promise.resolve();\n      }\n    });\n  }\n\n  private clearTimeout(): void {\n    if (this.timerHandle !== null) {\n      this.removalCallback(this);\n      clearTimeout(this.timerHandle);\n      this.timerHandle = null;\n    }\n  }\n}\n\nexport class AsyncQueue {\n  // The last promise in the queue.\n  private tail: Promise<unknown> = Promise.resolve();\n\n  // A list of retryable operations. Retryable operations are run in order and\n  // retried with backoff.\n  private retryableOps: Array<() => Promise<void>> = [];\n\n  // Is this AsyncQueue being shut down? Once it is set to true, it will not\n  // be changed again.\n  private _isShuttingDown: boolean = false;\n\n  // Operations scheduled to be queued in the future. Operations are\n  // automatically removed after they are run or canceled.\n  private delayedOperations: Array<DelayedOperation<unknown>> = [];\n\n  // visible for testing\n  failure: Error | null = null;\n\n  // Flag set while there's an outstanding AsyncQueue operation, used for\n  // assertion sanity-checks.\n  private operationInProgress = false;\n\n  // List of TimerIds to fast-forward delays for.\n  private timerIdsToSkip: TimerId[] = [];\n\n  // Backoff timer used to schedule retries for retryable operations\n  private backoff = new ExponentialBackoff(this, TimerId.AsyncQueueRetry);\n\n  // Visibility handler that triggers an immediate retry of all retryable\n  // operations. Meant to speed up recovery when we regain file system access\n  // after page comes into foreground.\n  private visibilityHandler: () => void = () => {\n    const document = getDocument();\n    if (document) {\n      logDebug(\n        LOG_TAG,\n        'Visibility state changed to  ',\n        document.visibilityState\n      );\n    }\n    this.backoff.skipBackoff();\n  };\n\n  constructor() {\n    const document = getDocument();\n    if (document && typeof document.addEventListener === 'function') {\n      document.addEventListener('visibilitychange', this.visibilityHandler);\n    }\n  }\n\n  // Is this AsyncQueue being shut down? If true, this instance will not enqueue\n  // any new operations, Promises from enqueue requests will not resolve.\n  get isShuttingDown(): boolean {\n    return this._isShuttingDown;\n  }\n\n  /**\n   * Adds a new operation to the queue without waiting for it to complete (i.e.\n   * we ignore the Promise result).\n   */\n  enqueueAndForget<T extends unknown>(op: () => Promise<T>): void {\n    // eslint-disable-next-line @typescript-eslint/no-floating-promises\n    this.enqueue(op);\n  }\n\n  /**\n   * Regardless if the queue has initialized shutdown, adds a new operation to the\n   * queue without waiting for it to complete (i.e. we ignore the Promise result).\n   */\n  enqueueAndForgetEvenAfterShutdown<T extends unknown>(\n    op: () => Promise<T>\n  ): void {\n    this.verifyNotFailed();\n    // eslint-disable-next-line @typescript-eslint/no-floating-promises\n    this.enqueueInternal(op);\n  }\n\n  /**\n   * Regardless if the queue has initialized shutdown, adds a new operation to the\n   * queue.\n   */\n  private enqueueEvenAfterShutdown<T extends unknown>(\n    op: () => Promise<T>\n  ): Promise<T> {\n    this.verifyNotFailed();\n    return this.enqueueInternal(op);\n  }\n\n  /**\n   * Adds a new operation to the queue and initialize the shut down of this queue.\n   * Returns a promise that will be resolved when the promise returned by the new\n   * operation is (with its value).\n   * Once this method is called, the only possible way to request running an operation\n   * is through `enqueueAndForgetEvenAfterShutdown`.\n   */\n  async enqueueAndInitiateShutdown(op: () => Promise<void>): Promise<void> {\n    this.verifyNotFailed();\n    if (!this._isShuttingDown) {\n      this._isShuttingDown = true;\n      const document = getDocument();\n      if (document && typeof document.removeEventListener === 'function') {\n        document.removeEventListener(\n          'visibilitychange',\n          this.visibilityHandler\n        );\n      }\n      await this.enqueueEvenAfterShutdown(op);\n    }\n  }\n\n  /**\n   * Adds a new operation to the queue. Returns a promise that will be resolved\n   * when the promise returned by the new operation is (with its value).\n   */\n  enqueue<T extends unknown>(op: () => Promise<T>): Promise<T> {\n    this.verifyNotFailed();\n    if (this._isShuttingDown) {\n      // Return a Promise which never resolves.\n      return new Promise<T>(resolve => {});\n    }\n    return this.enqueueInternal(op);\n  }\n\n  /**\n   * Enqueue a retryable operation.\n   *\n   * A retryable operation is rescheduled with backoff if it fails with a\n   * IndexedDbTransactionError (the error type used by SimpleDb). All\n   * retryable operations are executed in order and only run if all prior\n   * operations were retried successfully.\n   */\n  enqueueRetryable(op: () => Promise<void>): void {\n    this.retryableOps.push(op);\n    this.enqueueAndForget(() => this.retryNextOp());\n  }\n\n  /**\n   * Runs the next operation from the retryable queue. If the operation fails,\n   * reschedules with backoff.\n   */\n  private async retryNextOp(): Promise<void> {\n    if (this.retryableOps.length === 0) {\n      return;\n    }\n\n    try {\n      await this.retryableOps[0]();\n      this.retryableOps.shift();\n      this.backoff.reset();\n    } catch (e) {\n      if (isIndexedDbTransactionError(e)) {\n        logDebug(LOG_TAG, 'Operation failed with retryable error: ' + e);\n      } else {\n        throw e; // Failure will be handled by AsyncQueue\n      }\n    }\n\n    if (this.retryableOps.length > 0) {\n      // If there are additional operations, we re-schedule `retryNextOp()`.\n      // This is necessary to run retryable operations that failed during\n      // their initial attempt since we don't know whether they are already\n      // enqueued. If, for example, `op1`, `op2`, `op3` are enqueued and `op1`\n      // needs to  be re-run, we will run `op1`, `op1`, `op2` using the\n      // already enqueued calls to `retryNextOp()`. `op3()` will then run in the\n      // call scheduled here.\n      // Since `backoffAndRun()` cancels an existing backoff and schedules a\n      // new backoff on every call, there is only ever a single additional\n      // operation in the queue.\n      this.backoff.backoffAndRun(() => this.retryNextOp());\n    }\n  }\n\n  private enqueueInternal<T extends unknown>(op: () => Promise<T>): Promise<T> {\n    const newTail = this.tail.then(() => {\n      this.operationInProgress = true;\n      return op()\n        .catch((error: FirestoreError) => {\n          this.failure = error;\n          this.operationInProgress = false;\n          const message = getMessageOrStack(error);\n          logError('INTERNAL UNHANDLED ERROR: ', message);\n\n          // Re-throw the error so that this.tail becomes a rejected Promise and\n          // all further attempts to chain (via .then) will just short-circuit\n          // and return the rejected Promise.\n          throw error;\n        })\n        .then(result => {\n          this.operationInProgress = false;\n          return result;\n        });\n    });\n    this.tail = newTail;\n    return newTail;\n  }\n\n  /**\n   * Schedules an operation to be queued on the AsyncQueue once the specified\n   * `delayMs` has elapsed. The returned DelayedOperation can be used to cancel\n   * or fast-forward the operation prior to its running.\n   */\n  enqueueAfterDelay<T extends unknown>(\n    timerId: TimerId,\n    delayMs: number,\n    op: () => Promise<T>\n  ): DelayedOperation<T> {\n    this.verifyNotFailed();\n\n    debugAssert(\n      delayMs >= 0,\n      `Attempted to schedule an operation with a negative delay of ${delayMs}`\n    );\n\n    // Fast-forward delays for timerIds that have been overriden.\n    if (this.timerIdsToSkip.indexOf(timerId) > -1) {\n      delayMs = 0;\n    }\n\n    const delayedOp = DelayedOperation.createAndSchedule<T>(\n      this,\n      timerId,\n      delayMs,\n      op,\n      removedOp =>\n        this.removeDelayedOperation(removedOp as DelayedOperation<unknown>)\n    );\n    this.delayedOperations.push(delayedOp as DelayedOperation<unknown>);\n    return delayedOp;\n  }\n\n  private verifyNotFailed(): void {\n    if (this.failure) {\n      fail('AsyncQueue is already failed: ' + getMessageOrStack(this.failure));\n    }\n  }\n\n  /**\n   * Verifies there's an operation currently in-progress on the AsyncQueue.\n   * Unfortunately we can't verify that the running code is in the promise chain\n   * of that operation, so this isn't a foolproof check, but it should be enough\n   * to catch some bugs.\n   */\n  verifyOperationInProgress(): void {\n    debugAssert(\n      this.operationInProgress,\n      'verifyOpInProgress() called when no op in progress on this queue.'\n    );\n  }\n\n  /**\n   * Waits until all currently queued tasks are finished executing. Delayed\n   * operations are not run.\n   */\n  async drain(): Promise<void> {\n    // Operations in the queue prior to draining may have enqueued additional\n    // operations. Keep draining the queue until the tail is no longer advanced,\n    // which indicates that no more new operations were enqueued and that all\n    // operations were executed.\n    let currentTail: Promise<unknown>;\n    do {\n      currentTail = this.tail;\n      await currentTail;\n    } while (currentTail !== this.tail);\n  }\n\n  /**\n   * For Tests: Determine if a delayed operation with a particular TimerId\n   * exists.\n   */\n  containsDelayedOperation(timerId: TimerId): boolean {\n    for (const op of this.delayedOperations) {\n      if (op.timerId === timerId) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  /**\n   * For Tests: Runs some or all delayed operations early.\n   *\n   * @param lastTimerId Delayed operations up to and including this TimerId will\n   *  be drained. Pass TimerId.All to run all delayed operations.\n   * @returns a Promise that resolves once all operations have been run.\n   */\n  runAllDelayedOperationsUntil(lastTimerId: TimerId): Promise<void> {\n    // Note that draining may generate more delayed ops, so we do that first.\n    return this.drain().then(() => {\n      // Run ops in the same order they'd run if they ran naturally.\n      this.delayedOperations.sort((a, b) => a.targetTimeMs - b.targetTimeMs);\n\n      for (const op of this.delayedOperations) {\n        op.skipDelay();\n        if (lastTimerId !== TimerId.All && op.timerId === lastTimerId) {\n          break;\n        }\n      }\n\n      return this.drain();\n    });\n  }\n\n  /**\n   * For Tests: Skip all subsequent delays for a timer id.\n   */\n  skipDelaysForTimerId(timerId: TimerId): void {\n    this.timerIdsToSkip.push(timerId);\n  }\n\n  /** Called once a DelayedOperation is run or canceled. */\n  private removeDelayedOperation(op: DelayedOperation<unknown>): void {\n    // NOTE: indexOf / slice are O(n), but delayedOperations is expected to be small.\n    const index = this.delayedOperations.indexOf(op);\n    debugAssert(index >= 0, 'Delayed operation not found.');\n    this.delayedOperations.splice(index, 1);\n  }\n}\n\n/**\n * Returns a FirestoreError that can be surfaced to the user if the provided\n * error is an IndexedDbTransactionError. Re-throws the error otherwise.\n */\nexport function wrapInUserErrorIfRecoverable(\n  e: Error,\n  msg: string\n): FirestoreError {\n  logError(LOG_TAG, `${msg}: ${e}`);\n  if (isIndexedDbTransactionError(e)) {\n    return new FirestoreError(Code.UNAVAILABLE, `${msg}: ${e}`);\n  } else {\n    throw e;\n  }\n}\n\n/**\n * Chrome includes Error.message in Error.stack. Other browsers do not.\n * This returns expected output of message + stack when available.\n * @param error Error or FirestoreError\n */\nfunction getMessageOrStack(error: Error): string {\n  let message = error.message || '';\n  if (error.stack) {\n    if (error.stack.includes(error.message)) {\n      message = error.stack;\n    } else {\n      message = error.message + '\\n' + error.stack;\n    }\n  }\n  return message;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ListenSequence } from '../core/listen_sequence';\nimport { ListenSequenceNumber, TargetId } from '../core/types';\nimport { debugAssert } from '../util/assert';\nimport { AsyncQueue, DelayedOperation, TimerId } from '../util/async_queue';\nimport { getLogLevel, logDebug, LogLevel } from '../util/log';\nimport { primitiveComparator } from '../util/misc';\nimport { SortedMap } from '../util/sorted_map';\nimport { SortedSet } from '../util/sorted_set';\nimport { ignoreIfPrimaryLeaseLoss, LocalStore } from './local_store';\nimport {\n  GarbageCollectionScheduler,\n  PersistenceTransaction\n} from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { TargetData } from './target_data';\nimport { isIndexedDbTransactionError } from './simple_db';\n\nconst LOG_TAG = 'LruGarbageCollector';\n\n/**\n * Persistence layers intending to use LRU Garbage collection should have reference delegates that\n * implement this interface. This interface defines the operations that the LRU garbage collector\n * needs from the persistence layer.\n */\nexport interface LruDelegate {\n  readonly garbageCollector: LruGarbageCollector;\n\n  /** Enumerates all the targets in the TargetCache. */\n  forEachTarget(\n    txn: PersistenceTransaction,\n    f: (target: TargetData) => void\n  ): PersistencePromise<void>;\n\n  getSequenceNumberCount(\n    txn: PersistenceTransaction\n  ): PersistencePromise<number>;\n\n  /**\n   * Enumerates sequence numbers for documents not associated with a target.\n   * Note that this may include duplicate sequence numbers.\n   */\n  forEachOrphanedDocumentSequenceNumber(\n    txn: PersistenceTransaction,\n    f: (sequenceNumber: ListenSequenceNumber) => void\n  ): PersistencePromise<void>;\n\n  /**\n   * Removes all targets that have a sequence number less than or equal to `upperBound`, and are not\n   * present in the `activeTargetIds` set.\n   *\n   * @return the number of targets removed.\n   */\n  removeTargets(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<number>;\n\n  /**\n   * Removes all unreferenced documents from the cache that have a sequence number less than or\n   * equal to the given `upperBound`.\n   *\n   * @return the number of documents removed.\n   */\n  removeOrphanedDocuments(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber\n  ): PersistencePromise<number>;\n\n  getCacheSize(txn: PersistenceTransaction): PersistencePromise<number>;\n}\n\n/**\n * Describes a map whose keys are active target ids. We do not care about the type of the\n * values.\n */\nexport type ActiveTargets = SortedMap<TargetId, unknown>;\n\n// The type and comparator for the items contained in the SortedSet used in\n// place of a priority queue for the RollingSequenceNumberBuffer.\ntype BufferEntry = [ListenSequenceNumber, number];\nfunction bufferEntryComparator(\n  [aSequence, aIndex]: BufferEntry,\n  [bSequence, bIndex]: BufferEntry\n): number {\n  const seqCmp = primitiveComparator(aSequence, bSequence);\n  if (seqCmp === 0) {\n    // This order doesn't matter, but we can bias against churn by sorting\n    // entries created earlier as less than newer entries.\n    return primitiveComparator(aIndex, bIndex);\n  } else {\n    return seqCmp;\n  }\n}\n\n/**\n * Used to calculate the nth sequence number. Keeps a rolling buffer of the\n * lowest n values passed to `addElement`, and finally reports the largest of\n * them in `maxValue`.\n */\nclass RollingSequenceNumberBuffer {\n  private buffer: SortedSet<BufferEntry> = new SortedSet<BufferEntry>(\n    bufferEntryComparator\n  );\n\n  private previousIndex = 0;\n\n  constructor(private readonly maxElements: number) {}\n\n  private nextIndex(): number {\n    return ++this.previousIndex;\n  }\n\n  addElement(sequenceNumber: ListenSequenceNumber): void {\n    const entry: BufferEntry = [sequenceNumber, this.nextIndex()];\n    if (this.buffer.size < this.maxElements) {\n      this.buffer = this.buffer.add(entry);\n    } else {\n      const highestValue = this.buffer.last()!;\n      if (bufferEntryComparator(entry, highestValue) < 0) {\n        this.buffer = this.buffer.delete(highestValue).add(entry);\n      }\n    }\n  }\n\n  get maxValue(): ListenSequenceNumber {\n    // Guaranteed to be non-empty. If we decide we are not collecting any\n    // sequence numbers, nthSequenceNumber below short-circuits. If we have\n    // decided that we are collecting n sequence numbers, it's because n is some\n    // percentage of the existing sequence numbers. That means we should never\n    // be in a situation where we are collecting sequence numbers but don't\n    // actually have any.\n    return this.buffer.last()![0];\n  }\n}\n\n/**\n * Describes the results of a garbage collection run. `didRun` will be set to\n * `false` if collection was skipped (either it is disabled or the cache size\n * has not hit the threshold). If collection ran, the other fields will be\n * filled in with the details of the results.\n */\nexport interface LruResults {\n  readonly didRun: boolean;\n  readonly sequenceNumbersCollected: number;\n  readonly targetsRemoved: number;\n  readonly documentsRemoved: number;\n}\n\nconst GC_DID_NOT_RUN: LruResults = {\n  didRun: false,\n  sequenceNumbersCollected: 0,\n  targetsRemoved: 0,\n  documentsRemoved: 0\n};\n\nexport class LruParams {\n  static readonly COLLECTION_DISABLED = -1;\n  static readonly MINIMUM_CACHE_SIZE_BYTES = 1 * 1024 * 1024;\n  static readonly DEFAULT_CACHE_SIZE_BYTES = 40 * 1024 * 1024;\n  private static readonly DEFAULT_COLLECTION_PERCENTILE = 10;\n  private static readonly DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT = 1000;\n\n  static withCacheSize(cacheSize: number): LruParams {\n    return new LruParams(\n      cacheSize,\n      LruParams.DEFAULT_COLLECTION_PERCENTILE,\n      LruParams.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT\n    );\n  }\n\n  static readonly DEFAULT: LruParams = new LruParams(\n    LruParams.DEFAULT_CACHE_SIZE_BYTES,\n    LruParams.DEFAULT_COLLECTION_PERCENTILE,\n    LruParams.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT\n  );\n\n  static readonly DISABLED: LruParams = new LruParams(\n    LruParams.COLLECTION_DISABLED,\n    0,\n    0\n  );\n\n  constructor(\n    // When we attempt to collect, we will only do so if the cache size is greater than this\n    // threshold. Passing `COLLECTION_DISABLED` here will cause collection to always be skipped.\n    readonly cacheSizeCollectionThreshold: number,\n    // The percentage of sequence numbers that we will attempt to collect\n    readonly percentileToCollect: number,\n    // A cap on the total number of sequence numbers that will be collected. This prevents\n    // us from collecting a huge number of sequence numbers if the cache has grown very large.\n    readonly maximumSequenceNumbersToCollect: number\n  ) {}\n}\n\n/** How long we wait to try running LRU GC after SDK initialization. */\nconst INITIAL_GC_DELAY_MS = 1 * 60 * 1000;\n/** Minimum amount of time between GC checks, after the first one. */\nconst REGULAR_GC_DELAY_MS = 5 * 60 * 1000;\n\n/**\n * This class is responsible for the scheduling of LRU garbage collection. It handles checking\n * whether or not GC is enabled, as well as which delay to use before the next run.\n */\nexport class LruScheduler implements GarbageCollectionScheduler {\n  private hasRun: boolean = false;\n  private gcTask: DelayedOperation<void> | null;\n\n  constructor(\n    private readonly garbageCollector: LruGarbageCollector,\n    private readonly asyncQueue: AsyncQueue\n  ) {\n    this.gcTask = null;\n  }\n\n  start(localStore: LocalStore): void {\n    debugAssert(\n      this.gcTask === null,\n      'Cannot start an already started LruScheduler'\n    );\n    if (\n      this.garbageCollector.params.cacheSizeCollectionThreshold !==\n      LruParams.COLLECTION_DISABLED\n    ) {\n      this.scheduleGC(localStore);\n    }\n  }\n\n  stop(): void {\n    if (this.gcTask) {\n      this.gcTask.cancel();\n      this.gcTask = null;\n    }\n  }\n\n  get started(): boolean {\n    return this.gcTask !== null;\n  }\n\n  private scheduleGC(localStore: LocalStore): void {\n    debugAssert(\n      this.gcTask === null,\n      'Cannot schedule GC while a task is pending'\n    );\n    const delay = this.hasRun ? REGULAR_GC_DELAY_MS : INITIAL_GC_DELAY_MS;\n    logDebug(\n      'LruGarbageCollector',\n      `Garbage collection scheduled in ${delay}ms`\n    );\n    this.gcTask = this.asyncQueue.enqueueAfterDelay(\n      TimerId.LruGarbageCollection,\n      delay,\n      async () => {\n        this.gcTask = null;\n        this.hasRun = true;\n        try {\n          await localStore.collectGarbage(this.garbageCollector);\n        } catch (e) {\n          if (isIndexedDbTransactionError(e)) {\n            logDebug(\n              LOG_TAG,\n              'Ignoring IndexedDB error during garbage collection: ',\n              e\n            );\n          } else {\n            await ignoreIfPrimaryLeaseLoss(e);\n          }\n        }\n        await this.scheduleGC(localStore);\n      }\n    );\n  }\n}\n\n/** Implements the steps for LRU garbage collection. */\nexport class LruGarbageCollector {\n  constructor(\n    private readonly delegate: LruDelegate,\n    readonly params: LruParams\n  ) {}\n\n  /** Given a percentile of target to collect, returns the number of targets to collect. */\n  calculateTargetCount(\n    txn: PersistenceTransaction,\n    percentile: number\n  ): PersistencePromise<number> {\n    return this.delegate.getSequenceNumberCount(txn).next(targetCount => {\n      return Math.floor((percentile / 100.0) * targetCount);\n    });\n  }\n\n  /** Returns the nth sequence number, counting in order from the smallest. */\n  nthSequenceNumber(\n    txn: PersistenceTransaction,\n    n: number\n  ): PersistencePromise<ListenSequenceNumber> {\n    if (n === 0) {\n      return PersistencePromise.resolve(ListenSequence.INVALID);\n    }\n\n    const buffer = new RollingSequenceNumberBuffer(n);\n    return this.delegate\n      .forEachTarget(txn, target => buffer.addElement(target.sequenceNumber))\n      .next(() => {\n        return this.delegate.forEachOrphanedDocumentSequenceNumber(\n          txn,\n          sequenceNumber => buffer.addElement(sequenceNumber)\n        );\n      })\n      .next(() => buffer.maxValue);\n  }\n\n  /**\n   * Removes targets with a sequence number equal to or less than the given upper bound, and removes\n   * document associations with those targets.\n   */\n  removeTargets(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<number> {\n    return this.delegate.removeTargets(txn, upperBound, activeTargetIds);\n  }\n\n  /**\n   * Removes documents that have a sequence number equal to or less than the upper bound and are not\n   * otherwise pinned.\n   */\n  removeOrphanedDocuments(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber\n  ): PersistencePromise<number> {\n    return this.delegate.removeOrphanedDocuments(txn, upperBound);\n  }\n\n  collect(\n    txn: PersistenceTransaction,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<LruResults> {\n    if (\n      this.params.cacheSizeCollectionThreshold === LruParams.COLLECTION_DISABLED\n    ) {\n      logDebug('LruGarbageCollector', 'Garbage collection skipped; disabled');\n      return PersistencePromise.resolve(GC_DID_NOT_RUN);\n    }\n\n    return this.getCacheSize(txn).next(cacheSize => {\n      if (cacheSize < this.params.cacheSizeCollectionThreshold) {\n        logDebug(\n          'LruGarbageCollector',\n          `Garbage collection skipped; Cache size ${cacheSize} ` +\n            `is lower than threshold ${this.params.cacheSizeCollectionThreshold}`\n        );\n        return GC_DID_NOT_RUN;\n      } else {\n        return this.runGarbageCollection(txn, activeTargetIds);\n      }\n    });\n  }\n\n  getCacheSize(txn: PersistenceTransaction): PersistencePromise<number> {\n    return this.delegate.getCacheSize(txn);\n  }\n\n  private runGarbageCollection(\n    txn: PersistenceTransaction,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<LruResults> {\n    let upperBoundSequenceNumber: number;\n    let sequenceNumbersToCollect: number, targetsRemoved: number;\n    // Timestamps for various pieces of the process\n    let countedTargetsTs: number,\n      foundUpperBoundTs: number,\n      removedTargetsTs: number,\n      removedDocumentsTs: number;\n    const startTs = Date.now();\n    return this.calculateTargetCount(txn, this.params.percentileToCollect)\n      .next(sequenceNumbers => {\n        // Cap at the configured max\n        if (sequenceNumbers > this.params.maximumSequenceNumbersToCollect) {\n          logDebug(\n            'LruGarbageCollector',\n            'Capping sequence numbers to collect down ' +\n              `to the maximum of ${this.params.maximumSequenceNumbersToCollect} ` +\n              `from ${sequenceNumbers}`\n          );\n          sequenceNumbersToCollect = this.params\n            .maximumSequenceNumbersToCollect;\n        } else {\n          sequenceNumbersToCollect = sequenceNumbers;\n        }\n        countedTargetsTs = Date.now();\n\n        return this.nthSequenceNumber(txn, sequenceNumbersToCollect);\n      })\n      .next(upperBound => {\n        upperBoundSequenceNumber = upperBound;\n        foundUpperBoundTs = Date.now();\n\n        return this.removeTargets(\n          txn,\n          upperBoundSequenceNumber,\n          activeTargetIds\n        );\n      })\n      .next(numTargetsRemoved => {\n        targetsRemoved = numTargetsRemoved;\n        removedTargetsTs = Date.now();\n\n        return this.removeOrphanedDocuments(txn, upperBoundSequenceNumber);\n      })\n      .next(documentsRemoved => {\n        removedDocumentsTs = Date.now();\n\n        if (getLogLevel() <= LogLevel.DEBUG) {\n          const desc =\n            'LRU Garbage Collection\\n' +\n            `\\tCounted targets in ${countedTargetsTs - startTs}ms\\n` +\n            `\\tDetermined least recently used ${sequenceNumbersToCollect} in ` +\n            `${foundUpperBoundTs - countedTargetsTs}ms\\n` +\n            `\\tRemoved ${targetsRemoved} targets in ` +\n            `${removedTargetsTs - foundUpperBoundTs}ms\\n` +\n            `\\tRemoved ${documentsRemoved} documents in ` +\n            `${removedDocumentsTs - removedTargetsTs}ms\\n` +\n            `Total Duration: ${removedDocumentsTs - startTs}ms`;\n          logDebug('LruGarbageCollector', desc);\n        }\n\n        return PersistencePromise.resolve<LruResults>({\n          didRun: true,\n          sequenceNumbersCollected: sequenceNumbersToCollect,\n          targetsRemoved,\n          documentsRemoved\n        });\n      });\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ResourcePath } from '../model/path';\nimport { fail, hardAssert } from '../util/assert';\n\n/**\n * Helpers for dealing with resource paths stored in IndexedDB.\n *\n * Resource paths in their canonical string form do not sort as the server\n * sorts them. Specifically the server splits paths into segments first and then\n * sorts, putting end-of-segment before any character. In a UTF-8 string\n * encoding the slash ('/') that denotes the end-of-segment naturally comes\n * after other characters so the intent here is to encode the path delimiters in\n * such a way that the resulting strings sort naturally.\n *\n * Resource paths are also used for prefix scans so it's important to\n * distinguish whole segments from any longer segments of which they might be a\n * prefix. For example, it's important to make it possible to scan documents in\n * a collection \"foo\" without encountering documents in a collection \"foobar\".\n *\n * Separate from the concerns about resource path ordering and separation,\n * On Android, SQLite imposes additional restrictions since it does not handle\n * keys with embedded NUL bytes particularly well. Rather than change the\n * implementation we keep the encoding identical to keep the ports similar.\n *\n * Taken together this means resource paths when encoded for storage in\n * IndexedDB have the following characteristics:\n *\n *   * Segment separators (\"/\") sort before everything else.\n *   * All paths have a trailing separator.\n *   * NUL bytes do not exist in the output, since IndexedDB doesn't treat them\n * well.\n *\n * Therefore resource paths are encoded into string form using the following\n * rules:\n *\n *   * '\\x01' is used as an escape character.\n *   * Path separators are encoded as \"\\x01\\x01\"\n *   * NUL bytes are encoded as \"\\x01\\x10\"\n *   * '\\x01' is encoded as \"\\x01\\x11\"\n *\n * This encoding leaves some room between path separators and the NUL byte\n * just in case we decide to support integer document ids after all.\n *\n * Note that characters treated specially by the backend ('.', '/', and '~')\n * are not treated specially here. This class assumes that any unescaping of\n * resource path strings into actual ResourcePath objects will handle these\n * characters there.\n */\nexport type EncodedResourcePath = string;\n\nconst escapeChar = '\\u0001';\nconst encodedSeparatorChar = '\\u0001';\nconst encodedNul = '\\u0010';\nconst encodedEscape = '\\u0011';\n\n/**\n * Encodes a resource path into a IndexedDb-compatible string form.\n */\nexport function encodeResourcePath(path: ResourcePath): EncodedResourcePath {\n  let result = '';\n  for (let i = 0; i < path.length; i++) {\n    if (result.length > 0) {\n      result = encodeSeparator(result);\n    }\n    result = encodeSegment(path.get(i), result);\n  }\n  return encodeSeparator(result);\n}\n\n/** Encodes a single segment of a resource path into the given result */\nfunction encodeSegment(segment: string, resultBuf: string): string {\n  let result = resultBuf;\n  const length = segment.length;\n  for (let i = 0; i < length; i++) {\n    const c = segment.charAt(i);\n    switch (c) {\n      case '\\0':\n        result += escapeChar + encodedNul;\n        break;\n      case escapeChar:\n        result += escapeChar + encodedEscape;\n        break;\n      default:\n        result += c;\n    }\n  }\n  return result;\n}\n\n/** Encodes a path separator into the given result */\nfunction encodeSeparator(result: string): string {\n  return result + escapeChar + encodedSeparatorChar;\n}\n\n/**\n * Decodes the given IndexedDb-compatible string form of a resource path into\n * a ResourcePath instance. Note that this method is not suitable for use with\n * decoding resource names from the server; those are One Platform format\n * strings.\n */\nexport function decodeResourcePath(path: EncodedResourcePath): ResourcePath {\n  // Event the empty path must encode as a path of at least length 2. A path\n  // with exactly 2 must be the empty path.\n  const length = path.length;\n  hardAssert(length >= 2, 'Invalid path ' + path);\n  if (length === 2) {\n    hardAssert(\n      path.charAt(0) === escapeChar && path.charAt(1) === encodedSeparatorChar,\n      'Non-empty path ' + path + ' had length 2'\n    );\n    return ResourcePath.emptyPath();\n  }\n\n  // Escape characters cannot exist past the second-to-last position in the\n  // source value.\n  const lastReasonableEscapeIndex = length - 2;\n\n  const segments: string[] = [];\n  let segmentBuilder = '';\n\n  for (let start = 0; start < length; ) {\n    // The last two characters of a valid encoded path must be a separator, so\n    // there must be an end to this segment.\n    const end = path.indexOf(escapeChar, start);\n    if (end < 0 || end > lastReasonableEscapeIndex) {\n      fail('Invalid encoded resource path: \"' + path + '\"');\n    }\n\n    const next = path.charAt(end + 1);\n    switch (next) {\n      case encodedSeparatorChar:\n        const currentPiece = path.substring(start, end);\n        let segment;\n        if (segmentBuilder.length === 0) {\n          // Avoid copying for the common case of a segment that excludes \\0\n          // and \\001\n          segment = currentPiece;\n        } else {\n          segmentBuilder += currentPiece;\n          segment = segmentBuilder;\n          segmentBuilder = '';\n        }\n        segments.push(segment);\n        break;\n      case encodedNul:\n        segmentBuilder += path.substring(start, end);\n        segmentBuilder += '\\0';\n        break;\n      case encodedEscape:\n        // The escape character can be used in the output to encode itself.\n        segmentBuilder += path.substring(start, end + 1);\n        break;\n      default:\n        fail('Invalid encoded resource path: \"' + path + '\"');\n    }\n\n    start = end + 2;\n  }\n\n  return new ResourcePath(segments);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Timestamp } from '../api/timestamp';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport {\n  Document,\n  MaybeDocument,\n  NoDocument,\n  UnknownDocument\n} from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { MutationBatch } from '../model/mutation_batch';\nimport * as api from '../protos/firestore_proto_api';\nimport {\n  fromDocument,\n  fromDocumentsTarget,\n  fromMutation,\n  fromQueryTarget,\n  JsonProtoSerializer,\n  toDocument,\n  toDocumentsTarget,\n  toMutation,\n  toQueryTarget\n} from '../remote/serializer';\nimport { debugAssert, fail } from '../util/assert';\nimport { ByteString } from '../util/byte_string';\nimport { canonifyTarget, isDocumentTarget, Target } from '../core/target';\nimport {\n  DbMutationBatch,\n  DbNoDocument,\n  DbQuery,\n  DbRemoteDocument,\n  DbTarget,\n  DbTimestamp,\n  DbTimestampKey,\n  DbUnknownDocument\n} from './indexeddb_schema';\nimport { TargetData, TargetPurpose } from './target_data';\n\n/** Serializer for values stored in the LocalStore. */\nexport class LocalSerializer {\n  constructor(readonly remoteSerializer: JsonProtoSerializer) {}\n}\n\n/** Decodes a remote document from storage locally to a Document. */\nexport function fromDbRemoteDocument(\n  localSerializer: LocalSerializer,\n  remoteDoc: DbRemoteDocument\n): MaybeDocument {\n  if (remoteDoc.document) {\n    return fromDocument(\n      localSerializer.remoteSerializer,\n      remoteDoc.document,\n      !!remoteDoc.hasCommittedMutations\n    );\n  } else if (remoteDoc.noDocument) {\n    const key = DocumentKey.fromSegments(remoteDoc.noDocument.path);\n    const version = fromDbTimestamp(remoteDoc.noDocument.readTime);\n    return new NoDocument(key, version, {\n      hasCommittedMutations: !!remoteDoc.hasCommittedMutations\n    });\n  } else if (remoteDoc.unknownDocument) {\n    const key = DocumentKey.fromSegments(remoteDoc.unknownDocument.path);\n    const version = fromDbTimestamp(remoteDoc.unknownDocument.version);\n    return new UnknownDocument(key, version);\n  } else {\n    return fail('Unexpected DbRemoteDocument');\n  }\n}\n\n/** Encodes a document for storage locally. */\nexport function toDbRemoteDocument(\n  localSerializer: LocalSerializer,\n  maybeDoc: MaybeDocument,\n  readTime: SnapshotVersion\n): DbRemoteDocument {\n  const dbReadTime = toDbTimestampKey(readTime);\n  const parentPath = maybeDoc.key.path.popLast().toArray();\n  if (maybeDoc instanceof Document) {\n    const doc = toDocument(localSerializer.remoteSerializer, maybeDoc);\n    const hasCommittedMutations = maybeDoc.hasCommittedMutations;\n    return new DbRemoteDocument(\n      /* unknownDocument= */ null,\n      /* noDocument= */ null,\n      doc,\n      hasCommittedMutations,\n      dbReadTime,\n      parentPath\n    );\n  } else if (maybeDoc instanceof NoDocument) {\n    const path = maybeDoc.key.path.toArray();\n    const readTime = toDbTimestamp(maybeDoc.version);\n    const hasCommittedMutations = maybeDoc.hasCommittedMutations;\n    return new DbRemoteDocument(\n      /* unknownDocument= */ null,\n      new DbNoDocument(path, readTime),\n      /* document= */ null,\n      hasCommittedMutations,\n      dbReadTime,\n      parentPath\n    );\n  } else if (maybeDoc instanceof UnknownDocument) {\n    const path = maybeDoc.key.path.toArray();\n    const readTime = toDbTimestamp(maybeDoc.version);\n    return new DbRemoteDocument(\n      new DbUnknownDocument(path, readTime),\n      /* noDocument= */ null,\n      /* document= */ null,\n      /* hasCommittedMutations= */ true,\n      dbReadTime,\n      parentPath\n    );\n  } else {\n    return fail('Unexpected MaybeDocument');\n  }\n}\n\nexport function toDbTimestampKey(\n  snapshotVersion: SnapshotVersion\n): DbTimestampKey {\n  const timestamp = snapshotVersion.toTimestamp();\n  return [timestamp.seconds, timestamp.nanoseconds];\n}\n\nexport function fromDbTimestampKey(\n  dbTimestampKey: DbTimestampKey\n): SnapshotVersion {\n  const timestamp = new Timestamp(dbTimestampKey[0], dbTimestampKey[1]);\n  return SnapshotVersion.fromTimestamp(timestamp);\n}\n\nfunction toDbTimestamp(snapshotVersion: SnapshotVersion): DbTimestamp {\n  const timestamp = snapshotVersion.toTimestamp();\n  return new DbTimestamp(timestamp.seconds, timestamp.nanoseconds);\n}\n\nfunction fromDbTimestamp(dbTimestamp: DbTimestamp): SnapshotVersion {\n  const timestamp = new Timestamp(dbTimestamp.seconds, dbTimestamp.nanoseconds);\n  return SnapshotVersion.fromTimestamp(timestamp);\n}\n\n/** Encodes a batch of mutations into a DbMutationBatch for local storage. */\nexport function toDbMutationBatch(\n  localSerializer: LocalSerializer,\n  userId: string,\n  batch: MutationBatch\n): DbMutationBatch {\n  const serializedBaseMutations = batch.baseMutations.map(m =>\n    toMutation(localSerializer.remoteSerializer, m)\n  );\n  const serializedMutations = batch.mutations.map(m =>\n    toMutation(localSerializer.remoteSerializer, m)\n  );\n  return new DbMutationBatch(\n    userId,\n    batch.batchId,\n    batch.localWriteTime.toMillis(),\n    serializedBaseMutations,\n    serializedMutations\n  );\n}\n\n/** Decodes a DbMutationBatch into a MutationBatch */\nexport function fromDbMutationBatch(\n  localSerializer: LocalSerializer,\n  dbBatch: DbMutationBatch\n): MutationBatch {\n  const baseMutations = (dbBatch.baseMutations || []).map(m =>\n    fromMutation(localSerializer.remoteSerializer, m)\n  );\n  const mutations = dbBatch.mutations.map(m =>\n    fromMutation(localSerializer.remoteSerializer, m)\n  );\n  const timestamp = Timestamp.fromMillis(dbBatch.localWriteTimeMs);\n  return new MutationBatch(\n    dbBatch.batchId,\n    timestamp,\n    baseMutations,\n    mutations\n  );\n}\n\n/** Decodes a DbTarget into TargetData */\nexport function fromDbTarget(dbTarget: DbTarget): TargetData {\n  const version = fromDbTimestamp(dbTarget.readTime);\n  const lastLimboFreeSnapshotVersion =\n    dbTarget.lastLimboFreeSnapshotVersion !== undefined\n      ? fromDbTimestamp(dbTarget.lastLimboFreeSnapshotVersion)\n      : SnapshotVersion.min();\n\n  let target: Target;\n  if (isDocumentQuery(dbTarget.query)) {\n    target = fromDocumentsTarget(dbTarget.query);\n  } else {\n    target = fromQueryTarget(dbTarget.query);\n  }\n  return new TargetData(\n    target,\n    dbTarget.targetId,\n    TargetPurpose.Listen,\n    dbTarget.lastListenSequenceNumber,\n    version,\n    lastLimboFreeSnapshotVersion,\n    ByteString.fromBase64String(dbTarget.resumeToken)\n  );\n}\n\n/** Encodes TargetData into a DbTarget for storage locally. */\nexport function toDbTarget(\n  localSerializer: LocalSerializer,\n  targetData: TargetData\n): DbTarget {\n  debugAssert(\n    TargetPurpose.Listen === targetData.purpose,\n    'Only queries with purpose ' +\n      TargetPurpose.Listen +\n      ' may be stored, got ' +\n      targetData.purpose\n  );\n  const dbTimestamp = toDbTimestamp(targetData.snapshotVersion);\n  const dbLastLimboFreeTimestamp = toDbTimestamp(\n    targetData.lastLimboFreeSnapshotVersion\n  );\n  let queryProto: DbQuery;\n  if (isDocumentTarget(targetData.target)) {\n    queryProto = toDocumentsTarget(\n      localSerializer.remoteSerializer,\n      targetData.target\n    );\n  } else {\n    queryProto = toQueryTarget(\n      localSerializer.remoteSerializer,\n      targetData.target\n    );\n  }\n\n  // We can't store the resumeToken as a ByteString in IndexedDb, so we\n  // convert it to a base64 string for storage.\n  const resumeToken = targetData.resumeToken.toBase64();\n\n  // lastListenSequenceNumber is always 0 until we do real GC.\n  return new DbTarget(\n    targetData.targetId,\n    canonifyTarget(targetData.target),\n    dbTimestamp,\n    resumeToken,\n    targetData.sequenceNumber,\n    dbLastLimboFreeTimestamp,\n    queryProto\n  );\n}\n\n/**\n * A helper function for figuring out what kind of query has been stored.\n */\nfunction isDocumentQuery(dbQuery: DbQuery): dbQuery is api.DocumentsTarget {\n  return (dbQuery as api.DocumentsTarget).documents !== undefined;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Timestamp } from '../api/timestamp';\nimport { User } from '../auth/user';\nimport { isCollectionGroupQuery, isDocumentQuery, Query } from '../core/query';\nimport { BatchId } from '../core/types';\nimport { DocumentKeySet } from '../model/collections';\nimport { DocumentKey } from '../model/document_key';\nimport { Mutation } from '../model/mutation';\nimport { BATCHID_UNKNOWN, MutationBatch } from '../model/mutation_batch';\nimport { ResourcePath } from '../model/path';\nimport { debugAssert, fail, hardAssert } from '../util/assert';\nimport { primitiveComparator } from '../util/misc';\nimport { SortedMap } from '../util/sorted_map';\nimport { SortedSet } from '../util/sorted_set';\nimport { decodeResourcePath } from './encoded_resource_path';\nimport { IndexManager } from './index_manager';\nimport {\n  IndexedDbPersistence,\n  IndexedDbTransaction\n} from './indexeddb_persistence';\nimport {\n  DbDocumentMutation,\n  DbDocumentMutationKey,\n  DbMutationBatch,\n  DbMutationBatchKey,\n  DbMutationQueue,\n  DbMutationQueueKey\n} from './indexeddb_schema';\nimport {\n  fromDbMutationBatch,\n  LocalSerializer,\n  toDbMutationBatch\n} from './local_serializer';\nimport { MutationQueue } from './mutation_queue';\nimport { PersistenceTransaction, ReferenceDelegate } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { SimpleDbStore, SimpleDbTransaction } from './simple_db';\n\n/** A mutation queue for a specific user, backed by IndexedDB. */\nexport class IndexedDbMutationQueue implements MutationQueue {\n  /**\n   * Caches the document keys for pending mutation batches. If the mutation\n   * has been removed from IndexedDb, the cached value may continue to\n   * be used to retrieve the batch's document keys. To remove a cached value\n   * locally, `removeCachedMutationKeys()` should be invoked either directly\n   * or through `removeMutationBatches()`.\n   *\n   * With multi-tab, when the primary client acknowledges or rejects a mutation,\n   * this cache is used by secondary clients to invalidate the local\n   * view of the documents that were previously affected by the mutation.\n   */\n  // PORTING NOTE: Multi-tab only.\n  private documentKeysByBatchId = {} as { [batchId: number]: DocumentKeySet };\n\n  constructor(\n    /**\n     * The normalized userId (e.g. null UID => \"\" userId) used to store /\n     * retrieve mutations.\n     */\n    private userId: string,\n    private readonly serializer: LocalSerializer,\n    private readonly indexManager: IndexManager,\n    private readonly referenceDelegate: ReferenceDelegate\n  ) {}\n\n  /**\n   * Creates a new mutation queue for the given user.\n   * @param user The user for which to create a mutation queue.\n   * @param serializer The serializer to use when persisting to IndexedDb.\n   */\n  static forUser(\n    user: User,\n    serializer: LocalSerializer,\n    indexManager: IndexManager,\n    referenceDelegate: ReferenceDelegate\n  ): IndexedDbMutationQueue {\n    // TODO(mcg): Figure out what constraints there are on userIDs\n    // In particular, are there any reserved characters? are empty ids allowed?\n    // For the moment store these together in the same mutations table assuming\n    // that empty userIDs aren't allowed.\n    hardAssert(user.uid !== '', 'UserID must not be an empty string.');\n    const userId = user.isAuthenticated() ? user.uid! : '';\n    return new IndexedDbMutationQueue(\n      userId,\n      serializer,\n      indexManager,\n      referenceDelegate\n    );\n  }\n\n  checkEmpty(transaction: PersistenceTransaction): PersistencePromise<boolean> {\n    let empty = true;\n    const range = IDBKeyRange.bound(\n      [this.userId, Number.NEGATIVE_INFINITY],\n      [this.userId, Number.POSITIVE_INFINITY]\n    );\n    return mutationsStore(transaction)\n      .iterate(\n        { index: DbMutationBatch.userMutationsIndex, range },\n        (key, value, control) => {\n          empty = false;\n          control.done();\n        }\n      )\n      .next(() => empty);\n  }\n\n  addMutationBatch(\n    transaction: PersistenceTransaction,\n    localWriteTime: Timestamp,\n    baseMutations: Mutation[],\n    mutations: Mutation[]\n  ): PersistencePromise<MutationBatch> {\n    const documentStore = documentMutationsStore(transaction);\n    const mutationStore = mutationsStore(transaction);\n\n    // The IndexedDb implementation in Chrome (and Firefox) does not handle\n    // compound indices that include auto-generated keys correctly. To ensure\n    // that the index entry is added correctly in all browsers, we perform two\n    // writes: The first write is used to retrieve the next auto-generated Batch\n    // ID, and the second write populates the index and stores the actual\n    // mutation batch.\n    // See: https://bugs.chromium.org/p/chromium/issues/detail?id=701972\n\n    // We write an empty object to obtain key\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return mutationStore.add({} as any).next(batchId => {\n      hardAssert(\n        typeof batchId === 'number',\n        'Auto-generated key is not a number'\n      );\n\n      const batch = new MutationBatch(\n        batchId,\n        localWriteTime,\n        baseMutations,\n        mutations\n      );\n      const dbBatch = toDbMutationBatch(this.serializer, this.userId, batch);\n\n      const promises: Array<PersistencePromise<void>> = [];\n      let collectionParents = new SortedSet<ResourcePath>((l, r) =>\n        primitiveComparator(l.canonicalString(), r.canonicalString())\n      );\n      for (const mutation of mutations) {\n        const indexKey = DbDocumentMutation.key(\n          this.userId,\n          mutation.key.path,\n          batchId\n        );\n        collectionParents = collectionParents.add(mutation.key.path.popLast());\n        promises.push(mutationStore.put(dbBatch));\n        promises.push(\n          documentStore.put(indexKey, DbDocumentMutation.PLACEHOLDER)\n        );\n      }\n\n      collectionParents.forEach(parent => {\n        promises.push(\n          this.indexManager.addToCollectionParentIndex(transaction, parent)\n        );\n      });\n\n      transaction.addOnCommittedListener(() => {\n        this.documentKeysByBatchId[batchId] = batch.keys();\n      });\n\n      return PersistencePromise.waitFor(promises).next(() => batch);\n    });\n  }\n\n  lookupMutationBatch(\n    transaction: PersistenceTransaction,\n    batchId: BatchId\n  ): PersistencePromise<MutationBatch | null> {\n    return mutationsStore(transaction)\n      .get(batchId)\n      .next(dbBatch => {\n        if (dbBatch) {\n          hardAssert(\n            dbBatch.userId === this.userId,\n            `Unexpected user '${dbBatch.userId}' for mutation batch ${batchId}`\n          );\n          return fromDbMutationBatch(this.serializer, dbBatch);\n        }\n        return null;\n      });\n  }\n\n  /**\n   * Returns the document keys for the mutation batch with the given batchId.\n   * For primary clients, this method returns `null` after\n   * `removeMutationBatches()` has been called. Secondary clients return a\n   * cached result until `removeCachedMutationKeys()` is invoked.\n   */\n  // PORTING NOTE: Multi-tab only.\n  lookupMutationKeys(\n    transaction: PersistenceTransaction,\n    batchId: BatchId\n  ): PersistencePromise<DocumentKeySet | null> {\n    if (this.documentKeysByBatchId[batchId]) {\n      return PersistencePromise.resolve<DocumentKeySet | null>(\n        this.documentKeysByBatchId[batchId]\n      );\n    } else {\n      return this.lookupMutationBatch(transaction, batchId).next(batch => {\n        if (batch) {\n          const keys = batch.keys();\n          this.documentKeysByBatchId[batchId] = keys;\n          return keys;\n        } else {\n          return null;\n        }\n      });\n    }\n  }\n\n  getNextMutationBatchAfterBatchId(\n    transaction: PersistenceTransaction,\n    batchId: BatchId\n  ): PersistencePromise<MutationBatch | null> {\n    const nextBatchId = batchId + 1;\n\n    const range = IDBKeyRange.lowerBound([this.userId, nextBatchId]);\n    let foundBatch: MutationBatch | null = null;\n    return mutationsStore(transaction)\n      .iterate(\n        { index: DbMutationBatch.userMutationsIndex, range },\n        (key, dbBatch, control) => {\n          if (dbBatch.userId === this.userId) {\n            hardAssert(\n              dbBatch.batchId >= nextBatchId,\n              'Should have found mutation after ' + nextBatchId\n            );\n            foundBatch = fromDbMutationBatch(this.serializer, dbBatch);\n          }\n          control.done();\n        }\n      )\n      .next(() => foundBatch);\n  }\n\n  getHighestUnacknowledgedBatchId(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<BatchId> {\n    const range = IDBKeyRange.upperBound([\n      this.userId,\n      Number.POSITIVE_INFINITY\n    ]);\n\n    let batchId = BATCHID_UNKNOWN;\n    return mutationsStore(transaction)\n      .iterate(\n        { index: DbMutationBatch.userMutationsIndex, range, reverse: true },\n        (key, dbBatch, control) => {\n          batchId = dbBatch.batchId;\n          control.done();\n        }\n      )\n      .next(() => batchId);\n  }\n\n  getAllMutationBatches(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<MutationBatch[]> {\n    const range = IDBKeyRange.bound(\n      [this.userId, BATCHID_UNKNOWN],\n      [this.userId, Number.POSITIVE_INFINITY]\n    );\n    return mutationsStore(transaction)\n      .loadAll(DbMutationBatch.userMutationsIndex, range)\n      .next(dbBatches =>\n        dbBatches.map(dbBatch => fromDbMutationBatch(this.serializer, dbBatch))\n      );\n  }\n\n  getAllMutationBatchesAffectingDocumentKey(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<MutationBatch[]> {\n    // Scan the document-mutation index starting with a prefix starting with\n    // the given documentKey.\n    const indexPrefix = DbDocumentMutation.prefixForPath(\n      this.userId,\n      documentKey.path\n    );\n    const indexStart = IDBKeyRange.lowerBound(indexPrefix);\n\n    const results: MutationBatch[] = [];\n    return documentMutationsStore(transaction)\n      .iterate({ range: indexStart }, (indexKey, _, control) => {\n        const [userID, encodedPath, batchId] = indexKey;\n\n        // Only consider rows matching exactly the specific key of\n        // interest. Note that because we order by path first, and we\n        // order terminators before path separators, we'll encounter all\n        // the index rows for documentKey contiguously. In particular, all\n        // the rows for documentKey will occur before any rows for\n        // documents nested in a subcollection beneath documentKey so we\n        // can stop as soon as we hit any such row.\n        const path = decodeResourcePath(encodedPath);\n        if (userID !== this.userId || !documentKey.path.isEqual(path)) {\n          control.done();\n          return;\n        }\n        // Look up the mutation batch in the store.\n        return mutationsStore(transaction)\n          .get(batchId)\n          .next(mutation => {\n            if (!mutation) {\n              throw fail(\n                'Dangling document-mutation reference found: ' +\n                  indexKey +\n                  ' which points to ' +\n                  batchId\n              );\n            }\n            hardAssert(\n              mutation.userId === this.userId,\n              `Unexpected user '${mutation.userId}' for mutation batch ${batchId}`\n            );\n            results.push(fromDbMutationBatch(this.serializer, mutation));\n          });\n      })\n      .next(() => results);\n  }\n\n  getAllMutationBatchesAffectingDocumentKeys(\n    transaction: PersistenceTransaction,\n    documentKeys: SortedMap<DocumentKey, unknown>\n  ): PersistencePromise<MutationBatch[]> {\n    let uniqueBatchIDs = new SortedSet<BatchId>(primitiveComparator);\n\n    const promises: Array<PersistencePromise<void>> = [];\n    documentKeys.forEach(documentKey => {\n      const indexStart = DbDocumentMutation.prefixForPath(\n        this.userId,\n        documentKey.path\n      );\n      const range = IDBKeyRange.lowerBound(indexStart);\n\n      const promise = documentMutationsStore(transaction).iterate(\n        { range },\n        (indexKey, _, control) => {\n          const [userID, encodedPath, batchID] = indexKey;\n\n          // Only consider rows matching exactly the specific key of\n          // interest. Note that because we order by path first, and we\n          // order terminators before path separators, we'll encounter all\n          // the index rows for documentKey contiguously. In particular, all\n          // the rows for documentKey will occur before any rows for\n          // documents nested in a subcollection beneath documentKey so we\n          // can stop as soon as we hit any such row.\n          const path = decodeResourcePath(encodedPath);\n          if (userID !== this.userId || !documentKey.path.isEqual(path)) {\n            control.done();\n            return;\n          }\n\n          uniqueBatchIDs = uniqueBatchIDs.add(batchID);\n        }\n      );\n\n      promises.push(promise);\n    });\n\n    return PersistencePromise.waitFor(promises).next(() =>\n      this.lookupMutationBatches(transaction, uniqueBatchIDs)\n    );\n  }\n\n  getAllMutationBatchesAffectingQuery(\n    transaction: PersistenceTransaction,\n    query: Query\n  ): PersistencePromise<MutationBatch[]> {\n    debugAssert(\n      !isDocumentQuery(query),\n      \"Document queries shouldn't go down this path\"\n    );\n    debugAssert(\n      !isCollectionGroupQuery(query),\n      'CollectionGroup queries should be handled in LocalDocumentsView'\n    );\n\n    const queryPath = query.path;\n    const immediateChildrenLength = queryPath.length + 1;\n\n    // TODO(mcg): Actually implement a single-collection query\n    //\n    // This is actually executing an ancestor query, traversing the whole\n    // subtree below the collection which can be horrifically inefficient for\n    // some structures. The right way to solve this is to implement the full\n    // value index, but that's not in the cards in the near future so this is\n    // the best we can do for the moment.\n    //\n    // Since we don't yet index the actual properties in the mutations, our\n    // current approach is to just return all mutation batches that affect\n    // documents in the collection being queried.\n    const indexPrefix = DbDocumentMutation.prefixForPath(\n      this.userId,\n      queryPath\n    );\n    const indexStart = IDBKeyRange.lowerBound(indexPrefix);\n\n    // Collect up unique batchIDs encountered during a scan of the index. Use a\n    // SortedSet to accumulate batch IDs so they can be traversed in order in a\n    // scan of the main table.\n    let uniqueBatchIDs = new SortedSet<BatchId>(primitiveComparator);\n    return documentMutationsStore(transaction)\n      .iterate({ range: indexStart }, (indexKey, _, control) => {\n        const [userID, encodedPath, batchID] = indexKey;\n        const path = decodeResourcePath(encodedPath);\n        if (userID !== this.userId || !queryPath.isPrefixOf(path)) {\n          control.done();\n          return;\n        }\n        // Rows with document keys more than one segment longer than the\n        // query path can't be matches. For example, a query on 'rooms'\n        // can't match the document /rooms/abc/messages/xyx.\n        // TODO(mcg): we'll need a different scanner when we implement\n        // ancestor queries.\n        if (path.length !== immediateChildrenLength) {\n          return;\n        }\n        uniqueBatchIDs = uniqueBatchIDs.add(batchID);\n      })\n      .next(() => this.lookupMutationBatches(transaction, uniqueBatchIDs));\n  }\n\n  private lookupMutationBatches(\n    transaction: PersistenceTransaction,\n    batchIDs: SortedSet<BatchId>\n  ): PersistencePromise<MutationBatch[]> {\n    const results: MutationBatch[] = [];\n    const promises: Array<PersistencePromise<void>> = [];\n    // TODO(rockwood): Implement this using iterate.\n    batchIDs.forEach(batchId => {\n      promises.push(\n        mutationsStore(transaction)\n          .get(batchId)\n          .next(mutation => {\n            if (mutation === null) {\n              throw fail(\n                'Dangling document-mutation reference found, ' +\n                  'which points to ' +\n                  batchId\n              );\n            }\n            hardAssert(\n              mutation.userId === this.userId,\n              `Unexpected user '${mutation.userId}' for mutation batch ${batchId}`\n            );\n            results.push(fromDbMutationBatch(this.serializer, mutation));\n          })\n      );\n    });\n    return PersistencePromise.waitFor(promises).next(() => results);\n  }\n\n  removeMutationBatch(\n    transaction: PersistenceTransaction,\n    batch: MutationBatch\n  ): PersistencePromise<void> {\n    return removeMutationBatch(\n      (transaction as IndexedDbTransaction).simpleDbTransaction,\n      this.userId,\n      batch\n    ).next(removedDocuments => {\n      transaction.addOnCommittedListener(() => {\n        this.removeCachedMutationKeys(batch.batchId);\n      });\n      return PersistencePromise.forEach(\n        removedDocuments,\n        (key: DocumentKey) => {\n          return this.referenceDelegate.markPotentiallyOrphaned(\n            transaction,\n            key\n          );\n        }\n      );\n    });\n  }\n\n  /**\n   * Clears the cached keys for a mutation batch. This method should be\n   * called by secondary clients after they process mutation updates.\n   *\n   * Note that this method does not have to be called from primary clients as\n   * the corresponding cache entries are cleared when an acknowledged or\n   * rejected batch is removed from the mutation queue.\n   */\n  // PORTING NOTE: Multi-tab only\n  removeCachedMutationKeys(batchId: BatchId): void {\n    delete this.documentKeysByBatchId[batchId];\n  }\n\n  performConsistencyCheck(\n    txn: PersistenceTransaction\n  ): PersistencePromise<void> {\n    return this.checkEmpty(txn).next(empty => {\n      if (!empty) {\n        return PersistencePromise.resolve();\n      }\n\n      // Verify that there are no entries in the documentMutations index if\n      // the queue is empty.\n      const startRange = IDBKeyRange.lowerBound(\n        DbDocumentMutation.prefixForUser(this.userId)\n      );\n      const danglingMutationReferences: ResourcePath[] = [];\n      return documentMutationsStore(txn)\n        .iterate({ range: startRange }, (key, _, control) => {\n          const userID = key[0];\n          if (userID !== this.userId) {\n            control.done();\n            return;\n          } else {\n            const path = decodeResourcePath(key[1]);\n            danglingMutationReferences.push(path);\n          }\n        })\n        .next(() => {\n          hardAssert(\n            danglingMutationReferences.length === 0,\n            'Document leak -- detected dangling mutation references when queue is empty. ' +\n              'Dangling keys: ' +\n              danglingMutationReferences.map(p => p.canonicalString())\n          );\n        });\n    });\n  }\n\n  containsKey(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<boolean> {\n    return mutationQueueContainsKey(txn, this.userId, key);\n  }\n\n  // PORTING NOTE: Multi-tab only (state is held in memory in other clients).\n  /** Returns the mutation queue's metadata from IndexedDb. */\n  private getMutationQueueMetadata(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<DbMutationQueue> {\n    return mutationQueuesStore(transaction)\n      .get(this.userId)\n      .next((metadata: DbMutationQueue | null) => {\n        return (\n          metadata ||\n          new DbMutationQueue(\n            this.userId,\n            BATCHID_UNKNOWN,\n            /*lastStreamToken=*/ ''\n          )\n        );\n      });\n  }\n}\n\n/**\n * @return true if the mutation queue for the given user contains a pending\n *         mutation for the given key.\n */\nfunction mutationQueueContainsKey(\n  txn: PersistenceTransaction,\n  userId: string,\n  key: DocumentKey\n): PersistencePromise<boolean> {\n  const indexKey = DbDocumentMutation.prefixForPath(userId, key.path);\n  const encodedPath = indexKey[1];\n  const startRange = IDBKeyRange.lowerBound(indexKey);\n  let containsKey = false;\n  return documentMutationsStore(txn)\n    .iterate({ range: startRange, keysOnly: true }, (key, value, control) => {\n      const [userID, keyPath, /*batchID*/ _] = key;\n      if (userID === userId && keyPath === encodedPath) {\n        containsKey = true;\n      }\n      control.done();\n    })\n    .next(() => containsKey);\n}\n\n/** Returns true if any mutation queue contains the given document. */\nexport function mutationQueuesContainKey(\n  txn: PersistenceTransaction,\n  docKey: DocumentKey\n): PersistencePromise<boolean> {\n  let found = false;\n  return mutationQueuesStore(txn)\n    .iterateSerial(userId => {\n      return mutationQueueContainsKey(txn, userId, docKey).next(containsKey => {\n        if (containsKey) {\n          found = true;\n        }\n        return PersistencePromise.resolve(!containsKey);\n      });\n    })\n    .next(() => found);\n}\n\n/**\n * Delete a mutation batch and the associated document mutations.\n * @return A PersistencePromise of the document mutations that were removed.\n */\nexport function removeMutationBatch(\n  txn: SimpleDbTransaction,\n  userId: string,\n  batch: MutationBatch\n): PersistencePromise<DocumentKey[]> {\n  const mutationStore = txn.store<DbMutationBatchKey, DbMutationBatch>(\n    DbMutationBatch.store\n  );\n  const indexTxn = txn.store<DbDocumentMutationKey, DbDocumentMutation>(\n    DbDocumentMutation.store\n  );\n  const promises: Array<PersistencePromise<void>> = [];\n\n  const range = IDBKeyRange.only(batch.batchId);\n  let numDeleted = 0;\n  const removePromise = mutationStore.iterate(\n    { range },\n    (key, value, control) => {\n      numDeleted++;\n      return control.delete();\n    }\n  );\n  promises.push(\n    removePromise.next(() => {\n      hardAssert(\n        numDeleted === 1,\n        'Dangling document-mutation reference found: Missing batch ' +\n          batch.batchId\n      );\n    })\n  );\n  const removedDocuments: DocumentKey[] = [];\n  for (const mutation of batch.mutations) {\n    const indexKey = DbDocumentMutation.key(\n      userId,\n      mutation.key.path,\n      batch.batchId\n    );\n    promises.push(indexTxn.delete(indexKey));\n    removedDocuments.push(mutation.key);\n  }\n  return PersistencePromise.waitFor(promises).next(() => removedDocuments);\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the mutations object store.\n */\nfunction mutationsStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbMutationBatchKey, DbMutationBatch> {\n  return IndexedDbPersistence.getStore<DbMutationBatchKey, DbMutationBatch>(\n    txn,\n    DbMutationBatch.store\n  );\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the mutationQueues object store.\n */\nfunction documentMutationsStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbDocumentMutationKey, DbDocumentMutation> {\n  return IndexedDbPersistence.getStore<\n    DbDocumentMutationKey,\n    DbDocumentMutation\n  >(txn, DbDocumentMutation.store);\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the mutationQueues object store.\n */\nfunction mutationQueuesStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbMutationQueueKey, DbMutationQueue> {\n  return IndexedDbPersistence.getStore<DbMutationQueueKey, DbMutationQueue>(\n    txn,\n    DbMutationQueue.store\n  );\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { isCollectionGroupQuery, Query, queryMatches } from '../core/query';\nimport {\n  DocumentKeySet,\n  DocumentMap,\n  documentMap,\n  DocumentSizeEntries,\n  DocumentSizeEntry,\n  MaybeDocumentMap,\n  maybeDocumentMap,\n  nullableMaybeDocumentMap,\n  NullableMaybeDocumentMap\n} from '../model/collections';\nimport { Document, MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { ResourcePath } from '../model/path';\nimport { primitiveComparator } from '../util/misc';\nimport { SortedMap } from '../util/sorted_map';\nimport { SortedSet } from '../util/sorted_set';\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { debugAssert, fail, hardAssert } from '../util/assert';\nimport { IndexManager } from './index_manager';\nimport { IndexedDbPersistence } from './indexeddb_persistence';\nimport {\n  DbRemoteDocument,\n  DbRemoteDocumentGlobal,\n  DbRemoteDocumentGlobalKey,\n  DbRemoteDocumentKey\n} from './indexeddb_schema';\nimport {\n  fromDbRemoteDocument,\n  fromDbTimestampKey,\n  LocalSerializer,\n  toDbRemoteDocument,\n  toDbTimestampKey\n} from './local_serializer';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { RemoteDocumentCache } from './remote_document_cache';\nimport { RemoteDocumentChangeBuffer } from './remote_document_change_buffer';\nimport { IterateOptions, SimpleDbStore } from './simple_db';\nimport { ObjectMap } from '../util/obj_map';\n\nexport class IndexedDbRemoteDocumentCache implements RemoteDocumentCache {\n  /**\n   * @param {LocalSerializer} serializer The document serializer.\n   * @param {IndexManager} indexManager The query indexes that need to be maintained.\n   */\n  constructor(\n    readonly serializer: LocalSerializer,\n    private readonly indexManager: IndexManager\n  ) {}\n\n  /**\n   * Adds the supplied entries to the cache.\n   *\n   * All calls of `addEntry` are required to go through the RemoteDocumentChangeBuffer\n   * returned by `newChangeBuffer()` to ensure proper accounting of metadata.\n   */\n  private addEntry(\n    transaction: PersistenceTransaction,\n    key: DocumentKey,\n    doc: DbRemoteDocument\n  ): PersistencePromise<void> {\n    const documentStore = remoteDocumentsStore(transaction);\n    return documentStore.put(dbKey(key), doc);\n  }\n\n  /**\n   * Removes a document from the cache.\n   *\n   * All calls of `removeEntry`  are required to go through the RemoteDocumentChangeBuffer\n   * returned by `newChangeBuffer()` to ensure proper accounting of metadata.\n   */\n  private removeEntry(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<void> {\n    const store = remoteDocumentsStore(transaction);\n    const key = dbKey(documentKey);\n    return store.delete(key);\n  }\n\n  /**\n   * Updates the current cache size.\n   *\n   * Callers to `addEntry()` and `removeEntry()` *must* call this afterwards to update the\n   * cache's metadata.\n   */\n  private updateMetadata(\n    transaction: PersistenceTransaction,\n    sizeDelta: number\n  ): PersistencePromise<void> {\n    return this.getMetadata(transaction).next(metadata => {\n      metadata.byteSize += sizeDelta;\n      return this.setMetadata(transaction, metadata);\n    });\n  }\n\n  getEntry(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<MaybeDocument | null> {\n    return remoteDocumentsStore(transaction)\n      .get(dbKey(documentKey))\n      .next(dbRemoteDoc => {\n        return this.maybeDecodeDocument(dbRemoteDoc);\n      });\n  }\n\n  /**\n   * Looks up an entry in the cache.\n   *\n   * @param documentKey The key of the entry to look up.\n   * @return The cached MaybeDocument entry and its size, or null if we have nothing cached.\n   */\n  getSizedEntry(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<DocumentSizeEntry | null> {\n    return remoteDocumentsStore(transaction)\n      .get(dbKey(documentKey))\n      .next(dbRemoteDoc => {\n        const doc = this.maybeDecodeDocument(dbRemoteDoc);\n        return doc\n          ? {\n              maybeDocument: doc,\n              size: dbDocumentSize(dbRemoteDoc!)\n            }\n          : null;\n      });\n  }\n\n  getEntries(\n    transaction: PersistenceTransaction,\n    documentKeys: DocumentKeySet\n  ): PersistencePromise<NullableMaybeDocumentMap> {\n    let results = nullableMaybeDocumentMap();\n    return this.forEachDbEntry(\n      transaction,\n      documentKeys,\n      (key, dbRemoteDoc) => {\n        const doc = this.maybeDecodeDocument(dbRemoteDoc);\n        results = results.insert(key, doc);\n      }\n    ).next(() => results);\n  }\n\n  /**\n   * Looks up several entries in the cache.\n   *\n   * @param documentKeys The set of keys entries to look up.\n   * @return A map of MaybeDocuments indexed by key (if a document cannot be\n   *     found, the key will be mapped to null) and a map of sizes indexed by\n   *     key (zero if the key cannot be found).\n   */\n  getSizedEntries(\n    transaction: PersistenceTransaction,\n    documentKeys: DocumentKeySet\n  ): PersistencePromise<DocumentSizeEntries> {\n    let results = nullableMaybeDocumentMap();\n    let sizeMap = new SortedMap<DocumentKey, number>(DocumentKey.comparator);\n    return this.forEachDbEntry(\n      transaction,\n      documentKeys,\n      (key, dbRemoteDoc) => {\n        const doc = this.maybeDecodeDocument(dbRemoteDoc);\n        if (doc) {\n          results = results.insert(key, doc);\n          sizeMap = sizeMap.insert(key, dbDocumentSize(dbRemoteDoc!));\n        } else {\n          results = results.insert(key, null);\n          sizeMap = sizeMap.insert(key, 0);\n        }\n      }\n    ).next(() => {\n      return { maybeDocuments: results, sizeMap };\n    });\n  }\n\n  private forEachDbEntry(\n    transaction: PersistenceTransaction,\n    documentKeys: DocumentKeySet,\n    callback: (key: DocumentKey, doc: DbRemoteDocument | null) => void\n  ): PersistencePromise<void> {\n    if (documentKeys.isEmpty()) {\n      return PersistencePromise.resolve();\n    }\n\n    const range = IDBKeyRange.bound(\n      documentKeys.first()!.path.toArray(),\n      documentKeys.last()!.path.toArray()\n    );\n    const keyIter = documentKeys.getIterator();\n    let nextKey: DocumentKey | null = keyIter.getNext();\n\n    return remoteDocumentsStore(transaction)\n      .iterate({ range }, (potentialKeyRaw, dbRemoteDoc, control) => {\n        const potentialKey = DocumentKey.fromSegments(potentialKeyRaw);\n\n        // Go through keys not found in cache.\n        while (nextKey && DocumentKey.comparator(nextKey!, potentialKey) < 0) {\n          callback(nextKey!, null);\n          nextKey = keyIter.getNext();\n        }\n\n        if (nextKey && nextKey!.isEqual(potentialKey)) {\n          // Key found in cache.\n          callback(nextKey!, dbRemoteDoc);\n          nextKey = keyIter.hasNext() ? keyIter.getNext() : null;\n        }\n\n        // Skip to the next key (if there is one).\n        if (nextKey) {\n          control.skip(nextKey!.path.toArray());\n        } else {\n          control.done();\n        }\n      })\n      .next(() => {\n        // The rest of the keys are not in the cache. One case where `iterate`\n        // above won't go through them is when the cache is empty.\n        while (nextKey) {\n          callback(nextKey!, null);\n          nextKey = keyIter.hasNext() ? keyIter.getNext() : null;\n        }\n      });\n  }\n\n  getDocumentsMatchingQuery(\n    transaction: PersistenceTransaction,\n    query: Query,\n    sinceReadTime: SnapshotVersion\n  ): PersistencePromise<DocumentMap> {\n    debugAssert(\n      !isCollectionGroupQuery(query),\n      'CollectionGroup queries should be handled in LocalDocumentsView'\n    );\n    let results = documentMap();\n\n    const immediateChildrenPathLength = query.path.length + 1;\n\n    const iterationOptions: IterateOptions = {};\n    if (sinceReadTime.isEqual(SnapshotVersion.min())) {\n      // Documents are ordered by key, so we can use a prefix scan to narrow\n      // down the documents we need to match the query against.\n      const startKey = query.path.toArray();\n      iterationOptions.range = IDBKeyRange.lowerBound(startKey);\n    } else {\n      // Execute an index-free query and filter by read time. This is safe\n      // since all document changes to queries that have a\n      // lastLimboFreeSnapshotVersion (`sinceReadTime`) have a read time set.\n      const collectionKey = query.path.toArray();\n      const readTimeKey = toDbTimestampKey(sinceReadTime);\n      iterationOptions.range = IDBKeyRange.lowerBound(\n        [collectionKey, readTimeKey],\n        /* open= */ true\n      );\n      iterationOptions.index = DbRemoteDocument.collectionReadTimeIndex;\n    }\n\n    return remoteDocumentsStore(transaction)\n      .iterate(iterationOptions, (key, dbRemoteDoc, control) => {\n        // The query is actually returning any path that starts with the query\n        // path prefix which may include documents in subcollections. For\n        // example, a query on 'rooms' will return rooms/abc/messages/xyx but we\n        // shouldn't match it. Fix this by discarding rows with document keys\n        // more than one segment longer than the query path.\n        if (key.length !== immediateChildrenPathLength) {\n          return;\n        }\n\n        const maybeDoc = fromDbRemoteDocument(this.serializer, dbRemoteDoc);\n        if (!query.path.isPrefixOf(maybeDoc.key.path)) {\n          control.done();\n        } else if (\n          maybeDoc instanceof Document &&\n          queryMatches(query, maybeDoc)\n        ) {\n          results = results.insert(maybeDoc.key, maybeDoc);\n        }\n      })\n      .next(() => results);\n  }\n\n  /**\n   * Returns the set of documents that have changed since the specified read\n   * time.\n   */\n  // PORTING NOTE: This is only used for multi-tab synchronization.\n  getNewDocumentChanges(\n    transaction: PersistenceTransaction,\n    sinceReadTime: SnapshotVersion\n  ): PersistencePromise<{\n    changedDocs: MaybeDocumentMap;\n    readTime: SnapshotVersion;\n  }> {\n    let changedDocs = maybeDocumentMap();\n\n    let lastReadTime = toDbTimestampKey(sinceReadTime);\n\n    const documentsStore = remoteDocumentsStore(transaction);\n    const range = IDBKeyRange.lowerBound(lastReadTime, true);\n    return documentsStore\n      .iterate(\n        { index: DbRemoteDocument.readTimeIndex, range },\n        (_, dbRemoteDoc) => {\n          // Unlike `getEntry()` and others, `getNewDocumentChanges()` parses\n          // the documents directly since we want to keep sentinel deletes.\n          const doc = fromDbRemoteDocument(this.serializer, dbRemoteDoc);\n          changedDocs = changedDocs.insert(doc.key, doc);\n          lastReadTime = dbRemoteDoc.readTime!;\n        }\n      )\n      .next(() => {\n        return {\n          changedDocs,\n          readTime: fromDbTimestampKey(lastReadTime)\n        };\n      });\n  }\n\n  /**\n   * Returns the read time of the most recently read document in the cache, or\n   * SnapshotVersion.min() if not available.\n   */\n  // PORTING NOTE: This is only used for multi-tab synchronization.\n  getLastReadTime(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<SnapshotVersion> {\n    const documentsStore = remoteDocumentsStore(transaction);\n\n    // If there are no existing entries, we return SnapshotVersion.min().\n    let readTime = SnapshotVersion.min();\n\n    return documentsStore\n      .iterate(\n        { index: DbRemoteDocument.readTimeIndex, reverse: true },\n        (key, dbRemoteDoc, control) => {\n          if (dbRemoteDoc.readTime) {\n            readTime = fromDbTimestampKey(dbRemoteDoc.readTime);\n          }\n          control.done();\n        }\n      )\n      .next(() => readTime);\n  }\n\n  newChangeBuffer(options?: {\n    trackRemovals: boolean;\n  }): RemoteDocumentChangeBuffer {\n    return new IndexedDbRemoteDocumentCache.RemoteDocumentChangeBuffer(\n      this,\n      !!options && options.trackRemovals\n    );\n  }\n\n  getSize(txn: PersistenceTransaction): PersistencePromise<number> {\n    return this.getMetadata(txn).next(metadata => metadata.byteSize);\n  }\n\n  private getMetadata(\n    txn: PersistenceTransaction\n  ): PersistencePromise<DbRemoteDocumentGlobal> {\n    return documentGlobalStore(txn)\n      .get(DbRemoteDocumentGlobal.key)\n      .next(metadata => {\n        hardAssert(!!metadata, 'Missing document cache metadata');\n        return metadata!;\n      });\n  }\n\n  private setMetadata(\n    txn: PersistenceTransaction,\n    metadata: DbRemoteDocumentGlobal\n  ): PersistencePromise<void> {\n    return documentGlobalStore(txn).put(DbRemoteDocumentGlobal.key, metadata);\n  }\n\n  /**\n   * Decodes `remoteDoc` and returns the document (or null, if the document\n   * corresponds to the format used for sentinel deletes).\n   */\n  private maybeDecodeDocument(\n    dbRemoteDoc: DbRemoteDocument | null\n  ): MaybeDocument | null {\n    if (dbRemoteDoc) {\n      const doc = fromDbRemoteDocument(this.serializer, dbRemoteDoc);\n      if (\n        doc instanceof NoDocument &&\n        doc.version.isEqual(SnapshotVersion.min())\n      ) {\n        // The document is a sentinel removal and should only be used in the\n        // `getNewDocumentChanges()`.\n        return null;\n      }\n\n      return doc;\n    }\n    return null;\n  }\n\n  /**\n   * Handles the details of adding and updating documents in the IndexedDbRemoteDocumentCache.\n   *\n   * Unlike the MemoryRemoteDocumentChangeBuffer, the IndexedDb implementation computes the size\n   * delta for all submitted changes. This avoids having to re-read all documents from IndexedDb\n   * when we apply the changes.\n   */\n  private static RemoteDocumentChangeBuffer = class extends RemoteDocumentChangeBuffer {\n    // A map of document sizes prior to applying the changes in this buffer.\n    protected documentSizes: ObjectMap<DocumentKey, number> = new ObjectMap(\n      key => key.toString(),\n      (l, r) => l.isEqual(r)\n    );\n\n    /**\n     * @param documentCache The IndexedDbRemoteDocumentCache to apply the changes to.\n     * @param trackRemovals Whether to create sentinel deletes that can be tracked by\n     * `getNewDocumentChanges()`.\n     */\n    constructor(\n      private readonly documentCache: IndexedDbRemoteDocumentCache,\n      private readonly trackRemovals: boolean\n    ) {\n      super();\n    }\n\n    protected applyChanges(\n      transaction: PersistenceTransaction\n    ): PersistencePromise<void> {\n      const promises: Array<PersistencePromise<void>> = [];\n\n      let sizeDelta = 0;\n\n      let collectionParents = new SortedSet<ResourcePath>((l, r) =>\n        primitiveComparator(l.canonicalString(), r.canonicalString())\n      );\n\n      this.changes.forEach((key, maybeDocument) => {\n        const previousSize = this.documentSizes.get(key);\n        debugAssert(\n          previousSize !== undefined,\n          `Cannot modify a document that wasn't read (for ${key})`\n        );\n        if (maybeDocument) {\n          debugAssert(\n            !this.readTime.isEqual(SnapshotVersion.min()),\n            'Cannot add a document with a read time of zero'\n          );\n          const doc = toDbRemoteDocument(\n            this.documentCache.serializer,\n            maybeDocument,\n            this.readTime\n          );\n          collectionParents = collectionParents.add(key.path.popLast());\n\n          const size = dbDocumentSize(doc);\n          sizeDelta += size - previousSize!;\n          promises.push(this.documentCache.addEntry(transaction, key, doc));\n        } else {\n          sizeDelta -= previousSize!;\n          if (this.trackRemovals) {\n            // In order to track removals, we store a \"sentinel delete\" in the\n            // RemoteDocumentCache. This entry is represented by a NoDocument\n            // with a version of 0 and ignored by `maybeDecodeDocument()` but\n            // preserved in `getNewDocumentChanges()`.\n            const deletedDoc = toDbRemoteDocument(\n              this.documentCache.serializer,\n              new NoDocument(key, SnapshotVersion.min()),\n              this.readTime\n            );\n            promises.push(\n              this.documentCache.addEntry(transaction, key, deletedDoc)\n            );\n          } else {\n            promises.push(this.documentCache.removeEntry(transaction, key));\n          }\n        }\n      });\n\n      collectionParents.forEach(parent => {\n        promises.push(\n          this.documentCache.indexManager.addToCollectionParentIndex(\n            transaction,\n            parent\n          )\n        );\n      });\n\n      promises.push(this.documentCache.updateMetadata(transaction, sizeDelta));\n\n      return PersistencePromise.waitFor(promises);\n    }\n\n    protected getFromCache(\n      transaction: PersistenceTransaction,\n      documentKey: DocumentKey\n    ): PersistencePromise<MaybeDocument | null> {\n      // Record the size of everything we load from the cache so we can compute a delta later.\n      return this.documentCache\n        .getSizedEntry(transaction, documentKey)\n        .next(getResult => {\n          if (getResult === null) {\n            this.documentSizes.set(documentKey, 0);\n            return null;\n          } else {\n            this.documentSizes.set(documentKey, getResult.size);\n            return getResult.maybeDocument;\n          }\n        });\n    }\n\n    protected getAllFromCache(\n      transaction: PersistenceTransaction,\n      documentKeys: DocumentKeySet\n    ): PersistencePromise<NullableMaybeDocumentMap> {\n      // Record the size of everything we load from the cache so we can compute\n      // a delta later.\n      return this.documentCache\n        .getSizedEntries(transaction, documentKeys)\n        .next(({ maybeDocuments, sizeMap }) => {\n          // Note: `getAllFromCache` returns two maps instead of a single map from\n          // keys to `DocumentSizeEntry`s. This is to allow returning the\n          // `NullableMaybeDocumentMap` directly, without a conversion.\n          sizeMap.forEach((documentKey, size) => {\n            this.documentSizes.set(documentKey, size);\n          });\n          return maybeDocuments;\n        });\n    }\n  };\n}\n\nfunction documentGlobalStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbRemoteDocumentGlobalKey, DbRemoteDocumentGlobal> {\n  return IndexedDbPersistence.getStore<\n    DbRemoteDocumentGlobalKey,\n    DbRemoteDocumentGlobal\n  >(txn, DbRemoteDocumentGlobal.store);\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the remoteDocuments object store.\n */\nfunction remoteDocumentsStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbRemoteDocumentKey, DbRemoteDocument> {\n  return IndexedDbPersistence.getStore<DbRemoteDocumentKey, DbRemoteDocument>(\n    txn,\n    DbRemoteDocument.store\n  );\n}\n\nfunction dbKey(docKey: DocumentKey): DbRemoteDocumentKey {\n  return docKey.path.toArray();\n}\n\n/**\n * Retrusn an approximate size for the given document.\n */\nexport function dbDocumentSize(doc: DbRemoteDocument): number {\n  let value: unknown;\n  if (doc.document) {\n    value = doc.document;\n  } else if (doc.unknownDocument) {\n    value = doc.unknownDocument;\n  } else if (doc.noDocument) {\n    value = doc.noDocument;\n  } else {\n    throw fail('Unknown remote document type');\n  }\n  return JSON.stringify(value).length;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ResourcePath } from '../model/path';\nimport { debugAssert } from '../util/assert';\nimport { SortedSet } from '../util/sorted_set';\nimport { IndexManager } from './index_manager';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\n\n/**\n * An in-memory implementation of IndexManager.\n */\nexport class MemoryIndexManager implements IndexManager {\n  private collectionParentIndex = new MemoryCollectionParentIndex();\n\n  addToCollectionParentIndex(\n    transaction: PersistenceTransaction,\n    collectionPath: ResourcePath\n  ): PersistencePromise<void> {\n    this.collectionParentIndex.add(collectionPath);\n    return PersistencePromise.resolve();\n  }\n\n  getCollectionParents(\n    transaction: PersistenceTransaction,\n    collectionId: string\n  ): PersistencePromise<ResourcePath[]> {\n    return PersistencePromise.resolve(\n      this.collectionParentIndex.getEntries(collectionId)\n    );\n  }\n}\n\n/**\n * Internal implementation of the collection-parent index exposed by MemoryIndexManager.\n * Also used for in-memory caching by IndexedDbIndexManager and initial index population\n * in indexeddb_schema.ts\n */\nexport class MemoryCollectionParentIndex {\n  private index = {} as {\n    [collectionId: string]: SortedSet<ResourcePath>;\n  };\n\n  // Returns false if the entry already existed.\n  add(collectionPath: ResourcePath): boolean {\n    debugAssert(collectionPath.length % 2 === 1, 'Expected a collection path.');\n    const collectionId = collectionPath.lastSegment();\n    const parentPath = collectionPath.popLast();\n    const existingParents =\n      this.index[collectionId] ||\n      new SortedSet<ResourcePath>(ResourcePath.comparator);\n    const added = !existingParents.has(parentPath);\n    this.index[collectionId] = existingParents.add(parentPath);\n    return added;\n  }\n\n  has(collectionPath: ResourcePath): boolean {\n    const collectionId = collectionPath.lastSegment();\n    const parentPath = collectionPath.popLast();\n    const existingParents = this.index[collectionId];\n    return existingParents && existingParents.has(parentPath);\n  }\n\n  getEntries(collectionId: string): ResourcePath[] {\n    const parentPaths =\n      this.index[collectionId] ||\n      new SortedSet<ResourcePath>(ResourcePath.comparator);\n    return parentPaths.toArray();\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { BatchId, ListenSequenceNumber, TargetId } from '../core/types';\nimport { ResourcePath } from '../model/path';\nimport * as api from '../protos/firestore_proto_api';\nimport { debugAssert, hardAssert } from '../util/assert';\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { BATCHID_UNKNOWN } from '../model/mutation_batch';\nimport {\n  decodeResourcePath,\n  EncodedResourcePath,\n  encodeResourcePath\n} from './encoded_resource_path';\nimport { removeMutationBatch } from './indexeddb_mutation_queue';\nimport { dbDocumentSize } from './indexeddb_remote_document_cache';\nimport {\n  fromDbMutationBatch,\n  fromDbTarget,\n  LocalSerializer,\n  toDbTarget\n} from './local_serializer';\nimport { MemoryCollectionParentIndex } from './memory_index_manager';\nimport { PersistencePromise } from './persistence_promise';\nimport { SimpleDbSchemaConverter, SimpleDbTransaction } from './simple_db';\n\n/**\n * Schema Version for the Web client:\n * 1.  Initial version including Mutation Queue, Query Cache, and Remote\n *     Document Cache\n * 2.  Used to ensure a targetGlobal object exists and add targetCount to it. No\n *     longer required because migration 3 unconditionally clears it.\n * 3.  Dropped and re-created Query Cache to deal with cache corruption related\n *     to limbo resolution. Addresses\n *     https://github.com/firebase/firebase-ios-sdk/issues/1548\n * 4.  Multi-Tab Support.\n * 5.  Removal of held write acks.\n * 6.  Create document global for tracking document cache size.\n * 7.  Ensure every cached document has a sentinel row with a sequence number.\n * 8.  Add collection-parent index for Collection Group queries.\n * 9.  Change RemoteDocumentChanges store to be keyed by readTime rather than\n *     an auto-incrementing ID. This is required for Index-Free queries.\n * 10. Rewrite the canonical IDs to the explicit Protobuf-based format.\n */\nexport const SCHEMA_VERSION = 10;\n\n/** Performs database creation and schema upgrades. */\nexport class SchemaConverter implements SimpleDbSchemaConverter {\n  constructor(private readonly serializer: LocalSerializer) {}\n\n  /**\n   * Performs database creation and schema upgrades.\n   *\n   * Note that in production, this method is only ever used to upgrade the schema\n   * to SCHEMA_VERSION. Different values of toVersion are only used for testing\n   * and local feature development.\n   */\n  createOrUpgrade(\n    db: IDBDatabase,\n    txn: IDBTransaction,\n    fromVersion: number,\n    toVersion: number\n  ): PersistencePromise<void> {\n    hardAssert(\n      fromVersion < toVersion &&\n        fromVersion >= 0 &&\n        toVersion <= SCHEMA_VERSION,\n      `Unexpected schema upgrade from v${fromVersion} to v${toVersion}.`\n    );\n\n    const simpleDbTransaction = new SimpleDbTransaction(txn);\n\n    if (fromVersion < 1 && toVersion >= 1) {\n      createPrimaryClientStore(db);\n      createMutationQueue(db);\n      createQueryCache(db);\n      createRemoteDocumentCache(db);\n    }\n\n    // Migration 2 to populate the targetGlobal object no longer needed since\n    // migration 3 unconditionally clears it.\n\n    let p = PersistencePromise.resolve();\n    if (fromVersion < 3 && toVersion >= 3) {\n      // Brand new clients don't need to drop and recreate--only clients that\n      // potentially have corrupt data.\n      if (fromVersion !== 0) {\n        dropQueryCache(db);\n        createQueryCache(db);\n      }\n      p = p.next(() => writeEmptyTargetGlobalEntry(simpleDbTransaction));\n    }\n\n    if (fromVersion < 4 && toVersion >= 4) {\n      if (fromVersion !== 0) {\n        // Schema version 3 uses auto-generated keys to generate globally unique\n        // mutation batch IDs (this was previously ensured internally by the\n        // client). To migrate to the new schema, we have to read all mutations\n        // and write them back out. We preserve the existing batch IDs to guarantee\n        // consistency with other object stores. Any further mutation batch IDs will\n        // be auto-generated.\n        p = p.next(() =>\n          upgradeMutationBatchSchemaAndMigrateData(db, simpleDbTransaction)\n        );\n      }\n\n      p = p.next(() => {\n        createClientMetadataStore(db);\n      });\n    }\n\n    if (fromVersion < 5 && toVersion >= 5) {\n      p = p.next(() => this.removeAcknowledgedMutations(simpleDbTransaction));\n    }\n\n    if (fromVersion < 6 && toVersion >= 6) {\n      p = p.next(() => {\n        createDocumentGlobalStore(db);\n        return this.addDocumentGlobal(simpleDbTransaction);\n      });\n    }\n\n    if (fromVersion < 7 && toVersion >= 7) {\n      p = p.next(() => this.ensureSequenceNumbers(simpleDbTransaction));\n    }\n\n    if (fromVersion < 8 && toVersion >= 8) {\n      p = p.next(() =>\n        this.createCollectionParentIndex(db, simpleDbTransaction)\n      );\n    }\n\n    if (fromVersion < 9 && toVersion >= 9) {\n      p = p.next(() => {\n        // Multi-Tab used to manage its own changelog, but this has been moved\n        // to the DbRemoteDocument object store itself. Since the previous change\n        // log only contained transient data, we can drop its object store.\n        dropRemoteDocumentChangesStore(db);\n        createRemoteDocumentReadTimeIndex(txn);\n      });\n    }\n\n    if (fromVersion < 10 && toVersion >= 10) {\n      p = p.next(() => this.rewriteCanonicalIds(simpleDbTransaction));\n    }\n    return p;\n  }\n\n  private addDocumentGlobal(\n    txn: SimpleDbTransaction\n  ): PersistencePromise<void> {\n    let byteCount = 0;\n    return txn\n      .store<DbRemoteDocumentKey, DbRemoteDocument>(DbRemoteDocument.store)\n      .iterate((_, doc) => {\n        byteCount += dbDocumentSize(doc);\n      })\n      .next(() => {\n        const metadata = new DbRemoteDocumentGlobal(byteCount);\n        return txn\n          .store<DbRemoteDocumentGlobalKey, DbRemoteDocumentGlobal>(\n            DbRemoteDocumentGlobal.store\n          )\n          .put(DbRemoteDocumentGlobal.key, metadata);\n      });\n  }\n\n  private removeAcknowledgedMutations(\n    txn: SimpleDbTransaction\n  ): PersistencePromise<void> {\n    const queuesStore = txn.store<DbMutationQueueKey, DbMutationQueue>(\n      DbMutationQueue.store\n    );\n    const mutationsStore = txn.store<DbMutationBatchKey, DbMutationBatch>(\n      DbMutationBatch.store\n    );\n\n    return queuesStore.loadAll().next(queues => {\n      return PersistencePromise.forEach(queues, (queue: DbMutationQueue) => {\n        const range = IDBKeyRange.bound(\n          [queue.userId, BATCHID_UNKNOWN],\n          [queue.userId, queue.lastAcknowledgedBatchId]\n        );\n\n        return mutationsStore\n          .loadAll(DbMutationBatch.userMutationsIndex, range)\n          .next(dbBatches => {\n            return PersistencePromise.forEach(\n              dbBatches,\n              (dbBatch: DbMutationBatch) => {\n                hardAssert(\n                  dbBatch.userId === queue.userId,\n                  `Cannot process batch ${dbBatch.batchId} from unexpected user`\n                );\n                const batch = fromDbMutationBatch(this.serializer, dbBatch);\n\n                return removeMutationBatch(\n                  txn,\n                  queue.userId,\n                  batch\n                ).next(() => {});\n              }\n            );\n          });\n      });\n    });\n  }\n\n  /**\n   * Ensures that every document in the remote document cache has a corresponding sentinel row\n   * with a sequence number. Missing rows are given the most recently used sequence number.\n   */\n  private ensureSequenceNumbers(\n    txn: SimpleDbTransaction\n  ): PersistencePromise<void> {\n    const documentTargetStore = txn.store<\n      DbTargetDocumentKey,\n      DbTargetDocument\n    >(DbTargetDocument.store);\n    const documentsStore = txn.store<DbRemoteDocumentKey, DbRemoteDocument>(\n      DbRemoteDocument.store\n    );\n    const globalTargetStore = txn.store<DbTargetGlobalKey, DbTargetGlobal>(\n      DbTargetGlobal.store\n    );\n\n    return globalTargetStore.get(DbTargetGlobal.key).next(metadata => {\n      debugAssert(\n        !!metadata,\n        'Metadata should have been written during the version 3 migration'\n      );\n      const writeSentinelKey = (\n        path: ResourcePath\n      ): PersistencePromise<void> => {\n        return documentTargetStore.put(\n          new DbTargetDocument(\n            0,\n            encodeResourcePath(path),\n            metadata!.highestListenSequenceNumber!\n          )\n        );\n      };\n\n      const promises: Array<PersistencePromise<void>> = [];\n      return documentsStore\n        .iterate((key, doc) => {\n          const path = new ResourcePath(key);\n          const docSentinelKey = sentinelKey(path);\n          promises.push(\n            documentTargetStore.get(docSentinelKey).next(maybeSentinel => {\n              if (!maybeSentinel) {\n                return writeSentinelKey(path);\n              } else {\n                return PersistencePromise.resolve();\n              }\n            })\n          );\n        })\n        .next(() => PersistencePromise.waitFor(promises));\n    });\n  }\n\n  private createCollectionParentIndex(\n    db: IDBDatabase,\n    txn: SimpleDbTransaction\n  ): PersistencePromise<void> {\n    // Create the index.\n    db.createObjectStore(DbCollectionParent.store, {\n      keyPath: DbCollectionParent.keyPath\n    });\n\n    const collectionParentsStore = txn.store<\n      DbCollectionParentKey,\n      DbCollectionParent\n    >(DbCollectionParent.store);\n\n    // Helper to add an index entry iff we haven't already written it.\n    const cache = new MemoryCollectionParentIndex();\n    const addEntry = (\n      collectionPath: ResourcePath\n    ): PersistencePromise<void> | undefined => {\n      if (cache.add(collectionPath)) {\n        const collectionId = collectionPath.lastSegment();\n        const parentPath = collectionPath.popLast();\n        return collectionParentsStore.put({\n          collectionId,\n          parent: encodeResourcePath(parentPath)\n        });\n      }\n    };\n\n    // Index existing remote documents.\n    return txn\n      .store<DbRemoteDocumentKey, DbRemoteDocument>(DbRemoteDocument.store)\n      .iterate({ keysOnly: true }, (pathSegments, _) => {\n        const path = new ResourcePath(pathSegments);\n        return addEntry(path.popLast());\n      })\n      .next(() => {\n        // Index existing mutations.\n        return txn\n          .store<DbDocumentMutationKey, DbDocumentMutation>(\n            DbDocumentMutation.store\n          )\n          .iterate({ keysOnly: true }, ([userID, encodedPath, batchId], _) => {\n            const path = decodeResourcePath(encodedPath);\n            return addEntry(path.popLast());\n          });\n      });\n  }\n\n  private rewriteCanonicalIds(\n    txn: SimpleDbTransaction\n  ): PersistencePromise<void> {\n    const targetStore = txn.store<DbTargetKey, DbTarget>(DbTarget.store);\n    return targetStore.iterate((key, originalDbTarget) => {\n      const originalTargetData = fromDbTarget(originalDbTarget);\n      const updatedDbTarget = toDbTarget(this.serializer, originalTargetData);\n      return targetStore.put(updatedDbTarget);\n    });\n  }\n}\n\nfunction sentinelKey(path: ResourcePath): DbTargetDocumentKey {\n  return [0, encodeResourcePath(path)];\n}\n\n/**\n * Wrapper class to store timestamps (seconds and nanos) in IndexedDb objects.\n */\nexport class DbTimestamp {\n  constructor(public seconds: number, public nanoseconds: number) {}\n}\n\n/** A timestamp type that can be used in IndexedDb keys. */\nexport type DbTimestampKey = [/* seconds */ number, /* nanos */ number];\n\n// The key for the singleton object in the DbPrimaryClient is a single string.\nexport type DbPrimaryClientKey = typeof DbPrimaryClient.key;\n\n/**\n * A singleton object to be stored in the 'owner' store in IndexedDb.\n *\n * A given database can have a single primary tab assigned at a given time. That\n * tab must validate that it is still holding the primary lease before every\n * operation that requires locked access. The primary tab should regularly\n * write an updated timestamp to this lease to prevent other tabs from\n * \"stealing\" the primary lease\n */\nexport class DbPrimaryClient {\n  /**\n   * Name of the IndexedDb object store.\n   *\n   * Note that the name 'owner' is chosen to ensure backwards compatibility with\n   * older clients that only supported single locked access to the persistence\n   * layer.\n   */\n  static store = 'owner';\n\n  /**\n   * The key string used for the single object that exists in the\n   * DbPrimaryClient store.\n   */\n  static key = 'owner';\n\n  constructor(\n    public ownerId: string,\n    /** Whether to allow shared access from multiple tabs. */\n    public allowTabSynchronization: boolean,\n    public leaseTimestampMs: number\n  ) {}\n}\n\nfunction createPrimaryClientStore(db: IDBDatabase): void {\n  db.createObjectStore(DbPrimaryClient.store);\n}\n\n/** Object keys in the 'mutationQueues' store are userId strings. */\nexport type DbMutationQueueKey = string;\n\n/**\n * An object to be stored in the 'mutationQueues' store in IndexedDb.\n *\n * Each user gets a single queue of MutationBatches to apply to the server.\n * DbMutationQueue tracks the metadata about the queue.\n */\nexport class DbMutationQueue {\n  /** Name of the IndexedDb object store.  */\n  static store = 'mutationQueues';\n\n  /** Keys are automatically assigned via the userId property. */\n  static keyPath = 'userId';\n\n  constructor(\n    /**\n     * The normalized user ID to which this queue belongs.\n     */\n    public userId: string,\n    /**\n     * An identifier for the highest numbered batch that has been acknowledged\n     * by the server. All MutationBatches in this queue with batchIds less\n     * than or equal to this value are considered to have been acknowledged by\n     * the server.\n     *\n     * NOTE: this is deprecated and no longer used by the code.\n     */\n    public lastAcknowledgedBatchId: number,\n    /**\n     * A stream token that was previously sent by the server.\n     *\n     * See StreamingWriteRequest in datastore.proto for more details about\n     * usage.\n     *\n     * After sending this token, earlier tokens may not be used anymore so\n     * only a single stream token is retained.\n     *\n     * NOTE: this is deprecated and no longer used by the code.\n     */\n    public lastStreamToken: string\n  ) {}\n}\n\n/** The 'mutations' store  is keyed by batch ID. */\nexport type DbMutationBatchKey = BatchId;\n\n/**\n * An object to be stored in the 'mutations' store in IndexedDb.\n *\n * Represents a batch of user-level mutations intended to be sent to the server\n * in a single write. Each user-level batch gets a separate DbMutationBatch\n * with a new batchId.\n */\nexport class DbMutationBatch {\n  /** Name of the IndexedDb object store.  */\n  static store = 'mutations';\n\n  /** Keys are automatically assigned via the userId, batchId properties. */\n  static keyPath = 'batchId';\n\n  /** The index name for lookup of mutations by user. */\n  static userMutationsIndex = 'userMutationsIndex';\n\n  /** The user mutations index is keyed by [userId, batchId] pairs. */\n  static userMutationsKeyPath = ['userId', 'batchId'];\n\n  constructor(\n    /**\n     * The normalized user ID to which this batch belongs.\n     */\n    public userId: string,\n    /**\n     * An identifier for this batch, allocated using an auto-generated key.\n     */\n    public batchId: BatchId,\n    /**\n     * The local write time of the batch, stored as milliseconds since the\n     * epoch.\n     */\n    public localWriteTimeMs: number,\n    /**\n     * A list of \"mutations\" that represent a partial base state from when this\n     * write batch was initially created. During local application of the write\n     * batch, these baseMutations are applied prior to the real writes in order\n     * to override certain document fields from the remote document cache. This\n     * is necessary in the case of non-idempotent writes (e.g. `increment()`\n     * transforms) to make sure that the local view of the modified documents\n     * doesn't flicker if the remote document cache receives the result of the\n     * non-idempotent write before the write is removed from the queue.\n     *\n     * These mutations are never sent to the backend.\n     */\n    public baseMutations: api.Write[] | undefined,\n    /**\n     * A list of mutations to apply. All mutations will be applied atomically.\n     *\n     * Mutations are serialized via toMutation().\n     */\n    public mutations: api.Write[]\n  ) {}\n}\n\n/**\n * The key for a db document mutation, which is made up of a userID, path, and\n * batchId. Note that the path must be serialized into a form that indexedDB can\n * sort.\n */\nexport type DbDocumentMutationKey = [string, EncodedResourcePath, BatchId];\n\nfunction createMutationQueue(db: IDBDatabase): void {\n  db.createObjectStore(DbMutationQueue.store, {\n    keyPath: DbMutationQueue.keyPath\n  });\n\n  const mutationBatchesStore = db.createObjectStore(DbMutationBatch.store, {\n    keyPath: DbMutationBatch.keyPath,\n    autoIncrement: true\n  });\n  mutationBatchesStore.createIndex(\n    DbMutationBatch.userMutationsIndex,\n    DbMutationBatch.userMutationsKeyPath,\n    { unique: true }\n  );\n\n  db.createObjectStore(DbDocumentMutation.store);\n}\n\n/**\n * Upgrade function to migrate the 'mutations' store from V1 to V3. Loads\n * and rewrites all data.\n */\nfunction upgradeMutationBatchSchemaAndMigrateData(\n  db: IDBDatabase,\n  txn: SimpleDbTransaction\n): PersistencePromise<void> {\n  const v1MutationsStore = txn.store<[string, number], DbMutationBatch>(\n    DbMutationBatch.store\n  );\n  return v1MutationsStore.loadAll().next(existingMutations => {\n    db.deleteObjectStore(DbMutationBatch.store);\n\n    const mutationsStore = db.createObjectStore(DbMutationBatch.store, {\n      keyPath: DbMutationBatch.keyPath,\n      autoIncrement: true\n    });\n    mutationsStore.createIndex(\n      DbMutationBatch.userMutationsIndex,\n      DbMutationBatch.userMutationsKeyPath,\n      { unique: true }\n    );\n\n    const v3MutationsStore = txn.store<DbMutationBatchKey, DbMutationBatch>(\n      DbMutationBatch.store\n    );\n    const writeAll = existingMutations.map(mutation =>\n      v3MutationsStore.put(mutation)\n    );\n\n    return PersistencePromise.waitFor(writeAll);\n  });\n}\n\n/**\n * An object to be stored in the 'documentMutations' store in IndexedDb.\n *\n * A manually maintained index of all the mutation batches that affect a given\n * document key. The rows in this table are references based on the contents of\n * DbMutationBatch.mutations.\n */\nexport class DbDocumentMutation {\n  static store = 'documentMutations';\n\n  /**\n   * Creates a [userId] key for use in the DbDocumentMutations index to iterate\n   * over all of a user's document mutations.\n   */\n  static prefixForUser(userId: string): [string] {\n    return [userId];\n  }\n\n  /**\n   * Creates a [userId, encodedPath] key for use in the DbDocumentMutations\n   * index to iterate over all at document mutations for a given path or lower.\n   */\n  static prefixForPath(\n    userId: string,\n    path: ResourcePath\n  ): [string, EncodedResourcePath] {\n    return [userId, encodeResourcePath(path)];\n  }\n\n  /**\n   * Creates a full index key of [userId, encodedPath, batchId] for inserting\n   * and deleting into the DbDocumentMutations index.\n   */\n  static key(\n    userId: string,\n    path: ResourcePath,\n    batchId: BatchId\n  ): DbDocumentMutationKey {\n    return [userId, encodeResourcePath(path), batchId];\n  }\n\n  /**\n   * Because we store all the useful information for this store in the key,\n   * there is no useful information to store as the value. The raw (unencoded)\n   * path cannot be stored because IndexedDb doesn't store prototype\n   * information.\n   */\n  static PLACEHOLDER = new DbDocumentMutation();\n\n  private constructor() {}\n}\n\n/**\n * A key in the 'remoteDocuments' object store is a string array containing the\n * segments that make up the path.\n */\nexport type DbRemoteDocumentKey = string[];\n\nfunction createRemoteDocumentCache(db: IDBDatabase): void {\n  db.createObjectStore(DbRemoteDocument.store);\n}\n\n/**\n * Represents the known absence of a document at a particular version.\n * Stored in IndexedDb as part of a DbRemoteDocument object.\n */\nexport class DbNoDocument {\n  constructor(public path: string[], public readTime: DbTimestamp) {}\n}\n\n/**\n * Represents a document that is known to exist but whose data is unknown.\n * Stored in IndexedDb as part of a DbRemoteDocument object.\n */\nexport class DbUnknownDocument {\n  constructor(public path: string[], public version: DbTimestamp) {}\n}\n\n/**\n * An object to be stored in the 'remoteDocuments' store in IndexedDb.\n * It represents either:\n *\n * - A complete document.\n * - A \"no document\" representing a document that is known not to exist (at\n * some version).\n * - An \"unknown document\" representing a document that is known to exist (at\n * some version) but whose contents are unknown.\n *\n * Note: This is the persisted equivalent of a MaybeDocument and could perhaps\n * be made more general if necessary.\n */\nexport class DbRemoteDocument {\n  static store = 'remoteDocuments';\n\n  /**\n   * An index that provides access to all entries sorted by read time (which\n   * corresponds to the last modification time of each row).\n   *\n   * This index is used to provide a changelog for Multi-Tab.\n   */\n  static readTimeIndex = 'readTimeIndex';\n\n  static readTimeIndexPath = 'readTime';\n\n  /**\n   * An index that provides access to documents in a collection sorted by read\n   * time.\n   *\n   * This index is used to allow the RemoteDocumentCache to fetch newly changed\n   * documents in a collection.\n   */\n  static collectionReadTimeIndex = 'collectionReadTimeIndex';\n\n  static collectionReadTimeIndexPath = ['parentPath', 'readTime'];\n\n  // TODO: We are currently storing full document keys almost three times\n  // (once as part of the primary key, once - partly - as `parentPath` and once\n  // inside the encoded documents). During our next migration, we should\n  // rewrite the primary key as parentPath + document ID which would allow us\n  // to drop one value.\n\n  constructor(\n    /**\n     * Set to an instance of DbUnknownDocument if the data for a document is\n     * not known, but it is known that a document exists at the specified\n     * version (e.g. it had a successful update applied to it)\n     */\n    public unknownDocument: DbUnknownDocument | null | undefined,\n    /**\n     * Set to an instance of a DbNoDocument if it is known that no document\n     * exists.\n     */\n    public noDocument: DbNoDocument | null,\n    /**\n     * Set to an instance of a Document if there's a cached version of the\n     * document.\n     */\n    public document: api.Document | null,\n    /**\n     * Documents that were written to the remote document store based on\n     * a write acknowledgment are marked with `hasCommittedMutations`. These\n     * documents are potentially inconsistent with the backend's copy and use\n     * the write's commit version as their document version.\n     */\n    public hasCommittedMutations: boolean | undefined,\n\n    /**\n     * When the document was read from the backend. Undefined for data written\n     * prior to schema version 9.\n     */\n    public readTime: DbTimestampKey | undefined,\n\n    /**\n     * The path of the collection this document is part of. Undefined for data\n     * written prior to schema version 9.\n     */\n    public parentPath: string[] | undefined\n  ) {}\n}\n\n/**\n * Contains a single entry that has metadata about the remote document cache.\n */\nexport class DbRemoteDocumentGlobal {\n  static store = 'remoteDocumentGlobal';\n\n  static key = 'remoteDocumentGlobalKey';\n\n  /**\n   * @param byteSize Approximately the total size in bytes of all the documents in the document\n   * cache.\n   */\n  constructor(public byteSize: number) {}\n}\n\nexport type DbRemoteDocumentGlobalKey = typeof DbRemoteDocumentGlobal.key;\n\nfunction createDocumentGlobalStore(db: IDBDatabase): void {\n  db.createObjectStore(DbRemoteDocumentGlobal.store);\n}\n\n/**\n * A key in the 'targets' object store is a targetId of the query.\n */\nexport type DbTargetKey = TargetId;\n\n/**\n * The persisted type for a query nested with in the 'targets' store in\n * IndexedDb. We use the proto definitions for these two kinds of queries in\n * order to avoid writing extra serialization logic.\n */\nexport type DbQuery = api.QueryTarget | api.DocumentsTarget;\n\n/**\n * An object to be stored in the 'targets' store in IndexedDb.\n *\n * This is based on and should be kept in sync with the proto used in the iOS\n * client.\n *\n * Each query the client listens to against the server is tracked on disk so\n * that the query can be efficiently resumed on restart.\n */\nexport class DbTarget {\n  static store = 'targets';\n\n  /** Keys are automatically assigned via the targetId property. */\n  static keyPath = 'targetId';\n\n  /** The name of the queryTargets index. */\n  static queryTargetsIndexName = 'queryTargetsIndex';\n\n  /**\n   * The index of all canonicalIds to the targets that they match. This is not\n   * a unique mapping because canonicalId does not promise a unique name for all\n   * possible queries, so we append the targetId to make the mapping unique.\n   */\n  static queryTargetsKeyPath = ['canonicalId', 'targetId'];\n\n  constructor(\n    /**\n     * An auto-generated sequential numeric identifier for the query.\n     *\n     * Queries are stored using their canonicalId as the key, but these\n     * canonicalIds can be quite long so we additionally assign a unique\n     * queryId which can be used by referenced data structures (e.g.\n     * indexes) to minimize the on-disk cost.\n     */\n    public targetId: TargetId,\n    /**\n     * The canonical string representing this query. This is not unique.\n     */\n    public canonicalId: string,\n    /**\n     * The last readTime received from the Watch Service for this query.\n     *\n     * This is the same value as TargetChange.read_time in the protos.\n     */\n    public readTime: DbTimestamp,\n    /**\n     * An opaque, server-assigned token that allows watching a query to be\n     * resumed after disconnecting without retransmitting all the data\n     * that matches the query. The resume token essentially identifies a\n     * point in time from which the server should resume sending results.\n     *\n     * This is related to the snapshotVersion in that the resumeToken\n     * effectively also encodes that value, but the resumeToken is opaque\n     * and sometimes encodes additional information.\n     *\n     * A consequence of this is that the resumeToken should be used when\n     * asking the server to reason about where this client is in the watch\n     * stream, but the client should use the snapshotVersion for its own\n     * purposes.\n     *\n     * This is the same value as TargetChange.resume_token in the protos.\n     */\n    public resumeToken: string,\n    /**\n     * A sequence number representing the last time this query was\n     * listened to, used for garbage collection purposes.\n     *\n     * Conventionally this would be a timestamp value, but device-local\n     * clocks are unreliable and they must be able to create new listens\n     * even while disconnected. Instead this should be a monotonically\n     * increasing number that's incremented on each listen call.\n     *\n     * This is different from the queryId since the queryId is an\n     * immutable identifier assigned to the Query on first use while\n     * lastListenSequenceNumber is updated every time the query is\n     * listened to.\n     */\n    public lastListenSequenceNumber: number,\n    /**\n     * Denotes the maximum snapshot version at which the associated query view\n     * contained no limbo documents.  Undefined for data written prior to\n     * schema version 9.\n     */\n    public lastLimboFreeSnapshotVersion: DbTimestamp | undefined,\n    /**\n     * The query for this target.\n     *\n     * Because canonical ids are not unique we must store the actual query. We\n     * use the proto to have an object we can persist without having to\n     * duplicate translation logic to and from a `Query` object.\n     */\n    public query: DbQuery\n  ) {}\n}\n\n/**\n * The key for a DbTargetDocument, containing a targetId and an encoded resource\n * path.\n */\nexport type DbTargetDocumentKey = [TargetId, EncodedResourcePath];\n\n/**\n * An object representing an association between a target and a document, or a\n * sentinel row marking the last sequence number at which a document was used.\n * Each document cached must have a corresponding sentinel row before lru\n * garbage collection is enabled.\n *\n * The target associations and sentinel rows are co-located so that orphaned\n * documents and their sequence numbers can be identified efficiently via a scan\n * of this store.\n */\nexport class DbTargetDocument {\n  /** Name of the IndexedDb object store.  */\n  static store = 'targetDocuments';\n\n  /** Keys are automatically assigned via the targetId, path properties. */\n  static keyPath = ['targetId', 'path'];\n\n  /** The index name for the reverse index. */\n  static documentTargetsIndex = 'documentTargetsIndex';\n\n  /** We also need to create the reverse index for these properties. */\n  static documentTargetsKeyPath = ['path', 'targetId'];\n\n  constructor(\n    /**\n     * The targetId identifying a target or 0 for a sentinel row.\n     */\n    public targetId: TargetId,\n    /**\n     * The path to the document, as encoded in the key.\n     */\n    public path: EncodedResourcePath,\n    /**\n     * If this is a sentinel row, this should be the sequence number of the last\n     * time the document specified by `path` was used. Otherwise, it should be\n     * `undefined`.\n     */\n    public sequenceNumber?: ListenSequenceNumber\n  ) {\n    debugAssert(\n      (targetId === 0) === (sequenceNumber !== undefined),\n      'A target-document row must either have targetId == 0 and a defined sequence number, or a non-zero targetId and no sequence number'\n    );\n  }\n}\n\n/**\n * The type to represent the single allowed key for the DbTargetGlobal store.\n */\nexport type DbTargetGlobalKey = typeof DbTargetGlobal.key;\n\n/**\n * A record of global state tracked across all Targets, tracked separately\n * to avoid the need for extra indexes.\n *\n * This should be kept in-sync with the proto used in the iOS client.\n */\nexport class DbTargetGlobal {\n  /**\n   * The key string used for the single object that exists in the\n   * DbTargetGlobal store.\n   */\n  static key = 'targetGlobalKey';\n  static store = 'targetGlobal';\n\n  constructor(\n    /**\n     * The highest numbered target id across all targets.\n     *\n     * See DbTarget.targetId.\n     */\n    public highestTargetId: TargetId,\n    /**\n     * The highest numbered lastListenSequenceNumber across all targets.\n     *\n     * See DbTarget.lastListenSequenceNumber.\n     */\n    public highestListenSequenceNumber: number,\n    /**\n     * A global snapshot version representing the last consistent snapshot we\n     * received from the backend. This is monotonically increasing and any\n     * snapshots received from the backend prior to this version (e.g. for\n     * targets resumed with a resumeToken) should be suppressed (buffered)\n     * until the backend has caught up to this snapshot version again. This\n     * prevents our cache from ever going backwards in time.\n     */\n    public lastRemoteSnapshotVersion: DbTimestamp,\n    /**\n     * The number of targets persisted.\n     */\n    public targetCount: number\n  ) {}\n}\n\n/**\n * The key for a DbCollectionParent entry, containing the collection ID\n * and the parent path that contains it. Note that the parent path will be an\n * empty path in the case of root-level collections.\n */\nexport type DbCollectionParentKey = [string, EncodedResourcePath];\n\n/**\n * An object representing an association between a Collection id (e.g. 'messages')\n * to a parent path (e.g. '/chats/123') that contains it as a (sub)collection.\n * This is used to efficiently find all collections to query when performing\n * a Collection Group query.\n */\nexport class DbCollectionParent {\n  /** Name of the IndexedDb object store. */\n  static store = 'collectionParents';\n\n  /** Keys are automatically assigned via the collectionId, parent properties. */\n  static keyPath = ['collectionId', 'parent'];\n\n  constructor(\n    /**\n     * The collectionId (e.g. 'messages')\n     */\n    public collectionId: string,\n    /**\n     * The path to the parent (either a document location or an empty path for\n     * a root-level collection).\n     */\n    public parent: EncodedResourcePath\n  ) {}\n}\n\nfunction createQueryCache(db: IDBDatabase): void {\n  const targetDocumentsStore = db.createObjectStore(DbTargetDocument.store, {\n    keyPath: DbTargetDocument.keyPath\n  });\n  targetDocumentsStore.createIndex(\n    DbTargetDocument.documentTargetsIndex,\n    DbTargetDocument.documentTargetsKeyPath,\n    { unique: true }\n  );\n\n  const targetStore = db.createObjectStore(DbTarget.store, {\n    keyPath: DbTarget.keyPath\n  });\n\n  // NOTE: This is unique only because the TargetId is the suffix.\n  targetStore.createIndex(\n    DbTarget.queryTargetsIndexName,\n    DbTarget.queryTargetsKeyPath,\n    { unique: true }\n  );\n  db.createObjectStore(DbTargetGlobal.store);\n}\n\nfunction dropQueryCache(db: IDBDatabase): void {\n  db.deleteObjectStore(DbTargetDocument.store);\n  db.deleteObjectStore(DbTarget.store);\n  db.deleteObjectStore(DbTargetGlobal.store);\n}\n\nfunction dropRemoteDocumentChangesStore(db: IDBDatabase): void {\n  if (db.objectStoreNames.contains('remoteDocumentChanges')) {\n    db.deleteObjectStore('remoteDocumentChanges');\n  }\n}\n\n/**\n * Creates the target global singleton row.\n *\n * @param {IDBTransaction} txn The version upgrade transaction for indexeddb\n */\nfunction writeEmptyTargetGlobalEntry(\n  txn: SimpleDbTransaction\n): PersistencePromise<void> {\n  const globalStore = txn.store<DbTargetGlobalKey, DbTargetGlobal>(\n    DbTargetGlobal.store\n  );\n  const metadata = new DbTargetGlobal(\n    /*highestTargetId=*/ 0,\n    /*lastListenSequenceNumber=*/ 0,\n    SnapshotVersion.min().toTimestamp(),\n    /*targetCount=*/ 0\n  );\n  return globalStore.put(DbTargetGlobal.key, metadata);\n}\n\n/**\n * Creates indices on the RemoteDocuments store used for both multi-tab\n * and Index-Free queries.\n */\nfunction createRemoteDocumentReadTimeIndex(txn: IDBTransaction): void {\n  const remoteDocumentStore = txn.objectStore(DbRemoteDocument.store);\n  remoteDocumentStore.createIndex(\n    DbRemoteDocument.readTimeIndex,\n    DbRemoteDocument.readTimeIndexPath,\n    { unique: false }\n  );\n  remoteDocumentStore.createIndex(\n    DbRemoteDocument.collectionReadTimeIndex,\n    DbRemoteDocument.collectionReadTimeIndexPath,\n    { unique: false }\n  );\n}\n\n/**\n * A record of the metadata state of each client.\n *\n * PORTING NOTE: This is used to synchronize multi-tab state and does not need\n * to be ported to iOS or Android.\n */\nexport class DbClientMetadata {\n  /** Name of the IndexedDb object store. */\n  static store = 'clientMetadata';\n\n  /** Keys are automatically assigned via the clientId properties. */\n  static keyPath = 'clientId';\n\n  constructor(\n    // Note: Previous schema versions included a field\n    // \"lastProcessedDocumentChangeId\". Don't use anymore.\n\n    /** The auto-generated client id assigned at client startup. */\n    public clientId: string,\n    /** The last time this state was updated. */\n    public updateTimeMs: number,\n    /** Whether the client's network connection is enabled. */\n    public networkEnabled: boolean,\n    /** Whether this client is running in a foreground tab. */\n    public inForeground: boolean\n  ) {}\n}\n\n/** Object keys in the 'clientMetadata' store are clientId strings. */\nexport type DbClientMetadataKey = string;\n\nfunction createClientMetadataStore(db: IDBDatabase): void {\n  db.createObjectStore(DbClientMetadata.store, {\n    keyPath: DbClientMetadata.keyPath\n  });\n}\n\n// Visible for testing\nexport const V1_STORES = [\n  DbMutationQueue.store,\n  DbMutationBatch.store,\n  DbDocumentMutation.store,\n  DbRemoteDocument.store,\n  DbTarget.store,\n  DbPrimaryClient.store,\n  DbTargetGlobal.store,\n  DbTargetDocument.store\n];\n\n// V2 is no longer usable (see comment at top of file)\n\n// Visible for testing\nexport const V3_STORES = V1_STORES;\n\n// Visible for testing\n// Note: DbRemoteDocumentChanges is no longer used and dropped with v9.\nexport const V4_STORES = [...V3_STORES, DbClientMetadata.store];\n\n// V5 does not change the set of stores.\n\nexport const V6_STORES = [...V4_STORES, DbRemoteDocumentGlobal.store];\n\n// V7 does not change the set of stores.\n\nexport const V8_STORES = [...V6_STORES, DbCollectionParent.store];\n\n// V9 does not change the set of stores.\n\n// V10 does not change the set of stores.\n\n/**\n * The list of all default IndexedDB stores used throughout the SDK. This is\n * used when creating transactions so that access across all stores is done\n * atomically.\n */\nexport const ALL_STORES = V8_STORES;\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ResourcePath } from '../model/path';\nimport { debugAssert } from '../util/assert';\nimport { immediateSuccessor } from '../util/misc';\nimport {\n  decodeResourcePath,\n  encodeResourcePath\n} from './encoded_resource_path';\nimport { IndexManager } from './index_manager';\nimport { IndexedDbPersistence } from './indexeddb_persistence';\nimport { DbCollectionParent, DbCollectionParentKey } from './indexeddb_schema';\nimport { MemoryCollectionParentIndex } from './memory_index_manager';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { SimpleDbStore } from './simple_db';\n\n/**\n * A persisted implementation of IndexManager.\n */\nexport class IndexedDbIndexManager implements IndexManager {\n  /**\n   * An in-memory copy of the index entries we've already written since the SDK\n   * launched. Used to avoid re-writing the same entry repeatedly.\n   *\n   * This is *NOT* a complete cache of what's in persistence and so can never be used to\n   * satisfy reads.\n   */\n  private collectionParentsCache = new MemoryCollectionParentIndex();\n\n  /**\n   * Adds a new entry to the collection parent index.\n   *\n   * Repeated calls for the same collectionPath should be avoided within a\n   * transaction as IndexedDbIndexManager only caches writes once a transaction\n   * has been committed.\n   */\n  addToCollectionParentIndex(\n    transaction: PersistenceTransaction,\n    collectionPath: ResourcePath\n  ): PersistencePromise<void> {\n    debugAssert(collectionPath.length % 2 === 1, 'Expected a collection path.');\n    if (!this.collectionParentsCache.has(collectionPath)) {\n      const collectionId = collectionPath.lastSegment();\n      const parentPath = collectionPath.popLast();\n\n      transaction.addOnCommittedListener(() => {\n        // Add the collection to the in memory cache only if the transaction was\n        // successfully committed.\n        this.collectionParentsCache.add(collectionPath);\n      });\n\n      const collectionParent: DbCollectionParent = {\n        collectionId,\n        parent: encodeResourcePath(parentPath)\n      };\n      return collectionParentsStore(transaction).put(collectionParent);\n    }\n    return PersistencePromise.resolve();\n  }\n\n  getCollectionParents(\n    transaction: PersistenceTransaction,\n    collectionId: string\n  ): PersistencePromise<ResourcePath[]> {\n    const parentPaths = [] as ResourcePath[];\n    const range = IDBKeyRange.bound(\n      [collectionId, ''],\n      [immediateSuccessor(collectionId), ''],\n      /*lowerOpen=*/ false,\n      /*upperOpen=*/ true\n    );\n    return collectionParentsStore(transaction)\n      .loadAll(range)\n      .next(entries => {\n        for (const entry of entries) {\n          // This collectionId guard shouldn't be necessary (and isn't as long\n          // as we're running in a real browser), but there's a bug in\n          // indexeddbshim that breaks our range in our tests running in node:\n          // https://github.com/axemclion/IndexedDBShim/issues/334\n          if (entry.collectionId !== collectionId) {\n            break;\n          }\n          parentPaths.push(decodeResourcePath(entry.parent));\n        }\n        return parentPaths;\n      });\n  }\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the collectionParents\n * document store.\n */\nfunction collectionParentsStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbCollectionParentKey, DbCollectionParent> {\n  return IndexedDbPersistence.getStore<\n    DbCollectionParentKey,\n    DbCollectionParent\n  >(txn, DbCollectionParent.store);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { TargetId } from './types';\n\n/** Offset to ensure non-overlapping target ids. */\nconst OFFSET = 2;\n\n/**\n * Generates monotonically increasing target IDs for sending targets to the\n * watch stream.\n *\n * The client constructs two generators, one for the target cache, and one for\n * for the sync engine (to generate limbo documents targets). These\n * generators produce non-overlapping IDs (by using even and odd IDs\n * respectively).\n *\n * By separating the target ID space, the query cache can generate target IDs\n * that persist across client restarts, while sync engine can independently\n * generate in-memory target IDs that are transient and can be reused after a\n * restart.\n */\nexport class TargetIdGenerator {\n  constructor(private lastId: number) {}\n\n  next(): TargetId {\n    this.lastId += OFFSET;\n    return this.lastId;\n  }\n\n  static forTargetCache(): TargetIdGenerator {\n    // The target cache generator must return '2' in its first call to `next()`\n    // as there is no differentiation in the protocol layer between an unset\n    // number and the number '0'. If we were to sent a target with target ID\n    // '0', the backend would consider it unset and replace it with its own ID.\n    return new TargetIdGenerator(2 - OFFSET);\n  }\n\n  static forSyncEngine(): TargetIdGenerator {\n    // Sync engine assigns target IDs for limbo document detection.\n    return new TargetIdGenerator(1 - OFFSET);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Timestamp } from '../api/timestamp';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { ListenSequenceNumber, TargetId } from '../core/types';\nimport { DocumentKeySet, documentKeySet } from '../model/collections';\nimport { DocumentKey } from '../model/document_key';\nimport { hardAssert } from '../util/assert';\nimport { immediateSuccessor } from '../util/misc';\nimport { TargetIdGenerator } from '../core/target_id_generator';\nimport {\n  decodeResourcePath,\n  encodeResourcePath\n} from './encoded_resource_path';\nimport {\n  IndexedDbLruDelegate,\n  IndexedDbPersistence\n} from './indexeddb_persistence';\nimport {\n  DbTarget,\n  DbTargetDocument,\n  DbTargetDocumentKey,\n  DbTargetGlobal,\n  DbTargetGlobalKey,\n  DbTargetKey\n} from './indexeddb_schema';\nimport { fromDbTarget, LocalSerializer, toDbTarget } from './local_serializer';\nimport { ActiveTargets } from './lru_garbage_collector';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { TargetCache } from './target_cache';\nimport { TargetData } from './target_data';\nimport { SimpleDbStore } from './simple_db';\nimport { canonifyTarget, Target, targetEquals } from '../core/target';\n\nexport class IndexedDbTargetCache implements TargetCache {\n  constructor(\n    private readonly referenceDelegate: IndexedDbLruDelegate,\n    private serializer: LocalSerializer\n  ) {}\n\n  // PORTING NOTE: We don't cache global metadata for the target cache, since\n  // some of it (in particular `highestTargetId`) can be modified by secondary\n  // tabs. We could perhaps be more granular (and e.g. still cache\n  // `lastRemoteSnapshotVersion` in memory) but for simplicity we currently go\n  // to IndexedDb whenever we need to read metadata. We can revisit if it turns\n  // out to have a meaningful performance impact.\n\n  allocateTargetId(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<TargetId> {\n    return this.retrieveMetadata(transaction).next(metadata => {\n      const targetIdGenerator = new TargetIdGenerator(metadata.highestTargetId);\n      metadata.highestTargetId = targetIdGenerator.next();\n      return this.saveMetadata(transaction, metadata).next(\n        () => metadata.highestTargetId\n      );\n    });\n  }\n\n  getLastRemoteSnapshotVersion(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<SnapshotVersion> {\n    return this.retrieveMetadata(transaction).next(metadata => {\n      return SnapshotVersion.fromTimestamp(\n        new Timestamp(\n          metadata.lastRemoteSnapshotVersion.seconds,\n          metadata.lastRemoteSnapshotVersion.nanoseconds\n        )\n      );\n    });\n  }\n\n  getHighestSequenceNumber(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<ListenSequenceNumber> {\n    return this.retrieveMetadata(transaction).next(\n      targetGlobal => targetGlobal.highestListenSequenceNumber\n    );\n  }\n\n  setTargetsMetadata(\n    transaction: PersistenceTransaction,\n    highestListenSequenceNumber: number,\n    lastRemoteSnapshotVersion?: SnapshotVersion\n  ): PersistencePromise<void> {\n    return this.retrieveMetadata(transaction).next(metadata => {\n      metadata.highestListenSequenceNumber = highestListenSequenceNumber;\n      if (lastRemoteSnapshotVersion) {\n        metadata.lastRemoteSnapshotVersion = lastRemoteSnapshotVersion.toTimestamp();\n      }\n      if (highestListenSequenceNumber > metadata.highestListenSequenceNumber) {\n        metadata.highestListenSequenceNumber = highestListenSequenceNumber;\n      }\n      return this.saveMetadata(transaction, metadata);\n    });\n  }\n\n  addTargetData(\n    transaction: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    return this.saveTargetData(transaction, targetData).next(() => {\n      return this.retrieveMetadata(transaction).next(metadata => {\n        metadata.targetCount += 1;\n        this.updateMetadataFromTargetData(targetData, metadata);\n        return this.saveMetadata(transaction, metadata);\n      });\n    });\n  }\n\n  updateTargetData(\n    transaction: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    return this.saveTargetData(transaction, targetData);\n  }\n\n  removeTargetData(\n    transaction: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    return this.removeMatchingKeysForTargetId(transaction, targetData.targetId)\n      .next(() => targetsStore(transaction).delete(targetData.targetId))\n      .next(() => this.retrieveMetadata(transaction))\n      .next(metadata => {\n        hardAssert(\n          metadata.targetCount > 0,\n          'Removing from an empty target cache'\n        );\n        metadata.targetCount -= 1;\n        return this.saveMetadata(transaction, metadata);\n      });\n  }\n\n  /**\n   * Drops any targets with sequence number less than or equal to the upper bound, excepting those\n   * present in `activeTargetIds`. Document associations for the removed targets are also removed.\n   * Returns the number of targets removed.\n   */\n  removeTargets(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<number> {\n    let count = 0;\n    const promises: Array<PersistencePromise<void>> = [];\n    return targetsStore(txn)\n      .iterate((key, value) => {\n        const targetData = fromDbTarget(value);\n        if (\n          targetData.sequenceNumber <= upperBound &&\n          activeTargetIds.get(targetData.targetId) === null\n        ) {\n          count++;\n          promises.push(this.removeTargetData(txn, targetData));\n        }\n      })\n      .next(() => PersistencePromise.waitFor(promises))\n      .next(() => count);\n  }\n\n  /**\n   * Call provided function with each `TargetData` that we have cached.\n   */\n  forEachTarget(\n    txn: PersistenceTransaction,\n    f: (q: TargetData) => void\n  ): PersistencePromise<void> {\n    return targetsStore(txn).iterate((key, value) => {\n      const targetData = fromDbTarget(value);\n      f(targetData);\n    });\n  }\n\n  private retrieveMetadata(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<DbTargetGlobal> {\n    return globalTargetStore(transaction)\n      .get(DbTargetGlobal.key)\n      .next(metadata => {\n        hardAssert(metadata !== null, 'Missing metadata row.');\n        return metadata;\n      });\n  }\n\n  private saveMetadata(\n    transaction: PersistenceTransaction,\n    metadata: DbTargetGlobal\n  ): PersistencePromise<void> {\n    return globalTargetStore(transaction).put(DbTargetGlobal.key, metadata);\n  }\n\n  private saveTargetData(\n    transaction: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    return targetsStore(transaction).put(\n      toDbTarget(this.serializer, targetData)\n    );\n  }\n\n  /**\n   * In-place updates the provided metadata to account for values in the given\n   * TargetData. Saving is done separately. Returns true if there were any\n   * changes to the metadata.\n   */\n  private updateMetadataFromTargetData(\n    targetData: TargetData,\n    metadata: DbTargetGlobal\n  ): boolean {\n    let updated = false;\n    if (targetData.targetId > metadata.highestTargetId) {\n      metadata.highestTargetId = targetData.targetId;\n      updated = true;\n    }\n\n    if (targetData.sequenceNumber > metadata.highestListenSequenceNumber) {\n      metadata.highestListenSequenceNumber = targetData.sequenceNumber;\n      updated = true;\n    }\n    return updated;\n  }\n\n  getTargetCount(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<number> {\n    return this.retrieveMetadata(transaction).next(\n      metadata => metadata.targetCount\n    );\n  }\n\n  getTargetData(\n    transaction: PersistenceTransaction,\n    target: Target\n  ): PersistencePromise<TargetData | null> {\n    // Iterating by the canonicalId may yield more than one result because\n    // canonicalId values are not required to be unique per target. This query\n    // depends on the queryTargets index to be efficient.\n    const canonicalId = canonifyTarget(target);\n    const range = IDBKeyRange.bound(\n      [canonicalId, Number.NEGATIVE_INFINITY],\n      [canonicalId, Number.POSITIVE_INFINITY]\n    );\n    let result: TargetData | null = null;\n    return targetsStore(transaction)\n      .iterate(\n        { range, index: DbTarget.queryTargetsIndexName },\n        (key, value, control) => {\n          const found = fromDbTarget(value);\n          // After finding a potential match, check that the target is\n          // actually equal to the requested target.\n          if (targetEquals(target, found.target)) {\n            result = found;\n            control.done();\n          }\n        }\n      )\n      .next(() => result);\n  }\n\n  addMatchingKeys(\n    txn: PersistenceTransaction,\n    keys: DocumentKeySet,\n    targetId: TargetId\n  ): PersistencePromise<void> {\n    // PORTING NOTE: The reverse index (documentsTargets) is maintained by\n    // IndexedDb.\n    const promises: Array<PersistencePromise<void>> = [];\n    const store = documentTargetStore(txn);\n    keys.forEach(key => {\n      const path = encodeResourcePath(key.path);\n      promises.push(store.put(new DbTargetDocument(targetId, path)));\n      promises.push(this.referenceDelegate.addReference(txn, targetId, key));\n    });\n    return PersistencePromise.waitFor(promises);\n  }\n\n  removeMatchingKeys(\n    txn: PersistenceTransaction,\n    keys: DocumentKeySet,\n    targetId: TargetId\n  ): PersistencePromise<void> {\n    // PORTING NOTE: The reverse index (documentsTargets) is maintained by\n    // IndexedDb.\n    const store = documentTargetStore(txn);\n    return PersistencePromise.forEach(keys, (key: DocumentKey) => {\n      const path = encodeResourcePath(key.path);\n      return PersistencePromise.waitFor([\n        store.delete([targetId, path]),\n        this.referenceDelegate.removeReference(txn, targetId, key)\n      ]);\n    });\n  }\n\n  removeMatchingKeysForTargetId(\n    txn: PersistenceTransaction,\n    targetId: TargetId\n  ): PersistencePromise<void> {\n    const store = documentTargetStore(txn);\n    const range = IDBKeyRange.bound(\n      [targetId],\n      [targetId + 1],\n      /*lowerOpen=*/ false,\n      /*upperOpen=*/ true\n    );\n    return store.delete(range);\n  }\n\n  getMatchingKeysForTargetId(\n    txn: PersistenceTransaction,\n    targetId: TargetId\n  ): PersistencePromise<DocumentKeySet> {\n    const range = IDBKeyRange.bound(\n      [targetId],\n      [targetId + 1],\n      /*lowerOpen=*/ false,\n      /*upperOpen=*/ true\n    );\n    const store = documentTargetStore(txn);\n    let result = documentKeySet();\n\n    return store\n      .iterate({ range, keysOnly: true }, (key, _, control) => {\n        const path = decodeResourcePath(key[1]);\n        const docKey = new DocumentKey(path);\n        result = result.add(docKey);\n      })\n      .next(() => result);\n  }\n\n  containsKey(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<boolean> {\n    const path = encodeResourcePath(key.path);\n    const range = IDBKeyRange.bound(\n      [path],\n      [immediateSuccessor(path)],\n      /*lowerOpen=*/ false,\n      /*upperOpen=*/ true\n    );\n    let count = 0;\n    return documentTargetStore(txn!)\n      .iterate(\n        {\n          index: DbTargetDocument.documentTargetsIndex,\n          keysOnly: true,\n          range\n        },\n        ([targetId, path], _, control) => {\n          // Having a sentinel row for a document does not count as containing that document;\n          // For the target cache, containing the document means the document is part of some\n          // target.\n          if (targetId !== 0) {\n            count++;\n            control.done();\n          }\n        }\n      )\n      .next(() => count > 0);\n  }\n\n  /**\n   * Looks up a TargetData entry by target ID.\n   *\n   * @param targetId The target ID of the TargetData entry to look up.\n   * @return The cached TargetData entry, or null if the cache has no entry for\n   * the target.\n   */\n  // PORTING NOTE: Multi-tab only.\n  getTargetDataForTarget(\n    transaction: PersistenceTransaction,\n    targetId: TargetId\n  ): PersistencePromise<TargetData | null> {\n    return targetsStore(transaction)\n      .get(targetId)\n      .next(found => {\n        if (found) {\n          return fromDbTarget(found);\n        } else {\n          return null;\n        }\n      });\n  }\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the queries object store.\n */\nfunction targetsStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbTargetKey, DbTarget> {\n  return IndexedDbPersistence.getStore<DbTargetKey, DbTarget>(\n    txn,\n    DbTarget.store\n  );\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the target globals object store.\n */\nfunction globalTargetStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbTargetGlobalKey, DbTargetGlobal> {\n  return IndexedDbPersistence.getStore<DbTargetGlobalKey, DbTargetGlobal>(\n    txn,\n    DbTargetGlobal.store\n  );\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the document target object store.\n */\nexport function documentTargetStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbTargetDocumentKey, DbTargetDocument> {\n  return IndexedDbPersistence.getStore<DbTargetDocumentKey, DbTargetDocument>(\n    txn,\n    DbTargetDocument.store\n  );\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { User } from '../auth/user';\nimport { DatabaseId } from '../core/database_info';\nimport { ListenSequence, SequenceNumberSyncer } from '../core/listen_sequence';\nimport { ListenSequenceNumber, TargetId } from '../core/types';\nimport { DocumentKey } from '../model/document_key';\nimport { JsonProtoSerializer } from '../remote/serializer';\nimport { debugAssert, fail } from '../util/assert';\nimport { AsyncQueue, DelayedOperation, TimerId } from '../util/async_queue';\nimport { Code, FirestoreError } from '../util/error';\nimport { logDebug, logError } from '../util/log';\nimport {\n  decodeResourcePath,\n  EncodedResourcePath,\n  encodeResourcePath\n} from './encoded_resource_path';\nimport { IndexedDbIndexManager } from './indexeddb_index_manager';\nimport {\n  IndexedDbMutationQueue,\n  mutationQueuesContainKey\n} from './indexeddb_mutation_queue';\nimport { IndexedDbRemoteDocumentCache } from './indexeddb_remote_document_cache';\nimport {\n  ALL_STORES,\n  DbClientMetadata,\n  DbClientMetadataKey,\n  DbPrimaryClient,\n  DbPrimaryClientKey,\n  DbTargetDocument,\n  SCHEMA_VERSION,\n  SchemaConverter\n} from './indexeddb_schema';\nimport {\n  documentTargetStore,\n  IndexedDbTargetCache\n} from './indexeddb_target_cache';\nimport { LocalSerializer } from './local_serializer';\nimport {\n  ActiveTargets,\n  LruDelegate,\n  LruGarbageCollector,\n  LruParams\n} from './lru_garbage_collector';\nimport {\n  Persistence,\n  PersistenceTransaction,\n  PersistenceTransactionMode,\n  PRIMARY_LEASE_LOST_ERROR_MSG,\n  PrimaryStateListener,\n  ReferenceDelegate\n} from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { ClientId } from './shared_client_state';\nimport { TargetData } from './target_data';\nimport {\n  isIndexedDbTransactionError,\n  SimpleDb,\n  SimpleDbStore,\n  SimpleDbTransaction\n} from './simple_db';\nimport { DocumentLike, WindowLike } from '../util/types';\n\nconst LOG_TAG = 'IndexedDbPersistence';\n\n/**\n * Oldest acceptable age in milliseconds for client metadata before the client\n * is considered inactive and its associated data is garbage collected.\n */\nconst MAX_CLIENT_AGE_MS = 30 * 60 * 1000; // 30 minutes\n\n/**\n * Oldest acceptable metadata age for clients that may participate in the\n * primary lease election. Clients that have not updated their client metadata\n * within 5 seconds are not eligible to receive a primary lease.\n */\nconst MAX_PRIMARY_ELIGIBLE_AGE_MS = 5000;\n\n/**\n * The interval at which clients will update their metadata, including\n * refreshing their primary lease if held or potentially trying to acquire it if\n * not held.\n *\n * Primary clients may opportunistically refresh their metadata earlier\n * if they're already performing an IndexedDB operation.\n */\nconst CLIENT_METADATA_REFRESH_INTERVAL_MS = 4000;\n/** User-facing error when the primary lease is required but not available. */\nconst PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG =\n  'Failed to obtain exclusive access to the persistence layer. ' +\n  'To allow shared access, make sure to invoke ' +\n  '`enablePersistence()` with `synchronizeTabs:true` in all tabs. ' +\n  'If you are using `experimentalForceOwningTab:true`, make sure that only ' +\n  'one tab has persistence enabled at any given time.';\nconst UNSUPPORTED_PLATFORM_ERROR_MSG =\n  'This platform is either missing' +\n  ' IndexedDB or is known to have an incomplete implementation. Offline' +\n  ' persistence has been disabled.';\n\n// The format of the LocalStorage key that stores zombied client is:\n//     firestore_zombie_<persistence_prefix>_<instance_key>\nconst ZOMBIED_CLIENTS_KEY_PREFIX = 'firestore_zombie';\n\n/**\n * The name of the main (and currently only) IndexedDB database. This name is\n * appended to the prefix provided to the IndexedDbPersistence constructor.\n */\nexport const MAIN_DATABASE = 'main';\n\nexport class IndexedDbTransaction extends PersistenceTransaction {\n  constructor(\n    readonly simpleDbTransaction: SimpleDbTransaction,\n    readonly currentSequenceNumber: ListenSequenceNumber\n  ) {\n    super();\n  }\n}\n\n/**\n * An IndexedDB-backed instance of Persistence. Data is stored persistently\n * across sessions.\n *\n * On Web only, the Firestore SDKs support shared access to its persistence\n * layer. This allows multiple browser tabs to read and write to IndexedDb and\n * to synchronize state even without network connectivity. Shared access is\n * currently optional and not enabled unless all clients invoke\n * `enablePersistence()` with `{synchronizeTabs:true}`.\n *\n * In multi-tab mode, if multiple clients are active at the same time, the SDK\n * will designate one client as the primary client. An effort is made to pick\n * a visible, network-connected and active client, and this client is\n * responsible for letting other clients know about its presence. The primary\n * client writes a unique client-generated identifier (the client ID) to\n * IndexedDbs owner store every 4 seconds. If the primary client fails to\n * update this entry, another client can acquire the lease and take over as\n * primary.\n *\n * Some persistence operations in the SDK are designated as primary-client only\n * operations. This includes the acknowledgment of mutations and all updates of\n * remote documents. The effects of these operations are written to persistence\n * and then broadcast to other tabs via LocalStorage (see\n * `WebStorageSharedClientState`), which then refresh their state from\n * persistence.\n *\n * Similarly, the primary client listens to notifications sent by secondary\n * clients to discover persistence changes written by secondary clients, such as\n * the addition of new mutations and query targets.\n *\n * If multi-tab is not enabled and another tab already obtained the primary\n * lease, IndexedDbPersistence enters a failed state and all subsequent\n * operations will automatically fail.\n *\n * Additionally, there is an optimization so that when a tab is closed, the\n * primary lease is released immediately (this is especially important to make\n * sure that a refreshed tab is able to immediately re-acquire the primary\n * lease). Unfortunately, IndexedDB cannot be reliably used in window.unload\n * since it is an asynchronous API. So in addition to attempting to give up the\n * lease, the leaseholder writes its client ID to a \"zombiedClient\" entry in\n * LocalStorage which acts as an indicator that another tab should go ahead and\n * take the primary lease immediately regardless of the current lease timestamp.\n *\n * TODO(b/114226234): Remove `synchronizeTabs` section when multi-tab is no\n * longer optional.\n */\nexport class IndexedDbPersistence implements Persistence {\n  static getStore<Key extends IDBValidKey, Value>(\n    txn: PersistenceTransaction,\n    store: string\n  ): SimpleDbStore<Key, Value> {\n    if (txn instanceof IndexedDbTransaction) {\n      return SimpleDb.getStore<Key, Value>(txn.simpleDbTransaction, store);\n    } else {\n      throw fail(\n        'IndexedDbPersistence must use instances of IndexedDbTransaction'\n      );\n    }\n  }\n\n  private simpleDb: SimpleDb;\n\n  private listenSequence: ListenSequence | null = null;\n\n  private _started = false;\n  private isPrimary = false;\n  private networkEnabled = true;\n  private dbName: string;\n\n  /** Our window.unload handler, if registered. */\n  private windowUnloadHandler: (() => void) | null = null;\n  private inForeground = false;\n\n  private serializer: LocalSerializer;\n\n  /** Our 'visibilitychange' listener if registered. */\n  private documentVisibilityHandler: ((e?: Event) => void) | null = null;\n\n  /** The client metadata refresh task. */\n  private clientMetadataRefresher: DelayedOperation<void> | null = null;\n\n  /** The last time we garbage collected the client metadata object store. */\n  private lastGarbageCollectionTime = Number.NEGATIVE_INFINITY;\n\n  /** A listener to notify on primary state changes. */\n  private primaryStateListener: PrimaryStateListener = _ => Promise.resolve();\n\n  private readonly targetCache: IndexedDbTargetCache;\n  private readonly indexManager: IndexedDbIndexManager;\n  private readonly remoteDocumentCache: IndexedDbRemoteDocumentCache;\n  private readonly webStorage: Storage | null;\n  readonly referenceDelegate: IndexedDbLruDelegate;\n\n  constructor(\n    /**\n     * Whether to synchronize the in-memory state of multiple tabs and share\n     * access to local persistence.\n     */\n    private readonly allowTabSynchronization: boolean,\n\n    private readonly persistenceKey: string,\n    private readonly clientId: ClientId,\n    lruParams: LruParams,\n    private readonly queue: AsyncQueue,\n    private readonly window: WindowLike | null,\n    private readonly document: DocumentLike | null,\n    serializer: JsonProtoSerializer,\n    private readonly sequenceNumberSyncer: SequenceNumberSyncer,\n\n    /**\n     * If set to true, forcefully obtains database access. Existing tabs will\n     * no longer be able to access IndexedDB.\n     */\n    private readonly forceOwningTab: boolean\n  ) {\n    if (!IndexedDbPersistence.isAvailable()) {\n      throw new FirestoreError(\n        Code.UNIMPLEMENTED,\n        UNSUPPORTED_PLATFORM_ERROR_MSG\n      );\n    }\n\n    this.referenceDelegate = new IndexedDbLruDelegate(this, lruParams);\n    this.dbName = persistenceKey + MAIN_DATABASE;\n    this.serializer = new LocalSerializer(serializer);\n    this.simpleDb = new SimpleDb(\n      this.dbName,\n      SCHEMA_VERSION,\n      new SchemaConverter(this.serializer)\n    );\n    this.targetCache = new IndexedDbTargetCache(\n      this.referenceDelegate,\n      this.serializer\n    );\n    this.indexManager = new IndexedDbIndexManager();\n    this.remoteDocumentCache = new IndexedDbRemoteDocumentCache(\n      this.serializer,\n      this.indexManager\n    );\n    if (this.window && this.window.localStorage) {\n      this.webStorage = this.window.localStorage;\n    } else {\n      this.webStorage = null;\n      if (forceOwningTab === false) {\n        logError(\n          LOG_TAG,\n          'LocalStorage is unavailable. As a result, persistence may not work ' +\n            'reliably. In particular enablePersistence() could fail immediately ' +\n            'after refreshing the page.'\n        );\n      }\n    }\n  }\n\n  /**\n   * Attempt to start IndexedDb persistence.\n   *\n   * @return {Promise<void>} Whether persistence was enabled.\n   */\n  start(): Promise<void> {\n    debugAssert(!this.started, 'IndexedDbPersistence double-started!');\n    debugAssert(this.window !== null, \"Expected 'window' to be defined\");\n\n    // NOTE: This is expected to fail sometimes (in the case of another tab\n    // already having the persistence lock), so it's the first thing we should\n    // do.\n    return this.updateClientMetadataAndTryBecomePrimary()\n      .then(() => {\n        if (!this.isPrimary && !this.allowTabSynchronization) {\n          // Fail `start()` if `synchronizeTabs` is disabled and we cannot\n          // obtain the primary lease.\n          throw new FirestoreError(\n            Code.FAILED_PRECONDITION,\n            PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG\n          );\n        }\n        this.attachVisibilityHandler();\n        this.attachWindowUnloadHook();\n\n        this.scheduleClientMetadataAndPrimaryLeaseRefreshes();\n\n        return this.runTransaction(\n          'getHighestListenSequenceNumber',\n          'readonly',\n          txn => this.targetCache.getHighestSequenceNumber(txn)\n        );\n      })\n      .then(highestListenSequenceNumber => {\n        this.listenSequence = new ListenSequence(\n          highestListenSequenceNumber,\n          this.sequenceNumberSyncer\n        );\n      })\n      .then(() => {\n        this._started = true;\n      })\n      .catch(reason => {\n        this.simpleDb && this.simpleDb.close();\n        return Promise.reject(reason);\n      });\n  }\n\n  /**\n   * Registers a listener that gets called when the primary state of the\n   * instance changes. Upon registering, this listener is invoked immediately\n   * with the current primary state.\n   *\n   * PORTING NOTE: This is only used for Web multi-tab.\n   */\n  setPrimaryStateListener(\n    primaryStateListener: PrimaryStateListener\n  ): Promise<void> {\n    this.primaryStateListener = async primaryState => {\n      if (this.started) {\n        return primaryStateListener(primaryState);\n      }\n    };\n    return primaryStateListener(this.isPrimary);\n  }\n\n  /**\n   * Registers a listener that gets called when the database receives a\n   * version change event indicating that it has deleted.\n   *\n   * PORTING NOTE: This is only used for Web multi-tab.\n   */\n  setDatabaseDeletedListener(\n    databaseDeletedListener: () => Promise<void>\n  ): void {\n    this.simpleDb.setVersionChangeListener(async event => {\n      // Check if an attempt is made to delete IndexedDB.\n      if (event.newVersion === null) {\n        await databaseDeletedListener();\n      }\n    });\n  }\n\n  /**\n   * Adjusts the current network state in the client's metadata, potentially\n   * affecting the primary lease.\n   *\n   * PORTING NOTE: This is only used for Web multi-tab.\n   */\n  setNetworkEnabled(networkEnabled: boolean): void {\n    if (this.networkEnabled !== networkEnabled) {\n      this.networkEnabled = networkEnabled;\n      // Schedule a primary lease refresh for immediate execution. The eventual\n      // lease update will be propagated via `primaryStateListener`.\n      this.queue.enqueueAndForget(async () => {\n        if (this.started) {\n          await this.updateClientMetadataAndTryBecomePrimary();\n        }\n      });\n    }\n  }\n\n  /**\n   * Updates the client metadata in IndexedDb and attempts to either obtain or\n   * extend the primary lease for the local client. Asynchronously notifies the\n   * primary state listener if the client either newly obtained or released its\n   * primary lease.\n   */\n  private updateClientMetadataAndTryBecomePrimary(): Promise<void> {\n    return this.runTransaction(\n      'updateClientMetadataAndTryBecomePrimary',\n      'readwrite',\n      txn => {\n        const metadataStore = clientMetadataStore(txn);\n        return metadataStore\n          .put(\n            new DbClientMetadata(\n              this.clientId,\n              Date.now(),\n              this.networkEnabled,\n              this.inForeground\n            )\n          )\n          .next(() => {\n            if (this.isPrimary) {\n              return this.verifyPrimaryLease(txn).next(success => {\n                if (!success) {\n                  this.isPrimary = false;\n                  this.queue.enqueueRetryable(() =>\n                    this.primaryStateListener(false)\n                  );\n                }\n              });\n            }\n          })\n          .next(() => this.canActAsPrimary(txn))\n          .next(canActAsPrimary => {\n            if (this.isPrimary && !canActAsPrimary) {\n              return this.releasePrimaryLeaseIfHeld(txn).next(() => false);\n            } else if (canActAsPrimary) {\n              return this.acquireOrExtendPrimaryLease(txn).next(() => true);\n            } else {\n              return /* canActAsPrimary= */ false;\n            }\n          });\n      }\n    )\n      .catch(e => {\n        if (isIndexedDbTransactionError(e)) {\n          logDebug(LOG_TAG, 'Failed to extend owner lease: ', e);\n          // Proceed with the existing state. Any subsequent access to\n          // IndexedDB will verify the lease.\n          return this.isPrimary;\n        }\n\n        if (!this.allowTabSynchronization) {\n          throw e;\n        }\n\n        logDebug(\n          LOG_TAG,\n          'Releasing owner lease after error during lease refresh',\n          e\n        );\n        return /* isPrimary= */ false;\n      })\n      .then(isPrimary => {\n        if (this.isPrimary !== isPrimary) {\n          this.queue.enqueueRetryable(() =>\n            this.primaryStateListener(isPrimary)\n          );\n        }\n        this.isPrimary = isPrimary;\n      });\n  }\n\n  private verifyPrimaryLease(\n    txn: PersistenceTransaction\n  ): PersistencePromise<boolean> {\n    const store = primaryClientStore(txn);\n    return store.get(DbPrimaryClient.key).next(primaryClient => {\n      return PersistencePromise.resolve(this.isLocalClient(primaryClient));\n    });\n  }\n\n  private removeClientMetadata(\n    txn: PersistenceTransaction\n  ): PersistencePromise<void> {\n    const metadataStore = clientMetadataStore(txn);\n    return metadataStore.delete(this.clientId);\n  }\n\n  /**\n   * If the garbage collection threshold has passed, prunes the\n   * RemoteDocumentChanges and the ClientMetadata store based on the last update\n   * time of all clients.\n   */\n  private async maybeGarbageCollectMultiClientState(): Promise<void> {\n    if (\n      this.isPrimary &&\n      !this.isWithinAge(this.lastGarbageCollectionTime, MAX_CLIENT_AGE_MS)\n    ) {\n      this.lastGarbageCollectionTime = Date.now();\n\n      const inactiveClients = await this.runTransaction(\n        'maybeGarbageCollectMultiClientState',\n        'readwrite-primary',\n        txn => {\n          const metadataStore = IndexedDbPersistence.getStore<\n            DbClientMetadataKey,\n            DbClientMetadata\n          >(txn, DbClientMetadata.store);\n\n          return metadataStore.loadAll().next(existingClients => {\n            const active = this.filterActiveClients(\n              existingClients,\n              MAX_CLIENT_AGE_MS\n            );\n            const inactive = existingClients.filter(\n              client => active.indexOf(client) === -1\n            );\n\n            // Delete metadata for clients that are no longer considered active.\n            return PersistencePromise.forEach(\n              inactive,\n              (inactiveClient: DbClientMetadata) =>\n                metadataStore.delete(inactiveClient.clientId)\n            ).next(() => inactive);\n          });\n        }\n      ).catch(() => {\n        // Ignore primary lease violations or any other type of error. The next\n        // primary will run `maybeGarbageCollectMultiClientState()` again.\n        // We don't use `ignoreIfPrimaryLeaseLoss()` since we don't want to depend\n        // on LocalStore.\n        return [];\n      });\n\n      // Delete potential leftover entries that may continue to mark the\n      // inactive clients as zombied in LocalStorage.\n      // Ideally we'd delete the IndexedDb and LocalStorage zombie entries for\n      // the client atomically, but we can't. So we opt to delete the IndexedDb\n      // entries first to avoid potentially reviving a zombied client.\n      if (this.webStorage) {\n        for (const inactiveClient of inactiveClients) {\n          this.webStorage.removeItem(\n            this.zombiedClientLocalStorageKey(inactiveClient.clientId)\n          );\n        }\n      }\n    }\n  }\n\n  /**\n   * Schedules a recurring timer to update the client metadata and to either\n   * extend or acquire the primary lease if the client is eligible.\n   */\n  private scheduleClientMetadataAndPrimaryLeaseRefreshes(): void {\n    this.clientMetadataRefresher = this.queue.enqueueAfterDelay(\n      TimerId.ClientMetadataRefresh,\n      CLIENT_METADATA_REFRESH_INTERVAL_MS,\n      () => {\n        return this.updateClientMetadataAndTryBecomePrimary()\n          .then(() => this.maybeGarbageCollectMultiClientState())\n          .then(() => this.scheduleClientMetadataAndPrimaryLeaseRefreshes());\n      }\n    );\n  }\n\n  /** Checks whether `client` is the local client. */\n  private isLocalClient(client: DbPrimaryClient | null): boolean {\n    return client ? client.ownerId === this.clientId : false;\n  }\n\n  /**\n   * Evaluate the state of all active clients and determine whether the local\n   * client is or can act as the holder of the primary lease. Returns whether\n   * the client is eligible for the lease, but does not actually acquire it.\n   * May return 'false' even if there is no active leaseholder and another\n   * (foreground) client should become leaseholder instead.\n   */\n  private canActAsPrimary(\n    txn: PersistenceTransaction\n  ): PersistencePromise<boolean> {\n    if (this.forceOwningTab) {\n      return PersistencePromise.resolve<boolean>(true);\n    }\n    const store = primaryClientStore(txn);\n    return store\n      .get(DbPrimaryClient.key)\n      .next(currentPrimary => {\n        const currentLeaseIsValid =\n          currentPrimary !== null &&\n          this.isWithinAge(\n            currentPrimary.leaseTimestampMs,\n            MAX_PRIMARY_ELIGIBLE_AGE_MS\n          ) &&\n          !this.isClientZombied(currentPrimary.ownerId);\n\n        // A client is eligible for the primary lease if:\n        // - its network is enabled and the client's tab is in the foreground.\n        // - its network is enabled and no other client's tab is in the\n        //   foreground.\n        // - every clients network is disabled and the client's tab is in the\n        //   foreground.\n        // - every clients network is disabled and no other client's tab is in\n        //   the foreground.\n        // - the `forceOwningTab` setting was passed in.\n        if (currentLeaseIsValid) {\n          if (this.isLocalClient(currentPrimary) && this.networkEnabled) {\n            return true;\n          }\n\n          if (!this.isLocalClient(currentPrimary)) {\n            if (!currentPrimary!.allowTabSynchronization) {\n              // Fail the `canActAsPrimary` check if the current leaseholder has\n              // not opted into multi-tab synchronization. If this happens at\n              // client startup, we reject the Promise returned by\n              // `enablePersistence()` and the user can continue to use Firestore\n              // with in-memory persistence.\n              // If this fails during a lease refresh, we will instead block the\n              // AsyncQueue from executing further operations. Note that this is\n              // acceptable since mixing & matching different `synchronizeTabs`\n              // settings is not supported.\n              //\n              // TODO(b/114226234): Remove this check when `synchronizeTabs` can\n              // no longer be turned off.\n              throw new FirestoreError(\n                Code.FAILED_PRECONDITION,\n                PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG\n              );\n            }\n\n            return false;\n          }\n        }\n\n        if (this.networkEnabled && this.inForeground) {\n          return true;\n        }\n\n        return clientMetadataStore(txn)\n          .loadAll()\n          .next(existingClients => {\n            // Process all existing clients and determine whether at least one of\n            // them is better suited to obtain the primary lease.\n            const preferredCandidate = this.filterActiveClients(\n              existingClients,\n              MAX_PRIMARY_ELIGIBLE_AGE_MS\n            ).find(otherClient => {\n              if (this.clientId !== otherClient.clientId) {\n                const otherClientHasBetterNetworkState =\n                  !this.networkEnabled && otherClient.networkEnabled;\n                const otherClientHasBetterVisibility =\n                  !this.inForeground && otherClient.inForeground;\n                const otherClientHasSameNetworkState =\n                  this.networkEnabled === otherClient.networkEnabled;\n                if (\n                  otherClientHasBetterNetworkState ||\n                  (otherClientHasBetterVisibility &&\n                    otherClientHasSameNetworkState)\n                ) {\n                  return true;\n                }\n              }\n              return false;\n            });\n            return preferredCandidate === undefined;\n          });\n      })\n      .next(canActAsPrimary => {\n        if (this.isPrimary !== canActAsPrimary) {\n          logDebug(\n            LOG_TAG,\n            `Client ${\n              canActAsPrimary ? 'is' : 'is not'\n            } eligible for a primary lease.`\n          );\n        }\n        return canActAsPrimary;\n      });\n  }\n\n  async shutdown(): Promise<void> {\n    // The shutdown() operations are idempotent and can be called even when\n    // start() aborted (e.g. because it couldn't acquire the persistence lease).\n    this._started = false;\n\n    this.markClientZombied();\n    if (this.clientMetadataRefresher) {\n      this.clientMetadataRefresher.cancel();\n      this.clientMetadataRefresher = null;\n    }\n    this.detachVisibilityHandler();\n    this.detachWindowUnloadHook();\n    await this.runTransaction('shutdown', 'readwrite', txn => {\n      return this.releasePrimaryLeaseIfHeld(txn).next(() =>\n        this.removeClientMetadata(txn)\n      );\n    }).catch(e => {\n      logDebug(LOG_TAG, 'Proceeding with shutdown despite failure: ', e);\n    });\n    this.simpleDb.close();\n\n    // Remove the entry marking the client as zombied from LocalStorage since\n    // we successfully deleted its metadata from IndexedDb.\n    this.removeClientZombiedEntry();\n  }\n\n  /**\n   * Returns clients that are not zombied and have an updateTime within the\n   * provided threshold.\n   */\n  private filterActiveClients(\n    clients: DbClientMetadata[],\n    activityThresholdMs: number\n  ): DbClientMetadata[] {\n    return clients.filter(\n      client =>\n        this.isWithinAge(client.updateTimeMs, activityThresholdMs) &&\n        !this.isClientZombied(client.clientId)\n    );\n  }\n\n  /**\n   * Returns the IDs of the clients that are currently active. If multi-tab\n   * is not supported, returns an array that only contains the local client's\n   * ID.\n   *\n   * PORTING NOTE: This is only used for Web multi-tab.\n   */\n  getActiveClients(): Promise<ClientId[]> {\n    return this.runTransaction('getActiveClients', 'readonly', txn => {\n      return clientMetadataStore(txn)\n        .loadAll()\n        .next(clients =>\n          this.filterActiveClients(clients, MAX_CLIENT_AGE_MS).map(\n            clientMetadata => clientMetadata.clientId\n          )\n        );\n    });\n  }\n\n  get started(): boolean {\n    return this._started;\n  }\n\n  getMutationQueue(user: User): IndexedDbMutationQueue {\n    debugAssert(\n      this.started,\n      'Cannot initialize MutationQueue before persistence is started.'\n    );\n    return IndexedDbMutationQueue.forUser(\n      user,\n      this.serializer,\n      this.indexManager,\n      this.referenceDelegate\n    );\n  }\n\n  getTargetCache(): IndexedDbTargetCache {\n    debugAssert(\n      this.started,\n      'Cannot initialize TargetCache before persistence is started.'\n    );\n    return this.targetCache;\n  }\n\n  getRemoteDocumentCache(): IndexedDbRemoteDocumentCache {\n    debugAssert(\n      this.started,\n      'Cannot initialize RemoteDocumentCache before persistence is started.'\n    );\n    return this.remoteDocumentCache;\n  }\n\n  getIndexManager(): IndexedDbIndexManager {\n    debugAssert(\n      this.started,\n      'Cannot initialize IndexManager before persistence is started.'\n    );\n    return this.indexManager;\n  }\n\n  runTransaction<T>(\n    action: string,\n    mode: PersistenceTransactionMode,\n    transactionOperation: (\n      transaction: PersistenceTransaction\n    ) => PersistencePromise<T>\n  ): Promise<T> {\n    logDebug(LOG_TAG, 'Starting transaction:', action);\n\n    const simpleDbMode = mode === 'readonly' ? 'readonly' : 'readwrite';\n\n    let persistenceTransaction: PersistenceTransaction;\n\n    // Do all transactions as readwrite against all object stores, since we\n    // are the only reader/writer.\n    return this.simpleDb\n      .runTransaction(simpleDbMode, ALL_STORES, simpleDbTxn => {\n        persistenceTransaction = new IndexedDbTransaction(\n          simpleDbTxn,\n          this.listenSequence\n            ? this.listenSequence.next()\n            : ListenSequence.INVALID\n        );\n\n        if (mode === 'readwrite-primary') {\n          // While we merely verify that we have (or can acquire) the lease\n          // immediately, we wait to extend the primary lease until after\n          // executing transactionOperation(). This ensures that even if the\n          // transactionOperation takes a long time, we'll use a recent\n          // leaseTimestampMs in the extended (or newly acquired) lease.\n          return this.verifyPrimaryLease(persistenceTransaction)\n            .next(holdsPrimaryLease => {\n              if (holdsPrimaryLease) {\n                return /* holdsPrimaryLease= */ true;\n              }\n              return this.canActAsPrimary(persistenceTransaction);\n            })\n            .next(holdsPrimaryLease => {\n              if (!holdsPrimaryLease) {\n                logError(\n                  `Failed to obtain primary lease for action '${action}'.`\n                );\n                this.isPrimary = false;\n                this.queue.enqueueRetryable(() =>\n                  this.primaryStateListener(false)\n                );\n                throw new FirestoreError(\n                  Code.FAILED_PRECONDITION,\n                  PRIMARY_LEASE_LOST_ERROR_MSG\n                );\n              }\n              return transactionOperation(persistenceTransaction);\n            })\n            .next(result => {\n              return this.acquireOrExtendPrimaryLease(\n                persistenceTransaction\n              ).next(() => result);\n            });\n        } else {\n          return this.verifyAllowTabSynchronization(\n            persistenceTransaction\n          ).next(() => transactionOperation(persistenceTransaction));\n        }\n      })\n      .then(result => {\n        persistenceTransaction.raiseOnCommittedEvent();\n        return result;\n      });\n  }\n\n  /**\n   * Verifies that the current tab is the primary leaseholder or alternatively\n   * that the leaseholder has opted into multi-tab synchronization.\n   */\n  // TODO(b/114226234): Remove this check when `synchronizeTabs` can no longer\n  // be turned off.\n  private verifyAllowTabSynchronization(\n    txn: PersistenceTransaction\n  ): PersistencePromise<void> {\n    const store = primaryClientStore(txn);\n    return store.get(DbPrimaryClient.key).next(currentPrimary => {\n      const currentLeaseIsValid =\n        currentPrimary !== null &&\n        this.isWithinAge(\n          currentPrimary.leaseTimestampMs,\n          MAX_PRIMARY_ELIGIBLE_AGE_MS\n        ) &&\n        !this.isClientZombied(currentPrimary.ownerId);\n\n      if (currentLeaseIsValid && !this.isLocalClient(currentPrimary)) {\n        if (\n          !this.forceOwningTab &&\n          (!this.allowTabSynchronization ||\n            !currentPrimary!.allowTabSynchronization)\n        ) {\n          throw new FirestoreError(\n            Code.FAILED_PRECONDITION,\n            PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG\n          );\n        }\n      }\n    });\n  }\n\n  /**\n   * Obtains or extends the new primary lease for the local client. This\n   * method does not verify that the client is eligible for this lease.\n   */\n  private acquireOrExtendPrimaryLease(\n    txn: PersistenceTransaction\n  ): PersistencePromise<void> {\n    const newPrimary = new DbPrimaryClient(\n      this.clientId,\n      this.allowTabSynchronization,\n      Date.now()\n    );\n    return primaryClientStore(txn).put(DbPrimaryClient.key, newPrimary);\n  }\n\n  static isAvailable(): boolean {\n    return SimpleDb.isAvailable();\n  }\n\n  /** Checks the primary lease and removes it if we are the current primary. */\n  private releasePrimaryLeaseIfHeld(\n    txn: PersistenceTransaction\n  ): PersistencePromise<void> {\n    const store = primaryClientStore(txn);\n    return store.get(DbPrimaryClient.key).next(primaryClient => {\n      if (this.isLocalClient(primaryClient)) {\n        logDebug(LOG_TAG, 'Releasing primary lease.');\n        return store.delete(DbPrimaryClient.key);\n      } else {\n        return PersistencePromise.resolve();\n      }\n    });\n  }\n\n  /** Verifies that `updateTimeMs` is within `maxAgeMs`. */\n  private isWithinAge(updateTimeMs: number, maxAgeMs: number): boolean {\n    const now = Date.now();\n    const minAcceptable = now - maxAgeMs;\n    const maxAcceptable = now;\n    if (updateTimeMs < minAcceptable) {\n      return false;\n    } else if (updateTimeMs > maxAcceptable) {\n      logError(\n        `Detected an update time that is in the future: ${updateTimeMs} > ${maxAcceptable}`\n      );\n      return false;\n    }\n\n    return true;\n  }\n\n  private attachVisibilityHandler(): void {\n    if (\n      this.document !== null &&\n      typeof this.document.addEventListener === 'function'\n    ) {\n      this.documentVisibilityHandler = () => {\n        this.queue.enqueueAndForget(() => {\n          this.inForeground = this.document!.visibilityState === 'visible';\n          return this.updateClientMetadataAndTryBecomePrimary();\n        });\n      };\n\n      this.document.addEventListener(\n        'visibilitychange',\n        this.documentVisibilityHandler\n      );\n\n      this.inForeground = this.document.visibilityState === 'visible';\n    }\n  }\n\n  private detachVisibilityHandler(): void {\n    if (this.documentVisibilityHandler) {\n      debugAssert(\n        this.document !== null &&\n          typeof this.document.addEventListener === 'function',\n        \"Expected 'document.addEventListener' to be a function\"\n      );\n      this.document.removeEventListener(\n        'visibilitychange',\n        this.documentVisibilityHandler\n      );\n      this.documentVisibilityHandler = null;\n    }\n  }\n\n  /**\n   * Attaches a window.unload handler that will synchronously write our\n   * clientId to a \"zombie client id\" location in LocalStorage. This can be used\n   * by tabs trying to acquire the primary lease to determine that the lease\n   * is no longer valid even if the timestamp is recent. This is particularly\n   * important for the refresh case (so the tab correctly re-acquires the\n   * primary lease). LocalStorage is used for this rather than IndexedDb because\n   * it is a synchronous API and so can be used reliably from  an unload\n   * handler.\n   */\n  private attachWindowUnloadHook(): void {\n    if (typeof this.window?.addEventListener === 'function') {\n      this.windowUnloadHandler = () => {\n        // Note: In theory, this should be scheduled on the AsyncQueue since it\n        // accesses internal state. We execute this code directly during shutdown\n        // to make sure it gets a chance to run.\n        this.markClientZombied();\n\n        this.queue.enqueueAndForget(() => {\n          // Attempt graceful shutdown (including releasing our primary lease),\n          // but there's no guarantee it will complete.\n          return this.shutdown();\n        });\n      };\n      this.window.addEventListener('unload', this.windowUnloadHandler);\n    }\n  }\n\n  private detachWindowUnloadHook(): void {\n    if (this.windowUnloadHandler) {\n      debugAssert(\n        typeof this.window?.removeEventListener === 'function',\n        \"Expected 'window.removeEventListener' to be a function\"\n      );\n      this.window!.removeEventListener('unload', this.windowUnloadHandler);\n      this.windowUnloadHandler = null;\n    }\n  }\n\n  /**\n   * Returns whether a client is \"zombied\" based on its LocalStorage entry.\n   * Clients become zombied when their tab closes without running all of the\n   * cleanup logic in `shutdown()`.\n   */\n  private isClientZombied(clientId: ClientId): boolean {\n    try {\n      const isZombied =\n        this.webStorage?.getItem(\n          this.zombiedClientLocalStorageKey(clientId)\n        ) !== null;\n      logDebug(\n        LOG_TAG,\n        `Client '${clientId}' ${\n          isZombied ? 'is' : 'is not'\n        } zombied in LocalStorage`\n      );\n      return isZombied;\n    } catch (e) {\n      // Gracefully handle if LocalStorage isn't working.\n      logError(LOG_TAG, 'Failed to get zombied client id.', e);\n      return false;\n    }\n  }\n\n  /**\n   * Record client as zombied (a client that had its tab closed). Zombied\n   * clients are ignored during primary tab selection.\n   */\n  private markClientZombied(): void {\n    if (!this.webStorage) {\n      return;\n    }\n    try {\n      this.webStorage.setItem(\n        this.zombiedClientLocalStorageKey(this.clientId),\n        String(Date.now())\n      );\n    } catch (e) {\n      // Gracefully handle if LocalStorage isn't available / working.\n      logError('Failed to set zombie client id.', e);\n    }\n  }\n\n  /** Removes the zombied client entry if it exists. */\n  private removeClientZombiedEntry(): void {\n    if (!this.webStorage) {\n      return;\n    }\n    try {\n      this.webStorage.removeItem(\n        this.zombiedClientLocalStorageKey(this.clientId)\n      );\n    } catch (e) {\n      // Ignore\n    }\n  }\n\n  private zombiedClientLocalStorageKey(clientId: ClientId): string {\n    return `${ZOMBIED_CLIENTS_KEY_PREFIX}_${this.persistenceKey}_${clientId}`;\n  }\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the primary client object store.\n */\nfunction primaryClientStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbPrimaryClientKey, DbPrimaryClient> {\n  return IndexedDbPersistence.getStore<DbPrimaryClientKey, DbPrimaryClient>(\n    txn,\n    DbPrimaryClient.store\n  );\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the client metadata object store.\n */\nfunction clientMetadataStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbClientMetadataKey, DbClientMetadata> {\n  return IndexedDbPersistence.getStore<DbClientMetadataKey, DbClientMetadata>(\n    txn,\n    DbClientMetadata.store\n  );\n}\n\n/** Provides LRU functionality for IndexedDB persistence. */\nexport class IndexedDbLruDelegate implements ReferenceDelegate, LruDelegate {\n  readonly garbageCollector: LruGarbageCollector;\n\n  constructor(private readonly db: IndexedDbPersistence, params: LruParams) {\n    this.garbageCollector = new LruGarbageCollector(this, params);\n  }\n\n  getSequenceNumberCount(\n    txn: PersistenceTransaction\n  ): PersistencePromise<number> {\n    const docCountPromise = this.orphanedDocumentCount(txn);\n    const targetCountPromise = this.db.getTargetCache().getTargetCount(txn);\n    return targetCountPromise.next(targetCount =>\n      docCountPromise.next(docCount => targetCount + docCount)\n    );\n  }\n\n  private orphanedDocumentCount(\n    txn: PersistenceTransaction\n  ): PersistencePromise<number> {\n    let orphanedCount = 0;\n    return this.forEachOrphanedDocumentSequenceNumber(txn, _ => {\n      orphanedCount++;\n    }).next(() => orphanedCount);\n  }\n\n  forEachTarget(\n    txn: PersistenceTransaction,\n    f: (q: TargetData) => void\n  ): PersistencePromise<void> {\n    return this.db.getTargetCache().forEachTarget(txn, f);\n  }\n\n  forEachOrphanedDocumentSequenceNumber(\n    txn: PersistenceTransaction,\n    f: (sequenceNumber: ListenSequenceNumber) => void\n  ): PersistencePromise<void> {\n    return this.forEachOrphanedDocument(txn, (docKey, sequenceNumber) =>\n      f(sequenceNumber)\n    );\n  }\n\n  addReference(\n    txn: PersistenceTransaction,\n    targetId: TargetId,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    return writeSentinelKey(txn, key);\n  }\n\n  removeReference(\n    txn: PersistenceTransaction,\n    targetId: TargetId,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    return writeSentinelKey(txn, key);\n  }\n\n  removeTargets(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<number> {\n    return this.db\n      .getTargetCache()\n      .removeTargets(txn, upperBound, activeTargetIds);\n  }\n\n  markPotentiallyOrphaned(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    return writeSentinelKey(txn, key);\n  }\n\n  /**\n   * Returns true if anything would prevent this document from being garbage\n   * collected, given that the document in question is not present in any\n   * targets and has a sequence number less than or equal to the upper bound for\n   * the collection run.\n   */\n  private isPinned(\n    txn: PersistenceTransaction,\n    docKey: DocumentKey\n  ): PersistencePromise<boolean> {\n    return mutationQueuesContainKey(txn, docKey);\n  }\n\n  removeOrphanedDocuments(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber\n  ): PersistencePromise<number> {\n    const documentCache = this.db.getRemoteDocumentCache();\n    const changeBuffer = documentCache.newChangeBuffer();\n\n    const promises: Array<PersistencePromise<void>> = [];\n    let documentCount = 0;\n\n    const iteration = this.forEachOrphanedDocument(\n      txn,\n      (docKey, sequenceNumber) => {\n        if (sequenceNumber <= upperBound) {\n          const p = this.isPinned(txn, docKey).next(isPinned => {\n            if (!isPinned) {\n              documentCount++;\n              // Our size accounting requires us to read all documents before\n              // removing them.\n              return changeBuffer.getEntry(txn, docKey).next(() => {\n                changeBuffer.removeEntry(docKey);\n                return documentTargetStore(txn).delete(sentinelKey(docKey));\n              });\n            }\n          });\n          promises.push(p);\n        }\n      }\n    );\n\n    return iteration\n      .next(() => PersistencePromise.waitFor(promises))\n      .next(() => changeBuffer.apply(txn))\n      .next(() => documentCount);\n  }\n\n  removeTarget(\n    txn: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    const updated = targetData.withSequenceNumber(txn.currentSequenceNumber);\n    return this.db.getTargetCache().updateTargetData(txn, updated);\n  }\n\n  updateLimboDocument(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    return writeSentinelKey(txn, key);\n  }\n\n  /**\n   * Call provided function for each document in the cache that is 'orphaned'. Orphaned\n   * means not a part of any target, so the only entry in the target-document index for\n   * that document will be the sentinel row (targetId 0), which will also have the sequence\n   * number for the last time the document was accessed.\n   */\n  private forEachOrphanedDocument(\n    txn: PersistenceTransaction,\n    f: (docKey: DocumentKey, sequenceNumber: ListenSequenceNumber) => void\n  ): PersistencePromise<void> {\n    const store = documentTargetStore(txn);\n    let nextToReport: ListenSequenceNumber = ListenSequence.INVALID;\n    let nextPath: EncodedResourcePath;\n    return store\n      .iterate(\n        {\n          index: DbTargetDocument.documentTargetsIndex\n        },\n        ([targetId, docKey], { path, sequenceNumber }) => {\n          if (targetId === 0) {\n            // if nextToReport is valid, report it, this is a new key so the\n            // last one must not be a member of any targets.\n            if (nextToReport !== ListenSequence.INVALID) {\n              f(new DocumentKey(decodeResourcePath(nextPath)), nextToReport);\n            }\n            // set nextToReport to be this sequence number. It's the next one we\n            // might report, if we don't find any targets for this document.\n            // Note that the sequence number must be defined when the targetId\n            // is 0.\n            nextToReport = sequenceNumber!;\n            nextPath = path;\n          } else {\n            // set nextToReport to be invalid, we know we don't need to report\n            // this one since we found a target for it.\n            nextToReport = ListenSequence.INVALID;\n          }\n        }\n      )\n      .next(() => {\n        // Since we report sequence numbers after getting to the next key, we\n        // need to check if the last key we iterated over was an orphaned\n        // document and report it.\n        if (nextToReport !== ListenSequence.INVALID) {\n          f(new DocumentKey(decodeResourcePath(nextPath)), nextToReport);\n        }\n      });\n  }\n\n  getCacheSize(txn: PersistenceTransaction): PersistencePromise<number> {\n    return this.db.getRemoteDocumentCache().getSize(txn);\n  }\n}\n\nfunction sentinelKey(key: DocumentKey): [TargetId, EncodedResourcePath] {\n  return [0, encodeResourcePath(key.path)];\n}\n\n/**\n * @return A value suitable for writing a sentinel row in the target-document\n * store.\n */\nfunction sentinelRow(\n  key: DocumentKey,\n  sequenceNumber: ListenSequenceNumber\n): DbTargetDocument {\n  return new DbTargetDocument(0, encodeResourcePath(key.path), sequenceNumber);\n}\n\nfunction writeSentinelKey(\n  txn: PersistenceTransaction,\n  key: DocumentKey\n): PersistencePromise<void> {\n  return documentTargetStore(txn).put(\n    sentinelRow(key, txn.currentSequenceNumber)\n  );\n}\n\n/**\n * Generates a string used as a prefix when storing data in IndexedDB and\n * LocalStorage.\n */\nexport function indexedDbStoragePrefix(\n  databaseId: DatabaseId,\n  persistenceKey: string\n): string {\n  // Use two different prefix formats:\n  //\n  //   * firestore / persistenceKey / projectID . databaseID / ...\n  //   * firestore / persistenceKey / projectID / ...\n  //\n  // projectIDs are DNS-compatible names and cannot contain dots\n  // so there's no danger of collisions.\n  let database = databaseId.projectId;\n  if (!databaseId.isDefaultDatabase) {\n    database += '.' + databaseId.database;\n  }\n\n  return 'firestore/' + persistenceKey + '/' + database + '/';\n}\n\nexport async function indexedDbClearPersistence(\n  persistenceKey: string\n): Promise<void> {\n  if (!SimpleDb.isAvailable()) {\n    return Promise.resolve();\n  }\n  const dbName = persistenceKey + MAIN_DATABASE;\n  await SimpleDb.delete(dbName);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Timestamp } from '../api/timestamp';\nimport { User } from '../auth/user';\nimport { Query, queryToTarget } from '../core/query';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { canonifyTarget, Target, targetEquals } from '../core/target';\nimport { BatchId, TargetId } from '../core/types';\nimport {\n  DocumentKeySet,\n  documentKeySet,\n  DocumentMap,\n  maybeDocumentMap,\n  MaybeDocumentMap\n} from '../model/collections';\nimport { MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport {\n  Mutation,\n  PatchMutation,\n  Precondition,\n  extractMutationBaseValue\n} from '../model/mutation';\nimport {\n  BATCHID_UNKNOWN,\n  MutationBatch,\n  MutationBatchResult\n} from '../model/mutation_batch';\nimport { RemoteEvent, TargetChange } from '../remote/remote_event';\nimport { debugAssert, debugCast, hardAssert } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { logDebug } from '../util/log';\nimport { primitiveComparator } from '../util/misc';\nimport { ObjectMap } from '../util/obj_map';\nimport { SortedMap } from '../util/sorted_map';\n\nimport { LocalDocumentsView } from './local_documents_view';\nimport { LocalViewChanges } from './local_view_changes';\nimport { LruGarbageCollector, LruResults } from './lru_garbage_collector';\nimport { MutationQueue } from './mutation_queue';\nimport {\n  Persistence,\n  PersistenceTransaction,\n  PRIMARY_LEASE_LOST_ERROR_MSG\n} from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { TargetCache } from './target_cache';\nimport { QueryEngine } from './query_engine';\nimport { RemoteDocumentCache } from './remote_document_cache';\nimport { RemoteDocumentChangeBuffer } from './remote_document_change_buffer';\nimport { ClientId } from './shared_client_state';\nimport { TargetData, TargetPurpose } from './target_data';\nimport { IndexedDbPersistence } from './indexeddb_persistence';\nimport { IndexedDbMutationQueue } from './indexeddb_mutation_queue';\nimport { IndexedDbRemoteDocumentCache } from './indexeddb_remote_document_cache';\nimport { IndexedDbTargetCache } from './indexeddb_target_cache';\nimport { extractFieldMask } from '../model/object_value';\nimport { isIndexedDbTransactionError } from './simple_db';\n\nconst LOG_TAG = 'LocalStore';\n\n/** The result of a write to the local store. */\nexport interface LocalWriteResult {\n  batchId: BatchId;\n  changes: MaybeDocumentMap;\n}\n\n/** The result of a user-change operation in the local store. */\nexport interface UserChangeResult {\n  readonly affectedDocuments: MaybeDocumentMap;\n  readonly removedBatchIds: BatchId[];\n  readonly addedBatchIds: BatchId[];\n}\n\n/** The result of executing a query against the local store. */\nexport interface QueryResult {\n  readonly documents: DocumentMap;\n  readonly remoteKeys: DocumentKeySet;\n}\n\n/**\n * Local storage in the Firestore client. Coordinates persistence components\n * like the mutation queue and remote document cache to present a\n * latency-compensated view of stored data.\n *\n * The LocalStore is responsible for accepting mutations from the Sync Engine.\n * Writes from the client are put into a queue as provisional Mutations until\n * they are processed by the RemoteStore and confirmed as having been written\n * to the server.\n *\n * The local store provides the local version of documents that have been\n * modified locally. It maintains the constraint:\n *\n *   LocalDocument = RemoteDocument + Active(LocalMutations)\n *\n * (Active mutations are those that are enqueued and have not been previously\n * acknowledged or rejected).\n *\n * The RemoteDocument (\"ground truth\") state is provided via the\n * applyChangeBatch method. It will be some version of a server-provided\n * document OR will be a server-provided document PLUS acknowledged mutations:\n *\n *   RemoteDocument' = RemoteDocument + Acknowledged(LocalMutations)\n *\n * Note that this \"dirty\" version of a RemoteDocument will not be identical to a\n * server base version, since it has LocalMutations added to it pending getting\n * an authoritative copy from the server.\n *\n * Since LocalMutations can be rejected by the server, we have to be able to\n * revert a LocalMutation that has already been applied to the LocalDocument\n * (typically done by replaying all remaining LocalMutations to the\n * RemoteDocument to re-apply).\n *\n * The LocalStore is responsible for the garbage collection of the documents it\n * contains. For now, it every doc referenced by a view, the mutation queue, or\n * the RemoteStore.\n *\n * It also maintains the persistence of mapping queries to resume tokens and\n * target ids. It needs to know this data about queries to properly know what\n * docs it would be allowed to garbage collect.\n *\n * The LocalStore must be able to efficiently execute queries against its local\n * cache of the documents, to provide the initial set of results before any\n * remote changes have been received.\n *\n * Note: In TypeScript, most methods return Promises since the implementation\n * may rely on fetching data from IndexedDB which is async.\n * These Promises will only be rejected on an I/O error or other internal\n * (unexpected) failure (e.g. failed assert) and always represent an\n * unrecoverable error (should be caught / reported by the async_queue).\n */\nexport interface LocalStore {\n  /**\n   * Tells the LocalStore that the currently authenticated user has changed.\n   *\n   * In response the local store switches the mutation queue to the new user and\n   * returns any resulting document changes.\n   */\n  // PORTING NOTE: Android and iOS only return the documents affected by the\n  // change.\n  handleUserChange(user: User): Promise<UserChangeResult>;\n\n  /* Accept locally generated Mutations and commit them to storage. */\n  localWrite(mutations: Mutation[]): Promise<LocalWriteResult>;\n\n  /**\n   * Acknowledge the given batch.\n   *\n   * On the happy path when a batch is acknowledged, the local store will\n   *\n   *  + remove the batch from the mutation queue;\n   *  + apply the changes to the remote document cache;\n   *  + recalculate the latency compensated view implied by those changes (there\n   *    may be mutations in the queue that affect the documents but haven't been\n   *    acknowledged yet); and\n   *  + give the changed documents back the sync engine\n   *\n   * @returns The resulting (modified) documents.\n   */\n  acknowledgeBatch(batchResult: MutationBatchResult): Promise<MaybeDocumentMap>;\n\n  /**\n   * Remove mutations from the MutationQueue for the specified batch;\n   * LocalDocuments will be recalculated.\n   *\n   * @returns The resulting modified documents.\n   */\n  rejectBatch(batchId: BatchId): Promise<MaybeDocumentMap>;\n\n  /**\n   * Returns the largest (latest) batch id in mutation queue that is pending\n   * server response.\n   *\n   * Returns `BATCHID_UNKNOWN` if the queue is empty.\n   */\n  getHighestUnacknowledgedBatchId(): Promise<BatchId>;\n\n  /**\n   * Returns the last consistent snapshot processed (used by the RemoteStore to\n   * determine whether to buffer incoming snapshots from the backend).\n   */\n  getLastRemoteSnapshotVersion(): Promise<SnapshotVersion>;\n\n  /**\n   * Update the \"ground-state\" (remote) documents. We assume that the remote\n   * event reflects any write batches that have been acknowledged or rejected\n   * (i.e. we do not re-apply local mutations to updates from this event).\n   *\n   * LocalDocuments are re-calculated if there are remaining mutations in the\n   * queue.\n   */\n  applyRemoteEvent(remoteEvent: RemoteEvent): Promise<MaybeDocumentMap>;\n\n  /**\n   * Notify local store of the changed views to locally pin documents.\n   */\n  notifyLocalViewChanges(viewChanges: LocalViewChanges[]): Promise<void>;\n\n  /**\n   * Gets the mutation batch after the passed in batchId in the mutation queue\n   * or null if empty.\n   * @param afterBatchId If provided, the batch to search after.\n   * @returns The next mutation or null if there wasn't one.\n   */\n  nextMutationBatch(afterBatchId?: BatchId): Promise<MutationBatch | null>;\n\n  /**\n   * Read the current value of a Document with a given key or null if not\n   * found - used for testing.\n   */\n  readDocument(key: DocumentKey): Promise<MaybeDocument | null>;\n\n  /**\n   * Assigns the given target an internal ID so that its results can be pinned so\n   * they don't get GC'd. A target must be allocated in the local store before\n   * the store can be used to manage its view.\n   *\n   * Allocating an already allocated `Target` will return the existing `TargetData`\n   * for that `Target`.\n   */\n  allocateTarget(target: Target): Promise<TargetData>;\n\n  /**\n   * Returns the TargetData as seen by the LocalStore, including updates that may\n   * have not yet been persisted to the TargetCache.\n   */\n  // Visible for testing.\n  getTargetData(\n    transaction: PersistenceTransaction,\n    target: Target\n  ): PersistencePromise<TargetData | null>;\n\n  /**\n   * Unpin all the documents associated with the given target. If\n   * `keepPersistedTargetData` is set to false and Eager GC enabled, the method\n   * directly removes the associated target data from the target cache.\n   *\n   * Releasing a non-existing `Target` is a no-op.\n   */\n  // PORTING NOTE: `keepPersistedTargetData` is multi-tab only.\n  releaseTarget(\n    targetId: number,\n    keepPersistedTargetData: boolean\n  ): Promise<void>;\n\n  /**\n   * Runs the specified query against the local store and returns the results,\n   * potentially taking advantage of query data from previous executions (such\n   * as the set of remote keys).\n   *\n   * @param usePreviousResults Whether results from previous executions can\n   * be used to optimize this query execution.\n   */\n  executeQuery(query: Query, usePreviousResults: boolean): Promise<QueryResult>;\n\n  collectGarbage(garbageCollector: LruGarbageCollector): Promise<LruResults>;\n}\n\n/**\n * Implements `LocalStore` interface.\n *\n * Note: some field defined in this class might have public access level, but\n * the class is not exported so they are only accessible from this module.\n * This is useful to implement optional features (like bundles) in free\n * functions, such that they are tree-shakeable.\n */\nclass LocalStoreImpl implements LocalStore {\n  /**\n   * The maximum time to leave a resume token buffered without writing it out.\n   * This value is arbitrary: it's long enough to avoid several writes\n   * (possibly indefinitely if updates come more frequently than this) but\n   * short enough that restarting after crashing will still have a pretty\n   * recent resume token.\n   */\n  private static readonly RESUME_TOKEN_MAX_AGE_MICROS = 5 * 60 * 1e6;\n\n  /**\n   * The set of all mutations that have been sent but not yet been applied to\n   * the backend.\n   */\n  mutationQueue: MutationQueue;\n\n  /** The set of all cached remote documents. */\n  remoteDocuments: RemoteDocumentCache;\n\n  /**\n   * The \"local\" view of all documents (layering mutationQueue on top of\n   * remoteDocumentCache).\n   */\n  localDocuments: LocalDocumentsView;\n\n  /** Maps a target to its `TargetData`. */\n  targetCache: TargetCache;\n\n  /**\n   * Maps a targetID to data about its target.\n   *\n   * PORTING NOTE: We are using an immutable data structure on Web to make re-runs\n   * of `applyRemoteEvent()` idempotent.\n   */\n  targetDataByTarget = new SortedMap<TargetId, TargetData>(primitiveComparator);\n\n  /** Maps a target to its targetID. */\n  // TODO(wuandy): Evaluate if TargetId can be part of Target.\n  private targetIdByTarget = new ObjectMap<Target, TargetId>(\n    t => canonifyTarget(t),\n    targetEquals\n  );\n\n  /**\n   * The read time of the last entry processed by `getNewDocumentChanges()`.\n   *\n   * PORTING NOTE: This is only used for multi-tab synchronization.\n   */\n  lastDocumentChangeReadTime = SnapshotVersion.min();\n\n  constructor(\n    /** Manages our in-memory or durable persistence. */\n    readonly persistence: Persistence,\n    private queryEngine: QueryEngine,\n    initialUser: User\n  ) {\n    debugAssert(\n      persistence.started,\n      'LocalStore was passed an unstarted persistence implementation'\n    );\n    this.mutationQueue = persistence.getMutationQueue(initialUser);\n    this.remoteDocuments = persistence.getRemoteDocumentCache();\n    this.targetCache = persistence.getTargetCache();\n    this.localDocuments = new LocalDocumentsView(\n      this.remoteDocuments,\n      this.mutationQueue,\n      this.persistence.getIndexManager()\n    );\n    this.queryEngine.setLocalDocumentsView(this.localDocuments);\n  }\n\n  async handleUserChange(user: User): Promise<UserChangeResult> {\n    let newMutationQueue = this.mutationQueue;\n    let newLocalDocuments = this.localDocuments;\n\n    const result = await this.persistence.runTransaction(\n      'Handle user change',\n      'readonly',\n      txn => {\n        // Swap out the mutation queue, grabbing the pending mutation batches\n        // before and after.\n        let oldBatches: MutationBatch[];\n        return this.mutationQueue\n          .getAllMutationBatches(txn)\n          .next(promisedOldBatches => {\n            oldBatches = promisedOldBatches;\n\n            newMutationQueue = this.persistence.getMutationQueue(user);\n\n            // Recreate our LocalDocumentsView using the new\n            // MutationQueue.\n            newLocalDocuments = new LocalDocumentsView(\n              this.remoteDocuments,\n              newMutationQueue,\n              this.persistence.getIndexManager()\n            );\n            return newMutationQueue.getAllMutationBatches(txn);\n          })\n          .next(newBatches => {\n            const removedBatchIds: BatchId[] = [];\n            const addedBatchIds: BatchId[] = [];\n\n            // Union the old/new changed keys.\n            let changedKeys = documentKeySet();\n\n            for (const batch of oldBatches) {\n              removedBatchIds.push(batch.batchId);\n              for (const mutation of batch.mutations) {\n                changedKeys = changedKeys.add(mutation.key);\n              }\n            }\n\n            for (const batch of newBatches) {\n              addedBatchIds.push(batch.batchId);\n              for (const mutation of batch.mutations) {\n                changedKeys = changedKeys.add(mutation.key);\n              }\n            }\n\n            // Return the set of all (potentially) changed documents and the list\n            // of mutation batch IDs that were affected by change.\n            return newLocalDocuments\n              .getDocuments(txn, changedKeys)\n              .next(affectedDocuments => {\n                return {\n                  affectedDocuments,\n                  removedBatchIds,\n                  addedBatchIds\n                };\n              });\n          });\n      }\n    );\n\n    this.mutationQueue = newMutationQueue;\n    this.localDocuments = newLocalDocuments;\n    this.queryEngine.setLocalDocumentsView(this.localDocuments);\n\n    return result;\n  }\n\n  localWrite(mutations: Mutation[]): Promise<LocalWriteResult> {\n    const localWriteTime = Timestamp.now();\n    const keys = mutations.reduce(\n      (keys, m) => keys.add(m.key),\n      documentKeySet()\n    );\n\n    let existingDocs: MaybeDocumentMap;\n\n    return this.persistence\n      .runTransaction('Locally write mutations', 'readwrite', txn => {\n        // Load and apply all existing mutations. This lets us compute the\n        // current base state for all non-idempotent transforms before applying\n        // any additional user-provided writes.\n        return this.localDocuments.getDocuments(txn, keys).next(docs => {\n          existingDocs = docs;\n\n          // For non-idempotent mutations (such as `FieldValue.increment()`),\n          // we record the base state in a separate patch mutation. This is\n          // later used to guarantee consistent values and prevents flicker\n          // even if the backend sends us an update that already includes our\n          // transform.\n          const baseMutations: Mutation[] = [];\n\n          for (const mutation of mutations) {\n            const baseValue = extractMutationBaseValue(\n              mutation,\n              existingDocs.get(mutation.key)\n            );\n            if (baseValue != null) {\n              // NOTE: The base state should only be applied if there's some\n              // existing document to override, so use a Precondition of\n              // exists=true\n              baseMutations.push(\n                new PatchMutation(\n                  mutation.key,\n                  baseValue,\n                  extractFieldMask(baseValue.proto.mapValue!),\n                  Precondition.exists(true)\n                )\n              );\n            }\n          }\n\n          return this.mutationQueue.addMutationBatch(\n            txn,\n            localWriteTime,\n            baseMutations,\n            mutations\n          );\n        });\n      })\n      .then(batch => {\n        const changes = batch.applyToLocalDocumentSet(existingDocs);\n        return { batchId: batch.batchId, changes };\n      });\n  }\n\n  acknowledgeBatch(\n    batchResult: MutationBatchResult\n  ): Promise<MaybeDocumentMap> {\n    return this.persistence.runTransaction(\n      'Acknowledge batch',\n      'readwrite-primary',\n      txn => {\n        const affected = batchResult.batch.keys();\n        const documentBuffer = this.remoteDocuments.newChangeBuffer({\n          trackRemovals: true // Make sure document removals show up in `getNewDocumentChanges()`\n        });\n        return this.applyWriteToRemoteDocuments(\n          txn,\n          batchResult,\n          documentBuffer\n        )\n          .next(() => documentBuffer.apply(txn))\n          .next(() => this.mutationQueue.performConsistencyCheck(txn))\n          .next(() => this.localDocuments.getDocuments(txn, affected));\n      }\n    );\n  }\n\n  rejectBatch(batchId: BatchId): Promise<MaybeDocumentMap> {\n    return this.persistence.runTransaction(\n      'Reject batch',\n      'readwrite-primary',\n      txn => {\n        let affectedKeys: DocumentKeySet;\n        return this.mutationQueue\n          .lookupMutationBatch(txn, batchId)\n          .next((batch: MutationBatch | null) => {\n            hardAssert(batch !== null, 'Attempt to reject nonexistent batch!');\n            affectedKeys = batch.keys();\n            return this.mutationQueue.removeMutationBatch(txn, batch);\n          })\n          .next(() => {\n            return this.mutationQueue.performConsistencyCheck(txn);\n          })\n          .next(() => {\n            return this.localDocuments.getDocuments(txn, affectedKeys);\n          });\n      }\n    );\n  }\n\n  getHighestUnacknowledgedBatchId(): Promise<BatchId> {\n    return this.persistence.runTransaction(\n      'Get highest unacknowledged batch id',\n      'readonly',\n      txn => {\n        return this.mutationQueue.getHighestUnacknowledgedBatchId(txn);\n      }\n    );\n  }\n\n  getLastRemoteSnapshotVersion(): Promise<SnapshotVersion> {\n    return this.persistence.runTransaction(\n      'Get last remote snapshot version',\n      'readonly',\n      txn => this.targetCache.getLastRemoteSnapshotVersion(txn)\n    );\n  }\n\n  applyRemoteEvent(remoteEvent: RemoteEvent): Promise<MaybeDocumentMap> {\n    const remoteVersion = remoteEvent.snapshotVersion;\n    let newTargetDataByTargetMap = this.targetDataByTarget;\n\n    return this.persistence\n      .runTransaction('Apply remote event', 'readwrite-primary', txn => {\n        const documentBuffer = this.remoteDocuments.newChangeBuffer({\n          trackRemovals: true // Make sure document removals show up in `getNewDocumentChanges()`\n        });\n\n        // Reset newTargetDataByTargetMap in case this transaction gets re-run.\n        newTargetDataByTargetMap = this.targetDataByTarget;\n\n        const promises = [] as Array<PersistencePromise<void>>;\n        remoteEvent.targetChanges.forEach((change, targetId) => {\n          const oldTargetData = newTargetDataByTargetMap.get(targetId);\n          if (!oldTargetData) {\n            return;\n          }\n\n          // Only update the remote keys if the target is still active. This\n          // ensures that we can persist the updated target data along with\n          // the updated assignment.\n          promises.push(\n            this.targetCache\n              .removeMatchingKeys(txn, change.removedDocuments, targetId)\n              .next(() => {\n                return this.targetCache.addMatchingKeys(\n                  txn,\n                  change.addedDocuments,\n                  targetId\n                );\n              })\n          );\n\n          const resumeToken = change.resumeToken;\n          // Update the resume token if the change includes one.\n          if (resumeToken.approximateByteSize() > 0) {\n            const newTargetData = oldTargetData\n              .withResumeToken(resumeToken, remoteVersion)\n              .withSequenceNumber(txn.currentSequenceNumber);\n            newTargetDataByTargetMap = newTargetDataByTargetMap.insert(\n              targetId,\n              newTargetData\n            );\n\n            // Update the target data if there are target changes (or if\n            // sufficient time has passed since the last update).\n            if (\n              LocalStoreImpl.shouldPersistTargetData(\n                oldTargetData,\n                newTargetData,\n                change\n              )\n            ) {\n              promises.push(\n                this.targetCache.updateTargetData(txn, newTargetData)\n              );\n            }\n          }\n        });\n\n        let changedDocs = maybeDocumentMap();\n        let updatedKeys = documentKeySet();\n        remoteEvent.documentUpdates.forEach((key, doc) => {\n          updatedKeys = updatedKeys.add(key);\n        });\n\n        // Each loop iteration only affects its \"own\" doc, so it's safe to get all the remote\n        // documents in advance in a single call.\n        promises.push(\n          documentBuffer.getEntries(txn, updatedKeys).next(existingDocs => {\n            remoteEvent.documentUpdates.forEach((key, doc) => {\n              const existingDoc = existingDocs.get(key);\n\n              // Note: The order of the steps below is important, since we want\n              // to ensure that rejected limbo resolutions (which fabricate\n              // NoDocuments with SnapshotVersion.min()) never add documents to\n              // cache.\n              if (\n                doc instanceof NoDocument &&\n                doc.version.isEqual(SnapshotVersion.min())\n              ) {\n                // NoDocuments with SnapshotVersion.min() are used in manufactured\n                // events. We remove these documents from cache since we lost\n                // access.\n                documentBuffer.removeEntry(key, remoteVersion);\n                changedDocs = changedDocs.insert(key, doc);\n              } else if (\n                existingDoc == null ||\n                doc.version.compareTo(existingDoc.version) > 0 ||\n                (doc.version.compareTo(existingDoc.version) === 0 &&\n                  existingDoc.hasPendingWrites)\n              ) {\n                debugAssert(\n                  !SnapshotVersion.min().isEqual(remoteVersion),\n                  'Cannot add a document when the remote version is zero'\n                );\n                documentBuffer.addEntry(doc, remoteVersion);\n                changedDocs = changedDocs.insert(key, doc);\n              } else {\n                logDebug(\n                  LOG_TAG,\n                  'Ignoring outdated watch update for ',\n                  key,\n                  '. Current version:',\n                  existingDoc.version,\n                  ' Watch version:',\n                  doc.version\n                );\n              }\n\n              if (remoteEvent.resolvedLimboDocuments.has(key)) {\n                promises.push(\n                  this.persistence.referenceDelegate.updateLimboDocument(\n                    txn,\n                    key\n                  )\n                );\n              }\n            });\n          })\n        );\n\n        // HACK: The only reason we allow a null snapshot version is so that we\n        // can synthesize remote events when we get permission denied errors while\n        // trying to resolve the state of a locally cached document that is in\n        // limbo.\n        if (!remoteVersion.isEqual(SnapshotVersion.min())) {\n          const updateRemoteVersion = this.targetCache\n            .getLastRemoteSnapshotVersion(txn)\n            .next(lastRemoteSnapshotVersion => {\n              debugAssert(\n                remoteVersion.compareTo(lastRemoteSnapshotVersion) >= 0,\n                'Watch stream reverted to previous snapshot?? ' +\n                  remoteVersion +\n                  ' < ' +\n                  lastRemoteSnapshotVersion\n              );\n              return this.targetCache.setTargetsMetadata(\n                txn,\n                txn.currentSequenceNumber,\n                remoteVersion\n              );\n            });\n          promises.push(updateRemoteVersion);\n        }\n\n        return PersistencePromise.waitFor(promises)\n          .next(() => documentBuffer.apply(txn))\n          .next(() => {\n            return this.localDocuments.getLocalViewOfDocuments(\n              txn,\n              changedDocs\n            );\n          });\n      })\n      .then(changedDocs => {\n        this.targetDataByTarget = newTargetDataByTargetMap;\n        return changedDocs;\n      });\n  }\n\n  /**\n   * Returns true if the newTargetData should be persisted during an update of\n   * an active target. TargetData should always be persisted when a target is\n   * being released and should not call this function.\n   *\n   * While the target is active, TargetData updates can be omitted when nothing\n   * about the target has changed except metadata like the resume token or\n   * snapshot version. Occasionally it's worth the extra write to prevent these\n   * values from getting too stale after a crash, but this doesn't have to be\n   * too frequent.\n   */\n  private static shouldPersistTargetData(\n    oldTargetData: TargetData,\n    newTargetData: TargetData,\n    change: TargetChange\n  ): boolean {\n    hardAssert(\n      newTargetData.resumeToken.approximateByteSize() > 0,\n      'Attempted to persist target data with no resume token'\n    );\n\n    // Always persist target data if we don't already have a resume token.\n    if (oldTargetData.resumeToken.approximateByteSize() === 0) {\n      return true;\n    }\n\n    // Don't allow resume token changes to be buffered indefinitely. This\n    // allows us to be reasonably up-to-date after a crash and avoids needing\n    // to loop over all active queries on shutdown. Especially in the browser\n    // we may not get time to do anything interesting while the current tab is\n    // closing.\n    const timeDelta =\n      newTargetData.snapshotVersion.toMicroseconds() -\n      oldTargetData.snapshotVersion.toMicroseconds();\n    if (timeDelta >= this.RESUME_TOKEN_MAX_AGE_MICROS) {\n      return true;\n    }\n\n    // Otherwise if the only thing that has changed about a target is its resume\n    // token it's not worth persisting. Note that the RemoteStore keeps an\n    // in-memory view of the currently active targets which includes the current\n    // resume token, so stream failure or user changes will still use an\n    // up-to-date resume token regardless of what we do here.\n    const changes =\n      change.addedDocuments.size +\n      change.modifiedDocuments.size +\n      change.removedDocuments.size;\n    return changes > 0;\n  }\n\n  async notifyLocalViewChanges(viewChanges: LocalViewChanges[]): Promise<void> {\n    try {\n      await this.persistence.runTransaction(\n        'notifyLocalViewChanges',\n        'readwrite',\n        txn => {\n          return PersistencePromise.forEach(\n            viewChanges,\n            (viewChange: LocalViewChanges) => {\n              return PersistencePromise.forEach(\n                viewChange.addedKeys,\n                (key: DocumentKey) =>\n                  this.persistence.referenceDelegate.addReference(\n                    txn,\n                    viewChange.targetId,\n                    key\n                  )\n              ).next(() =>\n                PersistencePromise.forEach(\n                  viewChange.removedKeys,\n                  (key: DocumentKey) =>\n                    this.persistence.referenceDelegate.removeReference(\n                      txn,\n                      viewChange.targetId,\n                      key\n                    )\n                )\n              );\n            }\n          );\n        }\n      );\n    } catch (e) {\n      if (isIndexedDbTransactionError(e)) {\n        // If `notifyLocalViewChanges` fails, we did not advance the sequence\n        // number for the documents that were included in this transaction.\n        // This might trigger them to be deleted earlier than they otherwise\n        // would have, but it should not invalidate the integrity of the data.\n        logDebug(LOG_TAG, 'Failed to update sequence numbers: ' + e);\n      } else {\n        throw e;\n      }\n    }\n\n    for (const viewChange of viewChanges) {\n      const targetId = viewChange.targetId;\n\n      if (!viewChange.fromCache) {\n        const targetData = this.targetDataByTarget.get(targetId);\n        debugAssert(\n          targetData !== null,\n          `Can't set limbo-free snapshot version for unknown target: ${targetId}`\n        );\n\n        // Advance the last limbo free snapshot version\n        const lastLimboFreeSnapshotVersion = targetData.snapshotVersion;\n        const updatedTargetData = targetData.withLastLimboFreeSnapshotVersion(\n          lastLimboFreeSnapshotVersion\n        );\n        this.targetDataByTarget = this.targetDataByTarget.insert(\n          targetId,\n          updatedTargetData\n        );\n      }\n    }\n  }\n\n  nextMutationBatch(afterBatchId?: BatchId): Promise<MutationBatch | null> {\n    return this.persistence.runTransaction(\n      'Get next mutation batch',\n      'readonly',\n      txn => {\n        if (afterBatchId === undefined) {\n          afterBatchId = BATCHID_UNKNOWN;\n        }\n        return this.mutationQueue.getNextMutationBatchAfterBatchId(\n          txn,\n          afterBatchId\n        );\n      }\n    );\n  }\n\n  readDocument(key: DocumentKey): Promise<MaybeDocument | null> {\n    return this.persistence.runTransaction('read document', 'readonly', txn => {\n      return this.localDocuments.getDocument(txn, key);\n    });\n  }\n\n  allocateTarget(target: Target): Promise<TargetData> {\n    return this.persistence\n      .runTransaction('Allocate target', 'readwrite', txn => {\n        let targetData: TargetData;\n        return this.targetCache\n          .getTargetData(txn, target)\n          .next((cached: TargetData | null) => {\n            if (cached) {\n              // This target has been listened to previously, so reuse the\n              // previous targetID.\n              // TODO(mcg): freshen last accessed date?\n              targetData = cached;\n              return PersistencePromise.resolve(targetData);\n            } else {\n              return this.targetCache.allocateTargetId(txn).next(targetId => {\n                targetData = new TargetData(\n                  target,\n                  targetId,\n                  TargetPurpose.Listen,\n                  txn.currentSequenceNumber\n                );\n                return this.targetCache\n                  .addTargetData(txn, targetData)\n                  .next(() => targetData);\n              });\n            }\n          });\n      })\n      .then(targetData => {\n        // If Multi-Tab is enabled, the existing target data may be newer than\n        // the in-memory data\n        const cachedTargetData = this.targetDataByTarget.get(\n          targetData.targetId\n        );\n        if (\n          cachedTargetData === null ||\n          targetData.snapshotVersion.compareTo(\n            cachedTargetData.snapshotVersion\n          ) > 0\n        ) {\n          this.targetDataByTarget = this.targetDataByTarget.insert(\n            targetData.targetId,\n            targetData\n          );\n          this.targetIdByTarget.set(target, targetData.targetId);\n        }\n        return targetData;\n      });\n  }\n\n  getTargetData(\n    transaction: PersistenceTransaction,\n    target: Target\n  ): PersistencePromise<TargetData | null> {\n    const targetId = this.targetIdByTarget.get(target);\n    if (targetId !== undefined) {\n      return PersistencePromise.resolve<TargetData | null>(\n        this.targetDataByTarget.get(targetId)\n      );\n    } else {\n      return this.targetCache.getTargetData(transaction, target);\n    }\n  }\n\n  async releaseTarget(\n    targetId: number,\n    keepPersistedTargetData: boolean\n  ): Promise<void> {\n    const targetData = this.targetDataByTarget.get(targetId);\n    debugAssert(\n      targetData !== null,\n      `Tried to release nonexistent target: ${targetId}`\n    );\n\n    const mode = keepPersistedTargetData ? 'readwrite' : 'readwrite-primary';\n\n    try {\n      if (!keepPersistedTargetData) {\n        await this.persistence.runTransaction('Release target', mode, txn => {\n          return this.persistence.referenceDelegate.removeTarget(\n            txn,\n            targetData!\n          );\n        });\n      }\n    } catch (e) {\n      if (isIndexedDbTransactionError(e)) {\n        // All `releaseTarget` does is record the final metadata state for the\n        // target, but we've been recording this periodically during target\n        // activity. If we lose this write this could cause a very slight\n        // difference in the order of target deletion during GC, but we\n        // don't define exact LRU semantics so this is acceptable.\n        logDebug(\n          LOG_TAG,\n          `Failed to update sequence numbers for target ${targetId}: ${e}`\n        );\n      } else {\n        throw e;\n      }\n    }\n\n    this.targetDataByTarget = this.targetDataByTarget.remove(targetId);\n    this.targetIdByTarget.delete(targetData!.target);\n  }\n\n  executeQuery(\n    query: Query,\n    usePreviousResults: boolean\n  ): Promise<QueryResult> {\n    let lastLimboFreeSnapshotVersion = SnapshotVersion.min();\n    let remoteKeys = documentKeySet();\n\n    return this.persistence.runTransaction('Execute query', 'readonly', txn => {\n      return this.getTargetData(txn, queryToTarget(query))\n        .next(targetData => {\n          if (targetData) {\n            lastLimboFreeSnapshotVersion =\n              targetData.lastLimboFreeSnapshotVersion;\n            return this.targetCache\n              .getMatchingKeysForTargetId(txn, targetData.targetId)\n              .next(result => {\n                remoteKeys = result;\n              });\n          }\n        })\n        .next(() =>\n          this.queryEngine.getDocumentsMatchingQuery(\n            txn,\n            query,\n            usePreviousResults\n              ? lastLimboFreeSnapshotVersion\n              : SnapshotVersion.min(),\n            usePreviousResults ? remoteKeys : documentKeySet()\n          )\n        )\n        .next(documents => {\n          return { documents, remoteKeys };\n        });\n    });\n  }\n\n  private applyWriteToRemoteDocuments(\n    txn: PersistenceTransaction,\n    batchResult: MutationBatchResult,\n    documentBuffer: RemoteDocumentChangeBuffer\n  ): PersistencePromise<void> {\n    const batch = batchResult.batch;\n    const docKeys = batch.keys();\n    let promiseChain = PersistencePromise.resolve();\n    docKeys.forEach(docKey => {\n      promiseChain = promiseChain\n        .next(() => {\n          return documentBuffer.getEntry(txn, docKey);\n        })\n        .next((remoteDoc: MaybeDocument | null) => {\n          let doc = remoteDoc;\n          const ackVersion = batchResult.docVersions.get(docKey);\n          hardAssert(\n            ackVersion !== null,\n            'ackVersions should contain every doc in the write.'\n          );\n          if (!doc || doc.version.compareTo(ackVersion!) < 0) {\n            doc = batch.applyToRemoteDocument(docKey, doc, batchResult);\n            if (!doc) {\n              debugAssert(\n                !remoteDoc,\n                'Mutation batch ' +\n                  batch +\n                  ' applied to document ' +\n                  remoteDoc +\n                  ' resulted in null'\n              );\n            } else {\n              // We use the commitVersion as the readTime rather than the\n              // document's updateTime since the updateTime is not advanced\n              // for updates that do not modify the underlying document.\n              documentBuffer.addEntry(doc, batchResult.commitVersion);\n            }\n          }\n        });\n    });\n    return promiseChain.next(() =>\n      this.mutationQueue.removeMutationBatch(txn, batch)\n    );\n  }\n\n  collectGarbage(garbageCollector: LruGarbageCollector): Promise<LruResults> {\n    return this.persistence.runTransaction(\n      'Collect garbage',\n      'readwrite-primary',\n      txn => garbageCollector.collect(txn, this.targetDataByTarget)\n    );\n  }\n}\n\nexport function newLocalStore(\n  /** Manages our in-memory or durable persistence. */\n  persistence: Persistence,\n  queryEngine: QueryEngine,\n  initialUser: User\n): LocalStore {\n  return new LocalStoreImpl(persistence, queryEngine, initialUser);\n}\n\n/** Returns the local view of the documents affected by a mutation batch. */\n// PORTING NOTE: Multi-Tab only.\nexport function lookupMutationDocuments(\n  localStore: LocalStore,\n  batchId: BatchId\n): Promise<MaybeDocumentMap | null> {\n  const localStoreImpl = debugCast(localStore, LocalStoreImpl);\n  const mutationQueueImpl = debugCast(\n    localStoreImpl.mutationQueue,\n    IndexedDbMutationQueue // We only support IndexedDb in multi-tab mode.\n  );\n  return localStoreImpl.persistence.runTransaction(\n    'Lookup mutation documents',\n    'readonly',\n    txn => {\n      return mutationQueueImpl.lookupMutationKeys(txn, batchId).next(keys => {\n        if (keys) {\n          return localStoreImpl.localDocuments.getDocuments(\n            txn,\n            keys\n          ) as PersistencePromise<MaybeDocumentMap | null>;\n        } else {\n          return PersistencePromise.resolve<MaybeDocumentMap | null>(null);\n        }\n      });\n    }\n  );\n}\n\n// PORTING NOTE: Multi-Tab only.\nexport function removeCachedMutationBatchMetadata(\n  localStore: LocalStore,\n  batchId: BatchId\n): void {\n  const mutationQueueImpl = debugCast(\n    debugCast(localStore, LocalStoreImpl).mutationQueue,\n    IndexedDbMutationQueue // We only support IndexedDb in multi-tab mode.\n  );\n  mutationQueueImpl.removeCachedMutationKeys(batchId);\n}\n\n// PORTING NOTE: Multi-Tab only.\nexport function getActiveClientsFromPersistence(\n  localStore: LocalStore\n): Promise<ClientId[]> {\n  const persistenceImpl = debugCast(\n    debugCast(localStore, LocalStoreImpl).persistence,\n    IndexedDbPersistence // We only support IndexedDb in multi-tab mode.\n  );\n  return persistenceImpl.getActiveClients();\n}\n\n// PORTING NOTE: Multi-Tab only.\nexport function getCachedTarget(\n  localStore: LocalStore,\n  targetId: TargetId\n): Promise<Target | null> {\n  const localStoreImpl = debugCast(localStore, LocalStoreImpl);\n  const targetCacheImpl = debugCast(\n    localStoreImpl.targetCache,\n    IndexedDbTargetCache // We only support IndexedDb in multi-tab mode.\n  );\n  const cachedTargetData = localStoreImpl.targetDataByTarget.get(targetId);\n  if (cachedTargetData) {\n    return Promise.resolve(cachedTargetData.target);\n  } else {\n    return localStoreImpl.persistence.runTransaction(\n      'Get target data',\n      'readonly',\n      txn => {\n        return targetCacheImpl\n          .getTargetDataForTarget(txn, targetId)\n          .next(targetData => (targetData ? targetData.target : null));\n      }\n    );\n  }\n}\n\n/**\n * Returns the set of documents that have been updated since the last call.\n * If this is the first call, returns the set of changes since client\n * initialization. Further invocations will return document that have changed\n * since the prior call.\n */\n// PORTING NOTE: Multi-Tab only.\nexport function getNewDocumentChanges(\n  localStore: LocalStore\n): Promise<MaybeDocumentMap> {\n  const localStoreImpl = debugCast(localStore, LocalStoreImpl);\n  const remoteDocumentCacheImpl = debugCast(\n    localStoreImpl.remoteDocuments,\n    IndexedDbRemoteDocumentCache // We only support IndexedDb in multi-tab mode.\n  );\n  return localStoreImpl.persistence\n    .runTransaction('Get new document changes', 'readonly', txn =>\n      remoteDocumentCacheImpl.getNewDocumentChanges(\n        txn,\n        localStoreImpl.lastDocumentChangeReadTime\n      )\n    )\n    .then(({ changedDocs, readTime }) => {\n      localStoreImpl.lastDocumentChangeReadTime = readTime;\n      return changedDocs;\n    });\n}\n\n/**\n * Reads the newest document change from persistence and moves the internal\n * synchronization marker forward so that calls to `getNewDocumentChanges()`\n * only return changes that happened after client initialization.\n */\n// PORTING NOTE: Multi-Tab only.\nexport async function synchronizeLastDocumentChangeReadTime(\n  localStore: LocalStore\n): Promise<void> {\n  const localStoreImpl = debugCast(localStore, LocalStoreImpl);\n  const remoteDocumentCacheImpl = debugCast(\n    localStoreImpl.remoteDocuments,\n    IndexedDbRemoteDocumentCache // We only support IndexedDb in multi-tab mode.\n  );\n  return localStoreImpl.persistence\n    .runTransaction(\n      'Synchronize last document change read time',\n      'readonly',\n      txn => remoteDocumentCacheImpl.getLastReadTime(txn)\n    )\n    .then(readTime => {\n      localStoreImpl.lastDocumentChangeReadTime = readTime;\n    });\n}\n\n/**\n * Verifies the error thrown by a LocalStore operation. If a LocalStore\n * operation fails because the primary lease has been taken by another client,\n * we ignore the error (the persistence layer will immediately call\n * `applyPrimaryLease` to propagate the primary state change). All other errors\n * are re-thrown.\n *\n * @param err An error returned by a LocalStore operation.\n * @return A Promise that resolves after we recovered, or the original error.\n */\nexport async function ignoreIfPrimaryLeaseLoss(\n  err: FirestoreError\n): Promise<void> {\n  if (\n    err.code === Code.FAILED_PRECONDITION &&\n    err.message === PRIMARY_LEASE_LOST_ERROR_MSG\n  ) {\n    logDebug(LOG_TAG, 'Unexpectedly lost primary lease');\n  } else {\n    throw err;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { BatchId, TargetId } from '../core/types';\nimport { documentKeySet, DocumentKeySet } from '../model/collections';\nimport { DocumentKey } from '../model/document_key';\nimport { primitiveComparator } from '../util/misc';\nimport { SortedSet } from '../util/sorted_set';\nimport { ResourcePath } from '../model/path';\n\n/**\n * A collection of references to a document from some kind of numbered entity\n * (either a target ID or batch ID). As references are added to or removed from\n * the set corresponding events are emitted to a registered garbage collector.\n *\n * Each reference is represented by a DocumentReference object. Each of them\n * contains enough information to uniquely identify the reference. They are all\n * stored primarily in a set sorted by key. A document is considered garbage if\n * there's no references in that set (this can be efficiently checked thanks to\n * sorting by key).\n *\n * ReferenceSet also keeps a secondary set that contains references sorted by\n * IDs. This one is used to efficiently implement removal of all references by\n * some target ID.\n */\nexport class ReferenceSet {\n  // A set of outstanding references to a document sorted by key.\n  private refsByKey = new SortedSet(DocReference.compareByKey);\n\n  // A set of outstanding references to a document sorted by target id.\n  private refsByTarget = new SortedSet(DocReference.compareByTargetId);\n\n  /** Returns true if the reference set contains no references. */\n  isEmpty(): boolean {\n    return this.refsByKey.isEmpty();\n  }\n\n  /** Adds a reference to the given document key for the given ID. */\n  addReference(key: DocumentKey, id: TargetId | BatchId): void {\n    const ref = new DocReference(key, id);\n    this.refsByKey = this.refsByKey.add(ref);\n    this.refsByTarget = this.refsByTarget.add(ref);\n  }\n\n  /** Add references to the given document keys for the given ID. */\n  addReferences(keys: DocumentKeySet, id: TargetId | BatchId): void {\n    keys.forEach(key => this.addReference(key, id));\n  }\n\n  /**\n   * Removes a reference to the given document key for the given\n   * ID.\n   */\n  removeReference(key: DocumentKey, id: TargetId | BatchId): void {\n    this.removeRef(new DocReference(key, id));\n  }\n\n  removeReferences(keys: DocumentKeySet, id: TargetId | BatchId): void {\n    keys.forEach(key => this.removeReference(key, id));\n  }\n\n  /**\n   * Clears all references with a given ID. Calls removeRef() for each key\n   * removed.\n   */\n  removeReferencesForId(id: TargetId | BatchId): DocumentKey[] {\n    const emptyKey = new DocumentKey(new ResourcePath([]));\n    const startRef = new DocReference(emptyKey, id);\n    const endRef = new DocReference(emptyKey, id + 1);\n    const keys: DocumentKey[] = [];\n    this.refsByTarget.forEachInRange([startRef, endRef], ref => {\n      this.removeRef(ref);\n      keys.push(ref.key);\n    });\n    return keys;\n  }\n\n  removeAllReferences(): void {\n    this.refsByKey.forEach(ref => this.removeRef(ref));\n  }\n\n  private removeRef(ref: DocReference): void {\n    this.refsByKey = this.refsByKey.delete(ref);\n    this.refsByTarget = this.refsByTarget.delete(ref);\n  }\n\n  referencesForId(id: TargetId | BatchId): DocumentKeySet {\n    const emptyKey = new DocumentKey(new ResourcePath([]));\n    const startRef = new DocReference(emptyKey, id);\n    const endRef = new DocReference(emptyKey, id + 1);\n    let keys = documentKeySet();\n    this.refsByTarget.forEachInRange([startRef, endRef], ref => {\n      keys = keys.add(ref.key);\n    });\n    return keys;\n  }\n\n  containsKey(key: DocumentKey): boolean {\n    const ref = new DocReference(key, 0);\n    const firstRef = this.refsByKey.firstAfterOrEqual(ref);\n    return firstRef !== null && key.isEqual(firstRef.key);\n  }\n}\n\nexport class DocReference {\n  constructor(\n    public key: DocumentKey,\n    public targetOrBatchId: TargetId | BatchId\n  ) {}\n\n  /** Compare by key then by ID */\n  static compareByKey(left: DocReference, right: DocReference): number {\n    return (\n      DocumentKey.comparator(left.key, right.key) ||\n      primitiveComparator(left.targetOrBatchId, right.targetOrBatchId)\n    );\n  }\n\n  /** Compare by ID then by key */\n  static compareByTargetId(left: DocReference, right: DocReference): number {\n    return (\n      primitiveComparator(left.targetOrBatchId, right.targetOrBatchId) ||\n      DocumentKey.comparator(left.key, right.key)\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Simple wrapper around a nullable UID. Mostly exists to make code more\n * readable.\n */\nexport class User {\n  /** A user with a null UID. */\n  static readonly UNAUTHENTICATED = new User(null);\n\n  // TODO(mikelehen): Look into getting a proper uid-equivalent for\n  // non-FirebaseAuth providers.\n  static readonly GOOGLE_CREDENTIALS = new User('google-credentials-uid');\n  static readonly FIRST_PARTY = new User('first-party-uid');\n\n  constructor(readonly uid: string | null) {}\n\n  isAuthenticated(): boolean {\n    return this.uid != null;\n  }\n\n  /**\n   * Returns a key representing this user, suitable for inclusion in a\n   * dictionary.\n   */\n  toKey(): string {\n    if (this.isAuthenticated()) {\n      return 'uid:' + this.uid;\n    } else {\n      return 'anonymous-user';\n    }\n  }\n\n  isEqual(otherUser: User): boolean {\n    return otherUser.uid === this.uid;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { User } from '../auth/user';\nimport { hardAssert, debugAssert } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport {\n  FirebaseAuthInternal,\n  FirebaseAuthInternalName\n} from '@firebase/auth-interop-types';\nimport { Provider } from '@firebase/component';\nimport { logDebug } from '../util/log';\n\n// TODO(mikelehen): This should be split into multiple files and probably\n// moved to an auth/ folder to match other platforms.\n\nexport interface FirstPartyCredentialsSettings {\n  type: 'gapi';\n  client: unknown;\n  sessionIndex: string;\n}\n\nexport interface ProviderCredentialsSettings {\n  type: 'provider';\n  client: CredentialsProvider;\n}\n\n/** Settings for private credentials */\nexport type CredentialsSettings =\n  | FirstPartyCredentialsSettings\n  | ProviderCredentialsSettings;\n\nexport type TokenType = 'OAuth' | 'FirstParty';\nexport interface Token {\n  /** Type of token. */\n  type: TokenType;\n\n  /**\n   * The user with which the token is associated (used for persisting user\n   * state on disk, etc.).\n   */\n  user: User;\n\n  /** Extra header values to be passed along with a request */\n  authHeaders: { [header: string]: string };\n}\n\nexport class OAuthToken implements Token {\n  type = 'OAuth' as TokenType;\n  authHeaders: { [header: string]: string };\n  constructor(value: string, public user: User) {\n    this.authHeaders = {};\n    // Set the headers using Object Literal notation to avoid minification\n    this.authHeaders['Authorization'] = `Bearer ${value}`;\n  }\n}\n\n/**\n * A Listener for credential change events. The listener should fetch a new\n * token and may need to invalidate other state if the current user has also\n * changed.\n */\nexport type CredentialChangeListener = (user: User) => void;\n\n/**\n * Provides methods for getting the uid and token for the current user and\n * listening for changes.\n */\nexport interface CredentialsProvider {\n  /** Requests a token for the current user. */\n  getToken(): Promise<Token | null>;\n\n  /**\n   * Marks the last retrieved token as invalid, making the next GetToken request\n   * force-refresh the token.\n   */\n  invalidateToken(): void;\n\n  /**\n   * Specifies a listener to be notified of credential changes\n   * (sign-in / sign-out, token changes). It is immediately called once with the\n   * initial user.\n   */\n  setChangeListener(changeListener: CredentialChangeListener): void;\n\n  /** Removes the previously-set change listener. */\n  removeChangeListener(): void;\n}\n\n/** A CredentialsProvider that always yields an empty token. */\nexport class EmptyCredentialsProvider implements CredentialsProvider {\n  /**\n   * Stores the listener registered with setChangeListener()\n   * This isn't actually necessary since the UID never changes, but we use this\n   * to verify the listen contract is adhered to in tests.\n   */\n  private changeListener: CredentialChangeListener | null = null;\n\n  getToken(): Promise<Token | null> {\n    return Promise.resolve<Token | null>(null);\n  }\n\n  invalidateToken(): void {}\n\n  setChangeListener(changeListener: CredentialChangeListener): void {\n    debugAssert(\n      !this.changeListener,\n      'Can only call setChangeListener() once.'\n    );\n    this.changeListener = changeListener;\n    // Fire with initial user.\n    changeListener(User.UNAUTHENTICATED);\n  }\n\n  removeChangeListener(): void {\n    debugAssert(\n      this.changeListener !== null,\n      'removeChangeListener() when no listener registered'\n    );\n    this.changeListener = null;\n  }\n}\n\nexport class FirebaseCredentialsProvider implements CredentialsProvider {\n  /**\n   * The auth token listener registered with FirebaseApp, retained here so we\n   * can unregister it.\n   */\n  private tokenListener: ((token: string | null) => void) | null = null;\n\n  /** Tracks the current User. */\n  private currentUser: User = User.UNAUTHENTICATED;\n  private receivedInitialUser: boolean = false;\n\n  /**\n   * Counter used to detect if the token changed while a getToken request was\n   * outstanding.\n   */\n  private tokenCounter = 0;\n\n  /** The listener registered with setChangeListener(). */\n  private changeListener: CredentialChangeListener | null = null;\n\n  private forceRefresh = false;\n\n  private auth: FirebaseAuthInternal | null;\n\n  constructor(authProvider: Provider<FirebaseAuthInternalName>) {\n    this.tokenListener = () => {\n      this.tokenCounter++;\n      this.currentUser = this.getUser();\n      this.receivedInitialUser = true;\n      if (this.changeListener) {\n        this.changeListener(this.currentUser);\n      }\n    };\n\n    this.tokenCounter = 0;\n\n    this.auth = authProvider.getImmediate({ optional: true });\n\n    if (this.auth) {\n      this.auth.addAuthTokenListener(this.tokenListener!);\n    } else {\n      // if auth is not available, invoke tokenListener once with null token\n      this.tokenListener(null);\n      authProvider.get().then(\n        auth => {\n          this.auth = auth;\n          if (this.tokenListener) {\n            // tokenListener can be removed by removeChangeListener()\n            this.auth.addAuthTokenListener(this.tokenListener);\n          }\n        },\n        () => {\n          /* this.authProvider.get() never rejects */\n        }\n      );\n    }\n  }\n\n  getToken(): Promise<Token | null> {\n    debugAssert(\n      this.tokenListener != null,\n      'getToken cannot be called after listener removed.'\n    );\n\n    // Take note of the current value of the tokenCounter so that this method\n    // can fail (with an ABORTED error) if there is a token change while the\n    // request is outstanding.\n    const initialTokenCounter = this.tokenCounter;\n    const forceRefresh = this.forceRefresh;\n    this.forceRefresh = false;\n\n    if (!this.auth) {\n      return Promise.resolve(null);\n    }\n\n    return this.auth.getToken(forceRefresh).then(tokenData => {\n      // Cancel the request since the token changed while the request was\n      // outstanding so the response is potentially for a previous user (which\n      // user, we can't be sure).\n      if (this.tokenCounter !== initialTokenCounter) {\n        logDebug(\n          'FirebaseCredentialsProvider',\n          'getToken aborted due to token change.'\n        );\n        return this.getToken();\n      } else {\n        if (tokenData) {\n          hardAssert(\n            typeof tokenData.accessToken === 'string',\n            'Invalid tokenData returned from getToken():' + tokenData\n          );\n          return new OAuthToken(tokenData.accessToken, this.currentUser);\n        } else {\n          return null;\n        }\n      }\n    });\n  }\n\n  invalidateToken(): void {\n    this.forceRefresh = true;\n  }\n\n  setChangeListener(changeListener: CredentialChangeListener): void {\n    debugAssert(\n      !this.changeListener,\n      'Can only call setChangeListener() once.'\n    );\n    this.changeListener = changeListener;\n\n    // Fire the initial event\n    if (this.receivedInitialUser) {\n      changeListener(this.currentUser);\n    }\n  }\n\n  removeChangeListener(): void {\n    debugAssert(\n      this.tokenListener != null,\n      'removeChangeListener() called twice'\n    );\n    debugAssert(\n      this.changeListener !== null,\n      'removeChangeListener() called when no listener registered'\n    );\n\n    if (this.auth) {\n      this.auth.removeAuthTokenListener(this.tokenListener!);\n    }\n    this.tokenListener = null;\n    this.changeListener = null;\n  }\n\n  // Auth.getUid() can return null even with a user logged in. It is because\n  // getUid() is synchronous, but the auth code populating Uid is asynchronous.\n  // This method should only be called in the AuthTokenListener callback\n  // to guarantee to get the actual user.\n  private getUser(): User {\n    const currentUid = this.auth && this.auth.getUid();\n    hardAssert(\n      currentUid === null || typeof currentUid === 'string',\n      'Received invalid UID: ' + currentUid\n    );\n    return new User(currentUid);\n  }\n}\n\n// Manual type definition for the subset of Gapi we use.\ninterface Gapi {\n  auth: {\n    getAuthHeaderValueForFirstParty: (\n      userIdentifiers: Array<{ [key: string]: string }>\n    ) => string | null;\n  };\n}\n\n/*\n * FirstPartyToken provides a fresh token each time its value\n * is requested, because if the token is too old, requests will be rejected.\n * Technically this may no longer be necessary since the SDK should gracefully\n * recover from unauthenticated errors (see b/33147818 for context), but it's\n * safer to keep the implementation as-is.\n */\nexport class FirstPartyToken implements Token {\n  type = 'FirstParty' as TokenType;\n  user = User.FIRST_PARTY;\n\n  constructor(private gapi: Gapi, private sessionIndex: string) {}\n\n  get authHeaders(): { [header: string]: string } {\n    const headers: { [header: string]: string } = {\n      'X-Goog-AuthUser': this.sessionIndex\n    };\n    const authHeader = this.gapi.auth.getAuthHeaderValueForFirstParty([]);\n    if (authHeader) {\n      headers['Authorization'] = authHeader;\n    }\n    return headers;\n  }\n}\n\n/*\n * Provides user credentials required for the Firestore JavaScript SDK\n * to authenticate the user, using technique that is only available\n * to applications hosted by Google.\n */\nexport class FirstPartyCredentialsProvider implements CredentialsProvider {\n  constructor(private gapi: Gapi, private sessionIndex: string) {}\n\n  getToken(): Promise<Token | null> {\n    return Promise.resolve(new FirstPartyToken(this.gapi, this.sessionIndex));\n  }\n\n  setChangeListener(changeListener: CredentialChangeListener): void {\n    // Fire with initial uid.\n    changeListener(User.FIRST_PARTY);\n  }\n\n  removeChangeListener(): void {}\n\n  invalidateToken(): void {}\n}\n\n/**\n * Builds a CredentialsProvider depending on the type of\n * the credentials passed in.\n */\nexport function makeCredentialsProvider(\n  credentials?: CredentialsSettings\n): CredentialsProvider {\n  if (!credentials) {\n    return new EmptyCredentialsProvider();\n  }\n\n  switch (credentials.type) {\n    case 'gapi':\n      const client = credentials.client as Gapi;\n      // Make sure this really is a Gapi client.\n      hardAssert(\n        !!(\n          typeof client === 'object' &&\n          client !== null &&\n          client['auth'] &&\n          client['auth']['getAuthHeaderValueForFirstParty']\n        ),\n        'unexpected gapi interface'\n      );\n      return new FirstPartyCredentialsProvider(\n        client,\n        credentials.sessionIndex || '0'\n      );\n\n    case 'provider':\n      return credentials.client;\n\n    default:\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'makeCredentialsProvider failed due to invalid credential type'\n      );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { CredentialsProvider, Token } from '../api/credentials';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { TargetId } from '../core/types';\nimport { TargetData } from '../local/target_data';\nimport { Mutation, MutationResult } from '../model/mutation';\nimport * as api from '../protos/firestore_proto_api';\nimport { debugAssert, hardAssert } from '../util/assert';\nimport { AsyncQueue, DelayedOperation, TimerId } from '../util/async_queue';\nimport { Code, FirestoreError } from '../util/error';\nimport { logDebug, logError } from '../util/log';\n\nimport { isNullOrUndefined } from '../util/types';\nimport { ExponentialBackoff } from './backoff';\nimport { Connection, Stream } from './connection';\nimport {\n  fromVersion,\n  fromWatchChange,\n  fromWriteResults,\n  getEncodedDatabaseId,\n  JsonProtoSerializer,\n  toListenRequestLabels,\n  toMutation,\n  toTarget,\n  versionFromListenResponse\n} from './serializer';\nimport { WatchChange } from './watch_change';\n\nconst LOG_TAG = 'PersistentStream';\n\n// The generated proto interfaces for these class are missing the database\n// field. So we add it here.\n// TODO(b/36015800): Remove this once the api generator is fixed.\ninterface ListenRequest extends api.ListenRequest {\n  database?: string;\n}\nexport interface WriteRequest extends api.WriteRequest {\n  database?: string;\n}\n/**\n * PersistentStream can be in one of 5 states (each described in detail below)\n * based on the following state transition diagram:\n *\n *          start() called             auth & connection succeeded\n * INITIAL ----------------> STARTING -----------------------------> OPEN\n *                             ^  |                                   |\n *                             |  |                    error occurred |\n *                             |  \\-----------------------------v-----/\n *                             |                                |\n *                    backoff  |                                |\n *                    elapsed  |              start() called    |\n *                             \\--- BACKOFF <---------------- ERROR\n *\n * [any state] --------------------------> INITIAL\n *               stop() called or\n *               idle timer expired\n */\nconst enum PersistentStreamState {\n  /**\n   * The streaming RPC is not yet running and there's no error condition.\n   * Calling start() will start the stream immediately without backoff.\n   * While in this state isStarted() will return false.\n   */\n  Initial,\n\n  /**\n   * The stream is starting, either waiting for an auth token or for the stream\n   * to successfully open. While in this state, isStarted() will return true but\n   * isOpen() will return false.\n   */\n  Starting,\n\n  /**\n   * The streaming RPC is up and running. Requests and responses can flow\n   * freely. Both isStarted() and isOpen() will return true.\n   */\n  Open,\n\n  /**\n   * The stream encountered an error. The next start attempt will back off.\n   * While in this state isStarted() will return false.\n   */\n  Error,\n\n  /**\n   * An in-between state after an error where the stream is waiting before\n   * re-starting. After waiting is complete, the stream will try to open.\n   * While in this state isStarted() will return true but isOpen() will return\n   * false.\n   */\n  Backoff\n}\n\n/**\n * Provides a common interface that is shared by the listeners for stream\n * events by the concrete implementation classes.\n */\nexport interface PersistentStreamListener {\n  /**\n   * Called after the stream was established and can accept outgoing\n   * messages\n   */\n  onOpen: () => Promise<void>;\n  /**\n   * Called after the stream has closed. If there was an error, the\n   * FirestoreError will be set.\n   */\n  onClose: (err?: FirestoreError) => Promise<void>;\n}\n\n/** The time a stream stays open after it is marked idle. */\nconst IDLE_TIMEOUT_MS = 60 * 1000;\n\n/**\n * A PersistentStream is an abstract base class that represents a streaming RPC\n * to the Firestore backend. It's built on top of the connections own support\n * for streaming RPCs, and adds several critical features for our clients:\n *\n *   - Exponential backoff on failure\n *   - Authentication via CredentialsProvider\n *   - Dispatching all callbacks into the shared worker queue\n *   - Closing idle streams after 60 seconds of inactivity\n *\n * Subclasses of PersistentStream implement serialization of models to and\n * from the JSON representation of the protocol buffers for a specific\n * streaming RPC.\n *\n * ## Starting and Stopping\n *\n * Streaming RPCs are stateful and need to be start()ed before messages can\n * be sent and received. The PersistentStream will call the onOpen() function\n * of the listener once the stream is ready to accept requests.\n *\n * Should a start() fail, PersistentStream will call the registered onClose()\n * listener with a FirestoreError indicating what went wrong.\n *\n * A PersistentStream can be started and stopped repeatedly.\n *\n * Generic types:\n *  SendType: The type of the outgoing message of the underlying\n *    connection stream\n *  ReceiveType: The type of the incoming message of the underlying\n *    connection stream\n *  ListenerType: The type of the listener that will be used for callbacks\n */\nexport abstract class PersistentStream<\n  SendType,\n  ReceiveType,\n  ListenerType extends PersistentStreamListener\n> {\n  private state = PersistentStreamState.Initial;\n  /**\n   * A close count that's incremented every time the stream is closed; used by\n   * getCloseGuardedDispatcher() to invalidate callbacks that happen after\n   * close.\n   */\n  private closeCount = 0;\n\n  private idleTimer: DelayedOperation<void> | null = null;\n  private stream: Stream<SendType, ReceiveType> | null = null;\n\n  protected backoff: ExponentialBackoff;\n\n  constructor(\n    private queue: AsyncQueue,\n    connectionTimerId: TimerId,\n    private idleTimerId: TimerId,\n    protected connection: Connection,\n    private credentialsProvider: CredentialsProvider,\n    protected listener: ListenerType\n  ) {\n    this.backoff = new ExponentialBackoff(queue, connectionTimerId);\n  }\n\n  /**\n   * Returns true if start() has been called and no error has occurred. True\n   * indicates the stream is open or in the process of opening (which\n   * encompasses respecting backoff, getting auth tokens, and starting the\n   * actual RPC). Use isOpen() to determine if the stream is open and ready for\n   * outbound requests.\n   */\n  isStarted(): boolean {\n    return (\n      this.state === PersistentStreamState.Starting ||\n      this.state === PersistentStreamState.Open ||\n      this.state === PersistentStreamState.Backoff\n    );\n  }\n\n  /**\n   * Returns true if the underlying RPC is open (the onOpen() listener has been\n   * called) and the stream is ready for outbound requests.\n   */\n  isOpen(): boolean {\n    return this.state === PersistentStreamState.Open;\n  }\n\n  /**\n   * Starts the RPC. Only allowed if isStarted() returns false. The stream is\n   * not immediately ready for use: onOpen() will be invoked when the RPC is\n   * ready for outbound requests, at which point isOpen() will return true.\n   *\n   * When start returns, isStarted() will return true.\n   */\n  start(): void {\n    if (this.state === PersistentStreamState.Error) {\n      this.performBackoff();\n      return;\n    }\n\n    debugAssert(\n      this.state === PersistentStreamState.Initial,\n      'Already started'\n    );\n    this.auth();\n  }\n\n  /**\n   * Stops the RPC. This call is idempotent and allowed regardless of the\n   * current isStarted() state.\n   *\n   * When stop returns, isStarted() and isOpen() will both return false.\n   */\n  async stop(): Promise<void> {\n    if (this.isStarted()) {\n      await this.close(PersistentStreamState.Initial);\n    }\n  }\n\n  /**\n   * After an error the stream will usually back off on the next attempt to\n   * start it. If the error warrants an immediate restart of the stream, the\n   * sender can use this to indicate that the receiver should not back off.\n   *\n   * Each error will call the onClose() listener. That function can decide to\n   * inhibit backoff if required.\n   */\n  inhibitBackoff(): void {\n    debugAssert(\n      !this.isStarted(),\n      'Can only inhibit backoff in a stopped state'\n    );\n\n    this.state = PersistentStreamState.Initial;\n    this.backoff.reset();\n  }\n\n  /**\n   * Marks this stream as idle. If no further actions are performed on the\n   * stream for one minute, the stream will automatically close itself and\n   * notify the stream's onClose() handler with Status.OK. The stream will then\n   * be in a !isStarted() state, requiring the caller to start the stream again\n   * before further use.\n   *\n   * Only streams that are in state 'Open' can be marked idle, as all other\n   * states imply pending network operations.\n   */\n  markIdle(): void {\n    // Starts the idle time if we are in state 'Open' and are not yet already\n    // running a timer (in which case the previous idle timeout still applies).\n    if (this.isOpen() && this.idleTimer === null) {\n      this.idleTimer = this.queue.enqueueAfterDelay(\n        this.idleTimerId,\n        IDLE_TIMEOUT_MS,\n        () => this.handleIdleCloseTimer()\n      );\n    }\n  }\n\n  /** Sends a message to the underlying stream. */\n  protected sendRequest(msg: SendType): void {\n    this.cancelIdleCheck();\n    this.stream!.send(msg);\n  }\n\n  /** Called by the idle timer when the stream should close due to inactivity. */\n  private async handleIdleCloseTimer(): Promise<void> {\n    if (this.isOpen()) {\n      // When timing out an idle stream there's no reason to force the stream into backoff when\n      // it restarts so set the stream state to Initial instead of Error.\n      return this.close(PersistentStreamState.Initial);\n    }\n  }\n\n  /** Marks the stream as active again. */\n  private cancelIdleCheck(): void {\n    if (this.idleTimer) {\n      this.idleTimer.cancel();\n      this.idleTimer = null;\n    }\n  }\n\n  /**\n   * Closes the stream and cleans up as necessary:\n   *\n   * * closes the underlying GRPC stream;\n   * * calls the onClose handler with the given 'error';\n   * * sets internal stream state to 'finalState';\n   * * adjusts the backoff timer based on the error\n   *\n   * A new stream can be opened by calling start().\n   *\n   * @param finalState the intended state of the stream after closing.\n   * @param error the error the connection was closed with.\n   */\n  private async close(\n    finalState: PersistentStreamState,\n    error?: FirestoreError\n  ): Promise<void> {\n    debugAssert(this.isStarted(), 'Only started streams should be closed.');\n    debugAssert(\n      finalState === PersistentStreamState.Error || isNullOrUndefined(error),\n      \"Can't provide an error when not in an error state.\"\n    );\n\n    // Cancel any outstanding timers (they're guaranteed not to execute).\n    this.cancelIdleCheck();\n    this.backoff.cancel();\n\n    // Invalidates any stream-related callbacks (e.g. from auth or the\n    // underlying stream), guaranteeing they won't execute.\n    this.closeCount++;\n\n    if (finalState !== PersistentStreamState.Error) {\n      // If this is an intentional close ensure we don't delay our next connection attempt.\n      this.backoff.reset();\n    } else if (error && error.code === Code.RESOURCE_EXHAUSTED) {\n      // Log the error. (Probably either 'quota exceeded' or 'max queue length reached'.)\n      logError(error.toString());\n      logError(\n        'Using maximum backoff delay to prevent overloading the backend.'\n      );\n      this.backoff.resetToMax();\n    } else if (error && error.code === Code.UNAUTHENTICATED) {\n      // \"unauthenticated\" error means the token was rejected. Try force refreshing it in case it\n      // just expired.\n      this.credentialsProvider.invalidateToken();\n    }\n\n    // Clean up the underlying stream because we are no longer interested in events.\n    if (this.stream !== null) {\n      this.tearDown();\n      this.stream.close();\n      this.stream = null;\n    }\n\n    // This state must be assigned before calling onClose() to allow the callback to\n    // inhibit backoff or otherwise manipulate the state in its non-started state.\n    this.state = finalState;\n\n    // Notify the listener that the stream closed.\n    await this.listener.onClose(error);\n  }\n\n  /**\n   * Can be overridden to perform additional cleanup before the stream is closed.\n   * Calling super.tearDown() is not required.\n   */\n  protected tearDown(): void {}\n\n  /**\n   * Used by subclasses to start the concrete RPC and return the underlying\n   * connection stream.\n   */\n  protected abstract startRpc(\n    token: Token | null\n  ): Stream<SendType, ReceiveType>;\n\n  /**\n   * Called after the stream has received a message. The function will be\n   * called on the right queue and must return a Promise.\n   * @param message The message received from the stream.\n   */\n  protected abstract onMessage(message: ReceiveType): Promise<void>;\n\n  private auth(): void {\n    debugAssert(\n      this.state === PersistentStreamState.Initial,\n      'Must be in initial state to auth'\n    );\n\n    this.state = PersistentStreamState.Starting;\n\n    const dispatchIfNotClosed = this.getCloseGuardedDispatcher(this.closeCount);\n\n    // TODO(mikelehen): Just use dispatchIfNotClosed, but see TODO below.\n    const closeCount = this.closeCount;\n\n    this.credentialsProvider.getToken().then(\n      token => {\n        // Stream can be stopped while waiting for authentication.\n        // TODO(mikelehen): We really should just use dispatchIfNotClosed\n        // and let this dispatch onto the queue, but that opened a spec test can\n        // of worms that I don't want to deal with in this PR.\n        if (this.closeCount === closeCount) {\n          // Normally we'd have to schedule the callback on the AsyncQueue.\n          // However, the following calls are safe to be called outside the\n          // AsyncQueue since they don't chain asynchronous calls\n          this.startStream(token);\n        }\n      },\n      (error: Error) => {\n        dispatchIfNotClosed(() => {\n          const rpcError = new FirestoreError(\n            Code.UNKNOWN,\n            'Fetching auth token failed: ' + error.message\n          );\n          return this.handleStreamClose(rpcError);\n        });\n      }\n    );\n  }\n\n  private startStream(token: Token | null): void {\n    debugAssert(\n      this.state === PersistentStreamState.Starting,\n      'Trying to start stream in a non-starting state'\n    );\n\n    const dispatchIfNotClosed = this.getCloseGuardedDispatcher(this.closeCount);\n\n    this.stream = this.startRpc(token);\n    this.stream.onOpen(() => {\n      dispatchIfNotClosed(() => {\n        debugAssert(\n          this.state === PersistentStreamState.Starting,\n          'Expected stream to be in state Starting, but was ' + this.state\n        );\n        this.state = PersistentStreamState.Open;\n        return this.listener!.onOpen();\n      });\n    });\n    this.stream.onClose((error?: FirestoreError) => {\n      dispatchIfNotClosed(() => {\n        return this.handleStreamClose(error);\n      });\n    });\n    this.stream.onMessage((msg: ReceiveType) => {\n      dispatchIfNotClosed(() => {\n        return this.onMessage(msg);\n      });\n    });\n  }\n\n  private performBackoff(): void {\n    debugAssert(\n      this.state === PersistentStreamState.Error,\n      'Should only perform backoff when in Error state'\n    );\n    this.state = PersistentStreamState.Backoff;\n\n    this.backoff.backoffAndRun(async () => {\n      debugAssert(\n        this.state === PersistentStreamState.Backoff,\n        'Backoff elapsed but state is now: ' + this.state\n      );\n\n      this.state = PersistentStreamState.Initial;\n      this.start();\n      debugAssert(this.isStarted(), 'PersistentStream should have started');\n    });\n  }\n\n  // Visible for tests\n  handleStreamClose(error?: FirestoreError): Promise<void> {\n    debugAssert(\n      this.isStarted(),\n      \"Can't handle server close on non-started stream\"\n    );\n    logDebug(LOG_TAG, `close with error: ${error}`);\n\n    this.stream = null;\n\n    // In theory the stream could close cleanly, however, in our current model\n    // we never expect this to happen because if we stop a stream ourselves,\n    // this callback will never be called. To prevent cases where we retry\n    // without a backoff accidentally, we set the stream to error in all cases.\n    return this.close(PersistentStreamState.Error, error);\n  }\n\n  /**\n   * Returns a \"dispatcher\" function that dispatches operations onto the\n   * AsyncQueue but only runs them if closeCount remains unchanged. This allows\n   * us to turn auth / stream callbacks into no-ops if the stream is closed /\n   * re-opened, etc.\n   */\n  private getCloseGuardedDispatcher(\n    startCloseCount: number\n  ): (fn: () => Promise<void>) => void {\n    return (fn: () => Promise<void>): void => {\n      this.queue.enqueueAndForget(() => {\n        if (this.closeCount === startCloseCount) {\n          return fn();\n        } else {\n          logDebug(\n            LOG_TAG,\n            'stream callback skipped by getCloseGuardedDispatcher.'\n          );\n          return Promise.resolve();\n        }\n      });\n    };\n  }\n}\n\n/** Listener for the PersistentWatchStream */\nexport interface WatchStreamListener extends PersistentStreamListener {\n  /**\n   * Called on a watchChange. The snapshot parameter will be MIN if the watch\n   * change did not have a snapshot associated with it.\n   */\n  onWatchChange: (\n    watchChange: WatchChange,\n    snapshot: SnapshotVersion\n  ) => Promise<void>;\n}\n\n/**\n * A PersistentStream that implements the Listen RPC.\n *\n * Once the Listen stream has called the onOpen() listener, any number of\n * listen() and unlisten() calls can be made to control what changes will be\n * sent from the server for ListenResponses.\n */\nexport class PersistentListenStream extends PersistentStream<\n  api.ListenRequest,\n  api.ListenResponse,\n  WatchStreamListener\n> {\n  constructor(\n    queue: AsyncQueue,\n    connection: Connection,\n    credentials: CredentialsProvider,\n    private serializer: JsonProtoSerializer,\n    listener: WatchStreamListener\n  ) {\n    super(\n      queue,\n      TimerId.ListenStreamConnectionBackoff,\n      TimerId.ListenStreamIdle,\n      connection,\n      credentials,\n      listener\n    );\n  }\n\n  protected startRpc(\n    token: Token | null\n  ): Stream<api.ListenRequest, api.ListenResponse> {\n    return this.connection.openStream<api.ListenRequest, api.ListenResponse>(\n      'Listen',\n      token\n    );\n  }\n\n  protected onMessage(watchChangeProto: api.ListenResponse): Promise<void> {\n    // A successful response means the stream is healthy\n    this.backoff.reset();\n\n    const watchChange = fromWatchChange(this.serializer, watchChangeProto);\n    const snapshot = versionFromListenResponse(watchChangeProto);\n    return this.listener!.onWatchChange(watchChange, snapshot);\n  }\n\n  /**\n   * Registers interest in the results of the given target. If the target\n   * includes a resumeToken it will be included in the request. Results that\n   * affect the target will be streamed back as WatchChange messages that\n   * reference the targetId.\n   */\n  watch(targetData: TargetData): void {\n    const request: ListenRequest = {};\n    request.database = getEncodedDatabaseId(this.serializer);\n    request.addTarget = toTarget(this.serializer, targetData);\n\n    const labels = toListenRequestLabels(this.serializer, targetData);\n    if (labels) {\n      request.labels = labels;\n    }\n\n    this.sendRequest(request);\n  }\n\n  /**\n   * Unregisters interest in the results of the target associated with the\n   * given targetId.\n   */\n  unwatch(targetId: TargetId): void {\n    const request: ListenRequest = {};\n    request.database = getEncodedDatabaseId(this.serializer);\n    request.removeTarget = targetId;\n    this.sendRequest(request);\n  }\n}\n\n/** Listener for the PersistentWriteStream */\nexport interface WriteStreamListener extends PersistentStreamListener {\n  /**\n   * Called by the PersistentWriteStream upon a successful handshake response\n   * from the server, which is the receiver's cue to send any pending writes.\n   */\n  onHandshakeComplete: () => Promise<void>;\n\n  /**\n   * Called by the PersistentWriteStream upon receiving a StreamingWriteResponse\n   * from the server that contains a mutation result.\n   */\n  onMutationResult: (\n    commitVersion: SnapshotVersion,\n    results: MutationResult[]\n  ) => Promise<void>;\n}\n\n/**\n * A Stream that implements the Write RPC.\n *\n * The Write RPC requires the caller to maintain special streamToken\n * state in between calls, to help the server understand which responses the\n * client has processed by the time the next request is made. Every response\n * will contain a streamToken; this value must be passed to the next\n * request.\n *\n * After calling start() on this stream, the next request must be a handshake,\n * containing whatever streamToken is on hand. Once a response to this\n * request is received, all pending mutations may be submitted. When\n * submitting multiple batches of mutations at the same time, it's\n * okay to use the same streamToken for the calls to writeMutations.\n *\n * TODO(b/33271235): Use proto types\n */\nexport class PersistentWriteStream extends PersistentStream<\n  api.WriteRequest,\n  api.WriteResponse,\n  WriteStreamListener\n> {\n  private handshakeComplete_ = false;\n\n  constructor(\n    queue: AsyncQueue,\n    connection: Connection,\n    credentials: CredentialsProvider,\n    private serializer: JsonProtoSerializer,\n    listener: WriteStreamListener\n  ) {\n    super(\n      queue,\n      TimerId.WriteStreamConnectionBackoff,\n      TimerId.WriteStreamIdle,\n      connection,\n      credentials,\n      listener\n    );\n  }\n\n  /**\n   * The last received stream token from the server, used to acknowledge which\n   * responses the client has processed. Stream tokens are opaque checkpoint\n   * markers whose only real value is their inclusion in the next request.\n   *\n   * PersistentWriteStream manages propagating this value from responses to the\n   * next request.\n   */\n  private lastStreamToken: string | Uint8Array | undefined;\n\n  /**\n   * Tracks whether or not a handshake has been successfully exchanged and\n   * the stream is ready to accept mutations.\n   */\n  get handshakeComplete(): boolean {\n    return this.handshakeComplete_;\n  }\n\n  // Override of PersistentStream.start\n  start(): void {\n    this.handshakeComplete_ = false;\n    this.lastStreamToken = undefined;\n    super.start();\n  }\n\n  protected tearDown(): void {\n    if (this.handshakeComplete_) {\n      this.writeMutations([]);\n    }\n  }\n\n  protected startRpc(\n    token: Token | null\n  ): Stream<api.WriteRequest, api.WriteResponse> {\n    return this.connection.openStream<api.WriteRequest, api.WriteResponse>(\n      'Write',\n      token\n    );\n  }\n\n  protected onMessage(responseProto: api.WriteResponse): Promise<void> {\n    // Always capture the last stream token.\n    hardAssert(\n      !!responseProto.streamToken,\n      'Got a write response without a stream token'\n    );\n    this.lastStreamToken = responseProto.streamToken;\n\n    if (!this.handshakeComplete_) {\n      // The first response is always the handshake response\n      hardAssert(\n        !responseProto.writeResults || responseProto.writeResults.length === 0,\n        'Got mutation results for handshake'\n      );\n      this.handshakeComplete_ = true;\n      return this.listener!.onHandshakeComplete();\n    } else {\n      // A successful first write response means the stream is healthy,\n      // Note, that we could consider a successful handshake healthy, however,\n      // the write itself might be causing an error we want to back off from.\n      this.backoff.reset();\n\n      const results = fromWriteResults(\n        responseProto.writeResults,\n        responseProto.commitTime\n      );\n      const commitVersion = fromVersion(responseProto.commitTime!);\n      return this.listener!.onMutationResult(commitVersion, results);\n    }\n  }\n\n  /**\n   * Sends an initial streamToken to the server, performing the handshake\n   * required to make the StreamingWrite RPC work. Subsequent\n   * calls should wait until onHandshakeComplete was called.\n   */\n  writeHandshake(): void {\n    debugAssert(this.isOpen(), 'Writing handshake requires an opened stream');\n    debugAssert(!this.handshakeComplete_, 'Handshake already completed');\n    debugAssert(\n      !this.lastStreamToken,\n      'Stream token should be empty during handshake'\n    );\n    // TODO(dimond): Support stream resumption. We intentionally do not set the\n    // stream token on the handshake, ignoring any stream token we might have.\n    const request: WriteRequest = {};\n    request.database = getEncodedDatabaseId(this.serializer);\n    this.sendRequest(request);\n  }\n\n  /** Sends a group of mutations to the Firestore backend to apply. */\n  writeMutations(mutations: Mutation[]): void {\n    debugAssert(this.isOpen(), 'Writing mutations requires an opened stream');\n    debugAssert(\n      this.handshakeComplete_,\n      'Handshake must be complete before writing mutations'\n    );\n    debugAssert(\n      !!this.lastStreamToken,\n      'Trying to write mutation without a token'\n    );\n\n    const request: WriteRequest = {\n      streamToken: this.lastStreamToken,\n      writes: mutations.map(mutation => toMutation(this.serializer, mutation))\n    };\n\n    this.sendRequest(request);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { CredentialsProvider } from '../api/credentials';\nimport { Document, MaybeDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { Mutation } from '../model/mutation';\nimport * as api from '../protos/firestore_proto_api';\nimport { debugAssert, debugCast, hardAssert } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { Connection } from './connection';\nimport {\n  fromDocument,\n  fromMaybeDocument,\n  getEncodedDatabaseId,\n  JsonProtoSerializer,\n  toMutation,\n  toName,\n  toQueryTarget\n} from './serializer';\nimport {\n  PersistentListenStream,\n  PersistentWriteStream,\n  WatchStreamListener,\n  WriteStreamListener\n} from './persistent_stream';\nimport { AsyncQueue } from '../util/async_queue';\nimport { Query, queryToTarget } from '../core/query';\n\n/**\n * Datastore and its related methods are a wrapper around the external Google\n * Cloud Datastore grpc API, which provides an interface that is more convenient\n * for the rest of the client SDK architecture to consume.\n */\nexport abstract class Datastore {\n  abstract terminate(): void;\n}\n\n/**\n * An implementation of Datastore that exposes additional state for internal\n * consumption.\n */\nclass DatastoreImpl extends Datastore {\n  terminated = false;\n\n  constructor(\n    readonly credentials: CredentialsProvider,\n    readonly connection: Connection,\n    readonly serializer: JsonProtoSerializer\n  ) {\n    super();\n  }\n\n  verifyInitialized(): void {\n    debugAssert(!!this.connection, 'Datastore.start() not called');\n    if (this.terminated) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        'The client has already been terminated.'\n      );\n    }\n  }\n\n  /** Gets an auth token and invokes the provided RPC. */\n  invokeRPC<Req, Resp>(\n    rpcName: string,\n    path: string,\n    request: Req\n  ): Promise<Resp> {\n    this.verifyInitialized();\n    return this.credentials\n      .getToken()\n      .then(token => {\n        return this.connection.invokeRPC<Req, Resp>(\n          rpcName,\n          path,\n          request,\n          token\n        );\n      })\n      .catch((error: FirestoreError) => {\n        if (error.code === Code.UNAUTHENTICATED) {\n          this.credentials.invalidateToken();\n        }\n        throw error;\n      });\n  }\n\n  /** Gets an auth token and invokes the provided RPC with streamed results. */\n  invokeStreamingRPC<Req, Resp>(\n    rpcName: string,\n    path: string,\n    request: Req\n  ): Promise<Resp[]> {\n    this.verifyInitialized();\n    return this.credentials\n      .getToken()\n      .then(token => {\n        return this.connection.invokeStreamingRPC<Req, Resp>(\n          rpcName,\n          path,\n          request,\n          token\n        );\n      })\n      .catch((error: FirestoreError) => {\n        if (error.code === Code.UNAUTHENTICATED) {\n          this.credentials.invalidateToken();\n        }\n        throw error;\n      });\n  }\n\n  terminate(): void {\n    this.terminated = false;\n  }\n}\n\n// TODO(firestorexp): Make sure there is only one Datastore instance per\n// firestore-exp client.\nexport function newDatastore(\n  credentials: CredentialsProvider,\n  connection: Connection,\n  serializer: JsonProtoSerializer\n): Datastore {\n  return new DatastoreImpl(credentials, connection, serializer);\n}\n\nexport async function invokeCommitRpc(\n  datastore: Datastore,\n  mutations: Mutation[]\n): Promise<void> {\n  const datastoreImpl = debugCast(datastore, DatastoreImpl);\n  const path = getEncodedDatabaseId(datastoreImpl.serializer) + '/documents';\n  const request = {\n    writes: mutations.map(m => toMutation(datastoreImpl.serializer, m))\n  };\n  await datastoreImpl.invokeRPC('Commit', path, request);\n}\n\nexport async function invokeBatchGetDocumentsRpc(\n  datastore: Datastore,\n  keys: DocumentKey[]\n): Promise<MaybeDocument[]> {\n  const datastoreImpl = debugCast(datastore, DatastoreImpl);\n  const path = getEncodedDatabaseId(datastoreImpl.serializer) + '/documents';\n  const request = {\n    documents: keys.map(k => toName(datastoreImpl.serializer, k))\n  };\n  const response = await datastoreImpl.invokeStreamingRPC<\n    api.BatchGetDocumentsRequest,\n    api.BatchGetDocumentsResponse\n  >('BatchGetDocuments', path, request);\n\n  const docs = new Map<string, MaybeDocument>();\n  response.forEach(proto => {\n    const doc = fromMaybeDocument(datastoreImpl.serializer, proto);\n    docs.set(doc.key.toString(), doc);\n  });\n  const result: MaybeDocument[] = [];\n  keys.forEach(key => {\n    const doc = docs.get(key.toString());\n    hardAssert(!!doc, 'Missing entity in write response for ' + key);\n    result.push(doc);\n  });\n  return result;\n}\n\nexport async function invokeRunQueryRpc(\n  datastore: Datastore,\n  query: Query\n): Promise<Document[]> {\n  const datastoreImpl = debugCast(datastore, DatastoreImpl);\n  const request = toQueryTarget(datastoreImpl.serializer, queryToTarget(query));\n  const response = await datastoreImpl.invokeStreamingRPC<\n    api.RunQueryRequest,\n    api.RunQueryResponse\n  >('RunQuery', request.parent!, { structuredQuery: request.structuredQuery });\n  return (\n    response\n      // Omit RunQueryResponses that only contain readTimes.\n      .filter(proto => !!proto.document)\n      .map(proto =>\n        fromDocument(datastoreImpl.serializer, proto.document!, undefined)\n      )\n  );\n}\n\nexport function newPersistentWriteStream(\n  datastore: Datastore,\n  queue: AsyncQueue,\n  listener: WriteStreamListener\n): PersistentWriteStream {\n  const datastoreImpl = debugCast(datastore, DatastoreImpl);\n  datastoreImpl.verifyInitialized();\n  return new PersistentWriteStream(\n    queue,\n    datastoreImpl.connection,\n    datastoreImpl.credentials,\n    datastoreImpl.serializer,\n    listener\n  );\n}\n\nexport function newPersistentWatchStream(\n  datastore: Datastore,\n  queue: AsyncQueue,\n  listener: WatchStreamListener\n): PersistentListenStream {\n  const datastoreImpl = debugCast(datastore, DatastoreImpl);\n  datastoreImpl.verifyInitialized();\n  return new PersistentListenStream(\n    queue,\n    datastoreImpl.connection,\n    datastoreImpl.credentials,\n    datastoreImpl.serializer,\n    listener\n  );\n}\n","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { OnlineState } from '../core/types';\nimport { debugAssert } from '../util/assert';\nimport { AsyncQueue, DelayedOperation, TimerId } from '../util/async_queue';\nimport { FirestoreError } from '../util/error';\nimport { logError, logDebug } from '../util/log';\n\nconst LOG_TAG = 'OnlineStateTracker';\n\n// To deal with transient failures, we allow multiple stream attempts before\n// giving up and transitioning from OnlineState.Unknown to Offline.\n// TODO(mikelehen): This used to be set to 2 as a mitigation for b/66228394.\n// @jdimond thinks that bug is sufficiently fixed so that we can set this back\n// to 1. If that works okay, we could potentially remove this logic entirely.\nconst MAX_WATCH_STREAM_FAILURES = 1;\n\n// To deal with stream attempts that don't succeed or fail in a timely manner,\n// we have a timeout for OnlineState to reach Online or Offline.\n// If the timeout is reached, we transition to Offline rather than waiting\n// indefinitely.\nconst ONLINE_STATE_TIMEOUT_MS = 10 * 1000;\n\n/**\n * A component used by the RemoteStore to track the OnlineState (that is,\n * whether or not the client as a whole should be considered to be online or\n * offline), implementing the appropriate heuristics.\n *\n * In particular, when the client is trying to connect to the backend, we\n * allow up to MAX_WATCH_STREAM_FAILURES within ONLINE_STATE_TIMEOUT_MS for\n * a connection to succeed. If we have too many failures or the timeout elapses,\n * then we set the OnlineState to Offline, and the client will behave as if\n * it is offline (get()s will return cached data, etc.).\n */\nexport class OnlineStateTracker {\n  /** The current OnlineState. */\n  private state = OnlineState.Unknown;\n\n  /**\n   * A count of consecutive failures to open the stream. If it reaches the\n   * maximum defined by MAX_WATCH_STREAM_FAILURES, we'll set the OnlineState to\n   * Offline.\n   */\n  private watchStreamFailures = 0;\n\n  /**\n   * A timer that elapses after ONLINE_STATE_TIMEOUT_MS, at which point we\n   * transition from OnlineState.Unknown to OnlineState.Offline without waiting\n   * for the stream to actually fail (MAX_WATCH_STREAM_FAILURES times).\n   */\n  private onlineStateTimer: DelayedOperation<void> | null = null;\n\n  /**\n   * Whether the client should log a warning message if it fails to connect to\n   * the backend (initially true, cleared after a successful stream, or if we've\n   * logged the message already).\n   */\n  private shouldWarnClientIsOffline = true;\n\n  constructor(\n    private asyncQueue: AsyncQueue,\n    private onlineStateHandler: (onlineState: OnlineState) => void\n  ) {}\n\n  /**\n   * Called by RemoteStore when a watch stream is started (including on each\n   * backoff attempt).\n   *\n   * If this is the first attempt, it sets the OnlineState to Unknown and starts\n   * the onlineStateTimer.\n   */\n  handleWatchStreamStart(): void {\n    if (this.watchStreamFailures === 0) {\n      this.setAndBroadcast(OnlineState.Unknown);\n\n      debugAssert(\n        this.onlineStateTimer === null,\n        `onlineStateTimer shouldn't be started yet`\n      );\n      this.onlineStateTimer = this.asyncQueue.enqueueAfterDelay(\n        TimerId.OnlineStateTimeout,\n        ONLINE_STATE_TIMEOUT_MS,\n        () => {\n          this.onlineStateTimer = null;\n          debugAssert(\n            this.state === OnlineState.Unknown,\n            'Timer should be canceled if we transitioned to a different state.'\n          );\n          this.logClientOfflineWarningIfNecessary(\n            `Backend didn't respond within ${ONLINE_STATE_TIMEOUT_MS / 1000} ` +\n              `seconds.`\n          );\n          this.setAndBroadcast(OnlineState.Offline);\n\n          // NOTE: handleWatchStreamFailure() will continue to increment\n          // watchStreamFailures even though we are already marked Offline,\n          // but this is non-harmful.\n\n          return Promise.resolve();\n        }\n      );\n    }\n  }\n\n  /**\n   * Updates our OnlineState as appropriate after the watch stream reports a\n   * failure. The first failure moves us to the 'Unknown' state. We then may\n   * allow multiple failures (based on MAX_WATCH_STREAM_FAILURES) before we\n   * actually transition to the 'Offline' state.\n   */\n  handleWatchStreamFailure(error: FirestoreError): void {\n    if (this.state === OnlineState.Online) {\n      this.setAndBroadcast(OnlineState.Unknown);\n\n      // To get to OnlineState.Online, set() must have been called which would\n      // have reset our heuristics.\n      debugAssert(\n        this.watchStreamFailures === 0,\n        'watchStreamFailures must be 0'\n      );\n      debugAssert(\n        this.onlineStateTimer === null,\n        'onlineStateTimer must be null'\n      );\n    } else {\n      this.watchStreamFailures++;\n      if (this.watchStreamFailures >= MAX_WATCH_STREAM_FAILURES) {\n        this.clearOnlineStateTimer();\n\n        this.logClientOfflineWarningIfNecessary(\n          `Connection failed ${MAX_WATCH_STREAM_FAILURES} ` +\n            `times. Most recent error: ${error.toString()}`\n        );\n\n        this.setAndBroadcast(OnlineState.Offline);\n      }\n    }\n  }\n\n  /**\n   * Explicitly sets the OnlineState to the specified state.\n   *\n   * Note that this resets our timers / failure counters, etc. used by our\n   * Offline heuristics, so must not be used in place of\n   * handleWatchStreamStart() and handleWatchStreamFailure().\n   */\n  set(newState: OnlineState): void {\n    this.clearOnlineStateTimer();\n    this.watchStreamFailures = 0;\n\n    if (newState === OnlineState.Online) {\n      // We've connected to watch at least once. Don't warn the developer\n      // about being offline going forward.\n      this.shouldWarnClientIsOffline = false;\n    }\n\n    this.setAndBroadcast(newState);\n  }\n\n  private setAndBroadcast(newState: OnlineState): void {\n    if (newState !== this.state) {\n      this.state = newState;\n      this.onlineStateHandler(newState);\n    }\n  }\n\n  private logClientOfflineWarningIfNecessary(details: string): void {\n    const message =\n      `Could not reach Cloud Firestore backend. ${details}\\n` +\n      `This typically indicates that your device does not have a healthy ` +\n      `Internet connection at the moment. The client will operate in offline ` +\n      `mode until it is able to successfully connect to the backend.`;\n    if (this.shouldWarnClientIsOffline) {\n      logError(message);\n      this.shouldWarnClientIsOffline = false;\n    } else {\n      logDebug(LOG_TAG, message);\n    }\n  }\n\n  private clearOnlineStateTimer(): void {\n    if (this.onlineStateTimer !== null) {\n      this.onlineStateTimer.cancel();\n      this.onlineStateTimer = null;\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { OnlineState, TargetId } from '../core/types';\nimport { LocalStore } from '../local/local_store';\nimport { TargetData, TargetPurpose } from '../local/target_data';\nimport { MutationResult } from '../model/mutation';\nimport {\n  BATCHID_UNKNOWN,\n  MutationBatch,\n  MutationBatchResult\n} from '../model/mutation_batch';\nimport { debugAssert } from '../util/assert';\nimport { FirestoreError } from '../util/error';\nimport { logDebug } from '../util/log';\nimport { DocumentKeySet } from '../model/collections';\nimport { AsyncQueue } from '../util/async_queue';\nimport { ConnectivityMonitor, NetworkStatus } from './connectivity_monitor';\nimport {\n  Datastore,\n  newPersistentWatchStream,\n  newPersistentWriteStream\n} from './datastore';\nimport { OnlineStateTracker } from './online_state_tracker';\nimport {\n  PersistentListenStream,\n  PersistentWriteStream\n} from './persistent_stream';\nimport { RemoteSyncer } from './remote_syncer';\nimport { isPermanentWriteError } from './rpc_error';\nimport {\n  DocumentWatchChange,\n  ExistenceFilterChange,\n  TargetMetadataProvider,\n  WatchChange,\n  WatchChangeAggregator,\n  WatchTargetChange,\n  WatchTargetChangeState\n} from './watch_change';\nimport { ByteString } from '../util/byte_string';\nimport { isIndexedDbTransactionError } from '../local/simple_db';\nimport { User } from '../auth/user';\n\nconst LOG_TAG = 'RemoteStore';\n\n// TODO(b/35853402): Negotiate this with the stream.\nconst MAX_PENDING_WRITES = 10;\n\n/** Reasons for why the RemoteStore may be offline. */\nconst enum OfflineCause {\n  /** The user has explicitly disabled the network (via `disableNetwork()`). */\n  UserDisabled,\n  /** An IndexedDb failure occurred while persisting a stream update. */\n  IndexedDbFailed,\n  /** The tab is not the primary tab (only relevant with multi-tab). */\n  IsSecondary,\n  /** We are restarting the streams due to an Auth credential change. */\n  CredentialChange,\n  /** The connectivity state of the environment has changed. */\n  ConnectivityChange,\n  /** The RemoteStore has been shut down. */\n  Shutdown\n}\n\n/**\n * RemoteStore - An interface to remotely stored data, basically providing a\n * wrapper around the Datastore that is more reliable for the rest of the\n * system.\n *\n * RemoteStore is responsible for maintaining the connection to the server.\n * - maintaining a list of active listens.\n * - reconnecting when the connection is dropped.\n * - resuming all the active listens on reconnect.\n *\n * RemoteStore handles all incoming events from the Datastore.\n * - listening to the watch stream and repackaging the events as RemoteEvents\n * - notifying SyncEngine of any changes to the active listens.\n *\n * RemoteStore takes writes from other components and handles them reliably.\n * - pulling pending mutations from LocalStore and sending them to Datastore.\n * - retrying mutations that failed because of network problems.\n * - acking mutations to the SyncEngine once they are accepted or rejected.\n */\nexport class RemoteStore implements TargetMetadataProvider {\n  /**\n   * A list of up to MAX_PENDING_WRITES writes that we have fetched from the\n   * LocalStore via fillWritePipeline() and have or will send to the write\n   * stream.\n   *\n   * Whenever writePipeline.length > 0 the RemoteStore will attempt to start or\n   * restart the write stream. When the stream is established the writes in the\n   * pipeline will be sent in order.\n   *\n   * Writes remain in writePipeline until they are acknowledged by the backend\n   * and thus will automatically be re-sent if the stream is interrupted /\n   * restarted before they're acknowledged.\n   *\n   * Write responses from the backend are linked to their originating request\n   * purely based on order, and so we can just shift() writes from the front of\n   * the writePipeline as we receive responses.\n   */\n  private writePipeline: MutationBatch[] = [];\n\n  /**\n   * A mapping of watched targets that the client cares about tracking and the\n   * user has explicitly called a 'listen' for this target.\n   *\n   * These targets may or may not have been sent to or acknowledged by the\n   * server. On re-establishing the listen stream, these targets should be sent\n   * to the server. The targets removed with unlistens are removed eagerly\n   * without waiting for confirmation from the listen stream.\n   */\n  private listenTargets = new Map<TargetId, TargetData>();\n\n  private connectivityMonitor: ConnectivityMonitor;\n  private watchStream: PersistentListenStream;\n  private writeStream: PersistentWriteStream;\n  private watchChangeAggregator: WatchChangeAggregator | null = null;\n\n  /**\n   * A set of reasons for why the RemoteStore may be offline. If empty, the\n   * RemoteStore may start its network connections.\n   */\n  private offlineCauses = new Set<OfflineCause>();\n\n  private onlineStateTracker: OnlineStateTracker;\n\n  constructor(\n    /**\n     * The local store, used to fill the write pipeline with outbound mutations.\n     */\n    private localStore: LocalStore,\n    /** The client-side proxy for interacting with the backend. */\n    private datastore: Datastore,\n    private asyncQueue: AsyncQueue,\n    onlineStateHandler: (onlineState: OnlineState) => void,\n    connectivityMonitor: ConnectivityMonitor\n  ) {\n    this.connectivityMonitor = connectivityMonitor;\n    this.connectivityMonitor.addCallback((_: NetworkStatus) => {\n      asyncQueue.enqueueAndForget(async () => {\n        // Porting Note: Unlike iOS, `restartNetwork()` is called even when the\n        // network becomes unreachable as we don't have any other way to tear\n        // down our streams.\n        if (this.canUseNetwork()) {\n          logDebug(\n            LOG_TAG,\n            'Restarting streams for network reachability change.'\n          );\n          await this.restartNetwork();\n        }\n      });\n    });\n\n    this.onlineStateTracker = new OnlineStateTracker(\n      asyncQueue,\n      onlineStateHandler\n    );\n\n    // Create streams (but note they're not started yet).\n    this.watchStream = newPersistentWatchStream(this.datastore, asyncQueue, {\n      onOpen: this.onWatchStreamOpen.bind(this),\n      onClose: this.onWatchStreamClose.bind(this),\n      onWatchChange: this.onWatchStreamChange.bind(this)\n    });\n\n    this.writeStream = newPersistentWriteStream(this.datastore, asyncQueue, {\n      onOpen: this.onWriteStreamOpen.bind(this),\n      onClose: this.onWriteStreamClose.bind(this),\n      onHandshakeComplete: this.onWriteHandshakeComplete.bind(this),\n      onMutationResult: this.onMutationResult.bind(this)\n    });\n  }\n\n  /**\n   * SyncEngine to notify of watch and write events. This must be set\n   * immediately after construction.\n   */\n  syncEngine!: RemoteSyncer;\n\n  /**\n   * Starts up the remote store, creating streams, restoring state from\n   * LocalStore, etc.\n   */\n  start(): Promise<void> {\n    return this.enableNetwork();\n  }\n\n  /** Re-enables the network. Idempotent. */\n  enableNetwork(): Promise<void> {\n    this.offlineCauses.delete(OfflineCause.UserDisabled);\n    return this.enableNetworkInternal();\n  }\n\n  private async enableNetworkInternal(): Promise<void> {\n    if (this.canUseNetwork()) {\n      if (this.shouldStartWatchStream()) {\n        this.startWatchStream();\n      } else {\n        this.onlineStateTracker.set(OnlineState.Unknown);\n      }\n\n      // This will start the write stream if necessary.\n      await this.fillWritePipeline();\n    }\n  }\n\n  /**\n   * Temporarily disables the network. The network can be re-enabled using\n   * enableNetwork().\n   */\n  async disableNetwork(): Promise<void> {\n    this.offlineCauses.add(OfflineCause.UserDisabled);\n    await this.disableNetworkInternal();\n\n    // Set the OnlineState to Offline so get()s return from cache, etc.\n    this.onlineStateTracker.set(OnlineState.Offline);\n  }\n\n  private async disableNetworkInternal(): Promise<void> {\n    await this.writeStream.stop();\n    await this.watchStream.stop();\n\n    if (this.writePipeline.length > 0) {\n      logDebug(\n        LOG_TAG,\n        `Stopping write stream with ${this.writePipeline.length} pending writes`\n      );\n      this.writePipeline = [];\n    }\n\n    this.cleanUpWatchStreamState();\n  }\n\n  async shutdown(): Promise<void> {\n    logDebug(LOG_TAG, 'RemoteStore shutting down.');\n    this.offlineCauses.add(OfflineCause.Shutdown);\n    await this.disableNetworkInternal();\n    this.connectivityMonitor.shutdown();\n\n    // Set the OnlineState to Unknown (rather than Offline) to avoid potentially\n    // triggering spurious listener events with cached data, etc.\n    this.onlineStateTracker.set(OnlineState.Unknown);\n  }\n\n  /**\n   * Starts new listen for the given target. Uses resume token if provided. It\n   * is a no-op if the target of given `TargetData` is already being listened to.\n   */\n  listen(targetData: TargetData): void {\n    if (this.listenTargets.has(targetData.targetId)) {\n      return;\n    }\n\n    // Mark this as something the client is currently listening for.\n    this.listenTargets.set(targetData.targetId, targetData);\n\n    if (this.shouldStartWatchStream()) {\n      // The listen will be sent in onWatchStreamOpen\n      this.startWatchStream();\n    } else if (this.watchStream.isOpen()) {\n      this.sendWatchRequest(targetData);\n    }\n  }\n\n  /**\n   * Removes the listen from server. It is a no-op if the given target id is\n   * not being listened to.\n   */\n  unlisten(targetId: TargetId): void {\n    debugAssert(\n      this.listenTargets.has(targetId),\n      `unlisten called on target no currently watched: ${targetId}`\n    );\n\n    this.listenTargets.delete(targetId);\n    if (this.watchStream.isOpen()) {\n      this.sendUnwatchRequest(targetId);\n    }\n\n    if (this.listenTargets.size === 0) {\n      if (this.watchStream.isOpen()) {\n        this.watchStream.markIdle();\n      } else if (this.canUseNetwork()) {\n        // Revert to OnlineState.Unknown if the watch stream is not open and we\n        // have no listeners, since without any listens to send we cannot\n        // confirm if the stream is healthy and upgrade to OnlineState.Online.\n        this.onlineStateTracker.set(OnlineState.Unknown);\n      }\n    }\n  }\n\n  /** {@link TargetMetadataProvider.getTargetDataForTarget} */\n  getTargetDataForTarget(targetId: TargetId): TargetData | null {\n    return this.listenTargets.get(targetId) || null;\n  }\n\n  /** {@link TargetMetadataProvider.getRemoteKeysForTarget} */\n  getRemoteKeysForTarget(targetId: TargetId): DocumentKeySet {\n    return this.syncEngine.getRemoteKeysForTarget(targetId);\n  }\n\n  /**\n   * We need to increment the the expected number of pending responses we're due\n   * from watch so we wait for the ack to process any messages from this target.\n   */\n  private sendWatchRequest(targetData: TargetData): void {\n    this.watchChangeAggregator!.recordPendingTargetRequest(targetData.targetId);\n    this.watchStream.watch(targetData);\n  }\n\n  /**\n   * We need to increment the expected number of pending responses we're due\n   * from watch so we wait for the removal on the server before we process any\n   * messages from this target.\n   */\n  private sendUnwatchRequest(targetId: TargetId): void {\n    this.watchChangeAggregator!.recordPendingTargetRequest(targetId);\n    this.watchStream.unwatch(targetId);\n  }\n\n  private startWatchStream(): void {\n    debugAssert(\n      this.shouldStartWatchStream(),\n      'startWatchStream() called when shouldStartWatchStream() is false.'\n    );\n\n    this.watchChangeAggregator = new WatchChangeAggregator(this);\n    this.watchStream.start();\n    this.onlineStateTracker.handleWatchStreamStart();\n  }\n\n  /**\n   * Returns whether the watch stream should be started because it's necessary\n   * and has not yet been started.\n   */\n  private shouldStartWatchStream(): boolean {\n    return (\n      this.canUseNetwork() &&\n      !this.watchStream.isStarted() &&\n      this.listenTargets.size > 0\n    );\n  }\n\n  canUseNetwork(): boolean {\n    return this.offlineCauses.size === 0;\n  }\n\n  private cleanUpWatchStreamState(): void {\n    this.watchChangeAggregator = null;\n  }\n\n  private async onWatchStreamOpen(): Promise<void> {\n    this.listenTargets.forEach((targetData, targetId) => {\n      this.sendWatchRequest(targetData);\n    });\n  }\n\n  private async onWatchStreamClose(error?: FirestoreError): Promise<void> {\n    if (error === undefined) {\n      // Graceful stop (due to stop() or idle timeout). Make sure that's\n      // desirable.\n      debugAssert(\n        !this.shouldStartWatchStream(),\n        'Watch stream was stopped gracefully while still needed.'\n      );\n    }\n\n    this.cleanUpWatchStreamState();\n\n    // If we still need the watch stream, retry the connection.\n    if (this.shouldStartWatchStream()) {\n      this.onlineStateTracker.handleWatchStreamFailure(error!);\n\n      this.startWatchStream();\n    } else {\n      // No need to restart watch stream because there are no active targets.\n      // The online state is set to unknown because there is no active attempt\n      // at establishing a connection\n      this.onlineStateTracker.set(OnlineState.Unknown);\n    }\n  }\n\n  private async onWatchStreamChange(\n    watchChange: WatchChange,\n    snapshotVersion: SnapshotVersion\n  ): Promise<void> {\n    // Mark the client as online since we got a message from the server\n    this.onlineStateTracker.set(OnlineState.Online);\n\n    if (\n      watchChange instanceof WatchTargetChange &&\n      watchChange.state === WatchTargetChangeState.Removed &&\n      watchChange.cause\n    ) {\n      // There was an error on a target, don't wait for a consistent snapshot\n      // to raise events\n      try {\n        await this.handleTargetError(watchChange);\n      } catch (e) {\n        logDebug(\n          LOG_TAG,\n          'Failed to remove targets %s: %s ',\n          watchChange.targetIds.join(','),\n          e\n        );\n        await this.disableNetworkUntilRecovery(e);\n      }\n      return;\n    }\n\n    if (watchChange instanceof DocumentWatchChange) {\n      this.watchChangeAggregator!.handleDocumentChange(watchChange);\n    } else if (watchChange instanceof ExistenceFilterChange) {\n      this.watchChangeAggregator!.handleExistenceFilter(watchChange);\n    } else {\n      debugAssert(\n        watchChange instanceof WatchTargetChange,\n        'Expected watchChange to be an instance of WatchTargetChange'\n      );\n      this.watchChangeAggregator!.handleTargetChange(watchChange);\n    }\n\n    if (!snapshotVersion.isEqual(SnapshotVersion.min())) {\n      try {\n        const lastRemoteSnapshotVersion = await this.localStore.getLastRemoteSnapshotVersion();\n        if (snapshotVersion.compareTo(lastRemoteSnapshotVersion) >= 0) {\n          // We have received a target change with a global snapshot if the snapshot\n          // version is not equal to SnapshotVersion.min().\n          await this.raiseWatchSnapshot(snapshotVersion);\n        }\n      } catch (e) {\n        logDebug(LOG_TAG, 'Failed to raise snapshot:', e);\n        await this.disableNetworkUntilRecovery(e);\n      }\n    }\n  }\n\n  /**\n   * Recovery logic for IndexedDB errors that takes the network offline until\n   * `op` succeeds. Retries are scheduled with backoff using\n   * `enqueueRetryable()`. If `op()` is not provided, IndexedDB access is\n   * validated via a generic operation.\n   *\n   * The returned Promise is resolved once the network is disabled and before\n   * any retry attempt.\n   */\n  private async disableNetworkUntilRecovery(\n    e: FirestoreError,\n    op?: () => Promise<unknown>\n  ): Promise<void> {\n    if (isIndexedDbTransactionError(e)) {\n      debugAssert(\n        !this.offlineCauses.has(OfflineCause.IndexedDbFailed),\n        'Unexpected network event when IndexedDB was marked failed.'\n      );\n      this.offlineCauses.add(OfflineCause.IndexedDbFailed);\n\n      // Disable network and raise offline snapshots\n      await this.disableNetworkInternal();\n      this.onlineStateTracker.set(OnlineState.Offline);\n\n      if (!op) {\n        // Use a simple read operation to determine if IndexedDB recovered.\n        // Ideally, we would expose a health check directly on SimpleDb, but\n        // RemoteStore only has access to persistence through LocalStore.\n        op = () => this.localStore.getLastRemoteSnapshotVersion();\n      }\n\n      // Probe IndexedDB periodically and re-enable network\n      this.asyncQueue.enqueueRetryable(async () => {\n        logDebug(LOG_TAG, 'Retrying IndexedDB access');\n        await op!();\n        this.offlineCauses.delete(OfflineCause.IndexedDbFailed);\n        await this.enableNetworkInternal();\n      });\n    } else {\n      throw e;\n    }\n  }\n\n  /**\n   * Executes `op`. If `op` fails, takes the network offline until `op`\n   * succeeds. Returns after the first attempt.\n   */\n  private executeWithRecovery(op: () => Promise<void>): Promise<void> {\n    return op().catch(e => this.disableNetworkUntilRecovery(e, op));\n  }\n\n  /**\n   * Takes a batch of changes from the Datastore, repackages them as a\n   * RemoteEvent, and passes that on to the listener, which is typically the\n   * SyncEngine.\n   */\n  private raiseWatchSnapshot(snapshotVersion: SnapshotVersion): Promise<void> {\n    debugAssert(\n      !snapshotVersion.isEqual(SnapshotVersion.min()),\n      \"Can't raise event for unknown SnapshotVersion\"\n    );\n    const remoteEvent = this.watchChangeAggregator!.createRemoteEvent(\n      snapshotVersion\n    );\n\n    // Update in-memory resume tokens. LocalStore will update the\n    // persistent view of these when applying the completed RemoteEvent.\n    remoteEvent.targetChanges.forEach((change, targetId) => {\n      if (change.resumeToken.approximateByteSize() > 0) {\n        const targetData = this.listenTargets.get(targetId);\n        // A watched target might have been removed already.\n        if (targetData) {\n          this.listenTargets.set(\n            targetId,\n            targetData.withResumeToken(change.resumeToken, snapshotVersion)\n          );\n        }\n      }\n    });\n\n    // Re-establish listens for the targets that have been invalidated by\n    // existence filter mismatches.\n    remoteEvent.targetMismatches.forEach(targetId => {\n      const targetData = this.listenTargets.get(targetId);\n      if (!targetData) {\n        // A watched target might have been removed already.\n        return;\n      }\n\n      // Clear the resume token for the target, since we're in a known mismatch\n      // state.\n      this.listenTargets.set(\n        targetId,\n        targetData.withResumeToken(\n          ByteString.EMPTY_BYTE_STRING,\n          targetData.snapshotVersion\n        )\n      );\n\n      // Cause a hard reset by unwatching and rewatching immediately, but\n      // deliberately don't send a resume token so that we get a full update.\n      this.sendUnwatchRequest(targetId);\n\n      // Mark the target we send as being on behalf of an existence filter\n      // mismatch, but don't actually retain that in listenTargets. This ensures\n      // that we flag the first re-listen this way without impacting future\n      // listens of this target (that might happen e.g. on reconnect).\n      const requestTargetData = new TargetData(\n        targetData.target,\n        targetId,\n        TargetPurpose.ExistenceFilterMismatch,\n        targetData.sequenceNumber\n      );\n      this.sendWatchRequest(requestTargetData);\n    });\n\n    // Finally raise remote event\n    return this.syncEngine.applyRemoteEvent(remoteEvent);\n  }\n\n  /** Handles an error on a target */\n  private async handleTargetError(\n    watchChange: WatchTargetChange\n  ): Promise<void> {\n    debugAssert(!!watchChange.cause, 'Handling target error without a cause');\n    const error = watchChange.cause!;\n    for (const targetId of watchChange.targetIds) {\n      // A watched target might have been removed already.\n      if (this.listenTargets.has(targetId)) {\n        await this.syncEngine.rejectListen(targetId, error);\n        this.listenTargets.delete(targetId);\n        this.watchChangeAggregator!.removeTarget(targetId);\n      }\n    }\n  }\n\n  /**\n   * Attempts to fill our write pipeline with writes from the LocalStore.\n   *\n   * Called internally to bootstrap or refill the write pipeline and by\n   * SyncEngine whenever there are new mutations to process.\n   *\n   * Starts the write stream if necessary.\n   */\n  async fillWritePipeline(): Promise<void> {\n    let lastBatchIdRetrieved =\n      this.writePipeline.length > 0\n        ? this.writePipeline[this.writePipeline.length - 1].batchId\n        : BATCHID_UNKNOWN;\n\n    while (this.canAddToWritePipeline()) {\n      try {\n        const batch = await this.localStore.nextMutationBatch(\n          lastBatchIdRetrieved\n        );\n\n        if (batch === null) {\n          if (this.writePipeline.length === 0) {\n            this.writeStream.markIdle();\n          }\n          break;\n        } else {\n          lastBatchIdRetrieved = batch.batchId;\n          this.addToWritePipeline(batch);\n        }\n      } catch (e) {\n        await this.disableNetworkUntilRecovery(e);\n      }\n    }\n\n    if (this.shouldStartWriteStream()) {\n      this.startWriteStream();\n    }\n  }\n\n  /**\n   * Returns true if we can add to the write pipeline (i.e. the network is\n   * enabled and the write pipeline is not full).\n   */\n  private canAddToWritePipeline(): boolean {\n    return (\n      this.canUseNetwork() && this.writePipeline.length < MAX_PENDING_WRITES\n    );\n  }\n\n  // For testing\n  outstandingWrites(): number {\n    return this.writePipeline.length;\n  }\n\n  /**\n   * Queues additional writes to be sent to the write stream, sending them\n   * immediately if the write stream is established.\n   */\n  private addToWritePipeline(batch: MutationBatch): void {\n    debugAssert(\n      this.canAddToWritePipeline(),\n      'addToWritePipeline called when pipeline is full'\n    );\n    this.writePipeline.push(batch);\n\n    if (this.writeStream.isOpen() && this.writeStream.handshakeComplete) {\n      this.writeStream.writeMutations(batch.mutations);\n    }\n  }\n\n  private shouldStartWriteStream(): boolean {\n    return (\n      this.canUseNetwork() &&\n      !this.writeStream.isStarted() &&\n      this.writePipeline.length > 0\n    );\n  }\n\n  private startWriteStream(): void {\n    debugAssert(\n      this.shouldStartWriteStream(),\n      'startWriteStream() called when shouldStartWriteStream() is false.'\n    );\n    this.writeStream.start();\n  }\n\n  private async onWriteStreamOpen(): Promise<void> {\n    this.writeStream.writeHandshake();\n  }\n\n  private async onWriteHandshakeComplete(): Promise<void> {\n    // Send the write pipeline now that the stream is established.\n    for (const batch of this.writePipeline) {\n      this.writeStream.writeMutations(batch.mutations);\n    }\n  }\n\n  private async onMutationResult(\n    commitVersion: SnapshotVersion,\n    results: MutationResult[]\n  ): Promise<void> {\n    // This is a response to a write containing mutations and should be\n    // correlated to the first write in our write pipeline.\n    debugAssert(\n      this.writePipeline.length > 0,\n      'Got result for empty write pipeline'\n    );\n    const batch = this.writePipeline.shift()!;\n    const success = MutationBatchResult.from(batch, commitVersion, results);\n\n    await this.executeWithRecovery(() =>\n      this.syncEngine.applySuccessfulWrite(success)\n    );\n\n    // It's possible that with the completion of this mutation another\n    // slot has freed up.\n    await this.fillWritePipeline();\n  }\n\n  private async onWriteStreamClose(error?: FirestoreError): Promise<void> {\n    if (error === undefined) {\n      // Graceful stop (due to stop() or idle timeout). Make sure that's\n      // desirable.\n      debugAssert(\n        !this.shouldStartWriteStream(),\n        'Write stream was stopped gracefully while still needed.'\n      );\n    }\n\n    // If the write stream closed after the write handshake completes, a write\n    // operation failed and we fail the pending operation.\n    if (error && this.writeStream.handshakeComplete) {\n      // This error affects the actual write.\n      await this.handleWriteError(error!);\n    }\n\n    // The write stream might have been started by refilling the write\n    // pipeline for failed writes\n    if (this.shouldStartWriteStream()) {\n      this.startWriteStream();\n    }\n  }\n\n  private async handleWriteError(error: FirestoreError): Promise<void> {\n    // Only handle permanent errors here. If it's transient, just let the retry\n    // logic kick in.\n    if (isPermanentWriteError(error.code)) {\n      // This was a permanent error, the request itself was the problem\n      // so it's not going to succeed if we resend it.\n      const batch = this.writePipeline.shift()!;\n\n      // In this case it's also unlikely that the server itself is melting\n      // down -- this was just a bad request so inhibit backoff on the next\n      // restart.\n      this.writeStream.inhibitBackoff();\n\n      await this.executeWithRecovery(() =>\n        this.syncEngine.rejectFailedWrite(batch.batchId, error)\n      );\n\n      // It's possible that with the completion of this mutation\n      // another slot has freed up.\n      await this.fillWritePipeline();\n    } else {\n      // Transient error, just let the retry logic kick in.\n    }\n  }\n\n  private async restartNetwork(): Promise<void> {\n    this.offlineCauses.add(OfflineCause.ConnectivityChange);\n    await this.disableNetworkInternal();\n    this.onlineStateTracker.set(OnlineState.Unknown);\n    this.writeStream.inhibitBackoff();\n    this.watchStream.inhibitBackoff();\n    this.offlineCauses.delete(OfflineCause.ConnectivityChange);\n    await this.enableNetworkInternal();\n  }\n\n  async handleCredentialChange(user: User): Promise<void> {\n    this.asyncQueue.verifyOperationInProgress();\n\n    // Tear down and re-create our network streams. This will ensure we get a\n    // fresh auth token for the new user and re-fill the write pipeline with\n    // new mutations from the LocalStore (since mutations are per-user).\n    logDebug(LOG_TAG, 'RemoteStore received new credentials');\n    this.offlineCauses.add(OfflineCause.CredentialChange);\n\n    await this.disableNetworkInternal();\n    this.onlineStateTracker.set(OnlineState.Unknown);\n    await this.syncEngine.handleCredentialChange(user);\n\n    this.offlineCauses.delete(OfflineCause.CredentialChange);\n    await this.enableNetworkInternal();\n  }\n\n  /**\n   * Toggles the network state when the client gains or loses its primary lease.\n   */\n  async applyPrimaryState(isPrimary: boolean): Promise<void> {\n    if (isPrimary) {\n      this.offlineCauses.delete(OfflineCause.IsSecondary);\n      await this.enableNetworkInternal();\n    } else if (!isPrimary) {\n      this.offlineCauses.add(OfflineCause.IsSecondary);\n      await this.disableNetworkInternal();\n      this.onlineStateTracker.set(OnlineState.Unknown);\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { BatchId, MutationBatchState, TargetId } from '../core/types';\nimport { QueryTargetState } from './shared_client_state_syncer';\nimport { debugAssert } from '../util/assert';\nimport { ClientId } from './shared_client_state';\nimport { User } from '../auth/user';\n\n// The format of the LocalStorage key that stores the client state is:\n//     firestore_clients_<persistence_prefix>_<instance_key>\nexport const CLIENT_STATE_KEY_PREFIX = 'firestore_clients';\n\n/** Assembles the key for a client state in WebStorage */\nexport function createWebStorageClientStateKey(\n  persistenceKey: string,\n  clientId: ClientId\n): string {\n  debugAssert(\n    clientId.indexOf('_') === -1,\n    `Client key cannot contain '_', but was '${clientId}'`\n  );\n\n  return `${CLIENT_STATE_KEY_PREFIX}_${persistenceKey}_${clientId}`;\n}\n\n/**\n * The JSON representation of a clients's metadata as used during WebStorage\n * serialization. The ClientId is omitted here as it is encoded as part of the\n * key.\n */\nexport interface ClientStateSchema {\n  activeTargetIds: number[];\n  updateTimeMs: number;\n}\n\n// The format of the WebStorage key that stores the mutation state is:\n//     firestore_mutations_<persistence_prefix>_<batch_id>\n//     (for unauthenticated users)\n// or: firestore_mutations_<persistence_prefix>_<batch_id>_<user_uid>\n//\n// 'user_uid' is last to avoid needing to escape '_' characters that it might\n// contain.\nexport const MUTATION_BATCH_KEY_PREFIX = 'firestore_mutations';\n\n/** Assembles the key for a mutation batch in WebStorage */\nexport function createWebStorageMutationBatchKey(\n  persistenceKey: string,\n  user: User,\n  batchId: BatchId\n): string {\n  let mutationKey = `${MUTATION_BATCH_KEY_PREFIX}_${persistenceKey}_${batchId}`;\n\n  if (user.isAuthenticated()) {\n    mutationKey += `_${user.uid}`;\n  }\n\n  return mutationKey;\n}\n\n/**\n * The JSON representation of a mutation batch's metadata as used during\n * WebStorage serialization. The UserId and BatchId is omitted as it is\n * encoded as part of the key.\n */\nexport interface MutationMetadataSchema {\n  state: MutationBatchState;\n  error?: { code: string; message: string }; // Only set when state === 'rejected'\n  updateTimeMs: number;\n}\n\n// The format of the WebStorage key that stores a query target's metadata is:\n//     firestore_targets_<persistence_prefix>_<target_id>\nexport const QUERY_TARGET_KEY_PREFIX = 'firestore_targets';\n\n/** Assembles the key for a query state in WebStorage */\nexport function createWebStorageQueryTargetMetadataKey(\n  persistenceKey: string,\n  targetId: TargetId\n): string {\n  return `${QUERY_TARGET_KEY_PREFIX}_${persistenceKey}_${targetId}`;\n}\n\n/**\n * The JSON representation of a query target's state as used during WebStorage\n * serialization. The TargetId is omitted as it is encoded as part of the key.\n */\nexport interface QueryTargetStateSchema {\n  state: QueryTargetState;\n  error?: { code: string; message: string }; // Only set when state === 'rejected'\n  updateTimeMs: number;\n}\n\n// The WebStorage prefix that stores the primary tab's online state. The\n// format of the key is:\n//     firestore_online_state_<persistence_prefix>\nexport const ONLINE_STATE_KEY_PREFIX = 'firestore_online_state';\n\n/** Assembles the key for the online state of the primary tab. */\nexport function createWebStorageOnlineStateKey(persistenceKey: string): string {\n  return `${ONLINE_STATE_KEY_PREFIX}_${persistenceKey}`;\n}\n\n/**\n * The JSON representation of the system's online state, as written by the\n * primary client.\n */\nexport interface SharedOnlineStateSchema {\n  /**\n   * The clientId of the client that wrote this onlineState value. Tracked so\n   * that on startup, clients can check if this client is still active when\n   * determining whether to apply this value or not.\n   */\n  readonly clientId: string;\n  readonly onlineState: string;\n}\n\n// The WebStorage key prefix for the key that stores the last sequence number allocated. The key\n// looks like 'firestore_sequence_number_<persistence_prefix>'.\nexport const SEQUENCE_NUMBER_KEY_PREFIX = 'firestore_sequence_number';\n\n/** Assembles the key for the current sequence number. */\nexport function createWebStorageSequenceNumberKey(\n  persistenceKey: string\n): string {\n  return `${SEQUENCE_NUMBER_KEY_PREFIX}_${persistenceKey}`;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { User } from '../auth/user';\nimport { ListenSequence } from '../core/listen_sequence';\nimport {\n  BatchId,\n  ListenSequenceNumber,\n  MutationBatchState,\n  OnlineState,\n  TargetId\n} from '../core/types';\nimport { TargetIdSet, targetIdSet } from '../model/collections';\nimport { hardAssert, debugAssert } from '../util/assert';\nimport { AsyncQueue } from '../util/async_queue';\nimport { Code, FirestoreError } from '../util/error';\nimport { logError, logDebug } from '../util/log';\nimport { SortedSet } from '../util/sorted_set';\nimport { SortedMap } from '../util/sorted_map';\nimport { primitiveComparator } from '../util/misc';\nimport { isSafeInteger, WindowLike } from '../util/types';\nimport {\n  QueryTargetState,\n  SharedClientStateSyncer\n} from './shared_client_state_syncer';\nimport {\n  CLIENT_STATE_KEY_PREFIX,\n  ClientStateSchema,\n  createWebStorageClientStateKey,\n  createWebStorageMutationBatchKey,\n  createWebStorageOnlineStateKey,\n  createWebStorageQueryTargetMetadataKey,\n  createWebStorageSequenceNumberKey,\n  MUTATION_BATCH_KEY_PREFIX,\n  MutationMetadataSchema,\n  QUERY_TARGET_KEY_PREFIX,\n  QueryTargetStateSchema,\n  SharedOnlineStateSchema\n} from './shared_client_state_schema';\n\nconst LOG_TAG = 'SharedClientState';\n\n/**\n * A randomly-generated key assigned to each Firestore instance at startup.\n */\nexport type ClientId = string;\n\n/**\n * A `SharedClientState` keeps track of the global state of the mutations\n * and query targets for all active clients with the same persistence key (i.e.\n * project ID and FirebaseApp name). It relays local changes to other clients\n * and updates its local state as new state is observed.\n *\n * `SharedClientState` is primarily used for synchronization in Multi-Tab\n * environments. Each tab is responsible for registering its active query\n * targets and mutations. `SharedClientState` will then notify the listener\n * assigned to `.syncEngine` for updates to mutations and queries that\n * originated in other clients.\n *\n * To receive notifications, `.syncEngine` and `.onlineStateHandler` has to be\n * assigned before calling `start()`.\n */\nexport interface SharedClientState {\n  onlineStateHandler: ((onlineState: OnlineState) => void) | null;\n  sequenceNumberHandler:\n    | ((sequenceNumber: ListenSequenceNumber) => void)\n    | null;\n\n  /** Registers the Mutation Batch ID of a newly pending mutation. */\n  addPendingMutation(batchId: BatchId): void;\n\n  /**\n   * Records that a pending mutation has been acknowledged or rejected.\n   * Called by the primary client to notify secondary clients of mutation\n   * results as they come back from the backend.\n   */\n  updateMutationState(\n    batchId: BatchId,\n    state: 'acknowledged' | 'rejected',\n    error?: FirestoreError\n  ): void;\n\n  /**\n   * Associates a new Query Target ID with the local Firestore client. Returns\n   * the new query state for the query (which can be 'current' if the query is\n   * already associated with another tab).\n   *\n   * If the target id is already associated with local client, the method simply\n   * returns its `QueryTargetState`.\n   */\n  addLocalQueryTarget(targetId: TargetId): QueryTargetState;\n\n  /** Removes the Query Target ID association from the local client. */\n  removeLocalQueryTarget(targetId: TargetId): void;\n\n  /** Checks whether the target is associated with the local client. */\n  isLocalQueryTarget(targetId: TargetId): boolean;\n\n  /**\n   * Processes an update to a query target.\n   *\n   * Called by the primary client to notify secondary clients of document\n   * changes or state transitions that affect the provided query target.\n   */\n  updateQueryState(\n    targetId: TargetId,\n    state: QueryTargetState,\n    error?: FirestoreError\n  ): void;\n\n  /**\n   * Removes the target's metadata entry.\n   *\n   * Called by the primary client when all clients stopped listening to a query\n   * target.\n   */\n  clearQueryState(targetId: TargetId): void;\n\n  /**\n   * Gets the active Query Targets IDs for all active clients.\n   *\n   * The implementation for this may require O(n) runtime, where 'n' is the size\n   * of the result set.\n   */\n  // Visible for testing\n  getAllActiveQueryTargets(): SortedSet<TargetId>;\n\n  /**\n   * Checks whether the provided target ID is currently being listened to by\n   * any of the active clients.\n   *\n   * The implementation may require O(n*log m) runtime, where 'n' is the number\n   * of clients and 'm' the number of targets.\n   */\n  isActiveQueryTarget(targetId: TargetId): boolean;\n\n  /**\n   * Starts the SharedClientState, reads existing client data and registers\n   * listeners for updates to new and existing clients.\n   */\n  start(): Promise<void>;\n\n  /** Shuts down the `SharedClientState` and its listeners. */\n  shutdown(): void;\n\n  /**\n   * Changes the active user and removes all existing user-specific data. The\n   * user change does not call back into SyncEngine (for example, no mutations\n   * will be marked as removed).\n   */\n  handleUserChange(\n    user: User,\n    removedBatchIds: BatchId[],\n    addedBatchIds: BatchId[]\n  ): void;\n\n  /** Changes the shared online state of all clients. */\n  setOnlineState(onlineState: OnlineState): void;\n\n  writeSequenceNumber(sequenceNumber: ListenSequenceNumber): void;\n}\n\n/**\n * Holds the state of a mutation batch, including its user ID, batch ID and\n * whether the batch is 'pending', 'acknowledged' or 'rejected'.\n */\n// Visible for testing\nexport class MutationMetadata {\n  constructor(\n    readonly user: User,\n    readonly batchId: BatchId,\n    readonly state: MutationBatchState,\n    readonly error?: FirestoreError\n  ) {\n    debugAssert(\n      (error !== undefined) === (state === 'rejected'),\n      `MutationMetadata must contain an error iff state is 'rejected'`\n    );\n  }\n\n  /**\n   * Parses a MutationMetadata from its JSON representation in WebStorage.\n   * Logs a warning and returns null if the format of the data is not valid.\n   */\n  static fromWebStorageEntry(\n    user: User,\n    batchId: BatchId,\n    value: string\n  ): MutationMetadata | null {\n    const mutationBatch = JSON.parse(value) as MutationMetadataSchema;\n\n    let validData =\n      typeof mutationBatch === 'object' &&\n      ['pending', 'acknowledged', 'rejected'].indexOf(mutationBatch.state) !==\n        -1 &&\n      (mutationBatch.error === undefined ||\n        typeof mutationBatch.error === 'object');\n\n    let firestoreError: FirestoreError | undefined = undefined;\n\n    if (validData && mutationBatch.error) {\n      validData =\n        typeof mutationBatch.error.message === 'string' &&\n        typeof mutationBatch.error.code === 'string';\n      if (validData) {\n        firestoreError = new FirestoreError(\n          mutationBatch.error.code as Code,\n          mutationBatch.error.message\n        );\n      }\n    }\n\n    if (validData) {\n      return new MutationMetadata(\n        user,\n        batchId,\n        mutationBatch.state,\n        firestoreError\n      );\n    } else {\n      logError(\n        LOG_TAG,\n        `Failed to parse mutation state for ID '${batchId}': ${value}`\n      );\n      return null;\n    }\n  }\n\n  toWebStorageJSON(): string {\n    const batchMetadata: MutationMetadataSchema = {\n      state: this.state,\n      updateTimeMs: Date.now() // Modify the existing value to trigger update.\n    };\n\n    if (this.error) {\n      batchMetadata.error = {\n        code: this.error.code,\n        message: this.error.message\n      };\n    }\n\n    return JSON.stringify(batchMetadata);\n  }\n}\n\n/**\n * Holds the state of a query target, including its target ID and whether the\n * target is 'not-current', 'current' or 'rejected'.\n */\n// Visible for testing\nexport class QueryTargetMetadata {\n  constructor(\n    readonly targetId: TargetId,\n    readonly state: QueryTargetState,\n    readonly error?: FirestoreError\n  ) {\n    debugAssert(\n      (error !== undefined) === (state === 'rejected'),\n      `QueryTargetMetadata must contain an error iff state is 'rejected'`\n    );\n  }\n\n  /**\n   * Parses a QueryTargetMetadata from its JSON representation in WebStorage.\n   * Logs a warning and returns null if the format of the data is not valid.\n   */\n  static fromWebStorageEntry(\n    targetId: TargetId,\n    value: string\n  ): QueryTargetMetadata | null {\n    const targetState = JSON.parse(value) as QueryTargetStateSchema;\n\n    let validData =\n      typeof targetState === 'object' &&\n      ['not-current', 'current', 'rejected'].indexOf(targetState.state) !==\n        -1 &&\n      (targetState.error === undefined ||\n        typeof targetState.error === 'object');\n\n    let firestoreError: FirestoreError | undefined = undefined;\n\n    if (validData && targetState.error) {\n      validData =\n        typeof targetState.error.message === 'string' &&\n        typeof targetState.error.code === 'string';\n      if (validData) {\n        firestoreError = new FirestoreError(\n          targetState.error.code as Code,\n          targetState.error.message\n        );\n      }\n    }\n\n    if (validData) {\n      return new QueryTargetMetadata(\n        targetId,\n        targetState.state,\n        firestoreError\n      );\n    } else {\n      logError(\n        LOG_TAG,\n        `Failed to parse target state for ID '${targetId}': ${value}`\n      );\n      return null;\n    }\n  }\n\n  toWebStorageJSON(): string {\n    const targetState: QueryTargetStateSchema = {\n      state: this.state,\n      updateTimeMs: Date.now() // Modify the existing value to trigger update.\n    };\n\n    if (this.error) {\n      targetState.error = {\n        code: this.error.code,\n        message: this.error.message\n      };\n    }\n\n    return JSON.stringify(targetState);\n  }\n}\n\n/**\n * Metadata state of a single client denoting the query targets it is actively\n * listening to.\n */\n// Visible for testing.\nexport interface ClientState {\n  readonly activeTargetIds: TargetIdSet;\n}\n\n/**\n * This class represents the immutable ClientState for a client read from\n * WebStorage, containing the list of active query targets.\n */\nclass RemoteClientState implements ClientState {\n  private constructor(\n    readonly clientId: ClientId,\n    readonly activeTargetIds: TargetIdSet\n  ) {}\n\n  /**\n   * Parses a RemoteClientState from the JSON representation in WebStorage.\n   * Logs a warning and returns null if the format of the data is not valid.\n   */\n  static fromWebStorageEntry(\n    clientId: ClientId,\n    value: string\n  ): RemoteClientState | null {\n    const clientState = JSON.parse(value) as ClientStateSchema;\n\n    let validData =\n      typeof clientState === 'object' &&\n      clientState.activeTargetIds instanceof Array;\n\n    let activeTargetIdsSet = targetIdSet();\n\n    for (let i = 0; validData && i < clientState.activeTargetIds.length; ++i) {\n      validData = isSafeInteger(clientState.activeTargetIds[i]);\n      activeTargetIdsSet = activeTargetIdsSet.add(\n        clientState.activeTargetIds[i]\n      );\n    }\n\n    if (validData) {\n      return new RemoteClientState(clientId, activeTargetIdsSet);\n    } else {\n      logError(\n        LOG_TAG,\n        `Failed to parse client data for instance '${clientId}': ${value}`\n      );\n      return null;\n    }\n  }\n}\n\n/**\n * This class represents the online state for all clients participating in\n * multi-tab. The online state is only written to by the primary client, and\n * used in secondary clients to update their query views.\n */\nexport class SharedOnlineState {\n  constructor(readonly clientId: string, readonly onlineState: OnlineState) {}\n\n  /**\n   * Parses a SharedOnlineState from its JSON representation in WebStorage.\n   * Logs a warning and returns null if the format of the data is not valid.\n   */\n  static fromWebStorageEntry(value: string): SharedOnlineState | null {\n    const onlineState = JSON.parse(value) as SharedOnlineStateSchema;\n\n    const validData =\n      typeof onlineState === 'object' &&\n      ['Unknown', 'Online', 'Offline'].indexOf(onlineState.onlineState) !==\n        -1 &&\n      typeof onlineState.clientId === 'string';\n\n    if (validData) {\n      return new SharedOnlineState(\n        onlineState.clientId,\n        onlineState.onlineState as OnlineState\n      );\n    } else {\n      logError(LOG_TAG, `Failed to parse online state: ${value}`);\n      return null;\n    }\n  }\n}\n\n/**\n * Metadata state of the local client. Unlike `RemoteClientState`, this class is\n * mutable and keeps track of all pending mutations, which allows us to\n * update the range of pending mutation batch IDs as new mutations are added or\n * removed.\n *\n * The data in `LocalClientState` is not read from WebStorage and instead\n * updated via its instance methods. The updated state can be serialized via\n * `toWebStorageJSON()`.\n */\n// Visible for testing.\nexport class LocalClientState implements ClientState {\n  activeTargetIds = targetIdSet();\n\n  addQueryTarget(targetId: TargetId): void {\n    this.activeTargetIds = this.activeTargetIds.add(targetId);\n  }\n\n  removeQueryTarget(targetId: TargetId): void {\n    this.activeTargetIds = this.activeTargetIds.delete(targetId);\n  }\n\n  /**\n   * Converts this entry into a JSON-encoded format we can use for WebStorage.\n   * Does not encode `clientId` as it is part of the key in WebStorage.\n   */\n  toWebStorageJSON(): string {\n    const data: ClientStateSchema = {\n      activeTargetIds: this.activeTargetIds.toArray(),\n      updateTimeMs: Date.now() // Modify the existing value to trigger update.\n    };\n    return JSON.stringify(data);\n  }\n}\n\n/**\n * `WebStorageSharedClientState` uses WebStorage (window.localStorage) as the\n * backing store for the SharedClientState. It keeps track of all active\n * clients and supports modifications of the local client's data.\n */\nexport class WebStorageSharedClientState implements SharedClientState {\n  syncEngine: SharedClientStateSyncer | null = null;\n  onlineStateHandler: ((onlineState: OnlineState) => void) | null = null;\n  sequenceNumberHandler:\n    | ((sequenceNumber: ListenSequenceNumber) => void)\n    | null = null;\n\n  private readonly storage: Storage;\n  private readonly localClientStorageKey: string;\n  private readonly sequenceNumberKey: string;\n  private readonly storageListener = this.handleWebStorageEvent.bind(this);\n  private readonly onlineStateKey: string;\n  private readonly clientStateKeyRe: RegExp;\n  private readonly mutationBatchKeyRe: RegExp;\n  private readonly queryTargetKeyRe: RegExp;\n  private activeClients = new SortedMap<string, ClientState>(\n    primitiveComparator\n  );\n  private started = false;\n  private currentUser: User;\n\n  /**\n   * Captures WebStorage events that occur before `start()` is called. These\n   * events are replayed once `WebStorageSharedClientState` is started.\n   */\n  private earlyEvents: StorageEvent[] = [];\n\n  constructor(\n    private readonly window: WindowLike,\n    private readonly queue: AsyncQueue,\n    private readonly persistenceKey: string,\n    private readonly localClientId: ClientId,\n    initialUser: User\n  ) {\n    // Escape the special characters mentioned here:\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions\n    const escapedPersistenceKey = persistenceKey.replace(\n      /[.*+?^${}()|[\\]\\\\]/g,\n      '\\\\$&'\n    );\n\n    this.storage = this.window.localStorage;\n    this.currentUser = initialUser;\n    this.localClientStorageKey = createWebStorageClientStateKey(\n      this.persistenceKey,\n      this.localClientId\n    );\n    this.sequenceNumberKey = createWebStorageSequenceNumberKey(\n      this.persistenceKey\n    );\n    this.activeClients = this.activeClients.insert(\n      this.localClientId,\n      new LocalClientState()\n    );\n\n    this.clientStateKeyRe = new RegExp(\n      `^${CLIENT_STATE_KEY_PREFIX}_${escapedPersistenceKey}_([^_]*)$`\n    );\n    this.mutationBatchKeyRe = new RegExp(\n      `^${MUTATION_BATCH_KEY_PREFIX}_${escapedPersistenceKey}_(\\\\d+)(?:_(.*))?$`\n    );\n    this.queryTargetKeyRe = new RegExp(\n      `^${QUERY_TARGET_KEY_PREFIX}_${escapedPersistenceKey}_(\\\\d+)$`\n    );\n\n    this.onlineStateKey = createWebStorageOnlineStateKey(this.persistenceKey);\n\n    // Rather than adding the storage observer during start(), we add the\n    // storage observer during initialization. This ensures that we collect\n    // events before other components populate their initial state (during their\n    // respective start() calls). Otherwise, we might for example miss a\n    // mutation that is added after LocalStore's start() processed the existing\n    // mutations but before we observe WebStorage events.\n    this.window.addEventListener('storage', this.storageListener);\n  }\n\n  /** Returns 'true' if WebStorage is available in the current environment. */\n  static isAvailable(window: WindowLike | null): window is WindowLike {\n    return !!(window && window.localStorage);\n  }\n\n  async start(): Promise<void> {\n    debugAssert(!this.started, 'WebStorageSharedClientState already started');\n    debugAssert(\n      this.syncEngine !== null,\n      'syncEngine property must be set before calling start()'\n    );\n    debugAssert(\n      this.onlineStateHandler !== null,\n      'onlineStateHandler property must be set before calling start()'\n    );\n\n    // Retrieve the list of existing clients to backfill the data in\n    // SharedClientState.\n    const existingClients = await this.syncEngine!.getActiveClients();\n\n    for (const clientId of existingClients) {\n      if (clientId === this.localClientId) {\n        continue;\n      }\n\n      const storageItem = this.getItem(\n        createWebStorageClientStateKey(this.persistenceKey, clientId)\n      );\n      if (storageItem) {\n        const clientState = RemoteClientState.fromWebStorageEntry(\n          clientId,\n          storageItem\n        );\n        if (clientState) {\n          this.activeClients = this.activeClients.insert(\n            clientState.clientId,\n            clientState\n          );\n        }\n      }\n    }\n\n    this.persistClientState();\n\n    // Check if there is an existing online state and call the callback handler\n    // if applicable.\n    const onlineStateJSON = this.storage.getItem(this.onlineStateKey);\n    if (onlineStateJSON) {\n      const onlineState = this.fromWebStorageOnlineState(onlineStateJSON);\n      if (onlineState) {\n        this.handleOnlineStateEvent(onlineState);\n      }\n    }\n\n    for (const event of this.earlyEvents) {\n      this.handleWebStorageEvent(event);\n    }\n\n    this.earlyEvents = [];\n\n    // Register a window unload hook to remove the client metadata entry from\n    // WebStorage even if `shutdown()` was not called.\n    this.window.addEventListener('unload', () => this.shutdown());\n\n    this.started = true;\n  }\n\n  writeSequenceNumber(sequenceNumber: ListenSequenceNumber): void {\n    this.setItem(this.sequenceNumberKey, JSON.stringify(sequenceNumber));\n  }\n\n  getAllActiveQueryTargets(): TargetIdSet {\n    return this.extractActiveQueryTargets(this.activeClients);\n  }\n\n  isActiveQueryTarget(targetId: TargetId): boolean {\n    let found = false;\n    this.activeClients.forEach((key, value) => {\n      if (value.activeTargetIds.has(targetId)) {\n        found = true;\n      }\n    });\n    return found;\n  }\n\n  addPendingMutation(batchId: BatchId): void {\n    this.persistMutationState(batchId, 'pending');\n  }\n\n  updateMutationState(\n    batchId: BatchId,\n    state: 'acknowledged' | 'rejected',\n    error?: FirestoreError\n  ): void {\n    this.persistMutationState(batchId, state, error);\n\n    // Once a final mutation result is observed by other clients, they no longer\n    // access the mutation's metadata entry. Since WebStorage replays events\n    // in order, it is safe to delete the entry right after updating it.\n    this.removeMutationState(batchId);\n  }\n\n  addLocalQueryTarget(targetId: TargetId): QueryTargetState {\n    let queryState: QueryTargetState = 'not-current';\n\n    // Lookup an existing query state if the target ID was already registered\n    // by another tab\n    if (this.isActiveQueryTarget(targetId)) {\n      const storageItem = this.storage.getItem(\n        createWebStorageQueryTargetMetadataKey(this.persistenceKey, targetId)\n      );\n\n      if (storageItem) {\n        const metadata = QueryTargetMetadata.fromWebStorageEntry(\n          targetId,\n          storageItem\n        );\n        if (metadata) {\n          queryState = metadata.state;\n        }\n      }\n    }\n\n    this.localClientState.addQueryTarget(targetId);\n    this.persistClientState();\n\n    return queryState;\n  }\n\n  removeLocalQueryTarget(targetId: TargetId): void {\n    this.localClientState.removeQueryTarget(targetId);\n    this.persistClientState();\n  }\n\n  isLocalQueryTarget(targetId: TargetId): boolean {\n    return this.localClientState.activeTargetIds.has(targetId);\n  }\n\n  clearQueryState(targetId: TargetId): void {\n    this.removeItem(\n      createWebStorageQueryTargetMetadataKey(this.persistenceKey, targetId)\n    );\n  }\n\n  updateQueryState(\n    targetId: TargetId,\n    state: QueryTargetState,\n    error?: FirestoreError\n  ): void {\n    this.persistQueryTargetState(targetId, state, error);\n  }\n\n  handleUserChange(\n    user: User,\n    removedBatchIds: BatchId[],\n    addedBatchIds: BatchId[]\n  ): void {\n    removedBatchIds.forEach(batchId => {\n      this.removeMutationState(batchId);\n    });\n    this.currentUser = user;\n    addedBatchIds.forEach(batchId => {\n      this.addPendingMutation(batchId);\n    });\n  }\n\n  setOnlineState(onlineState: OnlineState): void {\n    this.persistOnlineState(onlineState);\n  }\n\n  shutdown(): void {\n    if (this.started) {\n      this.window.removeEventListener('storage', this.storageListener);\n      this.removeItem(this.localClientStorageKey);\n      this.started = false;\n    }\n  }\n\n  private getItem(key: string): string | null {\n    const value = this.storage.getItem(key);\n    logDebug(LOG_TAG, 'READ', key, value);\n    return value;\n  }\n\n  private setItem(key: string, value: string): void {\n    logDebug(LOG_TAG, 'SET', key, value);\n    this.storage.setItem(key, value);\n  }\n\n  private removeItem(key: string): void {\n    logDebug(LOG_TAG, 'REMOVE', key);\n    this.storage.removeItem(key);\n  }\n\n  private handleWebStorageEvent(event: Event): void {\n    // Note: The function is typed to take Event to be interface-compatible with\n    // `Window.addEventListener`.\n    const storageEvent = event as StorageEvent;\n    if (storageEvent.storageArea === this.storage) {\n      logDebug(LOG_TAG, 'EVENT', storageEvent.key, storageEvent.newValue);\n\n      if (storageEvent.key === this.localClientStorageKey) {\n        logError(\n          'Received WebStorage notification for local change. Another client might have ' +\n            'garbage-collected our state'\n        );\n        return;\n      }\n\n      this.queue.enqueueRetryable(async () => {\n        if (!this.started) {\n          this.earlyEvents.push(storageEvent);\n          return;\n        }\n\n        if (storageEvent.key === null) {\n          return;\n        }\n\n        if (this.clientStateKeyRe.test(storageEvent.key)) {\n          if (storageEvent.newValue != null) {\n            const clientState = this.fromWebStorageClientState(\n              storageEvent.key,\n              storageEvent.newValue\n            );\n            if (clientState) {\n              return this.handleClientStateEvent(\n                clientState.clientId,\n                clientState\n              );\n            }\n          } else {\n            const clientId = this.fromWebStorageClientStateKey(\n              storageEvent.key\n            )!;\n            return this.handleClientStateEvent(clientId, null);\n          }\n        } else if (this.mutationBatchKeyRe.test(storageEvent.key)) {\n          if (storageEvent.newValue !== null) {\n            const mutationMetadata = this.fromWebStorageMutationMetadata(\n              storageEvent.key,\n              storageEvent.newValue\n            );\n            if (mutationMetadata) {\n              return this.handleMutationBatchEvent(mutationMetadata);\n            }\n          }\n        } else if (this.queryTargetKeyRe.test(storageEvent.key)) {\n          if (storageEvent.newValue !== null) {\n            const queryTargetMetadata = this.fromWebStorageQueryTargetMetadata(\n              storageEvent.key,\n              storageEvent.newValue\n            );\n            if (queryTargetMetadata) {\n              return this.handleQueryTargetEvent(queryTargetMetadata);\n            }\n          }\n        } else if (storageEvent.key === this.onlineStateKey) {\n          if (storageEvent.newValue !== null) {\n            const onlineState = this.fromWebStorageOnlineState(\n              storageEvent.newValue\n            );\n            if (onlineState) {\n              return this.handleOnlineStateEvent(onlineState);\n            }\n          }\n        } else if (storageEvent.key === this.sequenceNumberKey) {\n          debugAssert(\n            !!this.sequenceNumberHandler,\n            'Missing sequenceNumberHandler'\n          );\n          const sequenceNumber = fromWebStorageSequenceNumber(\n            storageEvent.newValue\n          );\n          if (sequenceNumber !== ListenSequence.INVALID) {\n            this.sequenceNumberHandler!(sequenceNumber);\n          }\n        }\n      });\n    }\n  }\n\n  private get localClientState(): LocalClientState {\n    return this.activeClients.get(this.localClientId) as LocalClientState;\n  }\n\n  private persistClientState(): void {\n    this.setItem(\n      this.localClientStorageKey,\n      this.localClientState.toWebStorageJSON()\n    );\n  }\n\n  private persistMutationState(\n    batchId: BatchId,\n    state: MutationBatchState,\n    error?: FirestoreError\n  ): void {\n    const mutationState = new MutationMetadata(\n      this.currentUser,\n      batchId,\n      state,\n      error\n    );\n    const mutationKey = createWebStorageMutationBatchKey(\n      this.persistenceKey,\n      this.currentUser,\n      batchId\n    );\n    this.setItem(mutationKey, mutationState.toWebStorageJSON());\n  }\n\n  private removeMutationState(batchId: BatchId): void {\n    const mutationKey = createWebStorageMutationBatchKey(\n      this.persistenceKey,\n      this.currentUser,\n      batchId\n    );\n    this.removeItem(mutationKey);\n  }\n\n  private persistOnlineState(onlineState: OnlineState): void {\n    const entry: SharedOnlineStateSchema = {\n      clientId: this.localClientId,\n      onlineState\n    };\n    this.storage.setItem(this.onlineStateKey, JSON.stringify(entry));\n  }\n\n  private persistQueryTargetState(\n    targetId: TargetId,\n    state: QueryTargetState,\n    error?: FirestoreError\n  ): void {\n    const targetKey = createWebStorageQueryTargetMetadataKey(\n      this.persistenceKey,\n      targetId\n    );\n    const targetMetadata = new QueryTargetMetadata(targetId, state, error);\n    this.setItem(targetKey, targetMetadata.toWebStorageJSON());\n  }\n\n  /**\n   * Parses a client state key in WebStorage. Returns null if the key does not\n   * match the expected key format.\n   */\n  private fromWebStorageClientStateKey(key: string): ClientId | null {\n    const match = this.clientStateKeyRe.exec(key);\n    return match ? match[1] : null;\n  }\n\n  /**\n   * Parses a client state in WebStorage. Returns 'null' if the value could not\n   * be parsed.\n   */\n  private fromWebStorageClientState(\n    key: string,\n    value: string\n  ): RemoteClientState | null {\n    const clientId = this.fromWebStorageClientStateKey(key);\n    debugAssert(clientId !== null, `Cannot parse client state key '${key}'`);\n    return RemoteClientState.fromWebStorageEntry(clientId, value);\n  }\n\n  /**\n   * Parses a mutation batch state in WebStorage. Returns 'null' if the value\n   * could not be parsed.\n   */\n  private fromWebStorageMutationMetadata(\n    key: string,\n    value: string\n  ): MutationMetadata | null {\n    const match = this.mutationBatchKeyRe.exec(key);\n    debugAssert(match !== null, `Cannot parse mutation batch key '${key}'`);\n\n    const batchId = Number(match[1]);\n    const userId = match[2] !== undefined ? match[2] : null;\n    return MutationMetadata.fromWebStorageEntry(\n      new User(userId),\n      batchId,\n      value\n    );\n  }\n\n  /**\n   * Parses a query target state from WebStorage. Returns 'null' if the value\n   * could not be parsed.\n   */\n  private fromWebStorageQueryTargetMetadata(\n    key: string,\n    value: string\n  ): QueryTargetMetadata | null {\n    const match = this.queryTargetKeyRe.exec(key);\n    debugAssert(match !== null, `Cannot parse query target key '${key}'`);\n\n    const targetId = Number(match[1]);\n    return QueryTargetMetadata.fromWebStorageEntry(targetId, value);\n  }\n\n  /**\n   * Parses an online state from WebStorage. Returns 'null' if the value\n   * could not be parsed.\n   */\n  private fromWebStorageOnlineState(value: string): SharedOnlineState | null {\n    return SharedOnlineState.fromWebStorageEntry(value);\n  }\n\n  private async handleMutationBatchEvent(\n    mutationBatch: MutationMetadata\n  ): Promise<void> {\n    if (mutationBatch.user.uid !== this.currentUser.uid) {\n      logDebug(\n        LOG_TAG,\n        `Ignoring mutation for non-active user ${mutationBatch.user.uid}`\n      );\n      return;\n    }\n\n    return this.syncEngine!.applyBatchState(\n      mutationBatch.batchId,\n      mutationBatch.state,\n      mutationBatch.error\n    );\n  }\n\n  private handleQueryTargetEvent(\n    targetMetadata: QueryTargetMetadata\n  ): Promise<void> {\n    return this.syncEngine!.applyTargetState(\n      targetMetadata.targetId,\n      targetMetadata.state,\n      targetMetadata.error\n    );\n  }\n\n  private handleClientStateEvent(\n    clientId: ClientId,\n    clientState: RemoteClientState | null\n  ): Promise<void> {\n    const updatedClients = clientState\n      ? this.activeClients.insert(clientId, clientState)\n      : this.activeClients.remove(clientId);\n\n    const existingTargets = this.extractActiveQueryTargets(this.activeClients);\n    const newTargets = this.extractActiveQueryTargets(updatedClients);\n\n    const addedTargets: TargetId[] = [];\n    const removedTargets: TargetId[] = [];\n\n    newTargets.forEach(targetId => {\n      if (!existingTargets.has(targetId)) {\n        addedTargets.push(targetId);\n      }\n    });\n\n    existingTargets.forEach(targetId => {\n      if (!newTargets.has(targetId)) {\n        removedTargets.push(targetId);\n      }\n    });\n\n    return this.syncEngine!.applyActiveTargetsChange(\n      addedTargets,\n      removedTargets\n    ).then(() => {\n      this.activeClients = updatedClients;\n    });\n  }\n\n  private handleOnlineStateEvent(onlineState: SharedOnlineState): void {\n    // We check whether the client that wrote this online state is still active\n    // by comparing its client ID to the list of clients kept active in\n    // IndexedDb. If a client does not update their IndexedDb client state\n    // within 5 seconds, it is considered inactive and we don't emit an online\n    // state event.\n    if (this.activeClients.get(onlineState.clientId)) {\n      this.onlineStateHandler!(onlineState.onlineState);\n    }\n  }\n\n  private extractActiveQueryTargets(\n    clients: SortedMap<string, ClientState>\n  ): SortedSet<TargetId> {\n    let activeTargets = targetIdSet();\n    clients.forEach((kev, value) => {\n      activeTargets = activeTargets.unionWith(value.activeTargetIds);\n    });\n    return activeTargets;\n  }\n}\n\nfunction fromWebStorageSequenceNumber(\n  seqString: string | null\n): ListenSequenceNumber {\n  let sequenceNumber = ListenSequence.INVALID;\n  if (seqString != null) {\n    try {\n      const parsed = JSON.parse(seqString);\n      hardAssert(\n        typeof parsed === 'number',\n        'Found non-numeric sequence number'\n      );\n      sequenceNumber = parsed;\n    } catch (e) {\n      logError(LOG_TAG, 'Failed to read sequence number from WebStorage', e);\n    }\n  }\n  return sequenceNumber;\n}\n\n/**\n * `MemorySharedClientState` is a simple implementation of SharedClientState for\n * clients using memory persistence. The state in this class remains fully\n * isolated and no synchronization is performed.\n */\nexport class MemorySharedClientState implements SharedClientState {\n  private localState = new LocalClientState();\n  private queryState: { [targetId: number]: QueryTargetState } = {};\n  onlineStateHandler: ((onlineState: OnlineState) => void) | null = null;\n  sequenceNumberHandler:\n    | ((sequenceNumber: ListenSequenceNumber) => void)\n    | null = null;\n\n  addPendingMutation(batchId: BatchId): void {\n    // No op.\n  }\n\n  updateMutationState(\n    batchId: BatchId,\n    state: 'acknowledged' | 'rejected',\n    error?: FirestoreError\n  ): void {\n    // No op.\n  }\n\n  addLocalQueryTarget(targetId: TargetId): QueryTargetState {\n    this.localState.addQueryTarget(targetId);\n    return this.queryState[targetId] || 'not-current';\n  }\n\n  updateQueryState(\n    targetId: TargetId,\n    state: QueryTargetState,\n    error?: FirestoreError\n  ): void {\n    this.queryState[targetId] = state;\n  }\n\n  removeLocalQueryTarget(targetId: TargetId): void {\n    this.localState.removeQueryTarget(targetId);\n  }\n\n  isLocalQueryTarget(targetId: TargetId): boolean {\n    return this.localState.activeTargetIds.has(targetId);\n  }\n\n  clearQueryState(targetId: TargetId): void {\n    delete this.queryState[targetId];\n  }\n\n  getAllActiveQueryTargets(): TargetIdSet {\n    return this.localState.activeTargetIds;\n  }\n\n  isActiveQueryTarget(targetId: TargetId): boolean {\n    return this.localState.activeTargetIds.has(targetId);\n  }\n\n  start(): Promise<void> {\n    this.localState = new LocalClientState();\n    return Promise.resolve();\n  }\n\n  handleUserChange(\n    user: User,\n    removedBatchIds: BatchId[],\n    addedBatchIds: BatchId[]\n  ): void {\n    // No op.\n  }\n\n  setOnlineState(onlineState: OnlineState): void {\n    // No op.\n  }\n\n  shutdown(): void {}\n\n  writeSequenceNumber(sequenceNumber: ListenSequenceNumber): void {}\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { QueryResult } from '../local/local_store';\nimport {\n  documentKeySet,\n  DocumentKeySet,\n  MaybeDocumentMap\n} from '../model/collections';\nimport { Document, MaybeDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { DocumentSet } from '../model/document_set';\nimport { TargetChange } from '../remote/remote_event';\nimport { debugAssert, fail } from '../util/assert';\n\nimport { newQueryComparator, Query, queryMatches } from './query';\nimport { OnlineState } from './types';\nimport {\n  ChangeType,\n  DocumentChangeSet,\n  SyncState,\n  ViewSnapshot\n} from './view_snapshot';\n\nexport type LimboDocumentChange = AddedLimboDocument | RemovedLimboDocument;\nexport class AddedLimboDocument {\n  constructor(public key: DocumentKey) {}\n}\nexport class RemovedLimboDocument {\n  constructor(public key: DocumentKey) {}\n}\n\n/** The result of applying a set of doc changes to a view. */\nexport interface ViewDocumentChanges {\n  /** The new set of docs that should be in the view. */\n  documentSet: DocumentSet;\n  /** The diff of these docs with the previous set of docs. */\n  changeSet: DocumentChangeSet;\n  /**\n   * Whether the set of documents passed in was not sufficient to calculate the\n   * new state of the view and there needs to be another pass based on the\n   * local cache.\n   */\n  needsRefill: boolean;\n\n  mutatedKeys: DocumentKeySet;\n}\n\nexport interface ViewChange {\n  snapshot?: ViewSnapshot;\n  limboChanges: LimboDocumentChange[];\n}\n\n/**\n * View is responsible for computing the final merged truth of what docs are in\n * a query. It gets notified of local and remote changes to docs, and applies\n * the query filters and limits to determine the most correct possible results.\n */\nexport class View {\n  private syncState: SyncState | null = null;\n  /**\n   * A flag whether the view is current with the backend. A view is considered\n   * current after it has seen the current flag from the backend and did not\n   * lose consistency within the watch stream (e.g. because of an existence\n   * filter mismatch).\n   */\n  private current = false;\n  private documentSet: DocumentSet;\n  /** Documents in the view but not in the remote target */\n  private limboDocuments = documentKeySet();\n  /** Document Keys that have local changes */\n  private mutatedKeys = documentKeySet();\n  /** Query comparator that defines the document order in this view. */\n  private docComparator: (d1: Document, d2: Document) => number;\n\n  constructor(\n    private query: Query,\n    /** Documents included in the remote target */\n    private _syncedDocuments: DocumentKeySet\n  ) {\n    this.docComparator = newQueryComparator(query);\n    this.documentSet = new DocumentSet(this.docComparator);\n  }\n\n  /**\n   * The set of remote documents that the server has told us belongs to the target associated with\n   * this view.\n   */\n  get syncedDocuments(): DocumentKeySet {\n    return this._syncedDocuments;\n  }\n\n  /**\n   * Iterates over a set of doc changes, applies the query limit, and computes\n   * what the new results should be, what the changes were, and whether we may\n   * need to go back to the local cache for more results. Does not make any\n   * changes to the view.\n   * @param docChanges The doc changes to apply to this view.\n   * @param previousChanges If this is being called with a refill, then start\n   *        with this set of docs and changes instead of the current view.\n   * @return a new set of docs, changes, and refill flag.\n   */\n  computeDocChanges(\n    docChanges: MaybeDocumentMap,\n    previousChanges?: ViewDocumentChanges\n  ): ViewDocumentChanges {\n    const changeSet = previousChanges\n      ? previousChanges.changeSet\n      : new DocumentChangeSet();\n    const oldDocumentSet = previousChanges\n      ? previousChanges.documentSet\n      : this.documentSet;\n    let newMutatedKeys = previousChanges\n      ? previousChanges.mutatedKeys\n      : this.mutatedKeys;\n    let newDocumentSet = oldDocumentSet;\n    let needsRefill = false;\n\n    // Track the last doc in a (full) limit. This is necessary, because some\n    // update (a delete, or an update moving a doc past the old limit) might\n    // mean there is some other document in the local cache that either should\n    // come (1) between the old last limit doc and the new last document, in the\n    // case of updates, or (2) after the new last document, in the case of\n    // deletes. So we keep this doc at the old limit to compare the updates to.\n    //\n    // Note that this should never get used in a refill (when previousChanges is\n    // set), because there will only be adds -- no deletes or updates.\n    const lastDocInLimit =\n      this.query.hasLimitToFirst() && oldDocumentSet.size === this.query.limit\n        ? oldDocumentSet.last()\n        : null;\n    const firstDocInLimit =\n      this.query.hasLimitToLast() && oldDocumentSet.size === this.query.limit\n        ? oldDocumentSet.first()\n        : null;\n\n    docChanges.inorderTraversal(\n      (key: DocumentKey, newMaybeDoc: MaybeDocument) => {\n        const oldDoc = oldDocumentSet.get(key);\n        let newDoc = newMaybeDoc instanceof Document ? newMaybeDoc : null;\n        if (newDoc) {\n          debugAssert(\n            key.isEqual(newDoc.key),\n            'Mismatching keys found in document changes: ' +\n              key +\n              ' != ' +\n              newDoc.key\n          );\n          newDoc = queryMatches(this.query, newDoc) ? newDoc : null;\n        }\n\n        const oldDocHadPendingMutations = oldDoc\n          ? this.mutatedKeys.has(oldDoc.key)\n          : false;\n        const newDocHasPendingMutations = newDoc\n          ? newDoc.hasLocalMutations ||\n            // We only consider committed mutations for documents that were\n            // mutated during the lifetime of the view.\n            (this.mutatedKeys.has(newDoc.key) && newDoc.hasCommittedMutations)\n          : false;\n\n        let changeApplied = false;\n\n        // Calculate change\n        if (oldDoc && newDoc) {\n          const docsEqual = oldDoc.data().isEqual(newDoc.data());\n          if (!docsEqual) {\n            if (!this.shouldWaitForSyncedDocument(oldDoc, newDoc)) {\n              changeSet.track({\n                type: ChangeType.Modified,\n                doc: newDoc\n              });\n              changeApplied = true;\n\n              if (\n                (lastDocInLimit &&\n                  this.docComparator(newDoc, lastDocInLimit) > 0) ||\n                (firstDocInLimit &&\n                  this.docComparator(newDoc, firstDocInLimit) < 0)\n              ) {\n                // This doc moved from inside the limit to outside the limit.\n                // That means there may be some other doc in the local cache\n                // that should be included instead.\n                needsRefill = true;\n              }\n            }\n          } else if (oldDocHadPendingMutations !== newDocHasPendingMutations) {\n            changeSet.track({ type: ChangeType.Metadata, doc: newDoc });\n            changeApplied = true;\n          }\n        } else if (!oldDoc && newDoc) {\n          changeSet.track({ type: ChangeType.Added, doc: newDoc });\n          changeApplied = true;\n        } else if (oldDoc && !newDoc) {\n          changeSet.track({ type: ChangeType.Removed, doc: oldDoc });\n          changeApplied = true;\n\n          if (lastDocInLimit || firstDocInLimit) {\n            // A doc was removed from a full limit query. We'll need to\n            // requery from the local cache to see if we know about some other\n            // doc that should be in the results.\n            needsRefill = true;\n          }\n        }\n\n        if (changeApplied) {\n          if (newDoc) {\n            newDocumentSet = newDocumentSet.add(newDoc);\n            if (newDocHasPendingMutations) {\n              newMutatedKeys = newMutatedKeys.add(key);\n            } else {\n              newMutatedKeys = newMutatedKeys.delete(key);\n            }\n          } else {\n            newDocumentSet = newDocumentSet.delete(key);\n            newMutatedKeys = newMutatedKeys.delete(key);\n          }\n        }\n      }\n    );\n\n    // Drop documents out to meet limit/limitToLast requirement.\n    if (this.query.hasLimitToFirst() || this.query.hasLimitToLast()) {\n      while (newDocumentSet.size > this.query.limit!) {\n        const oldDoc = this.query.hasLimitToFirst()\n          ? newDocumentSet.last()\n          : newDocumentSet.first();\n        newDocumentSet = newDocumentSet.delete(oldDoc!.key);\n        newMutatedKeys = newMutatedKeys.delete(oldDoc!.key);\n        changeSet.track({ type: ChangeType.Removed, doc: oldDoc! });\n      }\n    }\n\n    debugAssert(\n      !needsRefill || !previousChanges,\n      'View was refilled using docs that themselves needed refilling.'\n    );\n    return {\n      documentSet: newDocumentSet,\n      changeSet,\n      needsRefill,\n      mutatedKeys: newMutatedKeys\n    };\n  }\n\n  private shouldWaitForSyncedDocument(\n    oldDoc: Document,\n    newDoc: Document\n  ): boolean {\n    // We suppress the initial change event for documents that were modified as\n    // part of a write acknowledgment (e.g. when the value of a server transform\n    // is applied) as Watch will send us the same document again.\n    // By suppressing the event, we only raise two user visible events (one with\n    // `hasPendingWrites` and the final state of the document) instead of three\n    // (one with `hasPendingWrites`, the modified document with\n    // `hasPendingWrites` and the final state of the document).\n    return (\n      oldDoc.hasLocalMutations &&\n      newDoc.hasCommittedMutations &&\n      !newDoc.hasLocalMutations\n    );\n  }\n\n  /**\n   * Updates the view with the given ViewDocumentChanges and optionally updates\n   * limbo docs and sync state from the provided target change.\n   * @param docChanges The set of changes to make to the view's docs.\n   * @param updateLimboDocuments Whether to update limbo documents based on this\n   *        change.\n   * @param targetChange A target change to apply for computing limbo docs and\n   *        sync state.\n   * @return A new ViewChange with the given docs, changes, and sync state.\n   */\n  // PORTING NOTE: The iOS/Android clients always compute limbo document changes.\n  applyChanges(\n    docChanges: ViewDocumentChanges,\n    updateLimboDocuments: boolean,\n    targetChange?: TargetChange\n  ): ViewChange {\n    debugAssert(\n      !docChanges.needsRefill,\n      'Cannot apply changes that need a refill'\n    );\n    const oldDocs = this.documentSet;\n    this.documentSet = docChanges.documentSet;\n    this.mutatedKeys = docChanges.mutatedKeys;\n    // Sort changes based on type and query comparator\n    const changes = docChanges.changeSet.getChanges();\n    changes.sort((c1, c2) => {\n      return (\n        compareChangeType(c1.type, c2.type) ||\n        this.docComparator(c1.doc, c2.doc)\n      );\n    });\n\n    this.applyTargetChange(targetChange);\n    const limboChanges = updateLimboDocuments\n      ? this.updateLimboDocuments()\n      : [];\n    const synced = this.limboDocuments.size === 0 && this.current;\n    const newSyncState = synced ? SyncState.Synced : SyncState.Local;\n    const syncStateChanged = newSyncState !== this.syncState;\n    this.syncState = newSyncState;\n\n    if (changes.length === 0 && !syncStateChanged) {\n      // no changes\n      return { limboChanges };\n    } else {\n      const snap: ViewSnapshot = new ViewSnapshot(\n        this.query,\n        docChanges.documentSet,\n        oldDocs,\n        changes,\n        docChanges.mutatedKeys,\n        newSyncState === SyncState.Local,\n        syncStateChanged,\n        /* excludesMetadataChanges= */ false\n      );\n      return {\n        snapshot: snap,\n        limboChanges\n      };\n    }\n  }\n\n  /**\n   * Applies an OnlineState change to the view, potentially generating a\n   * ViewChange if the view's syncState changes as a result.\n   */\n  applyOnlineStateChange(onlineState: OnlineState): ViewChange {\n    if (this.current && onlineState === OnlineState.Offline) {\n      // If we're offline, set `current` to false and then call applyChanges()\n      // to refresh our syncState and generate a ViewChange as appropriate. We\n      // are guaranteed to get a new TargetChange that sets `current` back to\n      // true once the client is back online.\n      this.current = false;\n      return this.applyChanges(\n        {\n          documentSet: this.documentSet,\n          changeSet: new DocumentChangeSet(),\n          mutatedKeys: this.mutatedKeys,\n          needsRefill: false\n        },\n        /* updateLimboDocuments= */ false\n      );\n    } else {\n      // No effect, just return a no-op ViewChange.\n      return { limboChanges: [] };\n    }\n  }\n\n  /**\n   * Returns whether the doc for the given key should be in limbo.\n   */\n  private shouldBeInLimbo(key: DocumentKey): boolean {\n    // If the remote end says it's part of this query, it's not in limbo.\n    if (this._syncedDocuments.has(key)) {\n      return false;\n    }\n    // The local store doesn't think it's a result, so it shouldn't be in limbo.\n    if (!this.documentSet.has(key)) {\n      return false;\n    }\n    // If there are local changes to the doc, they might explain why the server\n    // doesn't know that it's part of the query. So don't put it in limbo.\n    // TODO(klimt): Ideally, we would only consider changes that might actually\n    // affect this specific query.\n    if (this.documentSet.get(key)!.hasLocalMutations) {\n      return false;\n    }\n    // Everything else is in limbo.\n    return true;\n  }\n\n  /**\n   * Updates syncedDocuments, current, and limbo docs based on the given change.\n   * Returns the list of changes to which docs are in limbo.\n   */\n  private applyTargetChange(targetChange?: TargetChange): void {\n    if (targetChange) {\n      targetChange.addedDocuments.forEach(\n        key => (this._syncedDocuments = this._syncedDocuments.add(key))\n      );\n      targetChange.modifiedDocuments.forEach(key => {\n        debugAssert(\n          this._syncedDocuments.has(key),\n          `Modified document ${key} not found in view.`\n        );\n      });\n      targetChange.removedDocuments.forEach(\n        key => (this._syncedDocuments = this._syncedDocuments.delete(key))\n      );\n      this.current = targetChange.current;\n    }\n  }\n\n  private updateLimboDocuments(): LimboDocumentChange[] {\n    // We can only determine limbo documents when we're in-sync with the server.\n    if (!this.current) {\n      return [];\n    }\n\n    // TODO(klimt): Do this incrementally so that it's not quadratic when\n    // updating many documents.\n    const oldLimboDocuments = this.limboDocuments;\n    this.limboDocuments = documentKeySet();\n    this.documentSet.forEach(doc => {\n      if (this.shouldBeInLimbo(doc.key)) {\n        this.limboDocuments = this.limboDocuments.add(doc.key);\n      }\n    });\n\n    // Diff the new limbo docs with the old limbo docs.\n    const changes: LimboDocumentChange[] = [];\n    oldLimboDocuments.forEach(key => {\n      if (!this.limboDocuments.has(key)) {\n        changes.push(new RemovedLimboDocument(key));\n      }\n    });\n    this.limboDocuments.forEach(key => {\n      if (!oldLimboDocuments.has(key)) {\n        changes.push(new AddedLimboDocument(key));\n      }\n    });\n    return changes;\n  }\n\n  /**\n   * Update the in-memory state of the current view with the state read from\n   * persistence.\n   *\n   * We update the query view whenever a client's primary status changes:\n   * - When a client transitions from primary to secondary, it can miss\n   *   LocalStorage updates and its query views may temporarily not be\n   *   synchronized with the state on disk.\n   * - For secondary to primary transitions, the client needs to update the list\n   *   of `syncedDocuments` since secondary clients update their query views\n   *   based purely on synthesized RemoteEvents.\n   *\n   * @param queryResult.documents - The documents that match the query according\n   * to the LocalStore.\n   * @param queryResult.remoteKeys - The keys of the documents that match the\n   * query according to the backend.\n   *\n   * @return The ViewChange that resulted from this synchronization.\n   */\n  // PORTING NOTE: Multi-tab only.\n  synchronizeWithPersistedState(queryResult: QueryResult): ViewChange {\n    this._syncedDocuments = queryResult.remoteKeys;\n    this.limboDocuments = documentKeySet();\n    const docChanges = this.computeDocChanges(queryResult.documents);\n    return this.applyChanges(docChanges, /*updateLimboDocuments=*/ true);\n  }\n\n  /**\n   * Returns a view snapshot as if this query was just listened to. Contains\n   * a document add for every existing document and the `fromCache` and\n   * `hasPendingWrites` status of the already established view.\n   */\n  // PORTING NOTE: Multi-tab only.\n  computeInitialSnapshot(): ViewSnapshot {\n    return ViewSnapshot.fromInitialDocuments(\n      this.query,\n      this.documentSet,\n      this.mutatedKeys,\n      this.syncState === SyncState.Local\n    );\n  }\n}\n\nfunction compareChangeType(c1: ChangeType, c2: ChangeType): number {\n  const order = (change: ChangeType): 0 | 1 | 2 => {\n    switch (change) {\n      case ChangeType.Added:\n        return 1;\n      case ChangeType.Modified:\n        return 2;\n      case ChangeType.Metadata:\n        // A metadata change is converted to a modified change at the public\n        // api layer.  Since we sort by document key and then change type,\n        // metadata and modified changes must be sorted equivalently.\n        return 2;\n      case ChangeType.Removed:\n        return 0;\n      default:\n        return fail('Unknown ChangeType: ' + change);\n    }\n  };\n\n  return order(c1) - order(c2);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { User } from '../auth/user';\nimport {\n  getNewDocumentChanges,\n  getCachedTarget,\n  ignoreIfPrimaryLeaseLoss,\n  LocalStore,\n  getActiveClientsFromPersistence,\n  lookupMutationDocuments,\n  removeCachedMutationBatchMetadata\n} from '../local/local_store';\nimport { LocalViewChanges } from '../local/local_view_changes';\nimport { ReferenceSet } from '../local/reference_set';\nimport { TargetData, TargetPurpose } from '../local/target_data';\nimport {\n  documentKeySet,\n  DocumentKeySet,\n  MaybeDocumentMap\n} from '../model/collections';\nimport { MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { Mutation } from '../model/mutation';\nimport { BATCHID_UNKNOWN, MutationBatchResult } from '../model/mutation_batch';\nimport { RemoteEvent, TargetChange } from '../remote/remote_event';\nimport { RemoteStore } from '../remote/remote_store';\nimport { RemoteSyncer } from '../remote/remote_syncer';\nimport { debugAssert, debugCast, fail, hardAssert } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { logDebug } from '../util/log';\nimport { primitiveComparator } from '../util/misc';\nimport { ObjectMap } from '../util/obj_map';\nimport { Deferred } from '../util/promise';\nimport { SortedMap } from '../util/sorted_map';\n\nimport { ClientId, SharedClientState } from '../local/shared_client_state';\nimport { QueryTargetState } from '../local/shared_client_state_syncer';\nimport { SortedSet } from '../util/sorted_set';\nimport { ListenSequence } from './listen_sequence';\nimport {\n  canonifyQuery,\n  LimitType,\n  newQuery,\n  newQueryForPath,\n  Query,\n  queryEquals,\n  queryToTarget,\n  stringifyQuery\n} from './query';\nimport { SnapshotVersion } from './snapshot_version';\nimport { Target } from './target';\nimport { TargetIdGenerator } from './target_id_generator';\nimport {\n  BatchId,\n  MutationBatchState,\n  OnlineState,\n  OnlineStateSource,\n  TargetId\n} from './types';\nimport {\n  AddedLimboDocument,\n  LimboDocumentChange,\n  RemovedLimboDocument,\n  View,\n  ViewChange,\n  ViewDocumentChanges\n} from './view';\nimport { ViewSnapshot } from './view_snapshot';\nimport { wrapInUserErrorIfRecoverable } from '../util/async_queue';\nimport { Datastore } from '../remote/datastore';\n\nconst LOG_TAG = 'SyncEngine';\n\n/**\n * QueryView contains all of the data that SyncEngine needs to keep track of for\n * a particular query.\n */\nclass QueryView {\n  constructor(\n    /**\n     * The query itself.\n     */\n    public query: Query,\n    /**\n     * The target number created by the client that is used in the watch\n     * stream to identify this query.\n     */\n    public targetId: TargetId,\n    /**\n     * The view is responsible for computing the final merged truth of what\n     * docs are in the query. It gets notified of local and remote changes,\n     * and applies the query filters and limits to determine the most correct\n     * possible results.\n     */\n    public view: View\n  ) {}\n}\n\n/** Tracks a limbo resolution. */\nclass LimboResolution {\n  constructor(public key: DocumentKey) {}\n\n  /**\n   * Set to true once we've received a document. This is used in\n   * getRemoteKeysForTarget() and ultimately used by WatchChangeAggregator to\n   * decide whether it needs to manufacture a delete event for the target once\n   * the target is CURRENT.\n   */\n  receivedDocument: boolean = false;\n}\n\n/**\n * Interface implemented by EventManager to handle notifications from\n * SyncEngine.\n */\nexport interface SyncEngineListener {\n  /** Handles new view snapshots. */\n  onWatchChange(snapshots: ViewSnapshot[]): void;\n\n  /** Handles the failure of a query. */\n  onWatchError(query: Query, error: Error): void;\n\n  /** Handles a change in online state. */\n  onOnlineStateChange(onlineState: OnlineState): void;\n}\n\n/**\n * SyncEngine is the central controller in the client SDK architecture. It is\n * the glue code between the EventManager, LocalStore, and RemoteStore. Some of\n * SyncEngine's responsibilities include:\n * 1. Coordinating client requests and remote events between the EventManager\n *    and the local and remote data stores.\n * 2. Managing a View object for each query, providing the unified view between\n *    the local and remote data stores.\n * 3. Notifying the RemoteStore when the LocalStore has new mutations in its\n *    queue that need sending to the backend.\n *\n * The SyncEngines methods should only ever be called by methods running in the\n * global async queue.\n */\nexport interface SyncEngine extends RemoteSyncer {\n  isPrimaryClient: boolean;\n\n  /** Subscribes to SyncEngine notifications. Has to be called exactly once. */\n  subscribe(syncEngineListener: SyncEngineListener): void;\n\n  /**\n   * Initiates the new listen, resolves promise when listen enqueued to the\n   * server. All the subsequent view snapshots or errors are sent to the\n   * subscribed handlers. Returns the initial snapshot.\n   */\n  listen(query: Query): Promise<ViewSnapshot>;\n\n  /** Stops listening to the query. */\n  unlisten(query: Query): Promise<void>;\n\n  /**\n   * Initiates the write of local mutation batch which involves adding the\n   * writes to the mutation queue, notifying the remote store about new\n   * mutations and raising events for any changes this write caused.\n   *\n   * The promise returned by this call is resolved when the above steps\n   * have completed, *not* when the write was acked by the backend. The\n   * userCallback is resolved once the write was acked/rejected by the\n   * backend (or failed locally for any other reason).\n   */\n  write(batch: Mutation[], userCallback: Deferred<void>): Promise<void>;\n\n  /**\n   * Applies an OnlineState change to the sync engine and notifies any views of\n   * the change.\n   */\n  applyOnlineStateChange(\n    onlineState: OnlineState,\n    source: OnlineStateSource\n  ): void;\n\n  /**\n   * Registers a user callback that resolves when all pending mutations at the moment of calling\n   * are acknowledged .\n   */\n  registerPendingWritesCallback(callback: Deferred<void>): Promise<void>;\n\n  // Visible for testing\n  activeLimboDocumentResolutions(): SortedMap<DocumentKey, TargetId>;\n\n  // Visible for testing\n  enqueuedLimboDocumentResolutions(): DocumentKey[];\n\n  handleCredentialChange(user: User): Promise<void>;\n\n  getRemoteKeysForTarget(targetId: TargetId): DocumentKeySet;\n}\n\n/**\n * An implementation of `SyncEngine` coordinating with other parts of SDK.\n *\n * Note: some field defined in this class might have public access level, but\n * the class is not exported so they are only accessible from this module.\n * This is useful to implement optional features (like bundles) in free\n * functions, such that they are tree-shakeable.\n */\nclass SyncEngineImpl implements SyncEngine {\n  syncEngineListener: SyncEngineListener | null = null;\n\n  queryViewsByQuery = new ObjectMap<Query, QueryView>(\n    q => canonifyQuery(q),\n    queryEquals\n  );\n  queriesByTarget = new Map<TargetId, Query[]>();\n  /**\n   * The keys of documents that are in limbo for which we haven't yet started a\n   * limbo resolution query.\n   */\n  private enqueuedLimboResolutions: DocumentKey[] = [];\n  /**\n   * Keeps track of the target ID for each document that is in limbo with an\n   * active target.\n   */\n  activeLimboTargetsByKey = new SortedMap<DocumentKey, TargetId>(\n    DocumentKey.comparator\n  );\n  /**\n   * Keeps track of the information about an active limbo resolution for each\n   * active target ID that was started for the purpose of limbo resolution.\n   */\n  activeLimboResolutionsByTarget = new Map<TargetId, LimboResolution>();\n  limboDocumentRefs = new ReferenceSet();\n  /** Stores user completion handlers, indexed by User and BatchId. */\n  private mutationUserCallbacks = {} as {\n    [uidKey: string]: SortedMap<BatchId, Deferred<void>>;\n  };\n  /** Stores user callbacks waiting for all pending writes to be acknowledged. */\n  private pendingWritesCallbacks = new Map<BatchId, Array<Deferred<void>>>();\n  private limboTargetIdGenerator = TargetIdGenerator.forSyncEngine();\n\n  private onlineState = OnlineState.Unknown;\n\n  // The primary state is set to `true` or `false` immediately after Firestore\n  // startup. In the interim, a client should only be considered primary if\n  // `isPrimary` is true.\n  _isPrimaryClient: undefined | boolean = undefined;\n\n  constructor(\n    public localStore: LocalStore,\n    public remoteStore: RemoteStore,\n    protected datastore: Datastore,\n    // PORTING NOTE: Manages state synchronization in multi-tab environments.\n    public sharedClientState: SharedClientState,\n    private currentUser: User,\n    private maxConcurrentLimboResolutions: number\n  ) {}\n\n  get isPrimaryClient(): boolean {\n    return this._isPrimaryClient === true;\n  }\n\n  subscribe(syncEngineListener: SyncEngineListener): void {\n    debugAssert(\n      syncEngineListener !== null,\n      'SyncEngine listener cannot be null'\n    );\n    debugAssert(\n      this.syncEngineListener === null,\n      'SyncEngine already has a subscriber.'\n    );\n\n    this.syncEngineListener = syncEngineListener;\n  }\n\n  async listen(query: Query): Promise<ViewSnapshot> {\n    this.assertSubscribed('listen()');\n\n    let targetId;\n    let viewSnapshot;\n\n    const queryView = this.queryViewsByQuery.get(query);\n    if (queryView) {\n      // PORTING NOTE: With Multi-Tab Web, it is possible that a query view\n      // already exists when EventManager calls us for the first time. This\n      // happens when the primary tab is already listening to this query on\n      // behalf of another tab and the user of the primary also starts listening\n      // to the query. EventManager will not have an assigned target ID in this\n      // case and calls `listen` to obtain this ID.\n      targetId = queryView.targetId;\n      this.sharedClientState.addLocalQueryTarget(targetId);\n      viewSnapshot = queryView.view.computeInitialSnapshot();\n    } else {\n      const targetData = await this.localStore.allocateTarget(\n        queryToTarget(query)\n      );\n\n      const status = this.sharedClientState.addLocalQueryTarget(\n        targetData.targetId\n      );\n      targetId = targetData.targetId;\n      viewSnapshot = await this.initializeViewAndComputeSnapshot(\n        query,\n        targetId,\n        status === 'current'\n      );\n      if (this.isPrimaryClient) {\n        this.remoteStore.listen(targetData);\n      }\n    }\n\n    return viewSnapshot;\n  }\n\n  /**\n   * Registers a view for a previously unknown query and computes its initial\n   * snapshot.\n   */\n  async initializeViewAndComputeSnapshot(\n    query: Query,\n    targetId: TargetId,\n    current: boolean\n  ): Promise<ViewSnapshot> {\n    const queryResult = await this.localStore.executeQuery(\n      query,\n      /* usePreviousResults= */ true\n    );\n    const view = new View(query, queryResult.remoteKeys);\n    const viewDocChanges = view.computeDocChanges(queryResult.documents);\n    const synthesizedTargetChange = TargetChange.createSynthesizedTargetChangeForCurrentChange(\n      targetId,\n      current && this.onlineState !== OnlineState.Offline\n    );\n    const viewChange = view.applyChanges(\n      viewDocChanges,\n      /* updateLimboDocuments= */ this.isPrimaryClient,\n      synthesizedTargetChange\n    );\n    this.updateTrackedLimbos(targetId, viewChange.limboChanges);\n\n    debugAssert(\n      !!viewChange.snapshot,\n      'applyChanges for new view should always return a snapshot'\n    );\n\n    const data = new QueryView(query, targetId, view);\n    this.queryViewsByQuery.set(query, data);\n    if (this.queriesByTarget.has(targetId)) {\n      this.queriesByTarget.get(targetId)!.push(query);\n    } else {\n      this.queriesByTarget.set(targetId, [query]);\n    }\n    return viewChange.snapshot!;\n  }\n\n  async unlisten(query: Query): Promise<void> {\n    this.assertSubscribed('unlisten()');\n\n    const queryView = this.queryViewsByQuery.get(query)!;\n    debugAssert(\n      !!queryView,\n      'Trying to unlisten on query not found:' + stringifyQuery(query)\n    );\n\n    // Only clean up the query view and target if this is the only query mapped\n    // to the target.\n    const queries = this.queriesByTarget.get(queryView.targetId)!;\n    if (queries.length > 1) {\n      this.queriesByTarget.set(\n        queryView.targetId,\n        queries.filter(q => !queryEquals(q, query))\n      );\n      this.queryViewsByQuery.delete(query);\n      return;\n    }\n\n    // No other queries are mapped to the target, clean up the query and the target.\n    if (this.isPrimaryClient) {\n      // We need to remove the local query target first to allow us to verify\n      // whether any other client is still interested in this target.\n      this.sharedClientState.removeLocalQueryTarget(queryView.targetId);\n      const targetRemainsActive = this.sharedClientState.isActiveQueryTarget(\n        queryView.targetId\n      );\n\n      if (!targetRemainsActive) {\n        await this.localStore\n          .releaseTarget(queryView.targetId, /*keepPersistedTargetData=*/ false)\n          .then(() => {\n            this.sharedClientState.clearQueryState(queryView.targetId);\n            this.remoteStore.unlisten(queryView.targetId);\n            this.removeAndCleanupTarget(queryView.targetId);\n          })\n          .catch(ignoreIfPrimaryLeaseLoss);\n      }\n    } else {\n      this.removeAndCleanupTarget(queryView.targetId);\n      await this.localStore.releaseTarget(\n        queryView.targetId,\n        /*keepPersistedTargetData=*/ true\n      );\n    }\n  }\n\n  async write(batch: Mutation[], userCallback: Deferred<void>): Promise<void> {\n    this.assertSubscribed('write()');\n\n    try {\n      const result = await this.localStore.localWrite(batch);\n      this.sharedClientState.addPendingMutation(result.batchId);\n      this.addMutationCallback(result.batchId, userCallback);\n      await this.emitNewSnapsAndNotifyLocalStore(result.changes);\n      await this.remoteStore.fillWritePipeline();\n    } catch (e) {\n      // If we can't persist the mutation, we reject the user callback and\n      // don't send the mutation. The user can then retry the write.\n      const error = wrapInUserErrorIfRecoverable(e, `Failed to persist write`);\n      userCallback.reject(error);\n    }\n  }\n\n  async applyRemoteEvent(remoteEvent: RemoteEvent): Promise<void> {\n    this.assertSubscribed('applyRemoteEvent()');\n    try {\n      const changes = await this.localStore.applyRemoteEvent(remoteEvent);\n      // Update `receivedDocument` as appropriate for any limbo targets.\n      remoteEvent.targetChanges.forEach((targetChange, targetId) => {\n        const limboResolution = this.activeLimboResolutionsByTarget.get(\n          targetId\n        );\n        if (limboResolution) {\n          // Since this is a limbo resolution lookup, it's for a single document\n          // and it could be added, modified, or removed, but not a combination.\n          hardAssert(\n            targetChange.addedDocuments.size +\n              targetChange.modifiedDocuments.size +\n              targetChange.removedDocuments.size <=\n              1,\n            'Limbo resolution for single document contains multiple changes.'\n          );\n          if (targetChange.addedDocuments.size > 0) {\n            limboResolution.receivedDocument = true;\n          } else if (targetChange.modifiedDocuments.size > 0) {\n            hardAssert(\n              limboResolution.receivedDocument,\n              'Received change for limbo target document without add.'\n            );\n          } else if (targetChange.removedDocuments.size > 0) {\n            hardAssert(\n              limboResolution.receivedDocument,\n              'Received remove for limbo target document without add.'\n            );\n            limboResolution.receivedDocument = false;\n          } else {\n            // This was probably just a CURRENT targetChange or similar.\n          }\n        }\n      });\n      await this.emitNewSnapsAndNotifyLocalStore(changes, remoteEvent);\n    } catch (error) {\n      await ignoreIfPrimaryLeaseLoss(error);\n    }\n  }\n\n  applyOnlineStateChange(\n    onlineState: OnlineState,\n    source: OnlineStateSource\n  ): void {\n    // If we are the secondary client, we explicitly ignore the remote store's\n    // online state (the local client may go offline, even though the primary\n    // tab remains online) and only apply the primary tab's online state from\n    // SharedClientState.\n    if (\n      (this.isPrimaryClient && source === OnlineStateSource.RemoteStore) ||\n      (!this.isPrimaryClient && source === OnlineStateSource.SharedClientState)\n    ) {\n      this.assertSubscribed('applyOnlineStateChange()');\n      const newViewSnapshots = [] as ViewSnapshot[];\n      this.queryViewsByQuery.forEach((query, queryView) => {\n        const viewChange = queryView.view.applyOnlineStateChange(onlineState);\n        debugAssert(\n          viewChange.limboChanges.length === 0,\n          'OnlineState should not affect limbo documents.'\n        );\n        if (viewChange.snapshot) {\n          newViewSnapshots.push(viewChange.snapshot);\n        }\n      });\n      this.syncEngineListener!.onOnlineStateChange(onlineState);\n      this.syncEngineListener!.onWatchChange(newViewSnapshots);\n      this.onlineState = onlineState;\n      if (this.isPrimaryClient) {\n        this.sharedClientState.setOnlineState(onlineState);\n      }\n    }\n  }\n\n  async rejectListen(targetId: TargetId, err: FirestoreError): Promise<void> {\n    this.assertSubscribed('rejectListens()');\n\n    // PORTING NOTE: Multi-tab only.\n    this.sharedClientState.updateQueryState(targetId, 'rejected', err);\n\n    const limboResolution = this.activeLimboResolutionsByTarget.get(targetId);\n    const limboKey = limboResolution && limboResolution.key;\n    if (limboKey) {\n      // TODO(klimt): We really only should do the following on permission\n      // denied errors, but we don't have the cause code here.\n\n      // It's a limbo doc. Create a synthetic event saying it was deleted.\n      // This is kind of a hack. Ideally, we would have a method in the local\n      // store to purge a document. However, it would be tricky to keep all of\n      // the local store's invariants with another method.\n      let documentUpdates = new SortedMap<DocumentKey, MaybeDocument>(\n        DocumentKey.comparator\n      );\n      documentUpdates = documentUpdates.insert(\n        limboKey,\n        new NoDocument(limboKey, SnapshotVersion.min())\n      );\n      const resolvedLimboDocuments = documentKeySet().add(limboKey);\n      const event = new RemoteEvent(\n        SnapshotVersion.min(),\n        /* targetChanges= */ new Map<TargetId, TargetChange>(),\n        /* targetMismatches= */ new SortedSet<TargetId>(primitiveComparator),\n        documentUpdates,\n        resolvedLimboDocuments\n      );\n\n      await this.applyRemoteEvent(event);\n\n      // Since this query failed, we won't want to manually unlisten to it.\n      // We only remove it from bookkeeping after we successfully applied the\n      // RemoteEvent. If `applyRemoteEvent()` throws, we want to re-listen to\n      // this query when the RemoteStore restarts the Watch stream, which should\n      // re-trigger the target failure.\n      this.activeLimboTargetsByKey = this.activeLimboTargetsByKey.remove(\n        limboKey\n      );\n      this.activeLimboResolutionsByTarget.delete(targetId);\n      this.pumpEnqueuedLimboResolutions();\n    } else {\n      await this.localStore\n        .releaseTarget(targetId, /* keepPersistedTargetData */ false)\n        .then(() => this.removeAndCleanupTarget(targetId, err))\n        .catch(ignoreIfPrimaryLeaseLoss);\n    }\n  }\n\n  async applySuccessfulWrite(\n    mutationBatchResult: MutationBatchResult\n  ): Promise<void> {\n    this.assertSubscribed('applySuccessfulWrite()');\n\n    const batchId = mutationBatchResult.batch.batchId;\n\n    try {\n      const changes = await this.localStore.acknowledgeBatch(\n        mutationBatchResult\n      );\n\n      // The local store may or may not be able to apply the write result and\n      // raise events immediately (depending on whether the watcher is caught\n      // up), so we raise user callbacks first so that they consistently happen\n      // before listen events.\n      this.processUserCallback(batchId, /*error=*/ null);\n      this.triggerPendingWritesCallbacks(batchId);\n\n      this.sharedClientState.updateMutationState(batchId, 'acknowledged');\n      await this.emitNewSnapsAndNotifyLocalStore(changes);\n    } catch (error) {\n      await ignoreIfPrimaryLeaseLoss(error);\n    }\n  }\n\n  async rejectFailedWrite(\n    batchId: BatchId,\n    error: FirestoreError\n  ): Promise<void> {\n    this.assertSubscribed('rejectFailedWrite()');\n\n    try {\n      const changes = await this.localStore.rejectBatch(batchId);\n\n      // The local store may or may not be able to apply the write result and\n      // raise events immediately (depending on whether the watcher is caught up),\n      // so we raise user callbacks first so that they consistently happen before\n      // listen events.\n      this.processUserCallback(batchId, error);\n      this.triggerPendingWritesCallbacks(batchId);\n\n      this.sharedClientState.updateMutationState(batchId, 'rejected', error);\n      await this.emitNewSnapsAndNotifyLocalStore(changes);\n    } catch (error) {\n      await ignoreIfPrimaryLeaseLoss(error);\n    }\n  }\n\n  async registerPendingWritesCallback(callback: Deferred<void>): Promise<void> {\n    if (!this.remoteStore.canUseNetwork()) {\n      logDebug(\n        LOG_TAG,\n        'The network is disabled. The task returned by ' +\n          \"'awaitPendingWrites()' will not complete until the network is enabled.\"\n      );\n    }\n\n    try {\n      const highestBatchId = await this.localStore.getHighestUnacknowledgedBatchId();\n      if (highestBatchId === BATCHID_UNKNOWN) {\n        // Trigger the callback right away if there is no pending writes at the moment.\n        callback.resolve();\n        return;\n      }\n\n      const callbacks = this.pendingWritesCallbacks.get(highestBatchId) || [];\n      callbacks.push(callback);\n      this.pendingWritesCallbacks.set(highestBatchId, callbacks);\n    } catch (e) {\n      const firestoreError = wrapInUserErrorIfRecoverable(\n        e,\n        'Initialization of waitForPendingWrites() operation failed'\n      );\n      callback.reject(firestoreError);\n    }\n  }\n\n  /**\n   * Triggers the callbacks that are waiting for this batch id to get acknowledged by server,\n   * if there are any.\n   */\n  private triggerPendingWritesCallbacks(batchId: BatchId): void {\n    (this.pendingWritesCallbacks.get(batchId) || []).forEach(callback => {\n      callback.resolve();\n    });\n\n    this.pendingWritesCallbacks.delete(batchId);\n  }\n\n  /** Reject all outstanding callbacks waiting for pending writes to complete. */\n  private rejectOutstandingPendingWritesCallbacks(errorMessage: string): void {\n    this.pendingWritesCallbacks.forEach(callbacks => {\n      callbacks.forEach(callback => {\n        callback.reject(new FirestoreError(Code.CANCELLED, errorMessage));\n      });\n    });\n\n    this.pendingWritesCallbacks.clear();\n  }\n\n  private addMutationCallback(\n    batchId: BatchId,\n    callback: Deferred<void>\n  ): void {\n    let newCallbacks = this.mutationUserCallbacks[this.currentUser.toKey()];\n    if (!newCallbacks) {\n      newCallbacks = new SortedMap<BatchId, Deferred<void>>(\n        primitiveComparator\n      );\n    }\n    newCallbacks = newCallbacks.insert(batchId, callback);\n    this.mutationUserCallbacks[this.currentUser.toKey()] = newCallbacks;\n  }\n\n  /**\n   * Resolves or rejects the user callback for the given batch and then discards\n   * it.\n   */\n  processUserCallback(batchId: BatchId, error: Error | null): void {\n    let newCallbacks = this.mutationUserCallbacks[this.currentUser.toKey()];\n\n    // NOTE: Mutations restored from persistence won't have callbacks, so it's\n    // okay for there to be no callback for this ID.\n    if (newCallbacks) {\n      const callback = newCallbacks.get(batchId);\n      if (callback) {\n        debugAssert(\n          batchId === newCallbacks.minKey(),\n          'Mutation callbacks processed out-of-order?'\n        );\n        if (error) {\n          callback.reject(error);\n        } else {\n          callback.resolve();\n        }\n        newCallbacks = newCallbacks.remove(batchId);\n      }\n      this.mutationUserCallbacks[this.currentUser.toKey()] = newCallbacks;\n    }\n  }\n\n  removeAndCleanupTarget(targetId: number, error: Error | null = null): void {\n    this.sharedClientState.removeLocalQueryTarget(targetId);\n\n    debugAssert(\n      this.queriesByTarget.has(targetId) &&\n        this.queriesByTarget.get(targetId)!.length !== 0,\n      `There are no queries mapped to target id ${targetId}`\n    );\n\n    for (const query of this.queriesByTarget.get(targetId)!) {\n      this.queryViewsByQuery.delete(query);\n      if (error) {\n        this.syncEngineListener!.onWatchError(query, error);\n      }\n    }\n\n    this.queriesByTarget.delete(targetId);\n\n    if (this.isPrimaryClient) {\n      const limboKeys = this.limboDocumentRefs.removeReferencesForId(targetId);\n      limboKeys.forEach(limboKey => {\n        const isReferenced = this.limboDocumentRefs.containsKey(limboKey);\n        if (!isReferenced) {\n          // We removed the last reference for this key\n          this.removeLimboTarget(limboKey);\n        }\n      });\n    }\n  }\n\n  private removeLimboTarget(key: DocumentKey): void {\n    // It's possible that the target already got removed because the query failed. In that case,\n    // the key won't exist in `limboTargetsByKey`. Only do the cleanup if we still have the target.\n    const limboTargetId = this.activeLimboTargetsByKey.get(key);\n    if (limboTargetId === null) {\n      // This target already got removed, because the query failed.\n      return;\n    }\n\n    this.remoteStore.unlisten(limboTargetId);\n    this.activeLimboTargetsByKey = this.activeLimboTargetsByKey.remove(key);\n    this.activeLimboResolutionsByTarget.delete(limboTargetId);\n    this.pumpEnqueuedLimboResolutions();\n  }\n\n  updateTrackedLimbos(\n    targetId: TargetId,\n    limboChanges: LimboDocumentChange[]\n  ): void {\n    for (const limboChange of limboChanges) {\n      if (limboChange instanceof AddedLimboDocument) {\n        this.limboDocumentRefs.addReference(limboChange.key, targetId);\n        this.trackLimboChange(limboChange);\n      } else if (limboChange instanceof RemovedLimboDocument) {\n        logDebug(LOG_TAG, 'Document no longer in limbo: ' + limboChange.key);\n        this.limboDocumentRefs.removeReference(limboChange.key, targetId);\n        const isReferenced = this.limboDocumentRefs.containsKey(\n          limboChange.key\n        );\n        if (!isReferenced) {\n          // We removed the last reference for this key\n          this.removeLimboTarget(limboChange.key);\n        }\n      } else {\n        fail('Unknown limbo change: ' + JSON.stringify(limboChange));\n      }\n    }\n  }\n\n  private trackLimboChange(limboChange: AddedLimboDocument): void {\n    const key = limboChange.key;\n    if (!this.activeLimboTargetsByKey.get(key)) {\n      logDebug(LOG_TAG, 'New document in limbo: ' + key);\n      this.enqueuedLimboResolutions.push(key);\n      this.pumpEnqueuedLimboResolutions();\n    }\n  }\n\n  /**\n   * Starts listens for documents in limbo that are enqueued for resolution,\n   * subject to a maximum number of concurrent resolutions.\n   *\n   * Without bounding the number of concurrent resolutions, the server can fail\n   * with \"resource exhausted\" errors which can lead to pathological client\n   * behavior as seen in https://github.com/firebase/firebase-js-sdk/issues/2683.\n   */\n  private pumpEnqueuedLimboResolutions(): void {\n    while (\n      this.enqueuedLimboResolutions.length > 0 &&\n      this.activeLimboTargetsByKey.size < this.maxConcurrentLimboResolutions\n    ) {\n      const key = this.enqueuedLimboResolutions.shift()!;\n      const limboTargetId = this.limboTargetIdGenerator.next();\n      this.activeLimboResolutionsByTarget.set(\n        limboTargetId,\n        new LimboResolution(key)\n      );\n      this.activeLimboTargetsByKey = this.activeLimboTargetsByKey.insert(\n        key,\n        limboTargetId\n      );\n      this.remoteStore.listen(\n        new TargetData(\n          queryToTarget(newQueryForPath(key.path)),\n          limboTargetId,\n          TargetPurpose.LimboResolution,\n          ListenSequence.INVALID\n        )\n      );\n    }\n  }\n\n  // Visible for testing\n  activeLimboDocumentResolutions(): SortedMap<DocumentKey, TargetId> {\n    return this.activeLimboTargetsByKey;\n  }\n\n  // Visible for testing\n  enqueuedLimboDocumentResolutions(): DocumentKey[] {\n    return this.enqueuedLimboResolutions;\n  }\n\n  async emitNewSnapsAndNotifyLocalStore(\n    changes: MaybeDocumentMap,\n    remoteEvent?: RemoteEvent\n  ): Promise<void> {\n    const newSnaps: ViewSnapshot[] = [];\n    const docChangesInAllViews: LocalViewChanges[] = [];\n    const queriesProcessed: Array<Promise<void>> = [];\n\n    this.queryViewsByQuery.forEach((_, queryView) => {\n      queriesProcessed.push(\n        Promise.resolve()\n          .then(() => {\n            const viewDocChanges = queryView.view.computeDocChanges(changes);\n            if (!viewDocChanges.needsRefill) {\n              return viewDocChanges;\n            }\n            // The query has a limit and some docs were removed, so we need\n            // to re-run the query against the local store to make sure we\n            // didn't lose any good docs that had been past the limit.\n            return this.localStore\n              .executeQuery(queryView.query, /* usePreviousResults= */ false)\n              .then(({ documents }) => {\n                return queryView.view.computeDocChanges(\n                  documents,\n                  viewDocChanges\n                );\n              });\n          })\n          .then((viewDocChanges: ViewDocumentChanges) => {\n            const targetChange =\n              remoteEvent && remoteEvent.targetChanges.get(queryView.targetId);\n            const viewChange = queryView.view.applyChanges(\n              viewDocChanges,\n              /* updateLimboDocuments= */ this.isPrimaryClient,\n              targetChange\n            );\n            this.updateTrackedLimbos(\n              queryView.targetId,\n              viewChange.limboChanges\n            );\n            if (viewChange.snapshot) {\n              if (this.isPrimaryClient) {\n                this.sharedClientState.updateQueryState(\n                  queryView.targetId,\n                  viewChange.snapshot.fromCache ? 'not-current' : 'current'\n                );\n              }\n\n              newSnaps.push(viewChange.snapshot);\n              const docChanges = LocalViewChanges.fromSnapshot(\n                queryView.targetId,\n                viewChange.snapshot\n              );\n              docChangesInAllViews.push(docChanges);\n            }\n          })\n      );\n    });\n\n    await Promise.all(queriesProcessed);\n    this.syncEngineListener!.onWatchChange(newSnaps);\n    await this.localStore.notifyLocalViewChanges(docChangesInAllViews);\n  }\n\n  assertSubscribed(fnName: string): void {\n    debugAssert(\n      this.syncEngineListener !== null,\n      'Trying to call ' + fnName + ' before calling subscribe().'\n    );\n  }\n\n  async handleCredentialChange(user: User): Promise<void> {\n    const userChanged = !this.currentUser.isEqual(user);\n\n    if (userChanged) {\n      logDebug(LOG_TAG, 'User change. New user:', user.toKey());\n\n      const result = await this.localStore.handleUserChange(user);\n      this.currentUser = user;\n\n      // Fails tasks waiting for pending writes requested by previous user.\n      this.rejectOutstandingPendingWritesCallbacks(\n        \"'waitForPendingWrites' promise is rejected due to a user change.\"\n      );\n      // TODO(b/114226417): Consider calling this only in the primary tab.\n      this.sharedClientState.handleUserChange(\n        user,\n        result.removedBatchIds,\n        result.addedBatchIds\n      );\n      await this.emitNewSnapsAndNotifyLocalStore(result.affectedDocuments);\n    }\n  }\n\n  getRemoteKeysForTarget(targetId: TargetId): DocumentKeySet {\n    const limboResolution = this.activeLimboResolutionsByTarget.get(targetId);\n    if (limboResolution && limboResolution.receivedDocument) {\n      return documentKeySet().add(limboResolution.key);\n    } else {\n      let keySet = documentKeySet();\n      const queries = this.queriesByTarget.get(targetId);\n      if (!queries) {\n        return keySet;\n      }\n      for (const query of queries) {\n        const queryView = this.queryViewsByQuery.get(query);\n        debugAssert(\n          !!queryView,\n          `No query view found for ${stringifyQuery(query)}`\n        );\n        keySet = keySet.unionWith(queryView.view.syncedDocuments);\n      }\n      return keySet;\n    }\n  }\n}\n\nexport function newSyncEngine(\n  localStore: LocalStore,\n  remoteStore: RemoteStore,\n  datastore: Datastore,\n  // PORTING NOTE: Manages state synchronization in multi-tab environments.\n  sharedClientState: SharedClientState,\n  currentUser: User,\n  maxConcurrentLimboResolutions: number,\n  isPrimary: boolean\n): SyncEngine {\n  const syncEngine = new SyncEngineImpl(\n    localStore,\n    remoteStore,\n    datastore,\n    sharedClientState,\n    currentUser,\n    maxConcurrentLimboResolutions\n  );\n  if (isPrimary) {\n    syncEngine._isPrimaryClient = true;\n  }\n  return syncEngine;\n}\n\n/**\n * Reconcile the list of synced documents in an existing view with those\n * from persistence.\n */\nasync function synchronizeViewAndComputeSnapshot(\n  syncEngine: SyncEngine,\n  queryView: QueryView\n): Promise<ViewChange> {\n  const syncEngineImpl = debugCast(syncEngine, SyncEngineImpl);\n  const queryResult = await syncEngineImpl.localStore.executeQuery(\n    queryView.query,\n    /* usePreviousResults= */ true\n  );\n  const viewSnapshot = queryView.view.synchronizeWithPersistedState(\n    queryResult\n  );\n  if (syncEngineImpl.isPrimaryClient) {\n    syncEngineImpl.updateTrackedLimbos(\n      queryView.targetId,\n      viewSnapshot.limboChanges\n    );\n  }\n  return viewSnapshot;\n}\n\n/** Applies a mutation state to an existing batch.  */\n// PORTING NOTE: Multi-Tab only.\nexport async function applyBatchState(\n  syncEngine: SyncEngine,\n  batchId: BatchId,\n  batchState: MutationBatchState,\n  error?: FirestoreError\n): Promise<void> {\n  const syncEngineImpl = debugCast(syncEngine, SyncEngineImpl);\n  syncEngineImpl.assertSubscribed('applyBatchState()');\n  const documents = await lookupMutationDocuments(\n    syncEngineImpl.localStore,\n    batchId\n  );\n\n  if (documents === null) {\n    // A throttled tab may not have seen the mutation before it was completed\n    // and removed from the mutation queue, in which case we won't have cached\n    // the affected documents. In this case we can safely ignore the update\n    // since that means we didn't apply the mutation locally at all (if we\n    // had, we would have cached the affected documents), and so we will just\n    // see any resulting document changes via normal remote document updates\n    // as applicable.\n    logDebug(LOG_TAG, 'Cannot apply mutation batch with id: ' + batchId);\n    return;\n  }\n\n  if (batchState === 'pending') {\n    // If we are the primary client, we need to send this write to the\n    // backend. Secondary clients will ignore these writes since their remote\n    // connection is disabled.\n    await syncEngineImpl.remoteStore.fillWritePipeline();\n  } else if (batchState === 'acknowledged' || batchState === 'rejected') {\n    // NOTE: Both these methods are no-ops for batches that originated from\n    // other clients.\n    syncEngineImpl.processUserCallback(batchId, error ? error : null);\n    removeCachedMutationBatchMetadata(syncEngineImpl.localStore, batchId);\n  } else {\n    fail(`Unknown batchState: ${batchState}`);\n  }\n\n  await syncEngineImpl.emitNewSnapsAndNotifyLocalStore(documents);\n}\n\n/** Applies a query target change from a different tab. */\n// PORTING NOTE: Multi-Tab only.\nexport async function applyPrimaryState(\n  syncEngine: SyncEngine,\n  isPrimary: boolean\n): Promise<void> {\n  const syncEngineImpl = debugCast(syncEngine, SyncEngineImpl);\n  if (isPrimary === true && syncEngineImpl._isPrimaryClient !== true) {\n    // Secondary tabs only maintain Views for their local listeners and the\n    // Views internal state may not be 100% populated (in particular\n    // secondary tabs don't track syncedDocuments, the set of documents the\n    // server considers to be in the target). So when a secondary becomes\n    // primary, we need to need to make sure that all views for all targets\n    // match the state on disk.\n    const activeTargets = syncEngineImpl.sharedClientState.getAllActiveQueryTargets();\n    const activeQueries = await synchronizeQueryViewsAndRaiseSnapshots(\n      syncEngineImpl,\n      activeTargets.toArray(),\n      /*transitionToPrimary=*/ true\n    );\n    syncEngineImpl._isPrimaryClient = true;\n    await syncEngineImpl.remoteStore.applyPrimaryState(true);\n    for (const targetData of activeQueries) {\n      syncEngineImpl.remoteStore.listen(targetData);\n    }\n  } else if (isPrimary === false && syncEngineImpl._isPrimaryClient !== false) {\n    const activeTargets: TargetId[] = [];\n\n    let p = Promise.resolve();\n    syncEngineImpl.queriesByTarget.forEach((_, targetId) => {\n      if (syncEngineImpl.sharedClientState.isLocalQueryTarget(targetId)) {\n        activeTargets.push(targetId);\n      } else {\n        p = p.then(() => {\n          syncEngineImpl.removeAndCleanupTarget(targetId);\n          return syncEngineImpl.localStore.releaseTarget(\n            targetId,\n            /*keepPersistedTargetData=*/ true\n          );\n        });\n      }\n      syncEngineImpl.remoteStore.unlisten(targetId);\n    });\n    await p;\n\n    await synchronizeQueryViewsAndRaiseSnapshots(\n      syncEngineImpl,\n      activeTargets,\n      /*transitionToPrimary=*/ false\n    );\n    resetLimboDocuments(syncEngineImpl);\n    syncEngineImpl._isPrimaryClient = false;\n    await syncEngineImpl.remoteStore.applyPrimaryState(false);\n  }\n}\n\n// PORTING NOTE: Multi-Tab only.\nfunction resetLimboDocuments(syncEngine: SyncEngine): void {\n  const syncEngineImpl = debugCast(syncEngine, SyncEngineImpl);\n  syncEngineImpl.activeLimboResolutionsByTarget.forEach((_, targetId) => {\n    syncEngineImpl.remoteStore.unlisten(targetId);\n  });\n  syncEngineImpl.limboDocumentRefs.removeAllReferences();\n  syncEngineImpl.activeLimboResolutionsByTarget = new Map<\n    TargetId,\n    LimboResolution\n  >();\n  syncEngineImpl.activeLimboTargetsByKey = new SortedMap<DocumentKey, TargetId>(\n    DocumentKey.comparator\n  );\n}\n\n/**\n * Reconcile the query views of the provided query targets with the state from\n * persistence. Raises snapshots for any changes that affect the local\n * client and returns the updated state of all target's query data.\n *\n * @param targets the list of targets with views that need to be recomputed\n * @param transitionToPrimary `true` iff the tab transitions from a secondary\n * tab to a primary tab\n */\n// PORTING NOTE: Multi-Tab only.\nasync function synchronizeQueryViewsAndRaiseSnapshots(\n  syncEngine: SyncEngine,\n  targets: TargetId[],\n  transitionToPrimary: boolean\n): Promise<TargetData[]> {\n  const syncEngineImpl = debugCast(syncEngine, SyncEngineImpl);\n  const activeQueries: TargetData[] = [];\n  const newViewSnapshots: ViewSnapshot[] = [];\n  for (const targetId of targets) {\n    let targetData: TargetData;\n    const queries = syncEngineImpl.queriesByTarget.get(targetId);\n\n    if (queries && queries.length !== 0) {\n      // For queries that have a local View, we fetch their current state\n      // from LocalStore (as the resume token and the snapshot version\n      // might have changed) and reconcile their views with the persisted\n      // state (the list of syncedDocuments may have gotten out of sync).\n      targetData = await syncEngineImpl.localStore.allocateTarget(\n        queryToTarget(queries[0])\n      );\n\n      for (const query of queries) {\n        const queryView = syncEngineImpl.queryViewsByQuery.get(query);\n        debugAssert(\n          !!queryView,\n          `No query view found for ${stringifyQuery(query)}`\n        );\n\n        const viewChange = await synchronizeViewAndComputeSnapshot(\n          syncEngineImpl,\n          queryView\n        );\n        if (viewChange.snapshot) {\n          newViewSnapshots.push(viewChange.snapshot);\n        }\n      }\n    } else {\n      debugAssert(\n        transitionToPrimary,\n        'A secondary tab should never have an active view without an active target.'\n      );\n      // For queries that never executed on this client, we need to\n      // allocate the target in LocalStore and initialize a new View.\n      const target = await getCachedTarget(syncEngineImpl.localStore, targetId);\n      debugAssert(!!target, `Target for id ${targetId} not found`);\n      targetData = await syncEngineImpl.localStore.allocateTarget(target);\n      await syncEngineImpl.initializeViewAndComputeSnapshot(\n        synthesizeTargetToQuery(target!),\n        targetId,\n        /*current=*/ false\n      );\n    }\n\n    activeQueries.push(targetData!);\n  }\n\n  syncEngineImpl.syncEngineListener!.onWatchChange(newViewSnapshots);\n  return activeQueries;\n}\n\n/**\n * Creates a `Query` object from the specified `Target`. There is no way to\n * obtain the original `Query`, so we synthesize a `Query` from the `Target`\n * object.\n *\n * The synthesized result might be different from the original `Query`, but\n * since the synthesized `Query` should return the same results as the\n * original one (only the presentation of results might differ), the potential\n * difference will not cause issues.\n */\n// PORTING NOTE: Multi-Tab only.\nfunction synthesizeTargetToQuery(target: Target): Query {\n  return newQuery(\n    target.path,\n    target.collectionGroup,\n    target.orderBy,\n    target.filters,\n    target.limit,\n    LimitType.First,\n    target.startAt,\n    target.endAt\n  );\n}\n\n/** Returns the IDs of the clients that are currently active. */\n// PORTING NOTE: Multi-Tab only.\nexport function getActiveClients(syncEngine: SyncEngine): Promise<ClientId[]> {\n  const syncEngineImpl = debugCast(syncEngine, SyncEngineImpl);\n  return getActiveClientsFromPersistence(syncEngineImpl.localStore);\n}\n\n/** Applies a query target change from a different tab. */\n// PORTING NOTE: Multi-Tab only.\nexport async function applyTargetState(\n  syncEngine: SyncEngine,\n  targetId: TargetId,\n  state: QueryTargetState,\n  error?: FirestoreError\n): Promise<void> {\n  const syncEngineImpl = debugCast(syncEngine, SyncEngineImpl);\n  if (syncEngineImpl._isPrimaryClient) {\n    // If we receive a target state notification via WebStorage, we are\n    // either already secondary or another tab has taken the primary lease.\n    logDebug(LOG_TAG, 'Ignoring unexpected query state notification.');\n    return;\n  }\n\n  if (syncEngineImpl.queriesByTarget.has(targetId)) {\n    switch (state) {\n      case 'current':\n      case 'not-current': {\n        const changes = await getNewDocumentChanges(syncEngineImpl.localStore);\n        const synthesizedRemoteEvent = RemoteEvent.createSynthesizedRemoteEventForCurrentChange(\n          targetId,\n          state === 'current'\n        );\n        await syncEngineImpl.emitNewSnapsAndNotifyLocalStore(\n          changes,\n          synthesizedRemoteEvent\n        );\n        break;\n      }\n      case 'rejected': {\n        await syncEngineImpl.localStore.releaseTarget(\n          targetId,\n          /* keepPersistedTargetData */ true\n        );\n        syncEngineImpl.removeAndCleanupTarget(targetId, error);\n        break;\n      }\n      default:\n        fail('Unexpected target state: ' + state);\n    }\n  }\n}\n\n/** Adds or removes Watch targets for queries from different tabs. */\nexport async function applyActiveTargetsChange(\n  syncEngine: SyncEngine,\n  added: TargetId[],\n  removed: TargetId[]\n): Promise<void> {\n  const syncEngineImpl = debugCast(syncEngine, SyncEngineImpl);\n  if (!syncEngineImpl._isPrimaryClient) {\n    return;\n  }\n\n  for (const targetId of added) {\n    if (syncEngineImpl.queriesByTarget.has(targetId)) {\n      // A target might have been added in a previous attempt\n      logDebug(LOG_TAG, 'Adding an already active target ' + targetId);\n      continue;\n    }\n\n    const target = await getCachedTarget(syncEngineImpl.localStore, targetId);\n    debugAssert(!!target, `Query data for active target ${targetId} not found`);\n    const targetData = await syncEngineImpl.localStore.allocateTarget(target);\n    await syncEngineImpl.initializeViewAndComputeSnapshot(\n      synthesizeTargetToQuery(target),\n      targetData.targetId,\n      /*current=*/ false\n    );\n    syncEngineImpl.remoteStore.listen(targetData);\n  }\n\n  for (const targetId of removed) {\n    // Check that the target is still active since the target might have been\n    // removed if it has been rejected by the backend.\n    if (!syncEngineImpl.queriesByTarget.has(targetId)) {\n      continue;\n    }\n\n    // Release queries that are still active.\n    await syncEngineImpl.localStore\n      .releaseTarget(targetId, /* keepPersistedTargetData */ false)\n      .then(() => {\n        syncEngineImpl.remoteStore.unlisten(targetId);\n        syncEngineImpl.removeAndCleanupTarget(targetId);\n      })\n      .catch(ignoreIfPrimaryLeaseLoss);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert } from '../util/assert';\nimport { EventHandler } from '../util/misc';\nimport { ObjectMap } from '../util/obj_map';\nimport { canonifyQuery, Query, queryEquals, stringifyQuery } from './query';\nimport { SyncEngine, SyncEngineListener } from './sync_engine';\nimport { OnlineState } from './types';\nimport { ChangeType, DocumentViewChange, ViewSnapshot } from './view_snapshot';\nimport { wrapInUserErrorIfRecoverable } from '../util/async_queue';\n\n/**\n * Holds the listeners and the last received ViewSnapshot for a query being\n * tracked by EventManager.\n */\nclass QueryListenersInfo {\n  viewSnap: ViewSnapshot | undefined = undefined;\n  listeners: QueryListener[] = [];\n}\n\n/**\n * Interface for handling events from the EventManager.\n */\nexport interface Observer<T> {\n  next: EventHandler<T>;\n  error: EventHandler<Error>;\n}\n\n/**\n * EventManager is responsible for mapping queries to query event emitters.\n * It handles \"fan-out\". -- Identical queries will re-use the same watch on the\n * backend.\n */\nexport class EventManager implements SyncEngineListener {\n  private queries = new ObjectMap<Query, QueryListenersInfo>(\n    q => canonifyQuery(q),\n    queryEquals\n  );\n\n  private onlineState = OnlineState.Unknown;\n\n  private snapshotsInSyncListeners: Set<Observer<void>> = new Set();\n\n  constructor(private syncEngine: SyncEngine) {\n    this.syncEngine.subscribe(this);\n  }\n\n  async listen(listener: QueryListener): Promise<void> {\n    const query = listener.query;\n    let firstListen = false;\n\n    let queryInfo = this.queries.get(query);\n    if (!queryInfo) {\n      firstListen = true;\n      queryInfo = new QueryListenersInfo();\n    }\n\n    if (firstListen) {\n      try {\n        queryInfo.viewSnap = await this.syncEngine.listen(query);\n      } catch (e) {\n        const firestoreError = wrapInUserErrorIfRecoverable(\n          e,\n          `Initialization of query '${stringifyQuery(listener.query)}' failed`\n        );\n        listener.onError(firestoreError);\n        return;\n      }\n    }\n\n    this.queries.set(query, queryInfo);\n    queryInfo.listeners.push(listener);\n\n    // Run global snapshot listeners if a consistent snapshot has been emitted.\n    const raisedEvent = listener.applyOnlineStateChange(this.onlineState);\n    debugAssert(\n      !raisedEvent,\n      \"applyOnlineStateChange() shouldn't raise an event for brand-new listeners.\"\n    );\n\n    if (queryInfo.viewSnap) {\n      const raisedEvent = listener.onViewSnapshot(queryInfo.viewSnap);\n      if (raisedEvent) {\n        this.raiseSnapshotsInSyncEvent();\n      }\n    }\n  }\n\n  async unlisten(listener: QueryListener): Promise<void> {\n    const query = listener.query;\n    let lastListen = false;\n\n    const queryInfo = this.queries.get(query);\n    if (queryInfo) {\n      const i = queryInfo.listeners.indexOf(listener);\n      if (i >= 0) {\n        queryInfo.listeners.splice(i, 1);\n        lastListen = queryInfo.listeners.length === 0;\n      }\n    }\n\n    if (lastListen) {\n      this.queries.delete(query);\n      return this.syncEngine.unlisten(query);\n    }\n  }\n\n  onWatchChange(viewSnaps: ViewSnapshot[]): void {\n    let raisedEvent = false;\n    for (const viewSnap of viewSnaps) {\n      const query = viewSnap.query;\n      const queryInfo = this.queries.get(query);\n      if (queryInfo) {\n        for (const listener of queryInfo.listeners) {\n          if (listener.onViewSnapshot(viewSnap)) {\n            raisedEvent = true;\n          }\n        }\n        queryInfo.viewSnap = viewSnap;\n      }\n    }\n    if (raisedEvent) {\n      this.raiseSnapshotsInSyncEvent();\n    }\n  }\n\n  onWatchError(query: Query, error: Error): void {\n    const queryInfo = this.queries.get(query);\n    if (queryInfo) {\n      for (const listener of queryInfo.listeners) {\n        listener.onError(error);\n      }\n    }\n\n    // Remove all listeners. NOTE: We don't need to call syncEngine.unlisten()\n    // after an error.\n    this.queries.delete(query);\n  }\n\n  onOnlineStateChange(onlineState: OnlineState): void {\n    this.onlineState = onlineState;\n    let raisedEvent = false;\n    this.queries.forEach((_, queryInfo) => {\n      for (const listener of queryInfo.listeners) {\n        // Run global snapshot listeners if a consistent snapshot has been emitted.\n        if (listener.applyOnlineStateChange(onlineState)) {\n          raisedEvent = true;\n        }\n      }\n    });\n    if (raisedEvent) {\n      this.raiseSnapshotsInSyncEvent();\n    }\n  }\n\n  addSnapshotsInSyncListener(observer: Observer<void>): void {\n    this.snapshotsInSyncListeners.add(observer);\n    // Immediately fire an initial event, indicating all existing listeners\n    // are in-sync.\n    observer.next();\n  }\n\n  removeSnapshotsInSyncListener(observer: Observer<void>): void {\n    this.snapshotsInSyncListeners.delete(observer);\n  }\n\n  // Call all global snapshot listeners that have been set.\n  private raiseSnapshotsInSyncEvent(): void {\n    this.snapshotsInSyncListeners.forEach(observer => {\n      observer.next();\n    });\n  }\n}\n\nexport interface ListenOptions {\n  /** Raise events even when only the metadata changes */\n  readonly includeMetadataChanges?: boolean;\n\n  /**\n   * Wait for a sync with the server when online, but still raise events while\n   * offline.\n   */\n  readonly waitForSyncWhenOnline?: boolean;\n}\n\n/**\n * QueryListener takes a series of internal view snapshots and determines\n * when to raise the event.\n *\n * It uses an Observer to dispatch events.\n */\nexport class QueryListener {\n  /**\n   * Initial snapshots (e.g. from cache) may not be propagated to the wrapped\n   * observer. This flag is set to true once we've actually raised an event.\n   */\n  private raisedInitialEvent = false;\n\n  private options: ListenOptions;\n\n  private snap: ViewSnapshot | null = null;\n\n  private onlineState = OnlineState.Unknown;\n\n  constructor(\n    readonly query: Query,\n    private queryObserver: Observer<ViewSnapshot>,\n    options?: ListenOptions\n  ) {\n    this.options = options || {};\n  }\n\n  /**\n   * Applies the new ViewSnapshot to this listener, raising a user-facing event\n   * if applicable (depending on what changed, whether the user has opted into\n   * metadata-only changes, etc.). Returns true if a user-facing event was\n   * indeed raised.\n   */\n  onViewSnapshot(snap: ViewSnapshot): boolean {\n    debugAssert(\n      snap.docChanges.length > 0 || snap.syncStateChanged,\n      'We got a new snapshot with no changes?'\n    );\n\n    if (!this.options.includeMetadataChanges) {\n      // Remove the metadata only changes.\n      const docChanges: DocumentViewChange[] = [];\n      for (const docChange of snap.docChanges) {\n        if (docChange.type !== ChangeType.Metadata) {\n          docChanges.push(docChange);\n        }\n      }\n      snap = new ViewSnapshot(\n        snap.query,\n        snap.docs,\n        snap.oldDocs,\n        docChanges,\n        snap.mutatedKeys,\n        snap.fromCache,\n        snap.syncStateChanged,\n        /* excludesMetadataChanges= */ true\n      );\n    }\n    let raisedEvent = false;\n    if (!this.raisedInitialEvent) {\n      if (this.shouldRaiseInitialEvent(snap, this.onlineState)) {\n        this.raiseInitialEvent(snap);\n        raisedEvent = true;\n      }\n    } else if (this.shouldRaiseEvent(snap)) {\n      this.queryObserver.next(snap);\n      raisedEvent = true;\n    }\n\n    this.snap = snap;\n    return raisedEvent;\n  }\n\n  onError(error: Error): void {\n    this.queryObserver.error(error);\n  }\n\n  /** Returns whether a snapshot was raised. */\n  applyOnlineStateChange(onlineState: OnlineState): boolean {\n    this.onlineState = onlineState;\n    let raisedEvent = false;\n    if (\n      this.snap &&\n      !this.raisedInitialEvent &&\n      this.shouldRaiseInitialEvent(this.snap, onlineState)\n    ) {\n      this.raiseInitialEvent(this.snap);\n      raisedEvent = true;\n    }\n    return raisedEvent;\n  }\n\n  private shouldRaiseInitialEvent(\n    snap: ViewSnapshot,\n    onlineState: OnlineState\n  ): boolean {\n    debugAssert(\n      !this.raisedInitialEvent,\n      'Determining whether to raise first event but already had first event'\n    );\n\n    // Always raise the first event when we're synced\n    if (!snap.fromCache) {\n      return true;\n    }\n\n    // NOTE: We consider OnlineState.Unknown as online (it should become Offline\n    // or Online if we wait long enough).\n    const maybeOnline = onlineState !== OnlineState.Offline;\n    // Don't raise the event if we're online, aren't synced yet (checked\n    // above) and are waiting for a sync.\n    if (this.options.waitForSyncWhenOnline && maybeOnline) {\n      debugAssert(\n        snap.fromCache,\n        'Waiting for sync, but snapshot is not from cache'\n      );\n      return false;\n    }\n\n    // Raise data from cache if we have any documents or we are offline\n    return !snap.docs.isEmpty() || onlineState === OnlineState.Offline;\n  }\n\n  private shouldRaiseEvent(snap: ViewSnapshot): boolean {\n    // We don't need to handle includeDocumentMetadataChanges here because\n    // the Metadata only changes have already been stripped out if needed.\n    // At this point the only changes we will see are the ones we should\n    // propagate.\n    if (snap.docChanges.length > 0) {\n      return true;\n    }\n\n    const hasPendingWritesChanged =\n      this.snap && this.snap.hasPendingWrites !== snap.hasPendingWrites;\n    if (snap.syncStateChanged || hasPendingWritesChanged) {\n      return this.options.includeMetadataChanges === true;\n    }\n\n    // Generally we should have hit one of the cases above, but it's possible\n    // to get here if there were only metadata docChanges and they got\n    // stripped out.\n    return false;\n  }\n\n  private raiseInitialEvent(snap: ViewSnapshot): void {\n    debugAssert(\n      !this.raisedInitialEvent,\n      'Trying to raise initial events for second time'\n    );\n    snap = ViewSnapshot.fromInitialDocuments(\n      snap.query,\n      snap.docs,\n      snap.mutatedKeys,\n      snap.fromCache\n    );\n    this.raisedInitialEvent = true;\n    this.queryObserver.next(snap);\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { QueryEngine } from './query_engine';\nimport { LocalDocumentsView } from './local_documents_view';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport {\n  LimitType,\n  newQueryComparator,\n  Query,\n  queryMatches,\n  stringifyQuery\n} from '../core/query';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport {\n  DocumentKeySet,\n  DocumentMap,\n  MaybeDocumentMap\n} from '../model/collections';\nimport { Document } from '../model/document';\nimport { debugAssert } from '../util/assert';\nimport { getLogLevel, LogLevel, logDebug } from '../util/log';\nimport { SortedSet } from '../util/sorted_set';\n\n// TOOD(b/140938512): Drop SimpleQueryEngine and rename IndexFreeQueryEngine.\n\n/**\n * A query engine that takes advantage of the target document mapping in the\n * QueryCache. The IndexFreeQueryEngine optimizes query execution by only\n * reading the documents that previously matched a query plus any documents that were\n * edited after the query was last listened to.\n *\n * There are some cases where Index-Free queries are not guaranteed to produce\n * the same results as full collection scans. In these cases, the\n * IndexFreeQueryEngine falls back to full query processing. These cases are:\n *\n * - Limit queries where a document that matched the query previously no longer\n *   matches the query.\n *\n * - Limit queries where a document edit may cause the document to sort below\n *   another document that is in the local cache.\n *\n * - Queries that have never been CURRENT or free of Limbo documents.\n */\nexport class IndexFreeQueryEngine implements QueryEngine {\n  private localDocumentsView: LocalDocumentsView | undefined;\n\n  setLocalDocumentsView(localDocuments: LocalDocumentsView): void {\n    this.localDocumentsView = localDocuments;\n  }\n\n  getDocumentsMatchingQuery(\n    transaction: PersistenceTransaction,\n    query: Query,\n    lastLimboFreeSnapshotVersion: SnapshotVersion,\n    remoteKeys: DocumentKeySet\n  ): PersistencePromise<DocumentMap> {\n    debugAssert(\n      this.localDocumentsView !== undefined,\n      'setLocalDocumentsView() not called'\n    );\n\n    // Queries that match all documents don't benefit from using\n    // IndexFreeQueries. It is more efficient to scan all documents in a\n    // collection, rather than to perform individual lookups.\n    if (query.matchesAllDocuments()) {\n      return this.executeFullCollectionScan(transaction, query);\n    }\n\n    // Queries that have never seen a snapshot without limbo free documents\n    // should also be run as a full collection scan.\n    if (lastLimboFreeSnapshotVersion.isEqual(SnapshotVersion.min())) {\n      return this.executeFullCollectionScan(transaction, query);\n    }\n\n    return this.localDocumentsView!.getDocuments(transaction, remoteKeys).next(\n      documents => {\n        const previousResults = this.applyQuery(query, documents);\n\n        if (\n          (query.hasLimitToFirst() || query.hasLimitToLast()) &&\n          this.needsRefill(\n            query.limitType,\n            previousResults,\n            remoteKeys,\n            lastLimboFreeSnapshotVersion\n          )\n        ) {\n          return this.executeFullCollectionScan(transaction, query);\n        }\n\n        if (getLogLevel() <= LogLevel.DEBUG) {\n          logDebug(\n            'IndexFreeQueryEngine',\n            'Re-using previous result from %s to execute query: %s',\n            lastLimboFreeSnapshotVersion.toString(),\n            stringifyQuery(query)\n          );\n        }\n\n        // Retrieve all results for documents that were updated since the last\n        // limbo-document free remote snapshot.\n        return this.localDocumentsView!.getDocumentsMatchingQuery(\n          transaction,\n          query,\n          lastLimboFreeSnapshotVersion\n        ).next(updatedResults => {\n          // We merge `previousResults` into `updateResults`, since\n          // `updateResults` is already a DocumentMap. If a document is\n          // contained in both lists, then its contents are the same.\n          previousResults.forEach(doc => {\n            updatedResults = updatedResults.insert(doc.key, doc);\n          });\n          return updatedResults;\n        });\n      }\n    );\n  }\n\n  /** Applies the query filter and sorting to the provided documents.  */\n  private applyQuery(\n    query: Query,\n    documents: MaybeDocumentMap\n  ): SortedSet<Document> {\n    // Sort the documents and re-apply the query filter since previously\n    // matching documents do not necessarily still match the query.\n    let queryResults = new SortedSet<Document>(newQueryComparator(query));\n    documents.forEach((_, maybeDoc) => {\n      if (maybeDoc instanceof Document && queryMatches(query, maybeDoc)) {\n        queryResults = queryResults.add(maybeDoc);\n      }\n    });\n    return queryResults;\n  }\n\n  /**\n   * Determines if a limit query needs to be refilled from cache, making it\n   * ineligible for index-free execution.\n   *\n   * @param sortedPreviousResults The documents that matched the query when it\n   * was last synchronized, sorted by the query's comparator.\n   * @param remoteKeys The document keys that matched the query at the last\n   * snapshot.\n   * @param limboFreeSnapshotVersion The version of the snapshot when the query\n   * was last synchronized.\n   */\n  private needsRefill(\n    limitType: LimitType,\n    sortedPreviousResults: SortedSet<Document>,\n    remoteKeys: DocumentKeySet,\n    limboFreeSnapshotVersion: SnapshotVersion\n  ): boolean {\n    // The query needs to be refilled if a previously matching document no\n    // longer matches.\n    if (remoteKeys.size !== sortedPreviousResults.size) {\n      return true;\n    }\n\n    // Limit queries are not eligible for index-free query execution if there is\n    // a potential that an older document from cache now sorts before a document\n    // that was previously part of the limit. This, however, can only happen if\n    // the document at the edge of the limit goes out of limit.\n    // If a document that is not the limit boundary sorts differently,\n    // the boundary of the limit itself did not change and documents from cache\n    // will continue to be \"rejected\" by this boundary. Therefore, we can ignore\n    // any modifications that don't affect the last document.\n    const docAtLimitEdge =\n      limitType === LimitType.First\n        ? sortedPreviousResults.last()\n        : sortedPreviousResults.first();\n    if (!docAtLimitEdge) {\n      // We don't need to refill the query if there were already no documents.\n      return false;\n    }\n    return (\n      docAtLimitEdge.hasPendingWrites ||\n      docAtLimitEdge.version.compareTo(limboFreeSnapshotVersion) > 0\n    );\n  }\n\n  private executeFullCollectionScan(\n    transaction: PersistenceTransaction,\n    query: Query\n  ): PersistencePromise<DocumentMap> {\n    if (getLogLevel() <= LogLevel.DEBUG) {\n      logDebug(\n        'IndexFreeQueryEngine',\n        'Using full collection scan to execute query:',\n        stringifyQuery(query)\n      );\n    }\n\n    return this.localDocumentsView!.getDocumentsMatchingQuery(\n      transaction,\n      query,\n      SnapshotVersion.min()\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Timestamp } from '../api/timestamp';\nimport { isCollectionGroupQuery, Query } from '../core/query';\nimport { BatchId } from '../core/types';\nimport { DocumentKey } from '../model/document_key';\nimport { Mutation } from '../model/mutation';\nimport { MutationBatch, BATCHID_UNKNOWN } from '../model/mutation_batch';\nimport { debugAssert, hardAssert } from '../util/assert';\nimport { primitiveComparator } from '../util/misc';\nimport { SortedMap } from '../util/sorted_map';\nimport { SortedSet } from '../util/sorted_set';\n\nimport { IndexManager } from './index_manager';\nimport { MutationQueue } from './mutation_queue';\nimport { PersistenceTransaction, ReferenceDelegate } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { DocReference } from './reference_set';\n\nexport class MemoryMutationQueue implements MutationQueue {\n  /**\n   * The set of all mutations that have been sent but not yet been applied to\n   * the backend.\n   */\n  private mutationQueue: MutationBatch[] = [];\n\n  /** Next value to use when assigning sequential IDs to each mutation batch. */\n  private nextBatchId: BatchId = 1;\n\n  /** An ordered mapping between documents and the mutations batch IDs. */\n  private batchesByDocumentKey = new SortedSet(DocReference.compareByKey);\n\n  constructor(\n    private readonly indexManager: IndexManager,\n    private readonly referenceDelegate: ReferenceDelegate\n  ) {}\n\n  checkEmpty(transaction: PersistenceTransaction): PersistencePromise<boolean> {\n    return PersistencePromise.resolve(this.mutationQueue.length === 0);\n  }\n\n  addMutationBatch(\n    transaction: PersistenceTransaction,\n    localWriteTime: Timestamp,\n    baseMutations: Mutation[],\n    mutations: Mutation[]\n  ): PersistencePromise<MutationBatch> {\n    debugAssert(mutations.length !== 0, 'Mutation batches should not be empty');\n\n    const batchId = this.nextBatchId;\n    this.nextBatchId++;\n\n    if (this.mutationQueue.length > 0) {\n      const prior = this.mutationQueue[this.mutationQueue.length - 1];\n      debugAssert(\n        prior.batchId < batchId,\n        'Mutation batchIDs must be monotonically increasing order'\n      );\n    }\n\n    const batch = new MutationBatch(\n      batchId,\n      localWriteTime,\n      baseMutations,\n      mutations\n    );\n    this.mutationQueue.push(batch);\n\n    // Track references by document key and index collection parents.\n    for (const mutation of mutations) {\n      this.batchesByDocumentKey = this.batchesByDocumentKey.add(\n        new DocReference(mutation.key, batchId)\n      );\n\n      this.indexManager.addToCollectionParentIndex(\n        transaction,\n        mutation.key.path.popLast()\n      );\n    }\n\n    return PersistencePromise.resolve(batch);\n  }\n\n  lookupMutationBatch(\n    transaction: PersistenceTransaction,\n    batchId: BatchId\n  ): PersistencePromise<MutationBatch | null> {\n    return PersistencePromise.resolve(this.findMutationBatch(batchId));\n  }\n\n  getNextMutationBatchAfterBatchId(\n    transaction: PersistenceTransaction,\n    batchId: BatchId\n  ): PersistencePromise<MutationBatch | null> {\n    const nextBatchId = batchId + 1;\n\n    // The requested batchId may still be out of range so normalize it to the\n    // start of the queue.\n    const rawIndex = this.indexOfBatchId(nextBatchId);\n    const index = rawIndex < 0 ? 0 : rawIndex;\n    return PersistencePromise.resolve(\n      this.mutationQueue.length > index ? this.mutationQueue[index] : null\n    );\n  }\n\n  getHighestUnacknowledgedBatchId(): PersistencePromise<BatchId> {\n    return PersistencePromise.resolve(\n      this.mutationQueue.length === 0 ? BATCHID_UNKNOWN : this.nextBatchId - 1\n    );\n  }\n\n  getAllMutationBatches(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<MutationBatch[]> {\n    return PersistencePromise.resolve(this.mutationQueue.slice());\n  }\n\n  getAllMutationBatchesAffectingDocumentKey(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<MutationBatch[]> {\n    const start = new DocReference(documentKey, 0);\n    const end = new DocReference(documentKey, Number.POSITIVE_INFINITY);\n    const result: MutationBatch[] = [];\n    this.batchesByDocumentKey.forEachInRange([start, end], ref => {\n      debugAssert(\n        documentKey.isEqual(ref.key),\n        \"Should only iterate over a single key's batches\"\n      );\n      const batch = this.findMutationBatch(ref.targetOrBatchId);\n      debugAssert(\n        batch !== null,\n        'Batches in the index must exist in the main table'\n      );\n      result.push(batch!);\n    });\n\n    return PersistencePromise.resolve(result);\n  }\n\n  getAllMutationBatchesAffectingDocumentKeys(\n    transaction: PersistenceTransaction,\n    documentKeys: SortedMap<DocumentKey, unknown>\n  ): PersistencePromise<MutationBatch[]> {\n    let uniqueBatchIDs = new SortedSet<number>(primitiveComparator);\n\n    documentKeys.forEach(documentKey => {\n      const start = new DocReference(documentKey, 0);\n      const end = new DocReference(documentKey, Number.POSITIVE_INFINITY);\n      this.batchesByDocumentKey.forEachInRange([start, end], ref => {\n        debugAssert(\n          documentKey.isEqual(ref.key),\n          \"For each key, should only iterate over a single key's batches\"\n        );\n\n        uniqueBatchIDs = uniqueBatchIDs.add(ref.targetOrBatchId);\n      });\n    });\n\n    return PersistencePromise.resolve(this.findMutationBatches(uniqueBatchIDs));\n  }\n\n  getAllMutationBatchesAffectingQuery(\n    transaction: PersistenceTransaction,\n    query: Query\n  ): PersistencePromise<MutationBatch[]> {\n    debugAssert(\n      !isCollectionGroupQuery(query),\n      'CollectionGroup queries should be handled in LocalDocumentsView'\n    );\n    // Use the query path as a prefix for testing if a document matches the\n    // query.\n    const prefix = query.path;\n    const immediateChildrenPathLength = prefix.length + 1;\n\n    // Construct a document reference for actually scanning the index. Unlike\n    // the prefix the document key in this reference must have an even number of\n    // segments. The empty segment can be used a suffix of the query path\n    // because it precedes all other segments in an ordered traversal.\n    let startPath = prefix;\n    if (!DocumentKey.isDocumentKey(startPath)) {\n      startPath = startPath.child('');\n    }\n\n    const start = new DocReference(new DocumentKey(startPath), 0);\n\n    // Find unique batchIDs referenced by all documents potentially matching the\n    // query.\n    let uniqueBatchIDs = new SortedSet<number>(primitiveComparator);\n\n    this.batchesByDocumentKey.forEachWhile(ref => {\n      const rowKeyPath = ref.key.path;\n      if (!prefix.isPrefixOf(rowKeyPath)) {\n        return false;\n      } else {\n        // Rows with document keys more than one segment longer than the query\n        // path can't be matches. For example, a query on 'rooms' can't match\n        // the document /rooms/abc/messages/xyx.\n        // TODO(mcg): we'll need a different scanner when we implement\n        // ancestor queries.\n        if (rowKeyPath.length === immediateChildrenPathLength) {\n          uniqueBatchIDs = uniqueBatchIDs.add(ref.targetOrBatchId);\n        }\n        return true;\n      }\n    }, start);\n\n    return PersistencePromise.resolve(this.findMutationBatches(uniqueBatchIDs));\n  }\n\n  private findMutationBatches(batchIDs: SortedSet<number>): MutationBatch[] {\n    // Construct an array of matching batches, sorted by batchID to ensure that\n    // multiple mutations affecting the same document key are applied in order.\n    const result: MutationBatch[] = [];\n    batchIDs.forEach(batchId => {\n      const batch = this.findMutationBatch(batchId);\n      if (batch !== null) {\n        result.push(batch);\n      }\n    });\n    return result;\n  }\n\n  removeMutationBatch(\n    transaction: PersistenceTransaction,\n    batch: MutationBatch\n  ): PersistencePromise<void> {\n    // Find the position of the first batch for removal.\n    const batchIndex = this.indexOfExistingBatchId(batch.batchId, 'removed');\n    hardAssert(\n      batchIndex === 0,\n      'Can only remove the first entry of the mutation queue'\n    );\n    this.mutationQueue.shift();\n\n    let references = this.batchesByDocumentKey;\n    return PersistencePromise.forEach(batch.mutations, (mutation: Mutation) => {\n      const ref = new DocReference(mutation.key, batch.batchId);\n      references = references.delete(ref);\n      return this.referenceDelegate.markPotentiallyOrphaned(\n        transaction,\n        mutation.key\n      );\n    }).next(() => {\n      this.batchesByDocumentKey = references;\n    });\n  }\n\n  removeCachedMutationKeys(batchId: BatchId): void {\n    // No-op since the memory mutation queue does not maintain a separate cache.\n  }\n\n  containsKey(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<boolean> {\n    const ref = new DocReference(key, 0);\n    const firstRef = this.batchesByDocumentKey.firstAfterOrEqual(ref);\n    return PersistencePromise.resolve(key.isEqual(firstRef && firstRef.key));\n  }\n\n  performConsistencyCheck(\n    txn: PersistenceTransaction\n  ): PersistencePromise<void> {\n    if (this.mutationQueue.length === 0) {\n      debugAssert(\n        this.batchesByDocumentKey.isEmpty(),\n        'Document leak -- detected dangling mutation references when queue is empty.'\n      );\n    }\n    return PersistencePromise.resolve();\n  }\n\n  /**\n   * Finds the index of the given batchId in the mutation queue and asserts that\n   * the resulting index is within the bounds of the queue.\n   *\n   * @param batchId The batchId to search for\n   * @param action A description of what the caller is doing, phrased in passive\n   * form (e.g. \"acknowledged\" in a routine that acknowledges batches).\n   */\n  private indexOfExistingBatchId(batchId: BatchId, action: string): number {\n    const index = this.indexOfBatchId(batchId);\n    debugAssert(\n      index >= 0 && index < this.mutationQueue.length,\n      'Batches must exist to be ' + action\n    );\n    return index;\n  }\n\n  /**\n   * Finds the index of the given batchId in the mutation queue. This operation\n   * is O(1).\n   *\n   * @return The computed index of the batch with the given batchId, based on\n   * the state of the queue. Note this index can be negative if the requested\n   * batchId has already been remvoed from the queue or past the end of the\n   * queue if the batchId is larger than the last added batch.\n   */\n  private indexOfBatchId(batchId: BatchId): number {\n    if (this.mutationQueue.length === 0) {\n      // As an index this is past the end of the queue\n      return 0;\n    }\n\n    // Examine the front of the queue to figure out the difference between the\n    // batchId and indexes in the array. Note that since the queue is ordered\n    // by batchId, if the first batch has a larger batchId then the requested\n    // batchId doesn't exist in the queue.\n    const firstBatchId = this.mutationQueue[0].batchId;\n    return batchId - firstBatchId;\n  }\n\n  /**\n   * A version of lookupMutationBatch that doesn't return a promise, this makes\n   * other functions that uses this code easier to read and more efficent.\n   */\n  private findMutationBatch(batchId: BatchId): MutationBatch | null {\n    const index = this.indexOfBatchId(batchId);\n    if (index < 0 || index >= this.mutationQueue.length) {\n      return null;\n    }\n\n    const batch = this.mutationQueue[index];\n    debugAssert(batch.batchId === batchId, 'If found batch must match');\n    return batch;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { isCollectionGroupQuery, Query, queryMatches } from '../core/query';\nimport {\n  DocumentKeySet,\n  DocumentMap,\n  documentMap,\n  DocumentSizeEntry,\n  NullableMaybeDocumentMap,\n  nullableMaybeDocumentMap\n} from '../model/collections';\nimport { Document, MaybeDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { debugAssert } from '../util/assert';\nimport { SortedMap } from '../util/sorted_map';\nimport { IndexManager } from './index_manager';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { RemoteDocumentCache } from './remote_document_cache';\nimport { RemoteDocumentChangeBuffer } from './remote_document_change_buffer';\n\nexport type DocumentSizer = (doc: MaybeDocument) => number;\n\n/** Miscellaneous collection types / constants. */\ninterface MemoryRemoteDocumentCacheEntry extends DocumentSizeEntry {\n  readTime: SnapshotVersion;\n}\n\ntype DocumentEntryMap = SortedMap<DocumentKey, MemoryRemoteDocumentCacheEntry>;\nfunction documentEntryMap(): DocumentEntryMap {\n  return new SortedMap<DocumentKey, MemoryRemoteDocumentCacheEntry>(\n    DocumentKey.comparator\n  );\n}\n\nexport class MemoryRemoteDocumentCache implements RemoteDocumentCache {\n  /** Underlying cache of documents and their read times. */\n  private docs = documentEntryMap();\n\n  /** Size of all cached documents. */\n  private size = 0;\n\n  /**\n   * @param sizer Used to assess the size of a document. For eager GC, this is expected to just\n   * return 0 to avoid unnecessarily doing the work of calculating the size.\n   */\n  constructor(\n    private readonly indexManager: IndexManager,\n    private readonly sizer: DocumentSizer\n  ) {}\n\n  /**\n   * Adds the supplied entry to the cache and updates the cache size as appropriate.\n   *\n   * All calls of `addEntry`  are required to go through the RemoteDocumentChangeBuffer\n   * returned by `newChangeBuffer()`.\n   */\n  private addEntry(\n    transaction: PersistenceTransaction,\n    doc: MaybeDocument,\n    readTime: SnapshotVersion\n  ): PersistencePromise<void> {\n    debugAssert(\n      !readTime.isEqual(SnapshotVersion.min()),\n      'Cannot add a document with a read time of zero'\n    );\n\n    const key = doc.key;\n    const entry = this.docs.get(key);\n    const previousSize = entry ? entry.size : 0;\n    const currentSize = this.sizer(doc);\n\n    this.docs = this.docs.insert(key, {\n      maybeDocument: doc,\n      size: currentSize,\n      readTime\n    });\n\n    this.size += currentSize - previousSize;\n\n    return this.indexManager.addToCollectionParentIndex(\n      transaction,\n      key.path.popLast()\n    );\n  }\n\n  /**\n   * Removes the specified entry from the cache and updates the cache size as appropriate.\n   *\n   * All calls of `removeEntry` are required to go through the RemoteDocumentChangeBuffer\n   * returned by `newChangeBuffer()`.\n   */\n  private removeEntry(documentKey: DocumentKey): void {\n    const entry = this.docs.get(documentKey);\n    if (entry) {\n      this.docs = this.docs.remove(documentKey);\n      this.size -= entry.size;\n    }\n  }\n\n  getEntry(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<MaybeDocument | null> {\n    const entry = this.docs.get(documentKey);\n    return PersistencePromise.resolve(entry ? entry.maybeDocument : null);\n  }\n\n  getEntries(\n    transaction: PersistenceTransaction,\n    documentKeys: DocumentKeySet\n  ): PersistencePromise<NullableMaybeDocumentMap> {\n    let results = nullableMaybeDocumentMap();\n    documentKeys.forEach(documentKey => {\n      const entry = this.docs.get(documentKey);\n      results = results.insert(documentKey, entry ? entry.maybeDocument : null);\n    });\n    return PersistencePromise.resolve(results);\n  }\n\n  getDocumentsMatchingQuery(\n    transaction: PersistenceTransaction,\n    query: Query,\n    sinceReadTime: SnapshotVersion\n  ): PersistencePromise<DocumentMap> {\n    debugAssert(\n      !isCollectionGroupQuery(query),\n      'CollectionGroup queries should be handled in LocalDocumentsView'\n    );\n    let results = documentMap();\n\n    // Documents are ordered by key, so we can use a prefix scan to narrow down\n    // the documents we need to match the query against.\n    const prefix = new DocumentKey(query.path.child(''));\n    const iterator = this.docs.getIteratorFrom(prefix);\n    while (iterator.hasNext()) {\n      const {\n        key,\n        value: { maybeDocument, readTime }\n      } = iterator.getNext();\n      if (!query.path.isPrefixOf(key.path)) {\n        break;\n      }\n      if (readTime.compareTo(sinceReadTime) <= 0) {\n        continue;\n      }\n      if (\n        maybeDocument instanceof Document &&\n        queryMatches(query, maybeDocument)\n      ) {\n        results = results.insert(maybeDocument.key, maybeDocument);\n      }\n    }\n    return PersistencePromise.resolve(results);\n  }\n\n  forEachDocumentKey(\n    transaction: PersistenceTransaction,\n    f: (key: DocumentKey) => PersistencePromise<void>\n  ): PersistencePromise<void> {\n    return PersistencePromise.forEach(this.docs, (key: DocumentKey) => f(key));\n  }\n\n  newChangeBuffer(options?: {\n    trackRemovals: boolean;\n  }): RemoteDocumentChangeBuffer {\n    // `trackRemovals` is ignores since the MemoryRemoteDocumentCache keeps\n    // a separate changelog and does not need special handling for removals.\n    return new MemoryRemoteDocumentCache.RemoteDocumentChangeBuffer(this);\n  }\n\n  getSize(txn: PersistenceTransaction): PersistencePromise<number> {\n    return PersistencePromise.resolve(this.size);\n  }\n\n  /**\n   * Handles the details of adding and updating documents in the MemoryRemoteDocumentCache.\n   */\n  private static RemoteDocumentChangeBuffer = class extends RemoteDocumentChangeBuffer {\n    constructor(private readonly documentCache: MemoryRemoteDocumentCache) {\n      super();\n    }\n\n    protected applyChanges(\n      transaction: PersistenceTransaction\n    ): PersistencePromise<void> {\n      const promises: Array<PersistencePromise<void>> = [];\n      this.changes.forEach((key, doc) => {\n        if (doc) {\n          promises.push(\n            this.documentCache.addEntry(transaction, doc, this.readTime)\n          );\n        } else {\n          this.documentCache.removeEntry(key);\n        }\n      });\n      return PersistencePromise.waitFor(promises);\n    }\n\n    protected getFromCache(\n      transaction: PersistenceTransaction,\n      documentKey: DocumentKey\n    ): PersistencePromise<MaybeDocument | null> {\n      return this.documentCache.getEntry(transaction, documentKey);\n    }\n\n    protected getAllFromCache(\n      transaction: PersistenceTransaction,\n      documentKeys: DocumentKeySet\n    ): PersistencePromise<NullableMaybeDocumentMap> {\n      return this.documentCache.getEntries(transaction, documentKeys);\n    }\n  };\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { TargetIdGenerator } from '../core/target_id_generator';\nimport { ListenSequenceNumber, TargetId } from '../core/types';\nimport { DocumentKeySet } from '../model/collections';\nimport { DocumentKey } from '../model/document_key';\nimport { debugAssert } from '../util/assert';\nimport { ObjectMap } from '../util/obj_map';\n\nimport { ActiveTargets } from './lru_garbage_collector';\nimport { MemoryPersistence } from './memory_persistence';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { ReferenceSet } from './reference_set';\nimport { TargetCache } from './target_cache';\nimport { TargetData } from './target_data';\nimport { canonifyTarget, Target, targetEquals } from '../core/target';\n\nexport class MemoryTargetCache implements TargetCache {\n  /**\n   * Maps a target to the data about that target\n   */\n  private targets = new ObjectMap<Target, TargetData>(\n    t => canonifyTarget(t),\n    targetEquals\n  );\n\n  /** The last received snapshot version. */\n  private lastRemoteSnapshotVersion = SnapshotVersion.min();\n  /** The highest numbered target ID encountered. */\n  private highestTargetId: TargetId = 0;\n  /** The highest sequence number encountered. */\n  private highestSequenceNumber: ListenSequenceNumber = 0;\n  /**\n   * A ordered bidirectional mapping between documents and the remote target\n   * IDs.\n   */\n  private references = new ReferenceSet();\n\n  private targetCount = 0;\n\n  private targetIdGenerator = TargetIdGenerator.forTargetCache();\n\n  constructor(private readonly persistence: MemoryPersistence) {}\n\n  forEachTarget(\n    txn: PersistenceTransaction,\n    f: (q: TargetData) => void\n  ): PersistencePromise<void> {\n    this.targets.forEach((_, targetData) => f(targetData));\n    return PersistencePromise.resolve();\n  }\n\n  getLastRemoteSnapshotVersion(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<SnapshotVersion> {\n    return PersistencePromise.resolve(this.lastRemoteSnapshotVersion);\n  }\n\n  getHighestSequenceNumber(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<ListenSequenceNumber> {\n    return PersistencePromise.resolve(this.highestSequenceNumber);\n  }\n\n  allocateTargetId(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<TargetId> {\n    this.highestTargetId = this.targetIdGenerator.next();\n    return PersistencePromise.resolve(this.highestTargetId);\n  }\n\n  setTargetsMetadata(\n    transaction: PersistenceTransaction,\n    highestListenSequenceNumber: number,\n    lastRemoteSnapshotVersion?: SnapshotVersion\n  ): PersistencePromise<void> {\n    if (lastRemoteSnapshotVersion) {\n      this.lastRemoteSnapshotVersion = lastRemoteSnapshotVersion;\n    }\n    if (highestListenSequenceNumber > this.highestSequenceNumber) {\n      this.highestSequenceNumber = highestListenSequenceNumber;\n    }\n    return PersistencePromise.resolve();\n  }\n\n  private saveTargetData(targetData: TargetData): void {\n    this.targets.set(targetData.target, targetData);\n    const targetId = targetData.targetId;\n    if (targetId > this.highestTargetId) {\n      this.targetIdGenerator = new TargetIdGenerator(targetId);\n      this.highestTargetId = targetId;\n    }\n    if (targetData.sequenceNumber > this.highestSequenceNumber) {\n      this.highestSequenceNumber = targetData.sequenceNumber;\n    }\n  }\n\n  addTargetData(\n    transaction: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    debugAssert(\n      !this.targets.has(targetData.target),\n      'Adding a target that already exists'\n    );\n    this.saveTargetData(targetData);\n    this.targetCount += 1;\n    return PersistencePromise.resolve();\n  }\n\n  updateTargetData(\n    transaction: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    debugAssert(\n      this.targets.has(targetData.target),\n      'Updating a non-existent target'\n    );\n    this.saveTargetData(targetData);\n    return PersistencePromise.resolve();\n  }\n\n  removeTargetData(\n    transaction: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    debugAssert(this.targetCount > 0, 'Removing a target from an empty cache');\n    debugAssert(\n      this.targets.has(targetData.target),\n      'Removing a non-existent target from the cache'\n    );\n    this.targets.delete(targetData.target);\n    this.references.removeReferencesForId(targetData.targetId);\n    this.targetCount -= 1;\n    return PersistencePromise.resolve();\n  }\n\n  removeTargets(\n    transaction: PersistenceTransaction,\n    upperBound: ListenSequenceNumber,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<number> {\n    let count = 0;\n    const removals: Array<PersistencePromise<void>> = [];\n    this.targets.forEach((key, targetData) => {\n      if (\n        targetData.sequenceNumber <= upperBound &&\n        activeTargetIds.get(targetData.targetId) === null\n      ) {\n        this.targets.delete(key);\n        removals.push(\n          this.removeMatchingKeysForTargetId(transaction, targetData.targetId)\n        );\n        count++;\n      }\n    });\n    return PersistencePromise.waitFor(removals).next(() => count);\n  }\n\n  getTargetCount(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<number> {\n    return PersistencePromise.resolve(this.targetCount);\n  }\n\n  getTargetData(\n    transaction: PersistenceTransaction,\n    target: Target\n  ): PersistencePromise<TargetData | null> {\n    const targetData = this.targets.get(target) || null;\n    return PersistencePromise.resolve(targetData);\n  }\n\n  addMatchingKeys(\n    txn: PersistenceTransaction,\n    keys: DocumentKeySet,\n    targetId: TargetId\n  ): PersistencePromise<void> {\n    this.references.addReferences(keys, targetId);\n    return PersistencePromise.resolve();\n  }\n\n  removeMatchingKeys(\n    txn: PersistenceTransaction,\n    keys: DocumentKeySet,\n    targetId: TargetId\n  ): PersistencePromise<void> {\n    this.references.removeReferences(keys, targetId);\n    const referenceDelegate = this.persistence.referenceDelegate;\n    const promises: Array<PersistencePromise<void>> = [];\n    if (referenceDelegate) {\n      keys.forEach(key => {\n        promises.push(referenceDelegate.markPotentiallyOrphaned(txn, key));\n      });\n    }\n    return PersistencePromise.waitFor(promises);\n  }\n\n  removeMatchingKeysForTargetId(\n    txn: PersistenceTransaction,\n    targetId: TargetId\n  ): PersistencePromise<void> {\n    this.references.removeReferencesForId(targetId);\n    return PersistencePromise.resolve();\n  }\n\n  getMatchingKeysForTargetId(\n    txn: PersistenceTransaction,\n    targetId: TargetId\n  ): PersistencePromise<DocumentKeySet> {\n    const matchingKeys = this.references.referencesForId(targetId);\n    return PersistencePromise.resolve(matchingKeys);\n  }\n\n  containsKey(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<boolean> {\n    return PersistencePromise.resolve(this.references.containsKey(key));\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { User } from '../auth/user';\nimport { Document, MaybeDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { fail } from '../util/assert';\nimport { logDebug } from '../util/log';\nimport { ObjectMap } from '../util/obj_map';\nimport { encodeResourcePath } from './encoded_resource_path';\nimport {\n  ActiveTargets,\n  LruDelegate,\n  LruGarbageCollector,\n  LruParams\n} from './lru_garbage_collector';\nimport { ListenSequence } from '../core/listen_sequence';\nimport { ListenSequenceNumber, TargetId } from '../core/types';\nimport { estimateByteSize } from '../model/values';\nimport { MemoryIndexManager } from './memory_index_manager';\nimport { MemoryMutationQueue } from './memory_mutation_queue';\nimport { MemoryRemoteDocumentCache } from './memory_remote_document_cache';\nimport { MemoryTargetCache } from './memory_target_cache';\nimport { MutationQueue } from './mutation_queue';\nimport {\n  Persistence,\n  PersistenceTransaction,\n  PersistenceTransactionMode,\n  ReferenceDelegate\n} from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { ReferenceSet } from './reference_set';\nimport { TargetData } from './target_data';\n\nconst LOG_TAG = 'MemoryPersistence';\n/**\n * A memory-backed instance of Persistence. Data is stored only in RAM and\n * not persisted across sessions.\n */\nexport class MemoryPersistence implements Persistence {\n  /**\n   * Note that these are retained here to make it easier to write tests\n   * affecting both the in-memory and IndexedDB-backed persistence layers. Tests\n   * can create a new LocalStore wrapping this Persistence instance and this\n   * will make the in-memory persistence layer behave as if it were actually\n   * persisting values.\n   */\n  private readonly indexManager: MemoryIndexManager;\n  private mutationQueues: { [user: string]: MemoryMutationQueue } = {};\n  private readonly remoteDocumentCache: MemoryRemoteDocumentCache;\n  private readonly targetCache: MemoryTargetCache;\n  private readonly listenSequence = new ListenSequence(0);\n\n  private _started = false;\n\n  readonly referenceDelegate: MemoryReferenceDelegate;\n\n  /**\n   * The constructor accepts a factory for creating a reference delegate. This\n   * allows both the delegate and this instance to have strong references to\n   * each other without having nullable fields that would then need to be\n   * checked or asserted on every access.\n   */\n  constructor(\n    referenceDelegateFactory: (p: MemoryPersistence) => MemoryReferenceDelegate\n  ) {\n    this._started = true;\n    this.referenceDelegate = referenceDelegateFactory(this);\n    this.targetCache = new MemoryTargetCache(this);\n    const sizer = (doc: MaybeDocument): number =>\n      this.referenceDelegate.documentSize(doc);\n    this.indexManager = new MemoryIndexManager();\n    this.remoteDocumentCache = new MemoryRemoteDocumentCache(\n      this.indexManager,\n      sizer\n    );\n  }\n\n  start(): Promise<void> {\n    return Promise.resolve();\n  }\n\n  shutdown(): Promise<void> {\n    // No durable state to ensure is closed on shutdown.\n    this._started = false;\n    return Promise.resolve();\n  }\n\n  get started(): boolean {\n    return this._started;\n  }\n\n  setDatabaseDeletedListener(): void {\n    // No op.\n  }\n\n  setNetworkEnabled(): void {\n    // No op.\n  }\n\n  getIndexManager(): MemoryIndexManager {\n    return this.indexManager;\n  }\n\n  getMutationQueue(user: User): MutationQueue {\n    let queue = this.mutationQueues[user.toKey()];\n    if (!queue) {\n      queue = new MemoryMutationQueue(\n        this.indexManager,\n        this.referenceDelegate\n      );\n      this.mutationQueues[user.toKey()] = queue;\n    }\n    return queue;\n  }\n\n  getTargetCache(): MemoryTargetCache {\n    return this.targetCache;\n  }\n\n  getRemoteDocumentCache(): MemoryRemoteDocumentCache {\n    return this.remoteDocumentCache;\n  }\n\n  runTransaction<T>(\n    action: string,\n    mode: PersistenceTransactionMode,\n    transactionOperation: (\n      transaction: PersistenceTransaction\n    ) => PersistencePromise<T>\n  ): Promise<T> {\n    logDebug(LOG_TAG, 'Starting transaction:', action);\n    const txn = new MemoryTransaction(this.listenSequence.next());\n    this.referenceDelegate.onTransactionStarted();\n    return transactionOperation(txn)\n      .next(result => {\n        return this.referenceDelegate\n          .onTransactionCommitted(txn)\n          .next(() => result);\n      })\n      .toPromise()\n      .then(result => {\n        txn.raiseOnCommittedEvent();\n        return result;\n      });\n  }\n\n  mutationQueuesContainKey(\n    transaction: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<boolean> {\n    return PersistencePromise.or(\n      Object.values(this.mutationQueues).map(queue => () =>\n        queue.containsKey(transaction, key)\n      )\n    );\n  }\n}\n\n/**\n * Memory persistence is not actually transactional, but future implementations\n * may have transaction-scoped state.\n */\nexport class MemoryTransaction extends PersistenceTransaction {\n  constructor(readonly currentSequenceNumber: ListenSequenceNumber) {\n    super();\n  }\n}\n\nexport interface MemoryReferenceDelegate extends ReferenceDelegate {\n  documentSize(doc: MaybeDocument): number;\n  onTransactionStarted(): void;\n  onTransactionCommitted(txn: PersistenceTransaction): PersistencePromise<void>;\n}\n\nexport class MemoryEagerDelegate implements MemoryReferenceDelegate {\n  /** Tracks all documents that are active in Query views. */\n  private localViewReferences: ReferenceSet = new ReferenceSet();\n  /** The list of documents that are potentially GCed after each transaction. */\n  private _orphanedDocuments: Set<DocumentKey> | null = null;\n\n  private constructor(private readonly persistence: MemoryPersistence) {}\n\n  static factory(persistence: MemoryPersistence): MemoryEagerDelegate {\n    return new MemoryEagerDelegate(persistence);\n  }\n\n  private get orphanedDocuments(): Set<DocumentKey> {\n    if (!this._orphanedDocuments) {\n      throw fail('orphanedDocuments is only valid during a transaction.');\n    } else {\n      return this._orphanedDocuments;\n    }\n  }\n\n  addReference(\n    txn: PersistenceTransaction,\n    targetId: TargetId,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    this.localViewReferences.addReference(key, targetId);\n    this.orphanedDocuments.delete(key);\n    return PersistencePromise.resolve();\n  }\n\n  removeReference(\n    txn: PersistenceTransaction,\n    targetId: TargetId,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    this.localViewReferences.removeReference(key, targetId);\n    this.orphanedDocuments.add(key);\n    return PersistencePromise.resolve();\n  }\n\n  markPotentiallyOrphaned(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    this.orphanedDocuments.add(key);\n    return PersistencePromise.resolve();\n  }\n\n  removeTarget(\n    txn: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    const orphaned = this.localViewReferences.removeReferencesForId(\n      targetData.targetId\n    );\n    orphaned.forEach(key => this.orphanedDocuments.add(key));\n    const cache = this.persistence.getTargetCache();\n    return cache\n      .getMatchingKeysForTargetId(txn, targetData.targetId)\n      .next(keys => {\n        keys.forEach(key => this.orphanedDocuments.add(key));\n      })\n      .next(() => cache.removeTargetData(txn, targetData));\n  }\n\n  onTransactionStarted(): void {\n    this._orphanedDocuments = new Set<DocumentKey>();\n  }\n\n  onTransactionCommitted(\n    txn: PersistenceTransaction\n  ): PersistencePromise<void> {\n    // Remove newly orphaned documents.\n    const cache = this.persistence.getRemoteDocumentCache();\n    const changeBuffer = cache.newChangeBuffer();\n    return PersistencePromise.forEach(\n      this.orphanedDocuments,\n      (key: DocumentKey) => {\n        return this.isReferenced(txn, key).next(isReferenced => {\n          if (!isReferenced) {\n            changeBuffer.removeEntry(key);\n          }\n        });\n      }\n    ).next(() => {\n      this._orphanedDocuments = null;\n      return changeBuffer.apply(txn);\n    });\n  }\n\n  updateLimboDocument(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    return this.isReferenced(txn, key).next(isReferenced => {\n      if (isReferenced) {\n        this.orphanedDocuments.delete(key);\n      } else {\n        this.orphanedDocuments.add(key);\n      }\n    });\n  }\n\n  documentSize(doc: MaybeDocument): number {\n    // For eager GC, we don't care about the document size, there are no size thresholds.\n    return 0;\n  }\n\n  private isReferenced(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<boolean> {\n    return PersistencePromise.or([\n      () =>\n        PersistencePromise.resolve(this.localViewReferences.containsKey(key)),\n      () => this.persistence.getTargetCache().containsKey(txn, key),\n      () => this.persistence.mutationQueuesContainKey(txn, key)\n    ]);\n  }\n}\n\nexport class MemoryLruDelegate implements ReferenceDelegate, LruDelegate {\n  private orphanedSequenceNumbers: ObjectMap<\n    DocumentKey,\n    ListenSequenceNumber\n  > = new ObjectMap(\n    k => encodeResourcePath(k.path),\n    (l, r) => l.isEqual(r)\n  );\n\n  readonly garbageCollector: LruGarbageCollector;\n\n  constructor(\n    private readonly persistence: MemoryPersistence,\n    lruParams: LruParams\n  ) {\n    this.garbageCollector = new LruGarbageCollector(this, lruParams);\n  }\n\n  // No-ops, present so memory persistence doesn't have to care which delegate\n  // it has.\n  onTransactionStarted(): void {}\n\n  onTransactionCommitted(\n    txn: PersistenceTransaction\n  ): PersistencePromise<void> {\n    return PersistencePromise.resolve();\n  }\n\n  forEachTarget(\n    txn: PersistenceTransaction,\n    f: (q: TargetData) => void\n  ): PersistencePromise<void> {\n    return this.persistence.getTargetCache().forEachTarget(txn, f);\n  }\n\n  getSequenceNumberCount(\n    txn: PersistenceTransaction\n  ): PersistencePromise<number> {\n    const docCountPromise = this.orphanedDocumentCount(txn);\n    const targetCountPromise = this.persistence\n      .getTargetCache()\n      .getTargetCount(txn);\n    return targetCountPromise.next(targetCount =>\n      docCountPromise.next(docCount => targetCount + docCount)\n    );\n  }\n\n  private orphanedDocumentCount(\n    txn: PersistenceTransaction\n  ): PersistencePromise<number> {\n    let orphanedCount = 0;\n    return this.forEachOrphanedDocumentSequenceNumber(txn, _ => {\n      orphanedCount++;\n    }).next(() => orphanedCount);\n  }\n\n  forEachOrphanedDocumentSequenceNumber(\n    txn: PersistenceTransaction,\n    f: (sequenceNumber: ListenSequenceNumber) => void\n  ): PersistencePromise<void> {\n    return PersistencePromise.forEach(\n      this.orphanedSequenceNumbers,\n      (key, sequenceNumber) => {\n        // Pass in the exact sequence number as the upper bound so we know it won't be pinned by\n        // being too recent.\n        return this.isPinned(txn, key, sequenceNumber).next(isPinned => {\n          if (!isPinned) {\n            return f(sequenceNumber);\n          } else {\n            return PersistencePromise.resolve();\n          }\n        });\n      }\n    );\n  }\n\n  removeTargets(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<number> {\n    return this.persistence\n      .getTargetCache()\n      .removeTargets(txn, upperBound, activeTargetIds);\n  }\n\n  removeOrphanedDocuments(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber\n  ): PersistencePromise<number> {\n    let count = 0;\n    const cache = this.persistence.getRemoteDocumentCache();\n    const changeBuffer = cache.newChangeBuffer();\n    const p = cache.forEachDocumentKey(txn, key => {\n      return this.isPinned(txn, key, upperBound).next(isPinned => {\n        if (!isPinned) {\n          count++;\n          changeBuffer.removeEntry(key);\n        }\n      });\n    });\n    return p.next(() => changeBuffer.apply(txn)).next(() => count);\n  }\n\n  markPotentiallyOrphaned(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    this.orphanedSequenceNumbers.set(key, txn.currentSequenceNumber);\n    return PersistencePromise.resolve();\n  }\n\n  removeTarget(\n    txn: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    const updated = targetData.withSequenceNumber(txn.currentSequenceNumber);\n    return this.persistence.getTargetCache().updateTargetData(txn, updated);\n  }\n\n  addReference(\n    txn: PersistenceTransaction,\n    targetId: TargetId,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    this.orphanedSequenceNumbers.set(key, txn.currentSequenceNumber);\n    return PersistencePromise.resolve();\n  }\n\n  removeReference(\n    txn: PersistenceTransaction,\n    targetId: TargetId,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    this.orphanedSequenceNumbers.set(key, txn.currentSequenceNumber);\n    return PersistencePromise.resolve();\n  }\n\n  updateLimboDocument(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    this.orphanedSequenceNumbers.set(key, txn.currentSequenceNumber);\n    return PersistencePromise.resolve();\n  }\n\n  documentSize(maybeDoc: MaybeDocument): number {\n    let documentSize = maybeDoc.key.toString().length;\n    if (maybeDoc instanceof Document) {\n      documentSize += estimateByteSize(maybeDoc.toProto());\n    }\n    return documentSize;\n  }\n\n  private isPinned(\n    txn: PersistenceTransaction,\n    key: DocumentKey,\n    upperBound: ListenSequenceNumber\n  ): PersistencePromise<boolean> {\n    return PersistencePromise.or([\n      () => this.persistence.mutationQueuesContainKey(txn, key),\n      () => this.persistence.getTargetCache().containsKey(txn, key),\n      () => {\n        const orphanedAt = this.orphanedSequenceNumbers.get(key);\n        return PersistencePromise.resolve(\n          orphanedAt !== undefined && orphanedAt > upperBound\n        );\n      }\n    ]);\n  }\n\n  getCacheSize(txn: PersistenceTransaction): PersistencePromise<number> {\n    return this.persistence.getRemoteDocumentCache().getSize(txn);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert } from '../util/assert';\nimport { FirestoreError } from '../util/error';\n\nimport { Stream } from './connection';\n\n/**\n * Provides a simple helper class that implements the Stream interface to\n * bridge to other implementations that are streams but do not implement the\n * interface. The stream callbacks are invoked with the callOn... methods.\n */\nexport class StreamBridge<I, O> implements Stream<I, O> {\n  private wrappedOnOpen: (() => void) | undefined;\n  private wrappedOnClose: ((err?: FirestoreError) => void) | undefined;\n  private wrappedOnMessage: ((msg: O) => void) | undefined;\n\n  private sendFn: (msg: I) => void;\n  private closeFn: () => void;\n\n  constructor(args: { sendFn: (msg: I) => void; closeFn: () => void }) {\n    this.sendFn = args.sendFn;\n    this.closeFn = args.closeFn;\n  }\n\n  onOpen(callback: () => void): void {\n    debugAssert(!this.wrappedOnOpen, 'Called onOpen on stream twice!');\n    this.wrappedOnOpen = callback;\n  }\n\n  onClose(callback: (err?: FirestoreError) => void): void {\n    debugAssert(!this.wrappedOnClose, 'Called onClose on stream twice!');\n    this.wrappedOnClose = callback;\n  }\n\n  onMessage(callback: (msg: O) => void): void {\n    debugAssert(!this.wrappedOnMessage, 'Called onMessage on stream twice!');\n    this.wrappedOnMessage = callback;\n  }\n\n  close(): void {\n    this.closeFn();\n  }\n\n  send(msg: I): void {\n    this.sendFn(msg);\n  }\n\n  callOnOpen(): void {\n    debugAssert(\n      this.wrappedOnOpen !== undefined,\n      'Cannot call onOpen because no callback was set'\n    );\n    this.wrappedOnOpen();\n  }\n\n  callOnClose(err?: FirestoreError): void {\n    debugAssert(\n      this.wrappedOnClose !== undefined,\n      'Cannot call onClose because no callback was set'\n    );\n    this.wrappedOnClose(err);\n  }\n\n  callOnMessage(msg: O): void {\n    debugAssert(\n      this.wrappedOnMessage !== undefined,\n      'Cannot call onMessage because no callback was set'\n    );\n    this.wrappedOnMessage(msg);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Token } from '../api/credentials';\nimport { DatabaseId, DatabaseInfo } from '../core/database_info';\nimport { SDK_VERSION } from '../../src/core/version';\nimport { Connection, Stream } from './connection';\nimport { logDebug, logWarn } from '../util/log';\nimport { FirestoreError } from '../util/error';\nimport { StringMap } from '../util/types';\nimport { debugAssert } from '../util/assert';\n\nconst LOG_TAG = 'RestConnection';\n\n/**\n * Maps RPC names to the corresponding REST endpoint name.\n *\n * We use array notation to avoid mangling.\n */\nconst RPC_NAME_URL_MAPPING: StringMap = {};\n\nRPC_NAME_URL_MAPPING['BatchGetDocuments'] = 'batchGet';\nRPC_NAME_URL_MAPPING['Commit'] = 'commit';\nRPC_NAME_URL_MAPPING['RunQuery'] = 'runQuery';\n\nconst RPC_URL_VERSION = 'v1';\nconst X_GOOG_API_CLIENT_VALUE = 'gl-js/ fire/' + SDK_VERSION;\n\n/**\n * Base class for all Rest-based connections to the backend (WebChannel and\n * HTTP).\n */\nexport abstract class RestConnection implements Connection {\n  protected readonly databaseId: DatabaseId;\n  protected readonly baseUrl: string;\n  private readonly databaseRoot: string;\n\n  constructor(private readonly databaseInfo: DatabaseInfo) {\n    this.databaseId = databaseInfo.databaseId;\n    const proto = databaseInfo.ssl ? 'https' : 'http';\n    this.baseUrl = proto + '://' + databaseInfo.host;\n    this.databaseRoot =\n      'projects/' +\n      this.databaseId.projectId +\n      '/databases/' +\n      this.databaseId.database +\n      '/documents';\n  }\n\n  invokeRPC<Req, Resp>(\n    rpcName: string,\n    path: string,\n    req: Req,\n    token: Token | null\n  ): Promise<Resp> {\n    const url = this.makeUrl(rpcName, path);\n    logDebug(LOG_TAG, 'Sending: ', url, req);\n\n    const headers = {};\n    this.modifyHeadersForRequest(headers, token);\n\n    return this.performRPCRequest<Req, Resp>(rpcName, url, headers, req).then(\n      response => {\n        logDebug(LOG_TAG, 'Received: ', response);\n        return response;\n      },\n      (err: FirestoreError) => {\n        logWarn(\n          LOG_TAG,\n          `${rpcName} failed with error: `,\n          err,\n          'url: ',\n          url,\n          'request:',\n          req\n        );\n        throw err;\n      }\n    );\n  }\n\n  invokeStreamingRPC<Req, Resp>(\n    rpcName: string,\n    path: string,\n    request: Req,\n    token: Token | null\n  ): Promise<Resp[]> {\n    // The REST API automatically aggregates all of the streamed results, so we\n    // can just use the normal invoke() method.\n    return this.invokeRPC<Req, Resp[]>(rpcName, path, request, token);\n  }\n\n  abstract openStream<Req, Resp>(\n    rpcName: string,\n    token: Token | null\n  ): Stream<Req, Resp>;\n\n  /**\n   * Modifies the headers for a request, adding any authorization token if\n   * present and any additional headers for the request.\n   */\n  protected modifyHeadersForRequest(\n    headers: StringMap,\n    token: Token | null\n  ): void {\n    headers['X-Goog-Api-Client'] = X_GOOG_API_CLIENT_VALUE;\n\n    // Content-Type: text/plain will avoid preflight requests which might\n    // mess with CORS and redirects by proxies. If we add custom headers\n    // we will need to change this code to potentially use the $httpOverwrite\n    // parameter supported by ESF to avoid\ttriggering preflight requests.\n    headers['Content-Type'] = 'text/plain';\n\n    if (token) {\n      for (const header in token.authHeaders) {\n        if (token.authHeaders.hasOwnProperty(header)) {\n          headers[header] = token.authHeaders[header];\n        }\n      }\n    }\n  }\n\n  /**\n   * Performs an RPC request using an implementation specific networking layer.\n   */\n  protected abstract performRPCRequest<Req, Resp>(\n    rpcName: string,\n    url: string,\n    headers: StringMap,\n    body: Req\n  ): Promise<Resp>;\n\n  private makeUrl<Req>(rpcName: string, path: string): string {\n    const urlRpcName = RPC_NAME_URL_MAPPING[rpcName];\n    debugAssert(\n      urlRpcName !== undefined,\n      'Unknown REST mapping for: ' + rpcName\n    );\n    return `${this.baseUrl}/${RPC_URL_VERSION}/${path}:${urlRpcName}`;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  createWebChannelTransport,\n  ErrorCode,\n  EventType,\n  WebChannel,\n  WebChannelError,\n  WebChannelOptions,\n  XhrIo\n} from '@firebase/webchannel-wrapper';\n\nimport {\n  isBrowserExtension,\n  isElectron,\n  isIE,\n  isMobileCordova,\n  isReactNative,\n  isUWP\n} from '@firebase/util';\n\nimport { Token } from '../../api/credentials';\nimport { DatabaseInfo } from '../../core/database_info';\nimport { Stream } from '../../remote/connection';\nimport {\n  mapCodeFromRpcStatus,\n  mapCodeFromHttpResponseErrorStatus\n} from '../../remote/rpc_error';\nimport { StreamBridge } from '../../remote/stream_bridge';\nimport { fail, hardAssert } from '../../util/assert';\nimport { Code, FirestoreError } from '../../util/error';\nimport { logDebug, logWarn } from '../../util/log';\nimport { Rejecter, Resolver } from '../../util/promise';\nimport { StringMap } from '../../util/types';\nimport { RestConnection } from '../../remote/rest_connection';\n\nconst LOG_TAG = 'Connection';\n\nconst RPC_STREAM_SERVICE = 'google.firestore.v1.Firestore';\n\nconst XHR_TIMEOUT_SECS = 15;\n\nexport class WebChannelConnection extends RestConnection {\n  private readonly forceLongPolling: boolean;\n\n  constructor(info: DatabaseInfo) {\n    super(info);\n    this.forceLongPolling = info.forceLongPolling;\n  }\n\n  protected performRPCRequest<Req, Resp>(\n    rpcName: string,\n    url: string,\n    headers: StringMap,\n    body: Req\n  ): Promise<Resp> {\n    return new Promise((resolve: Resolver<Resp>, reject: Rejecter) => {\n      const xhr = new XhrIo();\n      xhr.listenOnce(EventType.COMPLETE, () => {\n        try {\n          switch (xhr.getLastErrorCode()) {\n            case ErrorCode.NO_ERROR:\n              const json = xhr.getResponseJson() as Resp;\n              logDebug(LOG_TAG, 'XHR received:', JSON.stringify(json));\n              resolve(json);\n              break;\n            case ErrorCode.TIMEOUT:\n              logDebug(LOG_TAG, 'RPC \"' + rpcName + '\" timed out');\n              reject(\n                new FirestoreError(Code.DEADLINE_EXCEEDED, 'Request time out')\n              );\n              break;\n            case ErrorCode.HTTP_ERROR:\n              const status = xhr.getStatus();\n              logDebug(\n                LOG_TAG,\n                'RPC \"' + rpcName + '\" failed with status:',\n                status,\n                'response text:',\n                xhr.getResponseText()\n              );\n              if (status > 0) {\n                const responseError = (xhr.getResponseJson() as WebChannelError)\n                  .error;\n                if (\n                  !!responseError &&\n                  !!responseError.status &&\n                  !!responseError.message\n                ) {\n                  const firestoreErrorCode = mapCodeFromHttpResponseErrorStatus(\n                    responseError.status\n                  );\n                  reject(\n                    new FirestoreError(\n                      firestoreErrorCode,\n                      responseError.message\n                    )\n                  );\n                } else {\n                  reject(\n                    new FirestoreError(\n                      Code.UNKNOWN,\n                      'Server responded with status ' + xhr.getStatus()\n                    )\n                  );\n                }\n              } else {\n                // If we received an HTTP_ERROR but there's no status code,\n                // it's most probably a connection issue\n                reject(\n                  new FirestoreError(Code.UNAVAILABLE, 'Connection failed.')\n                );\n              }\n              break;\n            default:\n              fail(\n                'RPC \"' +\n                  rpcName +\n                  '\" failed with unanticipated ' +\n                  'webchannel error ' +\n                  xhr.getLastErrorCode() +\n                  ': ' +\n                  xhr.getLastError() +\n                  ', giving up.'\n              );\n          }\n        } finally {\n          logDebug(LOG_TAG, 'RPC \"' + rpcName + '\" completed.');\n        }\n      });\n\n      const requestString = JSON.stringify(body);\n      xhr.send(url, 'POST', requestString, headers, XHR_TIMEOUT_SECS);\n    });\n  }\n\n  openStream<Req, Resp>(\n    rpcName: string,\n    token: Token | null\n  ): Stream<Req, Resp> {\n    const urlParts = [\n      this.baseUrl,\n      '/',\n      RPC_STREAM_SERVICE,\n      '/',\n      rpcName,\n      '/channel'\n    ];\n    const webchannelTransport = createWebChannelTransport();\n    const request: WebChannelOptions = {\n      // Required for backend stickiness, routing behavior is based on this\n      // parameter.\n      httpSessionIdParam: 'gsessionid',\n      initMessageHeaders: {},\n      messageUrlParams: {\n        // This param is used to improve routing and project isolation by the\n        // backend and must be included in every request.\n        database: `projects/${this.databaseId.projectId}/databases/${this.databaseId.database}`\n      },\n      sendRawJson: true,\n      supportsCrossDomainXhr: true,\n      internalChannelParams: {\n        // Override the default timeout (randomized between 10-20 seconds) since\n        // a large write batch on a slow internet connection may take a long\n        // time to send to the backend. Rather than have WebChannel impose a\n        // tight timeout which could lead to infinite timeouts and retries, we\n        // set it very large (5-10 minutes) and rely on the browser's builtin\n        // timeouts to kick in if the request isn't working.\n        forwardChannelRequestTimeoutMs: 10 * 60 * 1000\n      },\n      forceLongPolling: this.forceLongPolling\n    };\n\n    this.modifyHeadersForRequest(request.initMessageHeaders!, token);\n\n    // Sending the custom headers we just added to request.initMessageHeaders\n    // (Authorization, etc.) will trigger the browser to make a CORS preflight\n    // request because the XHR will no longer meet the criteria for a \"simple\"\n    // CORS request:\n    // https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS#Simple_requests\n    //\n    // Therefore to avoid the CORS preflight request (an extra network\n    // roundtrip), we use the httpHeadersOverwriteParam option to specify that\n    // the headers should instead be encoded into a special \"$httpHeaders\" query\n    // parameter, which is recognized by the webchannel backend. This is\n    // formally defined here:\n    // https://github.com/google/closure-library/blob/b0e1815b13fb92a46d7c9b3c30de5d6a396a3245/closure/goog/net/rpc/httpcors.js#L32\n    //\n    // TODO(b/145624756): There is a backend bug where $httpHeaders isn't respected if the request\n    // doesn't have an Origin header. So we have to exclude a few browser environments that are\n    // known to (sometimes) not include an Origin. See\n    // https://github.com/firebase/firebase-js-sdk/issues/1491.\n    if (\n      !isMobileCordova() &&\n      !isReactNative() &&\n      !isElectron() &&\n      !isIE() &&\n      !isUWP() &&\n      !isBrowserExtension()\n    ) {\n      request.httpHeadersOverwriteParam = '$httpHeaders';\n    }\n\n    const url = urlParts.join('');\n    logDebug(LOG_TAG, 'Creating WebChannel: ' + url, request);\n    const channel = webchannelTransport.createWebChannel(url, request);\n\n    // WebChannel supports sending the first message with the handshake - saving\n    // a network round trip. However, it will have to call send in the same\n    // JS event loop as open. In order to enforce this, we delay actually\n    // opening the WebChannel until send is called. Whether we have called\n    // open is tracked with this variable.\n    let opened = false;\n\n    // A flag to determine whether the stream was closed (by us or through an\n    // error/close event) to avoid delivering multiple close events or sending\n    // on a closed stream\n    let closed = false;\n\n    const streamBridge = new StreamBridge<Req, Resp>({\n      sendFn: (msg: Req) => {\n        if (!closed) {\n          if (!opened) {\n            logDebug(LOG_TAG, 'Opening WebChannel transport.');\n            channel.open();\n            opened = true;\n          }\n          logDebug(LOG_TAG, 'WebChannel sending:', msg);\n          channel.send(msg);\n        } else {\n          logDebug(LOG_TAG, 'Not sending because WebChannel is closed:', msg);\n        }\n      },\n      closeFn: () => channel.close()\n    });\n\n    // Closure events are guarded and exceptions are swallowed, so catch any\n    // exception and rethrow using a setTimeout so they become visible again.\n    // Note that eventually this function could go away if we are confident\n    // enough the code is exception free.\n    const unguardedEventListen = <T>(\n      type: string,\n      fn: (param?: T) => void\n    ): void => {\n      // TODO(dimond): closure typing seems broken because WebChannel does\n      // not implement goog.events.Listenable\n      channel.listen(type, (param: unknown) => {\n        try {\n          fn(param as T);\n        } catch (e) {\n          setTimeout(() => {\n            throw e;\n          }, 0);\n        }\n      });\n    };\n\n    unguardedEventListen(WebChannel.EventType.OPEN, () => {\n      if (!closed) {\n        logDebug(LOG_TAG, 'WebChannel transport opened.');\n      }\n    });\n\n    unguardedEventListen(WebChannel.EventType.CLOSE, () => {\n      if (!closed) {\n        closed = true;\n        logDebug(LOG_TAG, 'WebChannel transport closed');\n        streamBridge.callOnClose();\n      }\n    });\n\n    unguardedEventListen<Error>(WebChannel.EventType.ERROR, err => {\n      if (!closed) {\n        closed = true;\n        logWarn(LOG_TAG, 'WebChannel transport errored:', err);\n        streamBridge.callOnClose(\n          new FirestoreError(\n            Code.UNAVAILABLE,\n            'The operation could not be completed'\n          )\n        );\n      }\n    });\n\n    // WebChannel delivers message events as array. If batching is not enabled\n    // (it's off by default) each message will be delivered alone, resulting in\n    // a single element array.\n    interface WebChannelResponse {\n      data: Resp[];\n    }\n\n    unguardedEventListen<WebChannelResponse>(\n      WebChannel.EventType.MESSAGE,\n      msg => {\n        if (!closed) {\n          const msgData = msg!.data[0];\n          hardAssert(!!msgData, 'Got a webchannel message without data.');\n          // TODO(b/35143891): There is a bug in One Platform that caused errors\n          // (and only errors) to be wrapped in an extra array. To be forward\n          // compatible with the bug we need to check either condition. The latter\n          // can be removed once the fix has been rolled out.\n          // Use any because msgData.error is not typed.\n          const msgDataOrError: WebChannelError | object = msgData;\n          const error =\n            msgDataOrError.error ||\n            (msgDataOrError as WebChannelError[])[0]?.error;\n          if (error) {\n            logDebug(LOG_TAG, 'WebChannel received error:', error);\n            // error.status will be a string like 'OK' or 'NOT_FOUND'.\n            const status: string = error.status;\n            let code = mapCodeFromRpcStatus(status);\n            let message = error.message;\n            if (code === undefined) {\n              code = Code.INTERNAL;\n              message =\n                'Unknown error status: ' +\n                status +\n                ' with message ' +\n                error.message;\n            }\n            // Mark closed so no further events are propagated\n            closed = true;\n            streamBridge.callOnClose(new FirestoreError(code, message));\n            channel.close();\n          } else {\n            logDebug(LOG_TAG, 'WebChannel received:', msgData);\n            streamBridge.callOnMessage(msgData);\n          }\n        }\n      }\n    );\n\n    setTimeout(() => {\n      // Technically we could/should wait for the WebChannel opened event,\n      // but because we want to send the first message with the WebChannel\n      // handshake we pretend the channel opened here (asynchronously), and\n      // then delay the actual open until the first message is sent.\n      streamBridge.callOnOpen();\n    }, 0);\n    return streamBridge;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { logDebug } from '../../util/log';\nimport {\n  ConnectivityMonitor,\n  ConnectivityMonitorCallback,\n  NetworkStatus\n} from '../../remote/connectivity_monitor';\n\n// References to `window` are guarded by BrowserConnectivityMonitor.isAvailable()\n/* eslint-disable no-restricted-globals */\n\nconst LOG_TAG = 'ConnectivityMonitor';\n\n/**\n * Browser implementation of ConnectivityMonitor.\n */\nexport class BrowserConnectivityMonitor implements ConnectivityMonitor {\n  private readonly networkAvailableListener = (): void =>\n    this.onNetworkAvailable();\n  private readonly networkUnavailableListener = (): void =>\n    this.onNetworkUnavailable();\n  private callbacks: ConnectivityMonitorCallback[] = [];\n\n  constructor() {\n    this.configureNetworkMonitoring();\n  }\n\n  addCallback(callback: (status: NetworkStatus) => void): void {\n    this.callbacks.push(callback);\n  }\n\n  shutdown(): void {\n    window.removeEventListener('online', this.networkAvailableListener);\n    window.removeEventListener('offline', this.networkUnavailableListener);\n  }\n\n  private configureNetworkMonitoring(): void {\n    window.addEventListener('online', this.networkAvailableListener);\n    window.addEventListener('offline', this.networkUnavailableListener);\n  }\n\n  private onNetworkAvailable(): void {\n    logDebug(LOG_TAG, 'Network connectivity changed: AVAILABLE');\n    for (const callback of this.callbacks) {\n      callback(NetworkStatus.AVAILABLE);\n    }\n  }\n\n  private onNetworkUnavailable(): void {\n    logDebug(LOG_TAG, 'Network connectivity changed: UNAVAILABLE');\n    for (const callback of this.callbacks) {\n      callback(NetworkStatus.UNAVAILABLE);\n    }\n  }\n\n  // TODO(chenbrian): Consider passing in window either into this component or\n  // here for testing via FakeWindow.\n  /** Checks that all used attributes of window are available. */\n  static isAvailable(): boolean {\n    return (\n      typeof window !== 'undefined' &&\n      window.addEventListener !== undefined &&\n      window.removeEventListener !== undefined\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ConnectivityMonitor, NetworkStatus } from './connectivity_monitor';\n\nexport class NoopConnectivityMonitor implements ConnectivityMonitor {\n  addCallback(callback: (status: NetworkStatus) => void): void {\n    // No-op.\n  }\n\n  shutdown(): void {\n    // No-op.\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/** Return the Platform-specific serializer monitor. */\nimport { DatabaseId } from '../../core/database_info';\nimport { JsonProtoSerializer } from '../../remote/serializer';\n\nexport function newSerializer(databaseId: DatabaseId): JsonProtoSerializer {\n  return new JsonProtoSerializer(databaseId, /* useProto3Json= */ true);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ClientId,\n  MemorySharedClientState,\n  SharedClientState,\n  WebStorageSharedClientState\n} from '../local/shared_client_state';\nimport {\n  LocalStore,\n  newLocalStore,\n  synchronizeLastDocumentChangeReadTime\n} from '../local/local_store';\nimport {\n  applyActiveTargetsChange,\n  applyBatchState,\n  applyPrimaryState,\n  applyTargetState,\n  getActiveClients,\n  newSyncEngine,\n  SyncEngine\n} from './sync_engine';\nimport { RemoteStore } from '../remote/remote_store';\nimport { EventManager } from './event_manager';\nimport { AsyncQueue } from '../util/async_queue';\nimport { DatabaseId, DatabaseInfo } from './database_info';\nimport { Datastore, newDatastore } from '../remote/datastore';\nimport { User } from '../auth/user';\nimport { PersistenceSettings } from './firestore_client';\nimport { debugAssert } from '../util/assert';\nimport { GarbageCollectionScheduler, Persistence } from '../local/persistence';\nimport { Code, FirestoreError } from '../util/error';\nimport { OnlineStateSource } from './types';\nimport { LruParams, LruScheduler } from '../local/lru_garbage_collector';\nimport { IndexFreeQueryEngine } from '../local/index_free_query_engine';\nimport {\n  indexedDbStoragePrefix,\n  IndexedDbPersistence,\n  indexedDbClearPersistence\n} from '../local/indexeddb_persistence';\nimport {\n  MemoryEagerDelegate,\n  MemoryPersistence\n} from '../local/memory_persistence';\nimport { newConnection, newConnectivityMonitor } from '../platform/connection';\nimport { newSerializer } from '../platform/serializer';\nimport { getDocument, getWindow } from '../platform/dom';\nimport { CredentialsProvider } from '../api/credentials';\n\nconst MEMORY_ONLY_PERSISTENCE_ERROR_MESSAGE =\n  'You are using the memory-only build of Firestore. Persistence support is ' +\n  'only available via the @firebase/firestore bundle or the ' +\n  'firebase-firestore.js build.';\n\nexport interface ComponentConfiguration {\n  asyncQueue: AsyncQueue;\n  databaseInfo: DatabaseInfo;\n  credentials: CredentialsProvider;\n  clientId: ClientId;\n  initialUser: User;\n  maxConcurrentLimboResolutions: number;\n  persistenceSettings: PersistenceSettings;\n}\n\n/**\n * Initializes and wires components that are needed to interface with the local\n * cache. Implementations override `initialize()` to provide all components.\n */\nexport interface OfflineComponentProvider {\n  persistence: Persistence;\n  sharedClientState: SharedClientState;\n  localStore: LocalStore;\n  gcScheduler: GarbageCollectionScheduler | null;\n\n  initialize(cfg: ComponentConfiguration): Promise<void>;\n\n  terminate(): Promise<void>;\n\n  clearPersistence(\n    databaseId: DatabaseId,\n    persistenceKey: string\n  ): Promise<void>;\n}\n\n/**\n * Provides all components needed for Firestore with in-memory persistence.\n * Uses EagerGC garbage collection.\n */\nexport class MemoryOfflineComponentProvider\n  implements OfflineComponentProvider {\n  persistence!: Persistence;\n  sharedClientState!: SharedClientState;\n  localStore!: LocalStore;\n  gcScheduler!: GarbageCollectionScheduler | null;\n\n  async initialize(cfg: ComponentConfiguration): Promise<void> {\n    this.sharedClientState = this.createSharedClientState(cfg);\n    this.persistence = this.createPersistence(cfg);\n    await this.persistence.start();\n    this.gcScheduler = this.createGarbageCollectionScheduler(cfg);\n    this.localStore = this.createLocalStore(cfg);\n  }\n\n  createGarbageCollectionScheduler(\n    cfg: ComponentConfiguration\n  ): GarbageCollectionScheduler | null {\n    return null;\n  }\n\n  createLocalStore(cfg: ComponentConfiguration): LocalStore {\n    return newLocalStore(\n      this.persistence,\n      new IndexFreeQueryEngine(),\n      cfg.initialUser\n    );\n  }\n\n  createPersistence(cfg: ComponentConfiguration): Persistence {\n    if (cfg.persistenceSettings.durable) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        MEMORY_ONLY_PERSISTENCE_ERROR_MESSAGE\n      );\n    }\n    return new MemoryPersistence(MemoryEagerDelegate.factory);\n  }\n\n  createSharedClientState(cfg: ComponentConfiguration): SharedClientState {\n    return new MemorySharedClientState();\n  }\n\n  async terminate(): Promise<void> {\n    if (this.gcScheduler) {\n      this.gcScheduler.stop();\n    }\n    await this.sharedClientState.shutdown();\n    await this.persistence.shutdown();\n  }\n\n  clearPersistence(\n    databaseId: DatabaseId,\n    persistenceKey: string\n  ): Promise<void> {\n    throw new FirestoreError(\n      Code.FAILED_PRECONDITION,\n      MEMORY_ONLY_PERSISTENCE_ERROR_MESSAGE\n    );\n  }\n}\n\n/**\n * Provides all components needed for Firestore with IndexedDB persistence.\n */\nexport class IndexedDbOfflineComponentProvider extends MemoryOfflineComponentProvider {\n  persistence!: IndexedDbPersistence;\n  sharedClientState!: SharedClientState;\n  localStore!: LocalStore;\n  gcScheduler!: GarbageCollectionScheduler | null;\n\n  async initialize(cfg: ComponentConfiguration): Promise<void> {\n    await super.initialize(cfg);\n    await synchronizeLastDocumentChangeReadTime(this.localStore);\n  }\n\n  createGarbageCollectionScheduler(\n    cfg: ComponentConfiguration\n  ): GarbageCollectionScheduler | null {\n    const garbageCollector = this.persistence.referenceDelegate\n      .garbageCollector;\n    return new LruScheduler(garbageCollector, cfg.asyncQueue);\n  }\n\n  createPersistence(cfg: ComponentConfiguration): IndexedDbPersistence {\n    debugAssert(\n      cfg.persistenceSettings.durable,\n      'Can only start durable persistence'\n    );\n\n    const persistenceKey = indexedDbStoragePrefix(\n      cfg.databaseInfo.databaseId,\n      cfg.databaseInfo.persistenceKey\n    );\n    const serializer = newSerializer(cfg.databaseInfo.databaseId);\n    return new IndexedDbPersistence(\n      cfg.persistenceSettings.synchronizeTabs,\n      persistenceKey,\n      cfg.clientId,\n      LruParams.withCacheSize(cfg.persistenceSettings.cacheSizeBytes),\n      cfg.asyncQueue,\n      getWindow(),\n      getDocument(),\n      serializer,\n      this.sharedClientState,\n      cfg.persistenceSettings.forceOwningTab\n    );\n  }\n\n  createSharedClientState(cfg: ComponentConfiguration): SharedClientState {\n    return new MemorySharedClientState();\n  }\n\n  clearPersistence(\n    databaseId: DatabaseId,\n    persistenceKey: string\n  ): Promise<void> {\n    return indexedDbClearPersistence(\n      indexedDbStoragePrefix(databaseId, persistenceKey)\n    );\n  }\n}\n\n/**\n * Provides all components needed for Firestore with multi-tab IndexedDB\n * persistence.\n *\n * In the legacy client, this provider is used to provide both multi-tab and\n * non-multi-tab persistence since we cannot tell at build time whether\n * `synchronizeTabs` will be enabled.\n */\nexport class MultiTabOfflineComponentProvider extends IndexedDbOfflineComponentProvider {\n  constructor(\n    private readonly onlineComponentProvider: OnlineComponentProvider\n  ) {\n    super();\n  }\n\n  async initialize(cfg: ComponentConfiguration): Promise<void> {\n    await super.initialize(cfg);\n\n    await this.onlineComponentProvider.initialize(this, cfg);\n    const syncEngine = this.onlineComponentProvider.syncEngine;\n\n    if (this.sharedClientState instanceof WebStorageSharedClientState) {\n      this.sharedClientState.syncEngine = {\n        applyBatchState: applyBatchState.bind(null, syncEngine),\n        applyTargetState: applyTargetState.bind(null, syncEngine),\n        applyActiveTargetsChange: applyActiveTargetsChange.bind(\n          null,\n          syncEngine\n        ),\n        getActiveClients: getActiveClients.bind(null, syncEngine)\n      };\n      await this.sharedClientState.start();\n    }\n\n    // NOTE: This will immediately call the listener, so we make sure to\n    // set it after localStore / remoteStore are started.\n    await this.persistence.setPrimaryStateListener(async isPrimary => {\n      await applyPrimaryState(\n        this.onlineComponentProvider.syncEngine,\n        isPrimary\n      );\n      if (this.gcScheduler) {\n        if (isPrimary && !this.gcScheduler.started) {\n          this.gcScheduler.start(this.localStore);\n        } else if (!isPrimary) {\n          this.gcScheduler.stop();\n        }\n      }\n    });\n  }\n\n  createSharedClientState(cfg: ComponentConfiguration): SharedClientState {\n    if (\n      cfg.persistenceSettings.durable &&\n      cfg.persistenceSettings.synchronizeTabs\n    ) {\n      const window = getWindow();\n      if (!WebStorageSharedClientState.isAvailable(window)) {\n        throw new FirestoreError(\n          Code.UNIMPLEMENTED,\n          'IndexedDB persistence is only available on platforms that support LocalStorage.'\n        );\n      }\n      const persistenceKey = indexedDbStoragePrefix(\n        cfg.databaseInfo.databaseId,\n        cfg.databaseInfo.persistenceKey\n      );\n      return new WebStorageSharedClientState(\n        window,\n        cfg.asyncQueue,\n        persistenceKey,\n        cfg.clientId,\n        cfg.initialUser\n      );\n    }\n    return new MemorySharedClientState();\n  }\n}\n\n/**\n * Initializes and wires the components that are needed to interface with the\n * network.\n */\nexport class OnlineComponentProvider {\n  protected localStore!: LocalStore;\n  protected sharedClientState!: SharedClientState;\n  datastore!: Datastore;\n  eventManager!: EventManager;\n  remoteStore!: RemoteStore;\n  syncEngine!: SyncEngine;\n\n  async initialize(\n    offlineComponentProvider: OfflineComponentProvider,\n    cfg: ComponentConfiguration\n  ): Promise<void> {\n    if (this.localStore) {\n      // OnlineComponentProvider may get initialized multiple times if\n      // multi-tab persistence is used.\n      return;\n    }\n\n    this.localStore = offlineComponentProvider.localStore;\n    this.sharedClientState = offlineComponentProvider.sharedClientState;\n    this.datastore = this.createDatastore(cfg);\n    this.remoteStore = this.createRemoteStore(cfg);\n    this.syncEngine = this.createSyncEngine(cfg);\n    this.eventManager = this.createEventManager(cfg);\n\n    this.sharedClientState.onlineStateHandler = onlineState =>\n      this.syncEngine.applyOnlineStateChange(\n        onlineState,\n        OnlineStateSource.SharedClientState\n      );\n\n    this.remoteStore.syncEngine = this.syncEngine;\n\n    await this.remoteStore.start();\n    await this.remoteStore.applyPrimaryState(this.syncEngine.isPrimaryClient);\n  }\n\n  createEventManager(cfg: ComponentConfiguration): EventManager {\n    return new EventManager(this.syncEngine);\n  }\n\n  createDatastore(cfg: ComponentConfiguration): Datastore {\n    const serializer = newSerializer(cfg.databaseInfo.databaseId);\n    const connection = newConnection(cfg.databaseInfo);\n    return newDatastore(cfg.credentials, connection, serializer);\n  }\n\n  createRemoteStore(cfg: ComponentConfiguration): RemoteStore {\n    return new RemoteStore(\n      this.localStore,\n      this.datastore,\n      cfg.asyncQueue,\n      onlineState =>\n        this.syncEngine.applyOnlineStateChange(\n          onlineState,\n          OnlineStateSource.RemoteStore\n        ),\n      newConnectivityMonitor()\n    );\n  }\n\n  createSyncEngine(cfg: ComponentConfiguration): SyncEngine {\n    return newSyncEngine(\n      this.localStore,\n      this.remoteStore,\n      this.datastore,\n      this.sharedClientState,\n      cfg.initialUser,\n      cfg.maxConcurrentLimboResolutions,\n      !cfg.persistenceSettings.durable ||\n        !cfg.persistenceSettings.synchronizeTabs\n    );\n  }\n\n  terminate(): Promise<void> {\n    return this.remoteStore.shutdown();\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { WebChannelConnection } from './webchannel_connection';\nimport { DatabaseInfo } from '../../core/database_info';\nimport { Connection } from '../../remote/connection';\nimport { ConnectivityMonitor } from '../../remote/connectivity_monitor';\nimport { BrowserConnectivityMonitor } from './connectivity_monitor';\nimport { NoopConnectivityMonitor } from '../../remote/connectivity_monitor_noop';\n\n/** Initializes the WebChannelConnection for the browser. */\nexport function newConnection(databaseInfo: DatabaseInfo): Connection {\n  return new WebChannelConnection(databaseInfo);\n}\n\n/** Return the Platform-specific connectivity monitor. */\nexport function newConnectivityMonitor(): ConnectivityMonitor {\n  if (BrowserConnectivityMonitor.isAvailable()) {\n    return new BrowserConnectivityMonitor();\n  } else {\n    return new NoopConnectivityMonitor();\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { JsonObject } from '../model/object_value';\n\n/**\n * Observer/Subscribe interfaces.\n */\nexport type NextFn<T> = (value: T) => void;\nexport type ErrorFn = (error: Error) => void;\nexport type CompleteFn = () => void;\n\n// Allow for any of the Observer methods to be undefined.\nexport interface PartialObserver<T> {\n  next?: NextFn<T>;\n  error?: ErrorFn;\n  complete?: CompleteFn;\n}\n\nexport interface Unsubscribe {\n  (): void;\n}\n\nexport function isPartialObserver(obj: unknown): boolean {\n  return implementsAnyMethods(obj, ['next', 'error', 'complete']);\n}\n\n/**\n * Returns true if obj is an object and contains at least one of the specified\n * methods.\n */\nfunction implementsAnyMethods(obj: unknown, methods: string[]): boolean {\n  if (typeof obj !== 'object' || obj === null) {\n    return false;\n  }\n\n  const object = obj as JsonObject<unknown>;\n  for (const method of methods) {\n    if (method in object && typeof object[method] === 'function') {\n      return true;\n    }\n  }\n  return false;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Observer } from '../core/event_manager';\nimport { EventHandler } from './misc';\n\n/*\n * A wrapper implementation of Observer<T> that will dispatch events\n * asynchronously. To allow immediate silencing, a mute call is added which\n * causes events scheduled to no longer be raised.\n */\nexport class AsyncObserver<T> implements Observer<T> {\n  /**\n   * When set to true, will not raise future events. Necessary to deal with\n   * async detachment of listener.\n   */\n  private muted = false;\n\n  constructor(private observer: Partial<Observer<T>>) {}\n\n  next(value: T): void {\n    if (this.observer.next) {\n      this.scheduleEvent(this.observer.next, value);\n    }\n  }\n\n  error(error: Error): void {\n    if (this.observer.error) {\n      this.scheduleEvent(this.observer.error, error);\n    } else {\n      console.error('Uncaught Error in snapshot listener:', error);\n    }\n  }\n\n  mute(): void {\n    this.muted = true;\n  }\n\n  private scheduleEvent<E>(eventHandler: EventHandler<E>, event: E): void {\n    if (!this.muted) {\n      setTimeout(() => {\n        if (!this.muted) {\n          eventHandler(event);\n        }\n      }, 0);\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { fail } from './assert';\nimport { Code, FirestoreError } from './error';\nimport { Dict, forEach } from './obj';\nimport { DocumentKey } from '../model/document_key';\nimport { ResourcePath } from '../model/path';\n\n/** Types accepted by validateType() and related methods for validation. */\nexport type ValidationType =\n  | 'undefined'\n  | 'object'\n  | 'function'\n  | 'boolean'\n  | 'number'\n  | 'string'\n  | 'non-empty string';\n\n/**\n * Validates that no arguments were passed in the invocation of functionName.\n *\n * Forward the magic \"arguments\" variable as second parameter on which the\n * parameter validation is performed:\n * validateNoArgs('myFunction', arguments);\n */\nexport function validateNoArgs(functionName: string, args: IArguments): void {\n  if (args.length !== 0) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() does not support arguments, ` +\n        'but was called with ' +\n        formatPlural(args.length, 'argument') +\n        '.'\n    );\n  }\n}\n\n/**\n * Validates the invocation of functionName has the exact number of arguments.\n *\n * Forward the magic \"arguments\" variable as second parameter on which the\n * parameter validation is performed:\n * validateExactNumberOfArgs('myFunction', arguments, 2);\n */\nexport function validateExactNumberOfArgs(\n  functionName: string,\n  args: ArrayLike<unknown>,\n  numberOfArgs: number\n): void {\n  if (args.length !== numberOfArgs) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires ` +\n        formatPlural(numberOfArgs, 'argument') +\n        ', but was called with ' +\n        formatPlural(args.length, 'argument') +\n        '.'\n    );\n  }\n}\n\n/**\n * Validates the invocation of functionName has at least the provided number of\n * arguments (but can have many more).\n *\n * Forward the magic \"arguments\" variable as second parameter on which the\n * parameter validation is performed:\n * validateAtLeastNumberOfArgs('myFunction', arguments, 2);\n */\nexport function validateAtLeastNumberOfArgs(\n  functionName: string,\n  args: IArguments,\n  minNumberOfArgs: number\n): void {\n  if (args.length < minNumberOfArgs) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires at least ` +\n        formatPlural(minNumberOfArgs, 'argument') +\n        ', but was called with ' +\n        formatPlural(args.length, 'argument') +\n        '.'\n    );\n  }\n}\n\n/**\n * Validates the invocation of functionName has number of arguments between\n * the values provided.\n *\n * Forward the magic \"arguments\" variable as second parameter on which the\n * parameter validation is performed:\n * validateBetweenNumberOfArgs('myFunction', arguments, 2, 3);\n */\nexport function validateBetweenNumberOfArgs(\n  functionName: string,\n  args: IArguments,\n  minNumberOfArgs: number,\n  maxNumberOfArgs: number\n): void {\n  if (args.length < minNumberOfArgs || args.length > maxNumberOfArgs) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires between ${minNumberOfArgs} and ` +\n        `${maxNumberOfArgs} arguments, but was called with ` +\n        formatPlural(args.length, 'argument') +\n        '.'\n    );\n  }\n}\n\n/**\n * Validates the provided argument is an array and has as least the expected\n * number of elements.\n */\nexport function validateNamedArrayAtLeastNumberOfElements<T>(\n  functionName: string,\n  value: T[],\n  name: string,\n  minNumberOfElements: number\n): void {\n  if (!(value instanceof Array) || value.length < minNumberOfElements) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires its ${name} argument to be an ` +\n        'array with at least ' +\n        `${formatPlural(minNumberOfElements, 'element')}.`\n    );\n  }\n}\n\n/**\n * Validates the provided positional argument has the native JavaScript type\n * using typeof checks.\n */\nexport function validateArgType(\n  functionName: string,\n  type: ValidationType,\n  position: number,\n  argument: unknown\n): void {\n  validateType(functionName, type, `${ordinal(position)} argument`, argument);\n}\n\n/**\n * Validates the provided argument has the native JavaScript type using\n * typeof checks or is undefined.\n */\nexport function validateOptionalArgType(\n  functionName: string,\n  type: ValidationType,\n  position: number,\n  argument: unknown\n): void {\n  if (argument !== undefined) {\n    validateArgType(functionName, type, position, argument);\n  }\n}\n\n/**\n * Validates the provided named option has the native JavaScript type using\n * typeof checks.\n */\nexport function validateNamedType(\n  functionName: string,\n  type: ValidationType,\n  optionName: string,\n  argument: unknown\n): void {\n  validateType(functionName, type, `${optionName} option`, argument);\n}\n\n/**\n * Validates the provided named option has the native JavaScript type using\n * typeof checks or is undefined.\n */\nexport function validateNamedOptionalType(\n  functionName: string,\n  type: ValidationType,\n  optionName: string,\n  argument: unknown\n): void {\n  if (argument !== undefined) {\n    validateNamedType(functionName, type, optionName, argument);\n  }\n}\n\nexport function validateArrayElements<T>(\n  functionName: string,\n  optionName: string,\n  typeDescription: string,\n  argument: T[],\n  validator: (arg0: T) => boolean\n): void {\n  if (!(argument instanceof Array)) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires its ${optionName} ` +\n        `option to be an array, but it was: ${valueDescription(argument)}`\n    );\n  }\n\n  for (let i = 0; i < argument.length; ++i) {\n    if (!validator(argument[i])) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Function ${functionName}() requires all ${optionName} ` +\n          `elements to be ${typeDescription}, but the value at index ${i} ` +\n          `was: ${valueDescription(argument[i])}`\n      );\n    }\n  }\n}\n\nexport function validateOptionalArrayElements<T>(\n  functionName: string,\n  optionName: string,\n  typeDescription: string,\n  argument: T[] | undefined,\n  validator: (arg0: T) => boolean\n): void {\n  if (argument !== undefined) {\n    validateArrayElements(\n      functionName,\n      optionName,\n      typeDescription,\n      argument,\n      validator\n    );\n  }\n}\n\n/**\n * Validates that the provided named option equals one of the expected values.\n */\nexport function validateNamedPropertyEquals<T>(\n  functionName: string,\n  inputName: string,\n  optionName: string,\n  input: T,\n  expected: T[]\n): void {\n  const expectedDescription: string[] = [];\n\n  for (const val of expected) {\n    if (val === input) {\n      return;\n    }\n    expectedDescription.push(valueDescription(val));\n  }\n\n  const actualDescription = valueDescription(input);\n  throw new FirestoreError(\n    Code.INVALID_ARGUMENT,\n    `Invalid value ${actualDescription} provided to function ${functionName}() for option ` +\n      `\"${optionName}\". Acceptable values: ${expectedDescription.join(', ')}`\n  );\n}\n\n/**\n * Validates that the provided named option equals one of the expected values or\n * is undefined.\n */\nexport function validateNamedOptionalPropertyEquals<T>(\n  functionName: string,\n  inputName: string,\n  optionName: string,\n  input: T,\n  expected: T[]\n): void {\n  if (input !== undefined) {\n    validateNamedPropertyEquals(\n      functionName,\n      inputName,\n      optionName,\n      input,\n      expected\n    );\n  }\n}\n\n/**\n * Validates that the provided argument is a valid enum.\n *\n * @param functionName Function making the validation call.\n * @param enums Array containing all possible values for the enum.\n * @param position Position of the argument in `functionName`.\n * @param argument Argument to validate.\n * @return The value as T if the argument can be converted.\n */\nexport function validateStringEnum<T>(\n  functionName: string,\n  enums: T[],\n  position: number,\n  argument: unknown\n): T {\n  if (!enums.some(element => element === argument)) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Invalid value ${valueDescription(argument)} provided to function ` +\n        `${functionName}() for its ${ordinal(position)} argument. Acceptable ` +\n        `values: ${enums.join(', ')}`\n    );\n  }\n  return argument as T;\n}\n\n/**\n * Validates that `path` refers to a document (indicated by the fact it contains\n * an even numbers of segments).\n */\nexport function validateDocumentPath(path: ResourcePath): void {\n  if (!DocumentKey.isDocumentKey(path)) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Invalid document reference. Document references must have an even number of segments, but ${path} has ${path.length}.`\n    );\n  }\n}\n\n/**\n * Validates that `path` refers to a collection (indicated by the fact it\n * contains an odd numbers of segments).\n */\nexport function validateCollectionPath(path: ResourcePath): void {\n  if (DocumentKey.isDocumentKey(path)) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Invalid collection reference. Collection references must have an odd number of segments, but ${path} has ${path.length}.`\n    );\n  }\n}\n\n/** Helper to validate the type of a provided input. */\nfunction validateType(\n  functionName: string,\n  type: ValidationType,\n  inputName: string,\n  input: unknown\n): void {\n  let valid = false;\n  if (type === 'object') {\n    valid = isPlainObject(input);\n  } else if (type === 'non-empty string') {\n    valid = typeof input === 'string' && input !== '';\n  } else {\n    valid = typeof input === type;\n  }\n\n  if (!valid) {\n    const description = valueDescription(input);\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires its ${inputName} ` +\n        `to be of type ${type}, but it was: ${description}`\n    );\n  }\n}\n\n/**\n * Returns true if it's a non-null object without a custom prototype\n * (i.e. excludes Array, Date, etc.).\n */\nexport function isPlainObject(input: unknown): boolean {\n  return (\n    typeof input === 'object' &&\n    input !== null &&\n    (Object.getPrototypeOf(input) === Object.prototype ||\n      Object.getPrototypeOf(input) === null)\n  );\n}\n\n/** Returns a string describing the type / value of the provided input. */\nexport function valueDescription(input: unknown): string {\n  if (input === undefined) {\n    return 'undefined';\n  } else if (input === null) {\n    return 'null';\n  } else if (typeof input === 'string') {\n    if (input.length > 20) {\n      input = `${input.substring(0, 20)}...`;\n    }\n    return JSON.stringify(input);\n  } else if (typeof input === 'number' || typeof input === 'boolean') {\n    return '' + input;\n  } else if (typeof input === 'object') {\n    if (input instanceof Array) {\n      return 'an array';\n    } else {\n      const customObjectName = tryGetCustomObjectType(input!);\n      if (customObjectName) {\n        return `a custom ${customObjectName} object`;\n      } else {\n        return 'an object';\n      }\n    }\n  } else if (typeof input === 'function') {\n    return 'a function';\n  } else {\n    return fail('Unknown wrong type: ' + typeof input);\n  }\n}\n\n/** Hacky method to try to get the constructor name for an object. */\nexport function tryGetCustomObjectType(input: object): string | null {\n  if (input.constructor) {\n    const funcNameRegex = /function\\s+([^\\s(]+)\\s*\\(/;\n    const results = funcNameRegex.exec(input.constructor.toString());\n    if (results && results.length > 1) {\n      return results[1];\n    }\n  }\n  return null;\n}\n\n/** Validates the provided argument is defined. */\nexport function validateDefined(\n  functionName: string,\n  position: number,\n  argument: unknown\n): void {\n  if (argument === undefined) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires a valid ${ordinal(position)} ` +\n        `argument, but it was undefined.`\n    );\n  }\n}\n\n/**\n * Validates the provided positional argument is an object, and its keys and\n * values match the expected keys and types provided in optionTypes.\n */\nexport function validateOptionNames(\n  functionName: string,\n  options: object,\n  optionNames: string[]\n): void {\n  forEach(options as Dict<unknown>, (key, _) => {\n    if (optionNames.indexOf(key) < 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Unknown option '${key}' passed to function ${functionName}(). ` +\n          'Available options: ' +\n          optionNames.join(', ')\n      );\n    }\n  });\n}\n\n/**\n * Helper method to throw an error that the provided argument did not pass\n * an instanceof check.\n */\nexport function invalidClassError(\n  functionName: string,\n  type: string,\n  position: number,\n  argument: unknown\n): Error {\n  const description = valueDescription(argument);\n  return new FirestoreError(\n    Code.INVALID_ARGUMENT,\n    `Function ${functionName}() requires its ${ordinal(position)} ` +\n      `argument to be a ${type}, but it was: ${description}`\n  );\n}\n\nexport function validatePositiveNumber(\n  functionName: string,\n  position: number,\n  n: number\n): void {\n  if (n <= 0) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires its ${ordinal(\n        position\n      )} argument to be a positive number, but it was: ${n}.`\n    );\n  }\n}\n\n/** Converts a number to its english word representation */\nfunction ordinal(num: number): string {\n  switch (num) {\n    case 1:\n      return 'first';\n    case 2:\n      return 'second';\n    case 3:\n      return 'third';\n    default:\n      return num + 'th';\n  }\n}\n\n/**\n * Formats the given word as plural conditionally given the preceding number.\n */\nfunction formatPlural(num: number, str: string): string {\n  return `${num} ${str}` + (num === 1 ? '' : 's');\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { isBase64Available } from '../platform/base64';\nimport { Code, FirestoreError } from '../util/error';\nimport {\n  invalidClassError,\n  validateArgType,\n  validateExactNumberOfArgs\n} from '../util/input_validation';\nimport { ByteString } from '../util/byte_string';\n\n/** Helper function to assert Uint8Array is available at runtime. */\nfunction assertUint8ArrayAvailable(): void {\n  if (typeof Uint8Array === 'undefined') {\n    throw new FirestoreError(\n      Code.UNIMPLEMENTED,\n      'Uint8Arrays are not available in this environment.'\n    );\n  }\n}\n\n/** Helper function to assert Base64 functions are available at runtime. */\nfunction assertBase64Available(): void {\n  if (!isBase64Available()) {\n    throw new FirestoreError(\n      Code.UNIMPLEMENTED,\n      'Blobs are unavailable in Firestore in this environment.'\n    );\n  }\n}\n\n/**\n * Immutable class holding a blob (binary data).\n * This class is directly exposed in the public API.\n *\n * Note that while you can't hide the constructor in JavaScript code, we are\n * using the hack above to make sure no-one outside this module can call it.\n */\nexport class Blob {\n  // Prefix with underscore to signal that we consider this not part of the\n  // public API and to prevent it from showing up for autocompletion.\n  _byteString: ByteString;\n\n  constructor(byteString: ByteString) {\n    assertBase64Available();\n    this._byteString = byteString;\n  }\n\n  static fromBase64String(base64: string): Blob {\n    validateExactNumberOfArgs('Blob.fromBase64String', arguments, 1);\n    validateArgType('Blob.fromBase64String', 'string', 1, base64);\n    assertBase64Available();\n    try {\n      return new Blob(ByteString.fromBase64String(base64));\n    } catch (e) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Failed to construct Blob from Base64 string: ' + e\n      );\n    }\n  }\n\n  static fromUint8Array(array: Uint8Array): Blob {\n    validateExactNumberOfArgs('Blob.fromUint8Array', arguments, 1);\n    assertUint8ArrayAvailable();\n    if (!(array instanceof Uint8Array)) {\n      throw invalidClassError('Blob.fromUint8Array', 'Uint8Array', 1, array);\n    }\n    return new Blob(ByteString.fromUint8Array(array));\n  }\n\n  toBase64(): string {\n    validateExactNumberOfArgs('Blob.toBase64', arguments, 0);\n    assertBase64Available();\n    return this._byteString.toBase64();\n  }\n\n  toUint8Array(): Uint8Array {\n    validateExactNumberOfArgs('Blob.toUint8Array', arguments, 0);\n    assertUint8ArrayAvailable();\n    return this._byteString.toUint8Array();\n  }\n\n  toString(): string {\n    return 'Blob(base64: ' + this.toBase64() + ')';\n  }\n\n  isEqual(other: Blob): boolean {\n    return this._byteString.isEqual(other._byteString);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as firestore from '@firebase/firestore-types';\n\nimport { FieldPath as InternalFieldPath } from '../model/path';\nimport { Code, FirestoreError } from '../util/error';\nimport {\n  invalidClassError,\n  validateArgType,\n  validateNamedArrayAtLeastNumberOfElements\n} from '../util/input_validation';\n\n// The objects that are a part of this API are exposed to third-parties as\n// compiled javascript so we want to flag our private members with a leading\n// underscore to discourage their use.\n\n/**\n * A field class base class that is shared by the lite, full and legacy SDK,\n * which supports shared code that deals with FieldPaths.\n */\nexport abstract class BaseFieldPath {\n  /** Internal representation of a Firestore field path. */\n  readonly _internalPath: InternalFieldPath;\n\n  constructor(fieldNames: string[]) {\n    validateNamedArrayAtLeastNumberOfElements(\n      'FieldPath',\n      fieldNames,\n      'fieldNames',\n      1\n    );\n\n    for (let i = 0; i < fieldNames.length; ++i) {\n      validateArgType('FieldPath', 'string', i, fieldNames[i]);\n      if (fieldNames[i].length === 0) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `Invalid field name at argument $(i + 1). ` +\n            'Field names must not be empty.'\n        );\n      }\n    }\n\n    this._internalPath = new InternalFieldPath(fieldNames);\n  }\n}\n\n/**\n * A FieldPath refers to a field in a document. The path may consist of a single\n * field name (referring to a top-level field in the document), or a list of\n * field names (referring to a nested field in the document).\n */\nexport class FieldPath extends BaseFieldPath implements firestore.FieldPath {\n  /**\n   * Creates a FieldPath from the provided field names. If more than one field\n   * name is provided, the path will point to a nested field in a document.\n   *\n   * @param fieldNames A list of field names.\n   */\n  constructor(...fieldNames: string[]) {\n    super(fieldNames);\n  }\n\n  static documentId(): FieldPath {\n    /**\n     * Internal Note: The backend doesn't technically support querying by\n     * document ID. Instead it queries by the entire document name (full path\n     * included), but in the cases we currently support documentId(), the net\n     * effect is the same.\n     */\n    return new FieldPath(InternalFieldPath.keyField().canonicalString());\n  }\n\n  isEqual(other: firestore.FieldPath): boolean {\n    if (!(other instanceof FieldPath)) {\n      throw invalidClassError('isEqual', 'FieldPath', 1, other);\n    }\n    return this._internalPath.isEqual(other._internalPath);\n  }\n}\n\n/**\n * Matches any characters in a field path string that are reserved.\n */\nconst RESERVED = new RegExp('[~\\\\*/\\\\[\\\\]]');\n\n/**\n * Parses a field path string into a FieldPath, treating dots as separators.\n */\nexport function fromDotSeparatedString(path: string): FieldPath {\n  const found = path.search(RESERVED);\n  if (found >= 0) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Invalid field path (${path}). Paths must not contain ` +\n        `'~', '*', '/', '[', or ']'`\n    );\n  }\n  try {\n    return new FieldPath(...path.split('.'));\n  } catch (e) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Invalid field path (${path}). Paths must not be empty, ` +\n        `begin with '.', end with '.', or contain '..'`\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as firestore from '@firebase/firestore-types';\nimport {\n  validateArgType,\n  validateAtLeastNumberOfArgs,\n  validateExactNumberOfArgs,\n  validateNoArgs\n} from '../util/input_validation';\nimport { FieldTransform } from '../model/mutation';\nimport {\n  ArrayRemoveTransformOperation,\n  ArrayUnionTransformOperation,\n  NumericIncrementTransformOperation,\n  ServerTimestampTransform\n} from '../model/transform_operation';\nimport { ParseContext, parseData, UserDataSource } from './user_data_reader';\nimport { debugAssert } from '../util/assert';\nimport { toNumber } from '../remote/serializer';\n\n/**\n * An opaque base class for FieldValue sentinel objects in our public API that\n * is shared between the full, lite and legacy SDK.\n */\nexport abstract class SerializableFieldValue {\n  /** The public API endpoint that returns this class. */\n  abstract readonly _methodName: string;\n\n  /** A pointer to the implementing class. */\n  readonly _delegate: SerializableFieldValue = this;\n\n  abstract _toFieldTransform(context: ParseContext): FieldTransform | null;\n\n  abstract isEqual(other: SerializableFieldValue): boolean;\n}\n\nexport class DeleteFieldValueImpl extends SerializableFieldValue {\n  constructor(readonly _methodName: string) {\n    super();\n  }\n\n  _toFieldTransform(context: ParseContext): null {\n    if (context.dataSource === UserDataSource.MergeSet) {\n      // No transform to add for a delete, but we need to add it to our\n      // fieldMask so it gets deleted.\n      context.fieldMask.push(context.path!);\n    } else if (context.dataSource === UserDataSource.Update) {\n      debugAssert(\n        context.path!.length > 0,\n        `${this._methodName}() at the top level should have already ` +\n          'been handled.'\n      );\n      throw context.createError(\n        `${this._methodName}() can only appear at the top level ` +\n          'of your update data'\n      );\n    } else {\n      // We shouldn't encounter delete sentinels for queries or non-merge set() calls.\n      throw context.createError(\n        `${this._methodName}() cannot be used with set() unless you pass ` +\n          '{merge:true}'\n      );\n    }\n    return null;\n  }\n\n  isEqual(other: FieldValue): boolean {\n    return other instanceof DeleteFieldValueImpl;\n  }\n}\n\n/**\n * Creates a child context for parsing SerializableFieldValues.\n *\n * This is different than calling `ParseContext.contextWith` because it keeps\n * the fieldTransforms and fieldMask separate.\n *\n * The created context has its `dataSource` set to `UserDataSource.Argument`.\n * Although these values are used with writes, any elements in these FieldValues\n * are not considered writes since they cannot contain any FieldValue sentinels,\n * etc.\n *\n * @param fieldValue The sentinel FieldValue for which to create a child\n *     context.\n * @param context The parent context.\n * @param arrayElement Whether or not the FieldValue has an array.\n */\nfunction createSentinelChildContext(\n  fieldValue: SerializableFieldValue,\n  context: ParseContext,\n  arrayElement: boolean\n): ParseContext {\n  return new ParseContext(\n    {\n      dataSource: UserDataSource.Argument,\n      targetDoc: context.settings.targetDoc,\n      methodName: fieldValue._methodName,\n      arrayElement\n    },\n    context.databaseId,\n    context.serializer,\n    context.ignoreUndefinedProperties\n  );\n}\n\nexport class ServerTimestampFieldValueImpl extends SerializableFieldValue {\n  constructor(readonly _methodName: string) {\n    super();\n  }\n\n  _toFieldTransform(context: ParseContext): FieldTransform {\n    return new FieldTransform(context.path!, new ServerTimestampTransform());\n  }\n\n  isEqual(other: FieldValue): boolean {\n    return other instanceof ServerTimestampFieldValueImpl;\n  }\n}\n\nexport class ArrayUnionFieldValueImpl extends SerializableFieldValue {\n  constructor(\n    readonly _methodName: string,\n    private readonly _elements: unknown[]\n  ) {\n    super();\n  }\n\n  _toFieldTransform(context: ParseContext): FieldTransform {\n    const parseContext = createSentinelChildContext(\n      this,\n      context,\n      /*array=*/ true\n    );\n    const parsedElements = this._elements.map(\n      element => parseData(element, parseContext)!\n    );\n    const arrayUnion = new ArrayUnionTransformOperation(parsedElements);\n    return new FieldTransform(context.path!, arrayUnion);\n  }\n\n  isEqual(other: FieldValue): boolean {\n    // TODO(mrschmidt): Implement isEquals\n    return this === other;\n  }\n}\n\nexport class ArrayRemoveFieldValueImpl extends SerializableFieldValue {\n  constructor(readonly _methodName: string, readonly _elements: unknown[]) {\n    super();\n  }\n\n  _toFieldTransform(context: ParseContext): FieldTransform {\n    const parseContext = createSentinelChildContext(\n      this,\n      context,\n      /*array=*/ true\n    );\n    const parsedElements = this._elements.map(\n      element => parseData(element, parseContext)!\n    );\n    const arrayUnion = new ArrayRemoveTransformOperation(parsedElements);\n    return new FieldTransform(context.path!, arrayUnion);\n  }\n\n  isEqual(other: FieldValue): boolean {\n    // TODO(mrschmidt): Implement isEquals\n    return this === other;\n  }\n}\n\nexport class NumericIncrementFieldValueImpl extends SerializableFieldValue {\n  constructor(readonly _methodName: string, private readonly _operand: number) {\n    super();\n  }\n\n  _toFieldTransform(context: ParseContext): FieldTransform {\n    const numericIncrement = new NumericIncrementTransformOperation(\n      context.serializer,\n      toNumber(context.serializer, this._operand)\n    );\n    return new FieldTransform(context.path!, numericIncrement);\n  }\n\n  isEqual(other: FieldValue): boolean {\n    // TODO(mrschmidt): Implement isEquals\n    return this === other;\n  }\n}\n\n/** The public FieldValue class of the lite API. */\nexport abstract class FieldValue extends SerializableFieldValue\n  implements firestore.FieldValue {\n  protected constructor() {\n    super();\n  }\n\n  static delete(): firestore.FieldValue {\n    validateNoArgs('FieldValue.delete', arguments);\n    return new FieldValueDelegate(\n      new DeleteFieldValueImpl('FieldValue.delete')\n    );\n  }\n\n  static serverTimestamp(): firestore.FieldValue {\n    validateNoArgs('FieldValue.serverTimestamp', arguments);\n    return new FieldValueDelegate(\n      new ServerTimestampFieldValueImpl('FieldValue.serverTimestamp')\n    );\n  }\n\n  static arrayUnion(...elements: unknown[]): firestore.FieldValue {\n    validateAtLeastNumberOfArgs('FieldValue.arrayUnion', arguments, 1);\n    // NOTE: We don't actually parse the data until it's used in set() or\n    // update() since we'd need the Firestore instance to do this.\n    return new FieldValueDelegate(\n      new ArrayUnionFieldValueImpl('FieldValue.arrayUnion', elements)\n    );\n  }\n\n  static arrayRemove(...elements: unknown[]): firestore.FieldValue {\n    validateAtLeastNumberOfArgs('FieldValue.arrayRemove', arguments, 1);\n    // NOTE: We don't actually parse the data until it's used in set() or\n    // update() since we'd need the Firestore instance to do this.\n    return new FieldValueDelegate(\n      new ArrayRemoveFieldValueImpl('FieldValue.arrayRemove', elements)\n    );\n  }\n\n  static increment(n: number): firestore.FieldValue {\n    validateArgType('FieldValue.increment', 'number', 1, n);\n    validateExactNumberOfArgs('FieldValue.increment', arguments, 1);\n    return new FieldValueDelegate(\n      new NumericIncrementFieldValueImpl('FieldValue.increment', n)\n    );\n  }\n}\n\n/**\n * A delegate class that allows the FieldValue implementations returned by\n * deleteField(), serverTimestamp(), arrayUnion(), arrayRemove() and\n * increment() to be an instance of the legacy FieldValue class declared above.\n *\n * We don't directly subclass `FieldValue` in the various field value\n * implementations as the base FieldValue class differs between the lite, full\n * and legacy SDK.\n */\nclass FieldValueDelegate extends FieldValue implements firestore.FieldValue {\n  readonly _methodName: string;\n\n  constructor(readonly _delegate: SerializableFieldValue) {\n    super();\n    this._methodName = _delegate._methodName;\n  }\n\n  _toFieldTransform(context: ParseContext): FieldTransform | null {\n    return this._delegate._toFieldTransform(context);\n  }\n\n  isEqual(other: firestore.FieldValue): boolean {\n    if (!(other instanceof FieldValueDelegate)) {\n      return false;\n    }\n    return this._delegate.isEqual(other._delegate);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Code, FirestoreError } from '../util/error';\nimport {\n  validateArgType,\n  validateExactNumberOfArgs\n} from '../util/input_validation';\nimport { primitiveComparator } from '../util/misc';\n\n/**\n * Immutable class representing a geo point as latitude-longitude pair.\n * This class is directly exposed in the public API, including its constructor.\n */\nexport class GeoPoint {\n  // Prefix with underscore to signal this is a private variable in JS and\n  // prevent it showing up for autocompletion when typing latitude or longitude.\n  private _lat: number;\n  private _long: number;\n\n  constructor(latitude: number, longitude: number) {\n    validateExactNumberOfArgs('GeoPoint', arguments, 2);\n    validateArgType('GeoPoint', 'number', 1, latitude);\n    validateArgType('GeoPoint', 'number', 2, longitude);\n    if (!isFinite(latitude) || latitude < -90 || latitude > 90) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Latitude must be a number between -90 and 90, but was: ' + latitude\n      );\n    }\n    if (!isFinite(longitude) || longitude < -180 || longitude > 180) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Longitude must be a number between -180 and 180, but was: ' + longitude\n      );\n    }\n\n    this._lat = latitude;\n    this._long = longitude;\n  }\n\n  /**\n   * Returns the latitude of this geo point, a number between -90 and 90.\n   */\n  get latitude(): number {\n    return this._lat;\n  }\n\n  /**\n   * Returns the longitude of this geo point, a number between -180 and 180.\n   */\n  get longitude(): number {\n    return this._long;\n  }\n\n  isEqual(other: GeoPoint): boolean {\n    return this._lat === other._lat && this._long === other._long;\n  }\n\n  /**\n   * Actually private to JS consumers of our API, so this function is prefixed\n   * with an underscore.\n   */\n  _compareTo(other: GeoPoint): number {\n    return (\n      primitiveComparator(this._lat, other._lat) ||\n      primitiveComparator(this._long, other._long)\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as firestore from '@firebase/firestore-types';\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { Timestamp } from './timestamp';\nimport { DatabaseId } from '../core/database_info';\nimport { DocumentKey } from '../model/document_key';\nimport {\n  FieldMask,\n  FieldTransform,\n  Mutation,\n  PatchMutation,\n  Precondition,\n  SetMutation,\n  TransformMutation\n} from '../model/mutation';\nimport { FieldPath } from '../model/path';\nimport { debugAssert, fail } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { isPlainObject, valueDescription } from '../util/input_validation';\nimport { Dict, forEach, isEmpty } from '../util/obj';\nimport { ObjectValue, ObjectValueBuilder } from '../model/object_value';\nimport {\n  JsonProtoSerializer,\n  toBytes,\n  toNumber,\n  toResourceName,\n  toTimestamp\n} from '../remote/serializer';\nimport { Blob } from './blob';\nimport { BaseFieldPath, fromDotSeparatedString } from './field_path';\nimport { DeleteFieldValueImpl, SerializableFieldValue } from './field_value';\nimport { GeoPoint } from './geo_point';\nimport { newSerializer } from '../platform/serializer';\n\nconst RESERVED_FIELD_REGEX = /^__.*__$/;\n\n/**\n * An untyped Firestore Data Converter interface that is shared between the\n * lite, full and legacy SDK.\n */\nexport interface UntypedFirestoreDataConverter<T> {\n  toFirestore(modelObject: T): firestore.DocumentData;\n  toFirestore(\n    modelObject: Partial<T>,\n    options: firestore.SetOptions\n  ): firestore.DocumentData;\n  fromFirestore(snapshot: unknown, options?: unknown): T;\n}\n\n/**\n * A reference to a document in a Firebase project.\n *\n * This class serves as a common base class for the public DocumentReferences\n * exposed in the lite, full and legacy SDK.\n */\nexport class DocumentKeyReference<T> {\n  constructor(\n    readonly _databaseId: DatabaseId,\n    readonly _key: DocumentKey,\n    readonly _converter: UntypedFirestoreDataConverter<T> | null\n  ) {}\n}\n\n/** The result of parsing document data (e.g. for a setData call). */\nexport class ParsedSetData {\n  constructor(\n    readonly data: ObjectValue,\n    readonly fieldMask: FieldMask | null,\n    readonly fieldTransforms: FieldTransform[]\n  ) {}\n\n  toMutations(key: DocumentKey, precondition: Precondition): Mutation[] {\n    const mutations = [] as Mutation[];\n    if (this.fieldMask !== null) {\n      mutations.push(\n        new PatchMutation(key, this.data, this.fieldMask, precondition)\n      );\n    } else {\n      mutations.push(new SetMutation(key, this.data, precondition));\n    }\n    if (this.fieldTransforms.length > 0) {\n      mutations.push(new TransformMutation(key, this.fieldTransforms));\n    }\n    return mutations;\n  }\n}\n\n/** The result of parsing \"update\" data (i.e. for an updateData call). */\nexport class ParsedUpdateData {\n  constructor(\n    readonly data: ObjectValue,\n    readonly fieldMask: FieldMask,\n    readonly fieldTransforms: FieldTransform[]\n  ) {}\n\n  toMutations(key: DocumentKey, precondition: Precondition): Mutation[] {\n    const mutations = [\n      new PatchMutation(key, this.data, this.fieldMask, precondition)\n    ] as Mutation[];\n    if (this.fieldTransforms.length > 0) {\n      mutations.push(new TransformMutation(key, this.fieldTransforms));\n    }\n    return mutations;\n  }\n}\n\n/*\n * Represents what type of API method provided the data being parsed; useful\n * for determining which error conditions apply during parsing and providing\n * better error messages.\n */\nexport const enum UserDataSource {\n  Set,\n  Update,\n  MergeSet,\n  /**\n   * Indicates the source is a where clause, cursor bound, arrayUnion()\n   * element, etc. Of note, isWrite(source) will return false.\n   */\n  Argument,\n  /**\n   * Indicates that the source is an Argument that may directly contain nested\n   * arrays (e.g. the operand of an `in` query).\n   */\n  ArrayArgument\n}\n\nfunction isWrite(dataSource: UserDataSource): boolean {\n  switch (dataSource) {\n    case UserDataSource.Set: // fall through\n    case UserDataSource.MergeSet: // fall through\n    case UserDataSource.Update:\n      return true;\n    case UserDataSource.Argument:\n    case UserDataSource.ArrayArgument:\n      return false;\n    default:\n      throw fail(`Unexpected case for UserDataSource: ${dataSource}`);\n  }\n}\n\n/** Contains the settings that are mutated as we parse user data. */\ninterface ContextSettings {\n  /** Indicates what kind of API method this data came from. */\n  readonly dataSource: UserDataSource;\n  /** The name of the method the user called to create the ParseContext. */\n  readonly methodName: string;\n  /** The document the user is attempting to modify, if that applies. */\n  readonly targetDoc?: DocumentKey;\n  /**\n   * A path within the object being parsed. This could be an empty path (in\n   * which case the context represents the root of the data being parsed), or a\n   * nonempty path (indicating the context represents a nested location within\n   * the data).\n   */\n  readonly path?: FieldPath;\n  /**\n   * Whether or not this context corresponds to an element of an array.\n   * If not set, elements are treated as if they were outside of arrays.\n   */\n  readonly arrayElement?: boolean;\n  /**\n   * Whether or not a converter was specified in this context. If true, error\n   * messages will reference the converter when invalid data is provided.\n   */\n  readonly hasConverter?: boolean;\n}\n\n/** A \"context\" object passed around while parsing user data. */\nexport class ParseContext {\n  readonly fieldTransforms: FieldTransform[];\n  readonly fieldMask: FieldPath[];\n  /**\n   * Initializes a ParseContext with the given source and path.\n   *\n   * @param settings The settings for the parser.\n   * @param databaseId The database ID of the Firestore instance.\n   * @param serializer The serializer to use to generate the Value proto.\n   * @param ignoreUndefinedProperties Whether to ignore undefined properties\n   * rather than throw.\n   * @param fieldTransforms A mutable list of field transforms encountered while\n   *     parsing the data.\n   * @param fieldMask A mutable list of field paths encountered while parsing\n   *     the data.\n   *\n   * TODO(b/34871131): We don't support array paths right now, so path can be\n   * null to indicate the context represents any location within an array (in\n   * which case certain features will not work and errors will be somewhat\n   * compromised).\n   */\n  constructor(\n    readonly settings: ContextSettings,\n    readonly databaseId: DatabaseId,\n    readonly serializer: JsonProtoSerializer,\n    readonly ignoreUndefinedProperties: boolean,\n    fieldTransforms?: FieldTransform[],\n    fieldMask?: FieldPath[]\n  ) {\n    // Minor hack: If fieldTransforms is undefined, we assume this is an\n    // external call and we need to validate the entire path.\n    if (fieldTransforms === undefined) {\n      this.validatePath();\n    }\n    this.fieldTransforms = fieldTransforms || [];\n    this.fieldMask = fieldMask || [];\n  }\n\n  get path(): FieldPath | undefined {\n    return this.settings.path;\n  }\n\n  get dataSource(): UserDataSource {\n    return this.settings.dataSource;\n  }\n\n  /** Returns a new context with the specified settings overwritten. */\n  contextWith(configuration: Partial<ContextSettings>): ParseContext {\n    return new ParseContext(\n      { ...this.settings, ...configuration },\n      this.databaseId,\n      this.serializer,\n      this.ignoreUndefinedProperties,\n      this.fieldTransforms,\n      this.fieldMask\n    );\n  }\n\n  childContextForField(field: string): ParseContext {\n    const childPath = this.path?.child(field);\n    const context = this.contextWith({ path: childPath, arrayElement: false });\n    context.validatePathSegment(field);\n    return context;\n  }\n\n  childContextForFieldPath(field: FieldPath): ParseContext {\n    const childPath = this.path?.child(field);\n    const context = this.contextWith({ path: childPath, arrayElement: false });\n    context.validatePath();\n    return context;\n  }\n\n  childContextForArray(index: number): ParseContext {\n    // TODO(b/34871131): We don't support array paths right now; so make path\n    // undefined.\n    return this.contextWith({ path: undefined, arrayElement: true });\n  }\n\n  createError(reason: string): Error {\n    return createError(\n      reason,\n      this.settings.methodName,\n      this.settings.hasConverter || false,\n      this.path,\n      this.settings.targetDoc\n    );\n  }\n\n  /** Returns 'true' if 'fieldPath' was traversed when creating this context. */\n  contains(fieldPath: FieldPath): boolean {\n    return (\n      this.fieldMask.find(field => fieldPath.isPrefixOf(field)) !== undefined ||\n      this.fieldTransforms.find(transform =>\n        fieldPath.isPrefixOf(transform.field)\n      ) !== undefined\n    );\n  }\n\n  private validatePath(): void {\n    // TODO(b/34871131): Remove null check once we have proper paths for fields\n    // within arrays.\n    if (!this.path) {\n      return;\n    }\n    for (let i = 0; i < this.path.length; i++) {\n      this.validatePathSegment(this.path.get(i));\n    }\n  }\n\n  private validatePathSegment(segment: string): void {\n    if (segment.length === 0) {\n      throw this.createError('Document fields must not be empty');\n    }\n    if (isWrite(this.dataSource) && RESERVED_FIELD_REGEX.test(segment)) {\n      throw this.createError('Document fields cannot begin and end with \"__\"');\n    }\n  }\n}\n\n/**\n * Helper for parsing raw user input (provided via the API) into internal model\n * classes.\n */\nexport class UserDataReader {\n  private readonly serializer: JsonProtoSerializer;\n\n  constructor(\n    private readonly databaseId: DatabaseId,\n    private readonly ignoreUndefinedProperties: boolean,\n    serializer?: JsonProtoSerializer\n  ) {\n    this.serializer = serializer || newSerializer(databaseId);\n  }\n\n  /** Creates a new top-level parse context. */\n  createContext(\n    dataSource: UserDataSource,\n    methodName: string,\n    targetDoc?: DocumentKey,\n    hasConverter = false\n  ): ParseContext {\n    return new ParseContext(\n      {\n        dataSource,\n        methodName,\n        targetDoc,\n        path: FieldPath.emptyPath(),\n        arrayElement: false,\n        hasConverter\n      },\n      this.databaseId,\n      this.serializer,\n      this.ignoreUndefinedProperties\n    );\n  }\n}\n\n/** Parse document data from a set() call. */\nexport function parseSetData(\n  userDataReader: UserDataReader,\n  methodName: string,\n  targetDoc: DocumentKey,\n  input: unknown,\n  hasConverter: boolean,\n  options: firestore.SetOptions = {}\n): ParsedSetData {\n  const context = userDataReader.createContext(\n    options.merge || options.mergeFields\n      ? UserDataSource.MergeSet\n      : UserDataSource.Set,\n    methodName,\n    targetDoc,\n    hasConverter\n  );\n  validatePlainObject('Data must be an object, but it was:', context, input);\n  const updateData = parseObject(input, context)!;\n\n  let fieldMask: FieldMask | null;\n  let fieldTransforms: FieldTransform[];\n\n  if (options.merge) {\n    fieldMask = new FieldMask(context.fieldMask);\n    fieldTransforms = context.fieldTransforms;\n  } else if (options.mergeFields) {\n    const validatedFieldPaths: FieldPath[] = [];\n\n    for (const stringOrFieldPath of options.mergeFields) {\n      let fieldPath: FieldPath;\n\n      if (stringOrFieldPath instanceof BaseFieldPath) {\n        fieldPath = stringOrFieldPath._internalPath;\n      } else if (typeof stringOrFieldPath === 'string') {\n        fieldPath = fieldPathFromDotSeparatedString(\n          methodName,\n          stringOrFieldPath,\n          targetDoc\n        );\n      } else {\n        throw fail('Expected stringOrFieldPath to be a string or a FieldPath');\n      }\n\n      if (!context.contains(fieldPath)) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `Field '${fieldPath}' is specified in your field mask but missing from your input data.`\n        );\n      }\n\n      if (!fieldMaskContains(validatedFieldPaths, fieldPath)) {\n        validatedFieldPaths.push(fieldPath);\n      }\n    }\n\n    fieldMask = new FieldMask(validatedFieldPaths);\n    fieldTransforms = context.fieldTransforms.filter(transform =>\n      fieldMask!.covers(transform.field)\n    );\n  } else {\n    fieldMask = null;\n    fieldTransforms = context.fieldTransforms;\n  }\n\n  return new ParsedSetData(\n    new ObjectValue(updateData),\n    fieldMask,\n    fieldTransforms\n  );\n}\n\n/** Parse update data from an update() call. */\nexport function parseUpdateData(\n  userDataReader: UserDataReader,\n  methodName: string,\n  targetDoc: DocumentKey,\n  input: unknown\n): ParsedUpdateData {\n  const context = userDataReader.createContext(\n    UserDataSource.Update,\n    methodName,\n    targetDoc\n  );\n  validatePlainObject('Data must be an object, but it was:', context, input);\n\n  const fieldMaskPaths: FieldPath[] = [];\n  const updateData = new ObjectValueBuilder();\n  forEach(input as Dict<unknown>, (key, value) => {\n    const path = fieldPathFromDotSeparatedString(methodName, key, targetDoc);\n\n    const childContext = context.childContextForFieldPath(path);\n    if (\n      value instanceof SerializableFieldValue &&\n      value._delegate instanceof DeleteFieldValueImpl\n    ) {\n      // Add it to the field mask, but don't add anything to updateData.\n      fieldMaskPaths.push(path);\n    } else {\n      const parsedValue = parseData(value, childContext);\n      if (parsedValue != null) {\n        fieldMaskPaths.push(path);\n        updateData.set(path, parsedValue);\n      }\n    }\n  });\n\n  const mask = new FieldMask(fieldMaskPaths);\n  return new ParsedUpdateData(\n    updateData.build(),\n    mask,\n    context.fieldTransforms\n  );\n}\n\n/** Parse update data from a list of field/value arguments. */\nexport function parseUpdateVarargs(\n  userDataReader: UserDataReader,\n  methodName: string,\n  targetDoc: DocumentKey,\n  field: string | BaseFieldPath,\n  value: unknown,\n  moreFieldsAndValues: unknown[]\n): ParsedUpdateData {\n  const context = userDataReader.createContext(\n    UserDataSource.Update,\n    methodName,\n    targetDoc\n  );\n  const keys = [fieldPathFromArgument(methodName, field, targetDoc)];\n  const values = [value];\n\n  if (moreFieldsAndValues.length % 2 !== 0) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${methodName}() needs to be called with an even number ` +\n        'of arguments that alternate between field names and values.'\n    );\n  }\n\n  for (let i = 0; i < moreFieldsAndValues.length; i += 2) {\n    keys.push(\n      fieldPathFromArgument(\n        methodName,\n        moreFieldsAndValues[i] as string | BaseFieldPath\n      )\n    );\n    values.push(moreFieldsAndValues[i + 1]);\n  }\n\n  const fieldMaskPaths: FieldPath[] = [];\n  const updateData = new ObjectValueBuilder();\n\n  // We iterate in reverse order to pick the last value for a field if the\n  // user specified the field multiple times.\n  for (let i = keys.length - 1; i >= 0; --i) {\n    if (!fieldMaskContains(fieldMaskPaths, keys[i])) {\n      const path = keys[i];\n      const value = values[i];\n      const childContext = context.childContextForFieldPath(path);\n      if (\n        value instanceof SerializableFieldValue &&\n        value._delegate instanceof DeleteFieldValueImpl\n      ) {\n        // Add it to the field mask, but don't add anything to updateData.\n        fieldMaskPaths.push(path);\n      } else {\n        const parsedValue = parseData(value, childContext);\n        if (parsedValue != null) {\n          fieldMaskPaths.push(path);\n          updateData.set(path, parsedValue);\n        }\n      }\n    }\n  }\n\n  const mask = new FieldMask(fieldMaskPaths);\n  return new ParsedUpdateData(\n    updateData.build(),\n    mask,\n    context.fieldTransforms\n  );\n}\n\n/**\n * Parse a \"query value\" (e.g. value in a where filter or a value in a cursor\n * bound).\n *\n * @param allowArrays Whether the query value is an array that may directly\n * contain additional arrays (e.g. the operand of an `in` query).\n */\nexport function parseQueryValue(\n  userDataReader: UserDataReader,\n  methodName: string,\n  input: unknown,\n  allowArrays = false\n): api.Value {\n  const context = userDataReader.createContext(\n    allowArrays ? UserDataSource.ArrayArgument : UserDataSource.Argument,\n    methodName\n  );\n  const parsed = parseData(input, context);\n  debugAssert(parsed != null, 'Parsed data should not be null.');\n  debugAssert(\n    context.fieldTransforms.length === 0,\n    'Field transforms should have been disallowed.'\n  );\n  return parsed;\n}\n\n/**\n * Parses user data to Protobuf Values.\n *\n * @param input Data to be parsed.\n * @param context A context object representing the current path being parsed,\n * the source of the data being parsed, etc.\n * @return The parsed value, or null if the value was a FieldValue sentinel\n * that should not be included in the resulting parsed data.\n */\nexport function parseData(\n  input: unknown,\n  context: ParseContext\n): api.Value | null {\n  if (looksLikeJsonObject(input)) {\n    validatePlainObject('Unsupported field value:', context, input);\n    return parseObject(input, context);\n  } else if (input instanceof SerializableFieldValue) {\n    // FieldValues usually parse into transforms (except FieldValue.delete())\n    // in which case we do not want to include this field in our parsed data\n    // (as doing so will overwrite the field directly prior to the transform\n    // trying to transform it). So we don't add this location to\n    // context.fieldMask and we return null as our parsing result.\n    parseSentinelFieldValue(input, context);\n    return null;\n  } else {\n    // If context.path is null we are inside an array and we don't support\n    // field mask paths more granular than the top-level array.\n    if (context.path) {\n      context.fieldMask.push(context.path);\n    }\n\n    if (input instanceof Array) {\n      // TODO(b/34871131): Include the path containing the array in the error\n      // message.\n      // In the case of IN queries, the parsed data is an array (representing\n      // the set of values to be included for the IN query) that may directly\n      // contain additional arrays (each representing an individual field\n      // value), so we disable this validation.\n      if (\n        context.settings.arrayElement &&\n        context.dataSource !== UserDataSource.ArrayArgument\n      ) {\n        throw context.createError('Nested arrays are not supported');\n      }\n      return parseArray(input as unknown[], context);\n    } else {\n      return parseScalarValue(input, context);\n    }\n  }\n}\n\nfunction parseObject(\n  obj: Dict<unknown>,\n  context: ParseContext\n): { mapValue: api.MapValue } {\n  const fields: Dict<api.Value> = {};\n\n  if (isEmpty(obj)) {\n    // If we encounter an empty object, we explicitly add it to the update\n    // mask to ensure that the server creates a map entry.\n    if (context.path && context.path.length > 0) {\n      context.fieldMask.push(context.path);\n    }\n  } else {\n    forEach(obj, (key: string, val: unknown) => {\n      const parsedValue = parseData(val, context.childContextForField(key));\n      if (parsedValue != null) {\n        fields[key] = parsedValue;\n      }\n    });\n  }\n\n  return { mapValue: { fields } };\n}\n\nfunction parseArray(array: unknown[], context: ParseContext): api.Value {\n  const values: api.Value[] = [];\n  let entryIndex = 0;\n  for (const entry of array) {\n    let parsedEntry = parseData(\n      entry,\n      context.childContextForArray(entryIndex)\n    );\n    if (parsedEntry == null) {\n      // Just include nulls in the array for fields being replaced with a\n      // sentinel.\n      parsedEntry = { nullValue: 'NULL_VALUE' };\n    }\n    values.push(parsedEntry);\n    entryIndex++;\n  }\n  return { arrayValue: { values } };\n}\n\n/**\n * \"Parses\" the provided FieldValueImpl, adding any necessary transforms to\n * context.fieldTransforms.\n */\nfunction parseSentinelFieldValue(\n  value: SerializableFieldValue,\n  context: ParseContext\n): void {\n  // Sentinels are only supported with writes, and not within arrays.\n  if (!isWrite(context.dataSource)) {\n    throw context.createError(\n      `${value._methodName}() can only be used with update() and set()`\n    );\n  }\n  if (!context.path) {\n    throw context.createError(\n      `${value._methodName}() is not currently supported inside arrays`\n    );\n  }\n\n  const fieldTransform = value._toFieldTransform(context);\n  if (fieldTransform) {\n    context.fieldTransforms.push(fieldTransform);\n  }\n}\n\n/**\n * Helper to parse a scalar value (i.e. not an Object, Array, or FieldValue)\n *\n * @return The parsed value\n */\nfunction parseScalarValue(\n  value: unknown,\n  context: ParseContext\n): api.Value | null {\n  if (value === null) {\n    return { nullValue: 'NULL_VALUE' };\n  } else if (typeof value === 'number') {\n    return toNumber(context.serializer, value);\n  } else if (typeof value === 'boolean') {\n    return { booleanValue: value };\n  } else if (typeof value === 'string') {\n    return { stringValue: value };\n  } else if (value instanceof Date) {\n    const timestamp = Timestamp.fromDate(value);\n    return {\n      timestampValue: toTimestamp(context.serializer, timestamp)\n    };\n  } else if (value instanceof Timestamp) {\n    // Firestore backend truncates precision down to microseconds. To ensure\n    // offline mode works the same with regards to truncation, perform the\n    // truncation immediately without waiting for the backend to do that.\n    const timestamp = new Timestamp(\n      value.seconds,\n      Math.floor(value.nanoseconds / 1000) * 1000\n    );\n    return {\n      timestampValue: toTimestamp(context.serializer, timestamp)\n    };\n  } else if (value instanceof GeoPoint) {\n    return {\n      geoPointValue: {\n        latitude: value.latitude,\n        longitude: value.longitude\n      }\n    };\n  } else if (value instanceof Blob) {\n    return { bytesValue: toBytes(context.serializer, value) };\n  } else if (value instanceof DocumentKeyReference) {\n    const thisDb = context.databaseId;\n    const otherDb = value._databaseId;\n    if (!otherDb.isEqual(thisDb)) {\n      throw context.createError(\n        'Document reference is for database ' +\n          `${otherDb.projectId}/${otherDb.database} but should be ` +\n          `for database ${thisDb.projectId}/${thisDb.database}`\n      );\n    }\n    return {\n      referenceValue: toResourceName(\n        value._databaseId || context.databaseId,\n        value._key.path\n      )\n    };\n  } else if (value === undefined && context.ignoreUndefinedProperties) {\n    return null;\n  } else {\n    throw context.createError(\n      `Unsupported field value: ${valueDescription(value)}`\n    );\n  }\n}\n\n/**\n * Checks whether an object looks like a JSON object that should be converted\n * into a struct. Normal class/prototype instances are considered to look like\n * JSON objects since they should be converted to a struct value. Arrays, Dates,\n * GeoPoints, etc. are not considered to look like JSON objects since they map\n * to specific FieldValue types other than ObjectValue.\n */\nfunction looksLikeJsonObject(input: unknown): boolean {\n  return (\n    typeof input === 'object' &&\n    input !== null &&\n    !(input instanceof Array) &&\n    !(input instanceof Date) &&\n    !(input instanceof Timestamp) &&\n    !(input instanceof GeoPoint) &&\n    !(input instanceof Blob) &&\n    !(input instanceof DocumentKeyReference) &&\n    !(input instanceof SerializableFieldValue)\n  );\n}\n\nfunction validatePlainObject(\n  message: string,\n  context: ParseContext,\n  input: unknown\n): asserts input is Dict<unknown> {\n  if (!looksLikeJsonObject(input) || !isPlainObject(input)) {\n    const description = valueDescription(input);\n    if (description === 'an object') {\n      // Massage the error if it was an object.\n      throw context.createError(message + ' a custom object');\n    } else {\n      throw context.createError(message + ' ' + description);\n    }\n  }\n}\n\n/**\n * Helper that calls fromDotSeparatedString() but wraps any error thrown.\n */\nexport function fieldPathFromArgument(\n  methodName: string,\n  path: string | BaseFieldPath,\n  targetDoc?: DocumentKey\n): FieldPath {\n  if (path instanceof BaseFieldPath) {\n    return path._internalPath;\n  } else if (typeof path === 'string') {\n    return fieldPathFromDotSeparatedString(methodName, path);\n  } else {\n    const message = 'Field path arguments must be of type string or FieldPath.';\n    throw createError(\n      message,\n      methodName,\n      /* hasConverter= */ false,\n      /* path= */ undefined,\n      targetDoc\n    );\n  }\n}\n\n/**\n * Wraps fromDotSeparatedString with an error message about the method that\n * was thrown.\n * @param methodName The publicly visible method name\n * @param path The dot-separated string form of a field path which will be split\n * on dots.\n * @param targetDoc The document against which the field path will be evaluated.\n */\nexport function fieldPathFromDotSeparatedString(\n  methodName: string,\n  path: string,\n  targetDoc?: DocumentKey\n): FieldPath {\n  try {\n    return fromDotSeparatedString(path)._internalPath;\n  } catch (e) {\n    const message = errorMessage(e);\n    throw createError(\n      message,\n      methodName,\n      /* hasConverter= */ false,\n      /* path= */ undefined,\n      targetDoc\n    );\n  }\n}\n\nfunction createError(\n  reason: string,\n  methodName: string,\n  hasConverter: boolean,\n  path?: FieldPath,\n  targetDoc?: DocumentKey\n): Error {\n  const hasPath = path && !path.isEmpty();\n  const hasDocument = targetDoc !== undefined;\n  let message = `Function ${methodName}() called with invalid data`;\n  if (hasConverter) {\n    message += ' (via `toFirestore()`)';\n  }\n  message += '. ';\n\n  let description = '';\n  if (hasPath || hasDocument) {\n    description += ' (found';\n\n    if (hasPath) {\n      description += ` in field ${path}`;\n    }\n    if (hasDocument) {\n      description += ` in document ${targetDoc}`;\n    }\n    description += ')';\n  }\n\n  return new FirestoreError(\n    Code.INVALID_ARGUMENT,\n    message + reason + description\n  );\n}\n\n/**\n * Extracts the message from a caught exception, which should be an Error object\n * though JS doesn't guarantee that.\n */\nfunction errorMessage(error: Error | object): string {\n  return error instanceof Error ? error.message : error.toString();\n}\n\n/** Checks `haystack` if FieldPath `needle` is present. Runs in O(n). */\nfunction fieldMaskContains(haystack: FieldPath[], needle: FieldPath): boolean {\n  return haystack.some(v => v.isEqual(needle));\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ParsedSetData, ParsedUpdateData } from '../api/user_data_reader';\nimport { Document, MaybeDocument, NoDocument } from '../model/document';\n\nimport { DocumentKey } from '../model/document_key';\nimport {\n  DeleteMutation,\n  Mutation,\n  Precondition,\n  VerifyMutation\n} from '../model/mutation';\nimport {\n  Datastore,\n  invokeBatchGetDocumentsRpc,\n  invokeCommitRpc\n} from '../remote/datastore';\nimport { fail, debugAssert } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { SnapshotVersion } from './snapshot_version';\nimport { ResourcePath } from '../model/path';\n\n/**\n * Internal transaction object responsible for accumulating the mutations to\n * perform and the base versions for any documents read.\n */\nexport class Transaction {\n  // The version of each document that was read during this transaction.\n  private readVersions = new Map</* path */ string, SnapshotVersion>();\n  private mutations: Mutation[] = [];\n  private committed = false;\n\n  /**\n   * A deferred usage error that occurred previously in this transaction that\n   * will cause the transaction to fail once it actually commits.\n   */\n  private lastWriteError: FirestoreError | null = null;\n\n  /**\n   * Set of documents that have been written in the transaction.\n   *\n   * When there's more than one write to the same key in a transaction, any\n   * writes after the first are handled differently.\n   */\n  private writtenDocs: Set<DocumentKey> = new Set();\n\n  constructor(private datastore: Datastore) {}\n\n  async lookup(keys: DocumentKey[]): Promise<MaybeDocument[]> {\n    this.ensureCommitNotCalled();\n\n    if (this.mutations.length > 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Firestore transactions require all reads to be executed before all writes.'\n      );\n    }\n    const docs = await invokeBatchGetDocumentsRpc(this.datastore, keys);\n    docs.forEach(doc => {\n      if (doc instanceof NoDocument || doc instanceof Document) {\n        this.recordVersion(doc);\n      } else {\n        fail('Document in a transaction was a ' + doc.constructor.name);\n      }\n    });\n    return docs;\n  }\n\n  set(key: DocumentKey, data: ParsedSetData): void {\n    this.write(data.toMutations(key, this.precondition(key)));\n    this.writtenDocs.add(key);\n  }\n\n  update(key: DocumentKey, data: ParsedUpdateData): void {\n    try {\n      this.write(data.toMutations(key, this.preconditionForUpdate(key)));\n    } catch (e) {\n      this.lastWriteError = e;\n    }\n    this.writtenDocs.add(key);\n  }\n\n  delete(key: DocumentKey): void {\n    this.write([new DeleteMutation(key, this.precondition(key))]);\n    this.writtenDocs.add(key);\n  }\n\n  async commit(): Promise<void> {\n    this.ensureCommitNotCalled();\n\n    if (this.lastWriteError) {\n      throw this.lastWriteError;\n    }\n    const unwritten = this.readVersions;\n    // For each mutation, note that the doc was written.\n    this.mutations.forEach(mutation => {\n      unwritten.delete(mutation.key.toString());\n    });\n    // For each document that was read but not written to, we want to perform\n    // a `verify` operation.\n    unwritten.forEach((_, path) => {\n      const key = new DocumentKey(ResourcePath.fromString(path));\n      this.mutations.push(new VerifyMutation(key, this.precondition(key)));\n    });\n    await invokeCommitRpc(this.datastore, this.mutations);\n    this.committed = true;\n  }\n\n  private recordVersion(doc: MaybeDocument): void {\n    let docVersion: SnapshotVersion;\n\n    if (doc instanceof Document) {\n      docVersion = doc.version;\n    } else if (doc instanceof NoDocument) {\n      // For deleted docs, we must use baseVersion 0 when we overwrite them.\n      docVersion = SnapshotVersion.min();\n    } else {\n      throw fail('Document in a transaction was a ' + doc.constructor.name);\n    }\n\n    const existingVersion = this.readVersions.get(doc.key.toString());\n    if (existingVersion) {\n      if (!docVersion.isEqual(existingVersion)) {\n        // This transaction will fail no matter what.\n        throw new FirestoreError(\n          Code.ABORTED,\n          'Document version changed between two reads.'\n        );\n      }\n    } else {\n      this.readVersions.set(doc.key.toString(), docVersion);\n    }\n  }\n\n  /**\n   * Returns the version of this document when it was read in this transaction,\n   * as a precondition, or no precondition if it was not read.\n   */\n  private precondition(key: DocumentKey): Precondition {\n    const version = this.readVersions.get(key.toString());\n    if (!this.writtenDocs.has(key) && version) {\n      return Precondition.updateTime(version);\n    } else {\n      return Precondition.none();\n    }\n  }\n\n  /**\n   * Returns the precondition for a document if the operation is an update.\n   */\n  private preconditionForUpdate(key: DocumentKey): Precondition {\n    const version = this.readVersions.get(key.toString());\n    // The first time a document is written, we want to take into account the\n    // read time and existence\n    if (!this.writtenDocs.has(key) && version) {\n      if (version.isEqual(SnapshotVersion.min())) {\n        // The document doesn't exist, so fail the transaction.\n\n        // This has to be validated locally because you can't send a\n        // precondition that a document does not exist without changing the\n        // semantics of the backend write to be an insert. This is the reverse\n        // of what we want, since we want to assert that the document doesn't\n        // exist but then send the update and have it fail. Since we can't\n        // express that to the backend, we have to validate locally.\n\n        // Note: this can change once we can send separate verify writes in the\n        // transaction.\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          \"Can't update a document that doesn't exist.\"\n        );\n      }\n      // Document exists, base precondition on document update time.\n      return Precondition.updateTime(version);\n    } else {\n      // Document was not read, so we just use the preconditions for a blind\n      // update.\n      return Precondition.exists(true);\n    }\n  }\n\n  private write(mutations: Mutation[]): void {\n    this.ensureCommitNotCalled();\n    this.mutations = this.mutations.concat(mutations);\n  }\n\n  private ensureCommitNotCalled(): void {\n    debugAssert(\n      !this.committed,\n      'A transaction object cannot be used after its update callback has been invoked.'\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Deferred } from '../util/promise';\nimport { TimerId, AsyncQueue } from '../util/async_queue';\nimport { ExponentialBackoff } from '../remote/backoff';\nimport { Transaction } from './transaction';\nimport { Datastore } from '../remote/datastore';\nimport { isNullOrUndefined } from '../util/types';\nimport { isPermanentError } from '../remote/rpc_error';\nimport { FirestoreError } from '../util/error';\n\nconst RETRY_COUNT = 5;\n\n/**\n * TransactionRunner encapsulates the logic needed to run and retry transactions\n * with backoff.\n */\nexport class TransactionRunner<T> {\n  private retries = RETRY_COUNT;\n  private backoff: ExponentialBackoff;\n\n  constructor(\n    private readonly asyncQueue: AsyncQueue,\n    private readonly datastore: Datastore,\n    private readonly updateFunction: (transaction: Transaction) => Promise<T>,\n    private readonly deferred: Deferred<T>\n  ) {\n    this.backoff = new ExponentialBackoff(\n      this.asyncQueue,\n      TimerId.TransactionRetry\n    );\n  }\n\n  /** Runs the transaction and sets the result on deferred. */\n  run(): void {\n    this.runWithBackOff();\n  }\n\n  private runWithBackOff(): void {\n    this.backoff.backoffAndRun(async () => {\n      const transaction = new Transaction(this.datastore);\n      const userPromise = this.tryRunUpdateFunction(transaction);\n      if (userPromise) {\n        userPromise\n          .then(result => {\n            this.asyncQueue.enqueueAndForget(() => {\n              return transaction\n                .commit()\n                .then(() => {\n                  this.deferred.resolve(result);\n                })\n                .catch(commitError => {\n                  this.handleTransactionError(commitError);\n                });\n            });\n          })\n          .catch(userPromiseError => {\n            this.handleTransactionError(userPromiseError);\n          });\n      }\n    });\n  }\n\n  private tryRunUpdateFunction(transaction: Transaction): Promise<T> | null {\n    try {\n      const userPromise = this.updateFunction(transaction);\n      if (\n        isNullOrUndefined(userPromise) ||\n        !userPromise.catch ||\n        !userPromise.then\n      ) {\n        this.deferred.reject(\n          Error('Transaction callback must return a Promise')\n        );\n        return null;\n      }\n      return userPromise;\n    } catch (error) {\n      // Do not retry errors thrown by user provided updateFunction.\n      this.deferred.reject(error);\n      return null;\n    }\n  }\n\n  private handleTransactionError(error: Error): void {\n    if (this.retries > 0 && this.isRetryableTransactionError(error)) {\n      this.retries -= 1;\n      this.asyncQueue.enqueueAndForget(() => {\n        this.runWithBackOff();\n        return Promise.resolve();\n      });\n    } else {\n      this.deferred.reject(error);\n    }\n  }\n\n  private isRetryableTransactionError(error: Error): boolean {\n    if (error.name === 'FirebaseError') {\n      // In transactions, the backend will fail outdated reads with FAILED_PRECONDITION and\n      // non-matching document versions with ABORTED. These errors should be retried.\n      const code = (error as FirestoreError).code;\n      return (\n        code === 'aborted' ||\n        code === 'failed-precondition' ||\n        !isPermanentError(code)\n      );\n    }\n    return false;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { GetOptions } from '@firebase/firestore-types';\n\nimport { CredentialsProvider } from '../api/credentials';\nimport { User } from '../auth/user';\nimport { LocalStore } from '../local/local_store';\nimport { GarbageCollectionScheduler, Persistence } from '../local/persistence';\nimport { Document, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { Mutation } from '../model/mutation';\nimport { RemoteStore } from '../remote/remote_store';\nimport { AsyncQueue, wrapInUserErrorIfRecoverable } from '../util/async_queue';\nimport { Code, FirestoreError } from '../util/error';\nimport { logDebug } from '../util/log';\nimport { Deferred } from '../util/promise';\nimport {\n  EventManager,\n  ListenOptions,\n  Observer,\n  QueryListener\n} from './event_manager';\nimport { SyncEngine } from './sync_engine';\nimport { View } from './view';\nimport { SharedClientState } from '../local/shared_client_state';\nimport { AutoId } from '../util/misc';\nimport { DatabaseId, DatabaseInfo } from './database_info';\nimport { newQueryForPath, Query } from './query';\nimport { Transaction } from './transaction';\nimport { ViewSnapshot } from './view_snapshot';\nimport {\n  MemoryOfflineComponentProvider,\n  OfflineComponentProvider,\n  OnlineComponentProvider\n} from './component_provider';\nimport { PartialObserver, Unsubscribe } from '../api/observer';\nimport { AsyncObserver } from '../util/async_observer';\nimport { debugAssert } from '../util/assert';\nimport { TransactionRunner } from './transaction_runner';\nimport { Datastore } from '../remote/datastore';\n\nconst LOG_TAG = 'FirestoreClient';\nexport const MAX_CONCURRENT_LIMBO_RESOLUTIONS = 100;\n\n/** DOMException error code constants. */\nconst DOM_EXCEPTION_INVALID_STATE = 11;\nconst DOM_EXCEPTION_ABORTED = 20;\nconst DOM_EXCEPTION_QUOTA_EXCEEDED = 22;\n\nexport type PersistenceSettings =\n  | {\n      readonly durable: false;\n    }\n  | {\n      readonly durable: true;\n      readonly cacheSizeBytes: number;\n      readonly synchronizeTabs: boolean;\n      readonly forceOwningTab: boolean;\n    };\n\n/**\n * FirestoreClient is a top-level class that constructs and owns all of the\n * pieces of the client SDK architecture. It is responsible for creating the\n * async queue that is shared by all of the other components in the system.\n */\nexport class FirestoreClient {\n  // NOTE: These should technically have '|undefined' in the types, since\n  // they're initialized asynchronously rather than in the constructor, but\n  // given that all work is done on the async queue and we assert that\n  // initialization completes before any other work is queued, we're cheating\n  // with the types rather than littering the code with '!' or unnecessary\n  // undefined checks.\n  private databaseInfo!: DatabaseInfo;\n  private eventMgr!: EventManager;\n  private persistence!: Persistence;\n  private localStore!: LocalStore;\n  private datastore!: Datastore;\n  private remoteStore!: RemoteStore;\n  private syncEngine!: SyncEngine;\n  private gcScheduler!: GarbageCollectionScheduler | null;\n\n  // PORTING NOTE: SharedClientState is only used for multi-tab web.\n  private sharedClientState!: SharedClientState;\n\n  private readonly clientId = AutoId.newId();\n\n  // We defer our initialization until we get the current user from\n  // setChangeListener(). We block the async queue until we got the initial\n  // user and the initialization is completed. This will prevent any scheduled\n  // work from happening before initialization is completed.\n  //\n  // If initializationDone resolved then the FirestoreClient is in a usable\n  // state.\n  private readonly initializationDone = new Deferred<void>();\n\n  constructor(\n    private credentials: CredentialsProvider,\n    /**\n     * Asynchronous queue responsible for all of our internal processing. When\n     * we get incoming work from the user (via public API) or the network\n     * (incoming GRPC messages), we should always schedule onto this queue.\n     * This ensures all of our work is properly serialized (e.g. we don't\n     * start processing a new operation while the previous one is waiting for\n     * an async I/O to complete).\n     */\n    private asyncQueue: AsyncQueue\n  ) {}\n\n  /**\n   * Starts up the FirestoreClient, returning only whether or not enabling\n   * persistence succeeded.\n   *\n   * The intent here is to \"do the right thing\" as far as users are concerned.\n   * Namely, in cases where offline persistence is requested and possible,\n   * enable it, but otherwise fall back to persistence disabled. For the most\n   * part we expect this to succeed one way or the other so we don't expect our\n   * users to actually wait on the firestore.enablePersistence Promise since\n   * they generally won't care.\n   *\n   * Of course some users actually do care about whether or not persistence\n   * was successfully enabled, so the Promise returned from this method\n   * indicates this outcome.\n   *\n   * This presents a problem though: even before enablePersistence resolves or\n   * rejects, users may have made calls to e.g. firestore.collection() which\n   * means that the FirestoreClient in there will be available and will be\n   * enqueuing actions on the async queue.\n   *\n   * Meanwhile any failure of an operation on the async queue causes it to\n   * panic and reject any further work, on the premise that unhandled errors\n   * are fatal.\n   *\n   * Consequently the fallback is handled internally here in start, and if the\n   * fallback succeeds we signal success to the async queue even though the\n   * start() itself signals failure.\n   *\n   * @param databaseInfo The connection information for the current instance.\n   * @param offlineComponentProvider Provider that returns all components\n   * required for memory-only or IndexedDB persistence.\n   * @param onlineComponentProvider Provider that returns all components\n   * required for online support.\n   * @param persistenceSettings Settings object to configure offline\n   *     persistence.\n   * @returns A deferred result indicating the user-visible result of enabling\n   *     offline persistence. This method will reject this if IndexedDB fails to\n   *     start for any reason. If usePersistence is false this is\n   *     unconditionally resolved.\n   */\n  start(\n    databaseInfo: DatabaseInfo,\n    offlineComponentProvider: OfflineComponentProvider,\n    onlineComponentProvider: OnlineComponentProvider,\n    persistenceSettings: PersistenceSettings\n  ): Promise<void> {\n    this.verifyNotTerminated();\n\n    this.databaseInfo = databaseInfo;\n\n    // If usePersistence is true, certain classes of errors while starting are\n    // recoverable but only by falling back to persistence disabled.\n    //\n    // If there's an error in the first case but not in recovery we cannot\n    // reject the promise blocking the async queue because this will cause the\n    // async queue to panic.\n    const persistenceResult = new Deferred<void>();\n\n    let initialized = false;\n    this.credentials.setChangeListener(user => {\n      if (!initialized) {\n        initialized = true;\n\n        logDebug(LOG_TAG, 'Initializing. user=', user.uid);\n\n        return this.initializeComponents(\n          offlineComponentProvider,\n          onlineComponentProvider,\n          persistenceSettings,\n          user,\n          persistenceResult\n        ).then(this.initializationDone.resolve, this.initializationDone.reject);\n      } else {\n        this.asyncQueue.enqueueRetryable(() =>\n          this.remoteStore.handleCredentialChange(user)\n        );\n      }\n    });\n\n    // Block the async queue until initialization is done\n    this.asyncQueue.enqueueAndForget(() => this.initializationDone.promise);\n\n    // Return only the result of enabling persistence. Note that this does not\n    // need to await the completion of initializationDone because the result of\n    // this method should not reflect any other kind of failure to start.\n    return persistenceResult.promise;\n  }\n\n  /** Enables the network connection and requeues all pending operations. */\n  enableNetwork(): Promise<void> {\n    this.verifyNotTerminated();\n    return this.asyncQueue.enqueue(() => {\n      this.persistence.setNetworkEnabled(true);\n      return this.remoteStore.enableNetwork();\n    });\n  }\n\n  /**\n   * Initializes persistent storage, attempting to use IndexedDB if\n   * usePersistence is true or memory-only if false.\n   *\n   * If IndexedDB fails because it's already open in another tab or because the\n   * platform can't possibly support our implementation then this method rejects\n   * the persistenceResult and falls back on memory-only persistence.\n   *\n   * @param offlineComponentProvider Provider that returns all components\n   * required for memory-only or IndexedDB persistence.\n   * @param onlineComponentProvider Provider that returns all components\n   * required for online support.\n   * @param persistenceSettings Settings object to configure offline persistence\n   * @param user The initial user\n   * @param persistenceResult A deferred result indicating the user-visible\n   *     result of enabling offline persistence. This method will reject this if\n   *     IndexedDB fails to start for any reason. If usePersistence is false\n   *     this is unconditionally resolved.\n   * @returns a Promise indicating whether or not initialization should\n   *     continue, i.e. that one of the persistence implementations actually\n   *     succeeded.\n   */\n  private async initializeComponents(\n    offlineComponentProvider: OfflineComponentProvider,\n    onlineComponentProvider: OnlineComponentProvider,\n    persistenceSettings: PersistenceSettings,\n    user: User,\n    persistenceResult: Deferred<void>\n  ): Promise<void> {\n    try {\n      const componentConfiguration = {\n        asyncQueue: this.asyncQueue,\n        databaseInfo: this.databaseInfo,\n        clientId: this.clientId,\n        credentials: this.credentials,\n        initialUser: user,\n        maxConcurrentLimboResolutions: MAX_CONCURRENT_LIMBO_RESOLUTIONS,\n        persistenceSettings\n      };\n\n      await offlineComponentProvider.initialize(componentConfiguration);\n      await onlineComponentProvider.initialize(\n        offlineComponentProvider,\n        componentConfiguration\n      );\n\n      this.persistence = offlineComponentProvider.persistence;\n      this.sharedClientState = offlineComponentProvider.sharedClientState;\n      this.localStore = offlineComponentProvider.localStore;\n      this.gcScheduler = offlineComponentProvider.gcScheduler;\n      this.datastore = onlineComponentProvider.datastore;\n      this.remoteStore = onlineComponentProvider.remoteStore;\n      this.syncEngine = onlineComponentProvider.syncEngine;\n      this.eventMgr = onlineComponentProvider.eventManager;\n\n      // When a user calls clearPersistence() in one client, all other clients\n      // need to be terminated to allow the delete to succeed.\n      this.persistence.setDatabaseDeletedListener(async () => {\n        await this.terminate();\n      });\n\n      persistenceResult.resolve();\n    } catch (error) {\n      // Regardless of whether or not the retry succeeds, from an user\n      // perspective, offline persistence has failed.\n      persistenceResult.reject(error);\n\n      // An unknown failure on the first stage shuts everything down.\n      if (!this.canFallback(error)) {\n        throw error;\n      }\n      console.warn(\n        'Error enabling offline persistence. Falling back to' +\n          ' persistence disabled: ' +\n          error\n      );\n      return this.initializeComponents(\n        new MemoryOfflineComponentProvider(),\n        new OnlineComponentProvider(),\n        { durable: false },\n        user,\n        persistenceResult\n      );\n    }\n  }\n\n  /**\n   * Decides whether the provided error allows us to gracefully disable\n   * persistence (as opposed to crashing the client).\n   */\n  private canFallback(error: FirestoreError | DOMException): boolean {\n    if (error.name === 'FirebaseError') {\n      return (\n        error.code === Code.FAILED_PRECONDITION ||\n        error.code === Code.UNIMPLEMENTED\n      );\n    } else if (\n      typeof DOMException !== 'undefined' &&\n      error instanceof DOMException\n    ) {\n      // There are a few known circumstances where we can open IndexedDb but\n      // trying to read/write will fail (e.g. quota exceeded). For\n      // well-understood cases, we attempt to detect these and then gracefully\n      // fall back to memory persistence.\n      // NOTE: Rather than continue to add to this list, we could decide to\n      // always fall back, with the risk that we might accidentally hide errors\n      // representing actual SDK bugs.\n      return (\n        // When the browser is out of quota we could get either quota exceeded\n        // or an aborted error depending on whether the error happened during\n        // schema migration.\n        error.code === DOM_EXCEPTION_QUOTA_EXCEEDED ||\n        error.code === DOM_EXCEPTION_ABORTED ||\n        // Firefox Private Browsing mode disables IndexedDb and returns\n        // INVALID_STATE for any usage.\n        error.code === DOM_EXCEPTION_INVALID_STATE\n      );\n    }\n\n    return true;\n  }\n\n  /**\n   * Checks that the client has not been terminated. Ensures that other methods on\n   * this class cannot be called after the client is terminated.\n   */\n  private verifyNotTerminated(): void {\n    if (this.asyncQueue.isShuttingDown) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        'The client has already been terminated.'\n      );\n    }\n  }\n\n  /** Disables the network connection. Pending operations will not complete. */\n  disableNetwork(): Promise<void> {\n    this.verifyNotTerminated();\n    return this.asyncQueue.enqueue(() => {\n      this.persistence.setNetworkEnabled(false);\n      return this.remoteStore.disableNetwork();\n    });\n  }\n\n  terminate(): Promise<void> {\n    return this.asyncQueue.enqueueAndInitiateShutdown(async () => {\n      // PORTING NOTE: LocalStore does not need an explicit shutdown on web.\n      if (this.gcScheduler) {\n        this.gcScheduler.stop();\n      }\n\n      await this.remoteStore.shutdown();\n      await this.sharedClientState.shutdown();\n      await this.persistence.shutdown();\n\n      // `removeChangeListener` must be called after shutting down the\n      // RemoteStore as it will prevent the RemoteStore from retrieving\n      // auth tokens.\n      this.credentials.removeChangeListener();\n    });\n  }\n\n  /**\n   * Returns a Promise that resolves when all writes that were pending at the time this\n   * method was called received server acknowledgement. An acknowledgement can be either acceptance\n   * or rejection.\n   */\n  waitForPendingWrites(): Promise<void> {\n    this.verifyNotTerminated();\n\n    const deferred = new Deferred<void>();\n    this.asyncQueue.enqueueAndForget(() => {\n      return this.syncEngine.registerPendingWritesCallback(deferred);\n    });\n    return deferred.promise;\n  }\n\n  listen(\n    query: Query,\n    options: ListenOptions,\n    observer: Partial<Observer<ViewSnapshot>>\n  ): () => void {\n    this.verifyNotTerminated();\n    const wrappedObserver = new AsyncObserver(observer);\n    const listener = new QueryListener(query, wrappedObserver, options);\n    this.asyncQueue.enqueueAndForget(() => this.eventMgr.listen(listener));\n    return () => {\n      wrappedObserver.mute();\n      this.asyncQueue.enqueueAndForget(() => this.eventMgr.unlisten(listener));\n    };\n  }\n\n  async getDocumentFromLocalCache(\n    docKey: DocumentKey\n  ): Promise<Document | null> {\n    this.verifyNotTerminated();\n    await this.initializationDone.promise;\n    return enqueueReadDocumentFromCache(\n      this.asyncQueue,\n      this.localStore,\n      docKey\n    );\n  }\n\n  async getDocumentViaSnapshotListener(\n    key: DocumentKey,\n    options?: GetOptions\n  ): Promise<ViewSnapshot> {\n    this.verifyNotTerminated();\n    await this.initializationDone.promise;\n    return enqueueReadDocumentViaSnapshotListener(\n      this.asyncQueue,\n      this.eventMgr,\n      key,\n      options\n    );\n  }\n\n  async getDocumentsFromLocalCache(query: Query): Promise<ViewSnapshot> {\n    this.verifyNotTerminated();\n    await this.initializationDone.promise;\n    return enqueueExecuteQueryFromCache(\n      this.asyncQueue,\n      this.localStore,\n      query\n    );\n  }\n\n  async getDocumentsViaSnapshotListener(\n    query: Query,\n    options?: GetOptions\n  ): Promise<ViewSnapshot> {\n    this.verifyNotTerminated();\n    await this.initializationDone.promise;\n    return enqueueExecuteQueryViaSnapshotListener(\n      this.asyncQueue,\n      this.eventMgr,\n      query,\n      options\n    );\n  }\n\n  write(mutations: Mutation[]): Promise<void> {\n    this.verifyNotTerminated();\n    const deferred = new Deferred<void>();\n    this.asyncQueue.enqueueAndForget(() =>\n      this.syncEngine.write(mutations, deferred)\n    );\n    return deferred.promise;\n  }\n\n  databaseId(): DatabaseId {\n    return this.databaseInfo.databaseId;\n  }\n\n  addSnapshotsInSyncListener(observer: Partial<Observer<void>>): () => void {\n    this.verifyNotTerminated();\n    const wrappedObserver = new AsyncObserver(observer);\n    this.asyncQueue.enqueueAndForget(async () =>\n      this.eventMgr.addSnapshotsInSyncListener(wrappedObserver)\n    );\n    return () => {\n      wrappedObserver.mute();\n      this.asyncQueue.enqueueAndForget(async () =>\n        this.eventMgr.removeSnapshotsInSyncListener(wrappedObserver)\n      );\n    };\n  }\n\n  get clientTerminated(): boolean {\n    // Technically, the asyncQueue is still running, but only accepting operations\n    // related to termination or supposed to be run after termination. It is effectively\n    // terminated to the eyes of users.\n    return this.asyncQueue.isShuttingDown;\n  }\n\n  /**\n   * Takes an updateFunction in which a set of reads and writes can be performed\n   * atomically. In the updateFunction, the client can read and write values\n   * using the supplied transaction object. After the updateFunction, all\n   * changes will be committed. If a retryable error occurs (ex: some other\n   * client has changed any of the data referenced), then the updateFunction\n   * will be called again after a backoff. If the updateFunction still fails\n   * after all retries, then the transaction will be rejected.\n   *\n   * The transaction object passed to the updateFunction contains methods for\n   * accessing documents and collections. Unlike other datastore access, data\n   * accessed with the transaction will not reflect local changes that have not\n   * been committed. For this reason, it is required that all reads are\n   * performed before any writes. Transactions must be performed while online.\n   */\n  transaction<T>(\n    updateFunction: (transaction: Transaction) => Promise<T>\n  ): Promise<T> {\n    this.verifyNotTerminated();\n    const deferred = new Deferred<T>();\n    this.asyncQueue.enqueueAndForget(() => {\n      new TransactionRunner<T>(\n        this.asyncQueue,\n        this.datastore,\n        updateFunction,\n        deferred\n      ).run();\n      return Promise.resolve();\n    });\n    return deferred.promise;\n  }\n}\n\nexport function enqueueWrite(\n  asyncQueue: AsyncQueue,\n  syncEngine: SyncEngine,\n  mutations: Mutation[]\n): Promise<void> {\n  const deferred = new Deferred<void>();\n  asyncQueue.enqueueAndForget(() => syncEngine.write(mutations, deferred));\n  return deferred.promise;\n}\n\nexport function enqueueNetworkEnabled(\n  asyncQueue: AsyncQueue,\n  remoteStore: RemoteStore,\n  persistence: Persistence,\n  enabled: boolean\n): Promise<void> {\n  return asyncQueue.enqueue(() => {\n    persistence.setNetworkEnabled(enabled);\n    return enabled ? remoteStore.enableNetwork() : remoteStore.disableNetwork();\n  });\n}\n\nexport function enqueueWaitForPendingWrites(\n  asyncQueue: AsyncQueue,\n  syncEngine: SyncEngine\n): Promise<void> {\n  const deferred = new Deferred<void>();\n  asyncQueue.enqueueAndForget(() => {\n    return syncEngine.registerPendingWritesCallback(deferred);\n  });\n  return deferred.promise;\n}\n\nexport function enqueueListen(\n  asyncQueue: AsyncQueue,\n  eventManger: EventManager,\n  query: Query,\n  options: ListenOptions,\n  observer: PartialObserver<ViewSnapshot>\n): Unsubscribe {\n  const wrappedObserver = new AsyncObserver(observer);\n  const listener = new QueryListener(query, wrappedObserver, options);\n  asyncQueue.enqueueAndForget(() => eventManger.listen(listener));\n  return () => {\n    wrappedObserver.mute();\n    asyncQueue.enqueueAndForget(() => eventManger.unlisten(listener));\n  };\n}\n\nexport function enqueueSnapshotsInSyncListen(\n  asyncQueue: AsyncQueue,\n  eventManager: EventManager,\n  observer: PartialObserver<void>\n): Unsubscribe {\n  const wrappedObserver = new AsyncObserver(observer);\n  asyncQueue.enqueueAndForget(async () =>\n    eventManager.addSnapshotsInSyncListener(wrappedObserver)\n  );\n  return () => {\n    wrappedObserver.mute();\n    asyncQueue.enqueueAndForget(async () =>\n      eventManager.removeSnapshotsInSyncListener(wrappedObserver)\n    );\n  };\n}\n\nexport async function enqueueReadDocumentFromCache(\n  asyncQueue: AsyncQueue,\n  localStore: LocalStore,\n  docKey: DocumentKey\n): Promise<Document | null> {\n  const deferred = new Deferred<Document | null>();\n  await asyncQueue.enqueue(async () => {\n    try {\n      const maybeDoc = await localStore.readDocument(docKey);\n      if (maybeDoc instanceof Document) {\n        deferred.resolve(maybeDoc);\n      } else if (maybeDoc instanceof NoDocument) {\n        deferred.resolve(null);\n      } else {\n        deferred.reject(\n          new FirestoreError(\n            Code.UNAVAILABLE,\n            'Failed to get document from cache. (However, this document may ' +\n              \"exist on the server. Run again without setting 'source' in \" +\n              'the GetOptions to attempt to retrieve the document from the ' +\n              'server.)'\n          )\n        );\n      }\n    } catch (e) {\n      const firestoreError = wrapInUserErrorIfRecoverable(\n        e,\n        `Failed to get document '${docKey} from cache`\n      );\n      deferred.reject(firestoreError);\n    }\n  });\n  return deferred.promise;\n}\n\n/**\n * Retrieves a latency-compensated document from the backend via a\n * SnapshotListener.\n */\nexport function enqueueReadDocumentViaSnapshotListener(\n  asyncQueue: AsyncQueue,\n  eventManager: EventManager,\n  key: DocumentKey,\n  options?: GetOptions\n): Promise<ViewSnapshot> {\n  const result = new Deferred<ViewSnapshot>();\n  const unlisten = enqueueListen(\n    asyncQueue,\n    eventManager,\n    newQueryForPath(key.path),\n    {\n      includeMetadataChanges: true,\n      waitForSyncWhenOnline: true\n    },\n    {\n      next: (snap: ViewSnapshot) => {\n        // Remove query first before passing event to user to avoid\n        // user actions affecting the now stale query.\n        unlisten();\n\n        const exists = snap.docs.has(key);\n        if (!exists && snap.fromCache) {\n          // TODO(dimond): If we're online and the document doesn't\n          // exist then we resolve with a doc.exists set to false. If\n          // we're offline however, we reject the Promise in this\n          // case. Two options: 1) Cache the negative response from\n          // the server so we can deliver that even when you're\n          // offline 2) Actually reject the Promise in the online case\n          // if the document doesn't exist.\n          result.reject(\n            new FirestoreError(\n              Code.UNAVAILABLE,\n              'Failed to get document because the client is ' + 'offline.'\n            )\n          );\n        } else if (\n          exists &&\n          snap.fromCache &&\n          options &&\n          options.source === 'server'\n        ) {\n          result.reject(\n            new FirestoreError(\n              Code.UNAVAILABLE,\n              'Failed to get document from server. (However, this ' +\n                'document does exist in the local cache. Run again ' +\n                'without setting source to \"server\" to ' +\n                'retrieve the cached document.)'\n            )\n          );\n        } else {\n          debugAssert(\n            snap.docs.size <= 1,\n            'Expected zero or a single result on a document-only query'\n          );\n          result.resolve(snap);\n        }\n      },\n      error: e => result.reject(e)\n    }\n  );\n  return result.promise;\n}\n\nexport async function enqueueExecuteQueryFromCache(\n  asyncQueue: AsyncQueue,\n  localStore: LocalStore,\n  query: Query\n): Promise<ViewSnapshot> {\n  const deferred = new Deferred<ViewSnapshot>();\n  await asyncQueue.enqueue(async () => {\n    try {\n      const queryResult = await localStore.executeQuery(\n        query,\n        /* usePreviousResults= */ true\n      );\n      const view = new View(query, queryResult.remoteKeys);\n      const viewDocChanges = view.computeDocChanges(queryResult.documents);\n      const viewChange = view.applyChanges(\n        viewDocChanges,\n        /* updateLimboDocuments= */ false\n      );\n      deferred.resolve(viewChange.snapshot!);\n    } catch (e) {\n      const firestoreError = wrapInUserErrorIfRecoverable(\n        e,\n        `Failed to execute query '${query} against cache`\n      );\n      deferred.reject(firestoreError);\n    }\n  });\n  return deferred.promise;\n}\n\n/**\n * Retrieves a latency-compensated query snapshot from the backend via a\n * SnapshotListener.\n */\nexport function enqueueExecuteQueryViaSnapshotListener(\n  asyncQueue: AsyncQueue,\n  eventManager: EventManager,\n  query: Query,\n  options?: GetOptions\n): Promise<ViewSnapshot> {\n  const result = new Deferred<ViewSnapshot>();\n  const unlisten = enqueueListen(\n    asyncQueue,\n    eventManager,\n    query,\n    {\n      includeMetadataChanges: true,\n      waitForSyncWhenOnline: true\n    },\n    {\n      next: snapshot => {\n        // Remove query first before passing event to user to avoid\n        // user actions affecting the now stale query.\n        unlisten();\n\n        if (snapshot.fromCache && options && options.source === 'server') {\n          result.reject(\n            new FirestoreError(\n              Code.UNAVAILABLE,\n              'Failed to get documents from server. (However, these ' +\n                'documents may exist in the local cache. Run again ' +\n                'without setting source to \"server\" to ' +\n                'retrieve the cached documents.)'\n            )\n          );\n        } else {\n          result.resolve(snapshot);\n        }\n      },\n      error: e => result.reject(e)\n    }\n  );\n  return result.promise;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as firestore from '@firebase/firestore-types';\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { DocumentKeyReference } from './user_data_reader';\nimport { Blob } from './blob';\nimport { GeoPoint } from './geo_point';\nimport { Timestamp } from './timestamp';\nimport { DatabaseId } from '../core/database_info';\nimport { DocumentKey } from '../model/document_key';\nimport {\n  normalizeByteString,\n  normalizeNumber,\n  normalizeTimestamp,\n  typeOrder\n} from '../model/values';\nimport {\n  getLocalWriteTime,\n  getPreviousValue\n} from '../model/server_timestamps';\nimport { fail, hardAssert } from '../util/assert';\nimport { forEach } from '../util/obj';\nimport { TypeOrder } from '../model/object_value';\nimport { ResourcePath } from '../model/path';\nimport { isValidResourceName } from '../remote/serializer';\nimport { logError } from '../util/log';\n\nexport type ServerTimestampBehavior = 'estimate' | 'previous' | 'none';\n\n/**\n * Converts Firestore's internal types to the JavaScript types that we expose\n * to the user.\n */\nexport class UserDataWriter {\n  constructor(\n    private readonly databaseId: DatabaseId,\n    private readonly timestampsInSnapshots: boolean,\n    private readonly serverTimestampBehavior: ServerTimestampBehavior,\n    private readonly referenceFactory: (\n      key: DocumentKey\n    ) => DocumentKeyReference<firestore.DocumentData>\n  ) {}\n\n  convertValue(value: api.Value): unknown {\n    switch (typeOrder(value)) {\n      case TypeOrder.NullValue:\n        return null;\n      case TypeOrder.BooleanValue:\n        return value.booleanValue!;\n      case TypeOrder.NumberValue:\n        return normalizeNumber(value.integerValue || value.doubleValue);\n      case TypeOrder.TimestampValue:\n        return this.convertTimestamp(value.timestampValue!);\n      case TypeOrder.ServerTimestampValue:\n        return this.convertServerTimestamp(value);\n      case TypeOrder.StringValue:\n        return value.stringValue!;\n      case TypeOrder.BlobValue:\n        return new Blob(normalizeByteString(value.bytesValue!));\n      case TypeOrder.RefValue:\n        return this.convertReference(value.referenceValue!);\n      case TypeOrder.GeoPointValue:\n        return this.convertGeoPoint(value.geoPointValue!);\n      case TypeOrder.ArrayValue:\n        return this.convertArray(value.arrayValue!);\n      case TypeOrder.ObjectValue:\n        return this.convertObject(value.mapValue!);\n      default:\n        throw fail('Invalid value type: ' + JSON.stringify(value));\n    }\n  }\n\n  private convertObject(mapValue: api.MapValue): firestore.DocumentData {\n    const result: firestore.DocumentData = {};\n    forEach(mapValue.fields || {}, (key, value) => {\n      result[key] = this.convertValue(value);\n    });\n    return result;\n  }\n\n  private convertGeoPoint(value: api.LatLng): GeoPoint {\n    return new GeoPoint(\n      normalizeNumber(value.latitude),\n      normalizeNumber(value.longitude)\n    );\n  }\n\n  private convertArray(arrayValue: api.ArrayValue): unknown[] {\n    return (arrayValue.values || []).map(value => this.convertValue(value));\n  }\n\n  private convertServerTimestamp(value: api.Value): unknown {\n    switch (this.serverTimestampBehavior) {\n      case 'previous':\n        const previousValue = getPreviousValue(value);\n        if (previousValue == null) {\n          return null;\n        }\n        return this.convertValue(previousValue);\n      case 'estimate':\n        return this.convertTimestamp(getLocalWriteTime(value));\n      default:\n        return null;\n    }\n  }\n\n  private convertTimestamp(value: api.Timestamp): Timestamp | Date {\n    const normalizedValue = normalizeTimestamp(value);\n    const timestamp = new Timestamp(\n      normalizedValue.seconds,\n      normalizedValue.nanos\n    );\n    if (this.timestampsInSnapshots) {\n      return timestamp;\n    } else {\n      return timestamp.toDate();\n    }\n  }\n\n  private convertReference(\n    name: string\n  ): DocumentKeyReference<firestore.DocumentData> {\n    const resourcePath = ResourcePath.fromString(name);\n    hardAssert(\n      isValidResourceName(resourcePath),\n      'ReferenceValue is not valid ' + name\n    );\n    const databaseId = new DatabaseId(resourcePath.get(1), resourcePath.get(3));\n    const key = new DocumentKey(resourcePath.popFirst(5));\n\n    if (!databaseId.isEqual(this.databaseId)) {\n      // TODO(b/64130202): Somehow support foreign references.\n      logError(\n        `Document ${key} contains a document ` +\n          `reference within a different database (` +\n          `${databaseId.projectId}/${databaseId.database}) which is not ` +\n          `supported. It will be treated as a reference in the current ` +\n          `database (${this.databaseId.projectId}/${this.databaseId.database}) ` +\n          `instead.`\n      );\n    }\n\n    return this.referenceFactory(key);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as firestore from '@firebase/firestore-types';\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { FirebaseApp } from '@firebase/app-types';\nimport { _FirebaseApp, FirebaseService } from '@firebase/app-types/private';\nimport { DatabaseId, DatabaseInfo } from '../core/database_info';\nimport { ListenOptions } from '../core/event_manager';\nimport {\n  MemoryOfflineComponentProvider,\n  OfflineComponentProvider,\n  OnlineComponentProvider\n} from '../core/component_provider';\nimport { FirestoreClient, PersistenceSettings } from '../core/firestore_client';\nimport {\n  Bound,\n  Direction,\n  FieldFilter,\n  Filter,\n  isCollectionGroupQuery,\n  LimitType,\n  newQueryComparator,\n  newQueryForCollectionGroup,\n  newQueryForPath,\n  Operator,\n  OrderBy,\n  Query as InternalQuery,\n  queryEquals,\n  queryOrderBy,\n  queryWithAddedFilter,\n  queryWithAddedOrderBy,\n  queryWithEndAt,\n  queryWithLimit,\n  queryWithStartAt\n} from '../core/query';\nimport { Transaction as InternalTransaction } from '../core/transaction';\nimport { ChangeType, ViewSnapshot } from '../core/view_snapshot';\nimport { LruParams } from '../local/lru_garbage_collector';\nimport { Document, MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { DeleteMutation, Mutation, Precondition } from '../model/mutation';\nimport { FieldPath, ResourcePath } from '../model/path';\nimport { isServerTimestamp } from '../model/server_timestamps';\nimport { refValue } from '../model/values';\nimport { debugAssert, fail } from '../util/assert';\nimport { AsyncQueue } from '../util/async_queue';\nimport { Code, FirestoreError } from '../util/error';\nimport {\n  invalidClassError,\n  validateArgType,\n  validateAtLeastNumberOfArgs,\n  validateBetweenNumberOfArgs,\n  validateDefined,\n  validateExactNumberOfArgs,\n  validateNamedOptionalPropertyEquals,\n  validateNamedOptionalType,\n  validateNamedType,\n  validateOptionalArgType,\n  validateOptionalArrayElements,\n  validateOptionNames,\n  validatePositiveNumber,\n  validateStringEnum,\n  valueDescription\n} from '../util/input_validation';\nimport { getLogLevel, logError, LogLevel, setLogLevel } from '../util/log';\nimport { AutoId } from '../util/misc';\nimport { Deferred } from '../util/promise';\nimport { FieldPath as ExternalFieldPath } from './field_path';\nimport {\n  CredentialsProvider,\n  CredentialsSettings,\n  EmptyCredentialsProvider,\n  FirebaseCredentialsProvider,\n  makeCredentialsProvider\n} from './credentials';\nimport {\n  CompleteFn,\n  ErrorFn,\n  isPartialObserver,\n  NextFn,\n  PartialObserver,\n  Unsubscribe\n} from './observer';\nimport {\n  DocumentKeyReference,\n  fieldPathFromArgument,\n  parseQueryValue,\n  parseSetData,\n  parseUpdateData,\n  parseUpdateVarargs,\n  UntypedFirestoreDataConverter,\n  UserDataReader\n} from './user_data_reader';\nimport { UserDataWriter } from './user_data_writer';\nimport { FirebaseAuthInternalName } from '@firebase/auth-interop-types';\nimport { Provider } from '@firebase/component';\n\n// settings() defaults:\nconst DEFAULT_HOST = 'firestore.googleapis.com';\nconst DEFAULT_SSL = true;\nconst DEFAULT_TIMESTAMPS_IN_SNAPSHOTS = true;\nconst DEFAULT_FORCE_LONG_POLLING = false;\nconst DEFAULT_IGNORE_UNDEFINED_PROPERTIES = false;\n\n/**\n * Constant used to indicate the LRU garbage collection should be disabled.\n * Set this value as the `cacheSizeBytes` on the settings passed to the\n * `Firestore` instance.\n */\nexport const CACHE_SIZE_UNLIMITED = LruParams.COLLECTION_DISABLED;\n\n// enablePersistence() defaults:\nconst DEFAULT_SYNCHRONIZE_TABS = false;\n\n/** Undocumented, private additional settings not exposed in our public API. */\ninterface PrivateSettings extends firestore.Settings {\n  // Can be a google-auth-library or gapi client.\n  credentials?: CredentialsSettings;\n}\n\n/**\n * Options that can be provided in the Firestore constructor when not using\n * Firebase (aka standalone mode).\n */\nexport interface FirestoreDatabase {\n  projectId: string;\n  database?: string;\n}\n\n/**\n * A concrete type describing all the values that can be applied via a\n * user-supplied firestore.Settings object. This is a separate type so that\n * defaults can be supplied and the value can be checked for equality.\n */\nclass FirestoreSettings {\n  /** The hostname to connect to. */\n  readonly host: string;\n\n  /** Whether to use SSL when connecting. */\n  readonly ssl: boolean;\n\n  readonly timestampsInSnapshots: boolean;\n\n  readonly cacheSizeBytes: number;\n\n  readonly forceLongPolling: boolean;\n\n  readonly ignoreUndefinedProperties: boolean;\n\n  // Can be a google-auth-library or gapi client.\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  credentials?: any;\n\n  constructor(settings: PrivateSettings) {\n    if (settings.host === undefined) {\n      if (settings.ssl !== undefined) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          \"Can't provide ssl option if host option is not set\"\n        );\n      }\n      this.host = DEFAULT_HOST;\n      this.ssl = DEFAULT_SSL;\n    } else {\n      validateNamedType('settings', 'non-empty string', 'host', settings.host);\n      this.host = settings.host;\n\n      validateNamedOptionalType('settings', 'boolean', 'ssl', settings.ssl);\n      this.ssl = settings.ssl ?? DEFAULT_SSL;\n    }\n    validateOptionNames('settings', settings, [\n      'host',\n      'ssl',\n      'credentials',\n      'timestampsInSnapshots',\n      'cacheSizeBytes',\n      'experimentalForceLongPolling',\n      'ignoreUndefinedProperties'\n    ]);\n\n    validateNamedOptionalType(\n      'settings',\n      'object',\n      'credentials',\n      settings.credentials\n    );\n    this.credentials = settings.credentials;\n\n    validateNamedOptionalType(\n      'settings',\n      'boolean',\n      'timestampsInSnapshots',\n      settings.timestampsInSnapshots\n    );\n\n    validateNamedOptionalType(\n      'settings',\n      'boolean',\n      'ignoreUndefinedProperties',\n      settings.ignoreUndefinedProperties\n    );\n\n    // Nobody should set timestampsInSnapshots anymore, but the error depends on\n    // whether they set it to true or false...\n    if (settings.timestampsInSnapshots === true) {\n      logError(\n        \"The setting 'timestampsInSnapshots: true' is no longer required \" +\n          'and should be removed.'\n      );\n    } else if (settings.timestampsInSnapshots === false) {\n      logError(\n        \"Support for 'timestampsInSnapshots: false' will be removed soon. \" +\n          'You must update your code to handle Timestamp objects.'\n      );\n    }\n    this.timestampsInSnapshots =\n      settings.timestampsInSnapshots ?? DEFAULT_TIMESTAMPS_IN_SNAPSHOTS;\n    this.ignoreUndefinedProperties =\n      settings.ignoreUndefinedProperties ?? DEFAULT_IGNORE_UNDEFINED_PROPERTIES;\n\n    validateNamedOptionalType(\n      'settings',\n      'number',\n      'cacheSizeBytes',\n      settings.cacheSizeBytes\n    );\n    if (settings.cacheSizeBytes === undefined) {\n      this.cacheSizeBytes = LruParams.DEFAULT_CACHE_SIZE_BYTES;\n    } else {\n      if (\n        settings.cacheSizeBytes !== CACHE_SIZE_UNLIMITED &&\n        settings.cacheSizeBytes < LruParams.MINIMUM_CACHE_SIZE_BYTES\n      ) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `cacheSizeBytes must be at least ${LruParams.MINIMUM_CACHE_SIZE_BYTES}`\n        );\n      } else {\n        this.cacheSizeBytes = settings.cacheSizeBytes;\n      }\n    }\n\n    validateNamedOptionalType(\n      'settings',\n      'boolean',\n      'experimentalForceLongPolling',\n      settings.experimentalForceLongPolling\n    );\n    this.forceLongPolling =\n      settings.experimentalForceLongPolling ?? DEFAULT_FORCE_LONG_POLLING;\n  }\n\n  isEqual(other: FirestoreSettings): boolean {\n    return (\n      this.host === other.host &&\n      this.ssl === other.ssl &&\n      this.timestampsInSnapshots === other.timestampsInSnapshots &&\n      this.credentials === other.credentials &&\n      this.cacheSizeBytes === other.cacheSizeBytes &&\n      this.forceLongPolling === other.forceLongPolling &&\n      this.ignoreUndefinedProperties === other.ignoreUndefinedProperties\n    );\n  }\n}\n\n/**\n * The root reference to the database.\n */\nexport class Firestore implements firestore.FirebaseFirestore, FirebaseService {\n  // The objects that are a part of this API are exposed to third-parties as\n  // compiled javascript so we want to flag our private members with a leading\n  // underscore to discourage their use.\n  readonly _databaseId: DatabaseId;\n  private readonly _persistenceKey: string;\n  private _credentials: CredentialsProvider;\n  private readonly _firebaseApp: FirebaseApp | null = null;\n  private _settings: FirestoreSettings;\n\n  // The firestore client instance. This will be available as soon as\n  // configureClient is called, but any calls against it will block until\n  // setup has completed.\n  //\n  // Operations on the _firestoreClient don't block on _firestoreReady. Those\n  // are already set to synchronize on the async queue.\n  private _firestoreClient: FirestoreClient | undefined;\n\n  // Public for use in tests.\n  // TODO(mikelehen): Use modularized initialization instead.\n  readonly _queue = new AsyncQueue();\n\n  _userDataReader: UserDataReader | undefined;\n\n  // Note: We are using `MemoryComponentProvider` as a default\n  // ComponentProvider to ensure backwards compatibility with the format\n  // expected by the console build.\n  constructor(\n    databaseIdOrApp: FirestoreDatabase | FirebaseApp,\n    authProvider: Provider<FirebaseAuthInternalName>,\n    private _offlineComponentProvider: OfflineComponentProvider = new MemoryOfflineComponentProvider(),\n    private _onlineComponentProvider = new OnlineComponentProvider()\n  ) {\n    if (typeof (databaseIdOrApp as FirebaseApp).options === 'object') {\n      // This is very likely a Firebase app object\n      // TODO(b/34177605): Can we somehow use instanceof?\n      const app = databaseIdOrApp as FirebaseApp;\n      this._firebaseApp = app;\n      this._databaseId = Firestore.databaseIdFromApp(app);\n      this._persistenceKey = app.name;\n      this._credentials = new FirebaseCredentialsProvider(authProvider);\n    } else {\n      const external = databaseIdOrApp as FirestoreDatabase;\n      if (!external.projectId) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          'Must provide projectId'\n        );\n      }\n\n      this._databaseId = new DatabaseId(external.projectId, external.database);\n      // Use a default persistenceKey that lines up with FirebaseApp.\n      this._persistenceKey = '[DEFAULT]';\n      this._credentials = new EmptyCredentialsProvider();\n    }\n\n    this._settings = new FirestoreSettings({});\n  }\n\n  get _dataReader(): UserDataReader {\n    debugAssert(\n      !!this._firestoreClient,\n      'Cannot obtain UserDataReader before instance is intitialized'\n    );\n    if (!this._userDataReader) {\n      // Lazy initialize UserDataReader once the settings are frozen\n      this._userDataReader = new UserDataReader(\n        this._databaseId,\n        this._settings.ignoreUndefinedProperties\n      );\n    }\n    return this._userDataReader;\n  }\n\n  settings(settingsLiteral: firestore.Settings): void {\n    validateExactNumberOfArgs('Firestore.settings', arguments, 1);\n    validateArgType('Firestore.settings', 'object', 1, settingsLiteral);\n\n    const newSettings = new FirestoreSettings(settingsLiteral);\n    if (this._firestoreClient && !this._settings.isEqual(newSettings)) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        'Firestore has already been started and its settings can no longer ' +\n          'be changed. You can only call settings() before calling any other ' +\n          'methods on a Firestore object.'\n      );\n    }\n\n    this._settings = newSettings;\n    if (newSettings.credentials !== undefined) {\n      this._credentials = makeCredentialsProvider(newSettings.credentials);\n    }\n  }\n\n  enableNetwork(): Promise<void> {\n    this.ensureClientConfigured();\n    return this._firestoreClient!.enableNetwork();\n  }\n\n  disableNetwork(): Promise<void> {\n    this.ensureClientConfigured();\n    return this._firestoreClient!.disableNetwork();\n  }\n\n  enablePersistence(settings?: firestore.PersistenceSettings): Promise<void> {\n    if (this._firestoreClient) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        'Firestore has already been started and persistence can no longer ' +\n          'be enabled. You can only call enablePersistence() before calling ' +\n          'any other methods on a Firestore object.'\n      );\n    }\n\n    let synchronizeTabs = false;\n    let experimentalForceOwningTab = false;\n\n    if (settings) {\n      if (settings.experimentalTabSynchronization !== undefined) {\n        logError(\n          \"The 'experimentalTabSynchronization' setting will be removed. Use 'synchronizeTabs' instead.\"\n        );\n      }\n      synchronizeTabs =\n        settings.synchronizeTabs ??\n        settings.experimentalTabSynchronization ??\n        DEFAULT_SYNCHRONIZE_TABS;\n\n      experimentalForceOwningTab = settings.experimentalForceOwningTab\n        ? settings.experimentalForceOwningTab\n        : false;\n\n      if (synchronizeTabs && experimentalForceOwningTab) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          \"The 'experimentalForceOwningTab' setting cannot be used with 'synchronizeTabs'.\"\n        );\n      }\n    }\n\n    return this.configureClient(\n      this._offlineComponentProvider,\n      this._onlineComponentProvider,\n      {\n        durable: true,\n        cacheSizeBytes: this._settings.cacheSizeBytes,\n        synchronizeTabs,\n        forceOwningTab: experimentalForceOwningTab\n      }\n    );\n  }\n\n  async clearPersistence(): Promise<void> {\n    if (\n      this._firestoreClient !== undefined &&\n      !this._firestoreClient.clientTerminated\n    ) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        'Persistence can only be cleared before a Firestore instance is ' +\n          'initialized or after it is terminated.'\n      );\n    }\n\n    const deferred = new Deferred<void>();\n    this._queue.enqueueAndForgetEvenAfterShutdown(async () => {\n      try {\n        await this._offlineComponentProvider.clearPersistence(\n          this._databaseId,\n          this._persistenceKey\n        );\n        deferred.resolve();\n      } catch (e) {\n        deferred.reject(e);\n      }\n    });\n    return deferred.promise;\n  }\n\n  terminate(): Promise<void> {\n    (this.app as _FirebaseApp)._removeServiceInstance('firestore');\n    return this.INTERNAL.delete();\n  }\n\n  get _isTerminated(): boolean {\n    this.ensureClientConfigured();\n    return this._firestoreClient!.clientTerminated;\n  }\n\n  waitForPendingWrites(): Promise<void> {\n    this.ensureClientConfigured();\n    return this._firestoreClient!.waitForPendingWrites();\n  }\n\n  onSnapshotsInSync(observer: PartialObserver<void>): Unsubscribe;\n  onSnapshotsInSync(onSync: () => void): Unsubscribe;\n  onSnapshotsInSync(arg: unknown): Unsubscribe {\n    this.ensureClientConfigured();\n\n    if (isPartialObserver(arg)) {\n      return this._firestoreClient!.addSnapshotsInSyncListener(\n        arg as PartialObserver<void>\n      );\n    } else {\n      validateArgType('Firestore.onSnapshotsInSync', 'function', 1, arg);\n      const observer: PartialObserver<void> = {\n        next: arg as () => void\n      };\n      return this._firestoreClient!.addSnapshotsInSyncListener(observer);\n    }\n  }\n\n  ensureClientConfigured(): FirestoreClient {\n    if (!this._firestoreClient) {\n      // Kick off starting the client but don't actually wait for it.\n      // eslint-disable-next-line @typescript-eslint/no-floating-promises\n      this.configureClient(\n        new MemoryOfflineComponentProvider(),\n        new OnlineComponentProvider(),\n        {\n          durable: false\n        }\n      );\n    }\n    return this._firestoreClient as FirestoreClient;\n  }\n\n  private makeDatabaseInfo(): DatabaseInfo {\n    return new DatabaseInfo(\n      this._databaseId,\n      this._persistenceKey,\n      this._settings.host,\n      this._settings.ssl,\n      this._settings.forceLongPolling\n    );\n  }\n\n  private configureClient(\n    offlineComponentProvider: OfflineComponentProvider,\n    onlineComponentProvider: OnlineComponentProvider,\n    persistenceSettings: PersistenceSettings\n  ): Promise<void> {\n    debugAssert(!!this._settings.host, 'FirestoreSettings.host is not set');\n\n    debugAssert(\n      !this._firestoreClient,\n      'configureClient() called multiple times'\n    );\n\n    const databaseInfo = this.makeDatabaseInfo();\n\n    this._firestoreClient = new FirestoreClient(this._credentials, this._queue);\n\n    return this._firestoreClient.start(\n      databaseInfo,\n      offlineComponentProvider,\n      onlineComponentProvider,\n      persistenceSettings\n    );\n  }\n\n  private static databaseIdFromApp(app: FirebaseApp): DatabaseId {\n    if (!contains(app.options, 'projectId')) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        '\"projectId\" not provided in firebase.initializeApp.'\n      );\n    }\n\n    const projectId = app.options.projectId;\n    if (!projectId || typeof projectId !== 'string') {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'projectId must be a string in FirebaseApp.options'\n      );\n    }\n    return new DatabaseId(projectId);\n  }\n\n  get app(): FirebaseApp {\n    if (!this._firebaseApp) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        \"Firestore was not initialized using the Firebase SDK. 'app' is \" +\n          'not available'\n      );\n    }\n    return this._firebaseApp;\n  }\n\n  INTERNAL = {\n    delete: async (): Promise<void> => {\n      // The client must be initalized to ensure that all subsequent API usage\n      // throws an exception.\n      this.ensureClientConfigured();\n      await this._firestoreClient!.terminate();\n    }\n  };\n\n  collection(pathString: string): firestore.CollectionReference {\n    validateExactNumberOfArgs('Firestore.collection', arguments, 1);\n    validateArgType('Firestore.collection', 'non-empty string', 1, pathString);\n    this.ensureClientConfigured();\n    return new CollectionReference(\n      ResourcePath.fromString(pathString),\n      this,\n      /* converter= */ null\n    );\n  }\n\n  doc(pathString: string): firestore.DocumentReference {\n    validateExactNumberOfArgs('Firestore.doc', arguments, 1);\n    validateArgType('Firestore.doc', 'non-empty string', 1, pathString);\n    this.ensureClientConfigured();\n    return DocumentReference.forPath(\n      ResourcePath.fromString(pathString),\n      this,\n      /* converter= */ null\n    );\n  }\n\n  collectionGroup(collectionId: string): firestore.Query {\n    validateExactNumberOfArgs('Firestore.collectionGroup', arguments, 1);\n    validateArgType(\n      'Firestore.collectionGroup',\n      'non-empty string',\n      1,\n      collectionId\n    );\n    if (collectionId.indexOf('/') >= 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid collection ID '${collectionId}' passed to function ` +\n          `Firestore.collectionGroup(). Collection IDs must not contain '/'.`\n      );\n    }\n    this.ensureClientConfigured();\n    return new Query(\n      newQueryForCollectionGroup(collectionId),\n      this,\n      /* converter= */ null\n    );\n  }\n\n  runTransaction<T>(\n    updateFunction: (transaction: firestore.Transaction) => Promise<T>\n  ): Promise<T> {\n    validateExactNumberOfArgs('Firestore.runTransaction', arguments, 1);\n    validateArgType('Firestore.runTransaction', 'function', 1, updateFunction);\n    return this.ensureClientConfigured().transaction(\n      (transaction: InternalTransaction) => {\n        return updateFunction(new Transaction(this, transaction));\n      }\n    );\n  }\n\n  batch(): firestore.WriteBatch {\n    this.ensureClientConfigured();\n\n    return new WriteBatch(this);\n  }\n\n  static get logLevel(): firestore.LogLevel {\n    switch (getLogLevel()) {\n      case LogLevel.DEBUG:\n        return 'debug';\n      case LogLevel.ERROR:\n        return 'error';\n      case LogLevel.SILENT:\n        return 'silent';\n      case LogLevel.WARN:\n        return 'warn';\n      case LogLevel.INFO:\n        return 'info';\n      case LogLevel.VERBOSE:\n        return 'verbose';\n      default:\n        // The default log level is error\n        return 'error';\n    }\n  }\n\n  static setLogLevel(level: firestore.LogLevel): void {\n    validateExactNumberOfArgs('Firestore.setLogLevel', arguments, 1);\n    validateStringEnum(\n      'setLogLevel',\n      ['debug', 'error', 'silent', 'warn', 'info', 'verbose'],\n      1,\n      level\n    );\n    setLogLevel(level);\n  }\n\n  // Note: this is not a property because the minifier can't work correctly with\n  // the way TypeScript compiler outputs properties.\n  _areTimestampsInSnapshotsEnabled(): boolean {\n    return this._settings.timestampsInSnapshots;\n  }\n}\n\n/**\n * A reference to a transaction.\n */\nexport class Transaction implements firestore.Transaction {\n  constructor(\n    private _firestore: Firestore,\n    private _transaction: InternalTransaction\n  ) {}\n\n  get<T>(\n    documentRef: firestore.DocumentReference<T>\n  ): Promise<firestore.DocumentSnapshot<T>> {\n    validateExactNumberOfArgs('Transaction.get', arguments, 1);\n    const ref = validateReference(\n      'Transaction.get',\n      documentRef,\n      this._firestore\n    );\n    return this._transaction\n      .lookup([ref._key])\n      .then((docs: MaybeDocument[]) => {\n        if (!docs || docs.length !== 1) {\n          return fail('Mismatch in docs returned from document lookup.');\n        }\n        const doc = docs[0];\n        if (doc instanceof NoDocument) {\n          return new DocumentSnapshot<T>(\n            this._firestore,\n            ref._key,\n            null,\n            /* fromCache= */ false,\n            /* hasPendingWrites= */ false,\n            ref._converter\n          );\n        } else if (doc instanceof Document) {\n          return new DocumentSnapshot<T>(\n            this._firestore,\n            ref._key,\n            doc,\n            /* fromCache= */ false,\n            /* hasPendingWrites= */ false,\n            ref._converter\n          );\n        } else {\n          throw fail(\n            `BatchGetDocumentsRequest returned unexpected document type: ${doc.constructor.name}`\n          );\n        }\n      });\n  }\n\n  set<T>(\n    documentRef: DocumentReference<T>,\n    data: Partial<T>,\n    options: firestore.SetOptions\n  ): Transaction;\n  set<T>(documentRef: DocumentReference<T>, data: T): Transaction;\n  set<T>(\n    documentRef: firestore.DocumentReference<T>,\n    value: T | Partial<T>,\n    options?: firestore.SetOptions\n  ): Transaction {\n    validateBetweenNumberOfArgs('Transaction.set', arguments, 2, 3);\n    const ref = validateReference(\n      'Transaction.set',\n      documentRef,\n      this._firestore\n    );\n    options = validateSetOptions('Transaction.set', options);\n    const convertedValue = applyFirestoreDataConverter(\n      ref._converter,\n      value,\n      options\n    );\n    const parsed = parseSetData(\n      this._firestore._dataReader,\n      'Transaction.set',\n      ref._key,\n      convertedValue,\n      ref._converter !== null,\n      options\n    );\n    this._transaction.set(ref._key, parsed);\n    return this;\n  }\n\n  update(\n    documentRef: firestore.DocumentReference<unknown>,\n    value: firestore.UpdateData\n  ): Transaction;\n  update(\n    documentRef: firestore.DocumentReference<unknown>,\n    field: string | ExternalFieldPath,\n    value: unknown,\n    ...moreFieldsAndValues: unknown[]\n  ): Transaction;\n  update(\n    documentRef: firestore.DocumentReference<unknown>,\n    fieldOrUpdateData: string | ExternalFieldPath | firestore.UpdateData,\n    value?: unknown,\n    ...moreFieldsAndValues: unknown[]\n  ): Transaction {\n    let ref;\n    let parsed;\n\n    if (\n      typeof fieldOrUpdateData === 'string' ||\n      fieldOrUpdateData instanceof ExternalFieldPath\n    ) {\n      validateAtLeastNumberOfArgs('Transaction.update', arguments, 3);\n      ref = validateReference(\n        'Transaction.update',\n        documentRef,\n        this._firestore\n      );\n      parsed = parseUpdateVarargs(\n        this._firestore._dataReader,\n        'Transaction.update',\n        ref._key,\n        fieldOrUpdateData,\n        value,\n        moreFieldsAndValues\n      );\n    } else {\n      validateExactNumberOfArgs('Transaction.update', arguments, 2);\n      ref = validateReference(\n        'Transaction.update',\n        documentRef,\n        this._firestore\n      );\n      parsed = parseUpdateData(\n        this._firestore._dataReader,\n        'Transaction.update',\n        ref._key,\n        fieldOrUpdateData\n      );\n    }\n\n    this._transaction.update(ref._key, parsed);\n    return this;\n  }\n\n  delete(documentRef: firestore.DocumentReference<unknown>): Transaction {\n    validateExactNumberOfArgs('Transaction.delete', arguments, 1);\n    const ref = validateReference(\n      'Transaction.delete',\n      documentRef,\n      this._firestore\n    );\n    this._transaction.delete(ref._key);\n    return this;\n  }\n}\n\nexport class WriteBatch implements firestore.WriteBatch {\n  private _mutations = [] as Mutation[];\n  private _committed = false;\n\n  constructor(private _firestore: Firestore) {}\n\n  set<T>(\n    documentRef: DocumentReference<T>,\n    data: Partial<T>,\n    options: firestore.SetOptions\n  ): WriteBatch;\n  set<T>(documentRef: DocumentReference<T>, data: T): WriteBatch;\n  set<T>(\n    documentRef: firestore.DocumentReference<T>,\n    value: T | Partial<T>,\n    options?: firestore.SetOptions\n  ): WriteBatch {\n    validateBetweenNumberOfArgs('WriteBatch.set', arguments, 2, 3);\n    this.verifyNotCommitted();\n    const ref = validateReference(\n      'WriteBatch.set',\n      documentRef,\n      this._firestore\n    );\n    options = validateSetOptions('WriteBatch.set', options);\n    const convertedValue = applyFirestoreDataConverter(\n      ref._converter,\n      value,\n      options\n    );\n    const parsed = parseSetData(\n      this._firestore._dataReader,\n      'WriteBatch.set',\n      ref._key,\n      convertedValue,\n      ref._converter !== null,\n      options\n    );\n    this._mutations = this._mutations.concat(\n      parsed.toMutations(ref._key, Precondition.none())\n    );\n    return this;\n  }\n\n  update(\n    documentRef: firestore.DocumentReference<unknown>,\n    value: firestore.UpdateData\n  ): WriteBatch;\n  update(\n    documentRef: firestore.DocumentReference<unknown>,\n    field: string | ExternalFieldPath,\n    value: unknown,\n    ...moreFieldsAndValues: unknown[]\n  ): WriteBatch;\n  update(\n    documentRef: firestore.DocumentReference<unknown>,\n    fieldOrUpdateData: string | ExternalFieldPath | firestore.UpdateData,\n    value?: unknown,\n    ...moreFieldsAndValues: unknown[]\n  ): WriteBatch {\n    this.verifyNotCommitted();\n\n    let ref;\n    let parsed;\n\n    if (\n      typeof fieldOrUpdateData === 'string' ||\n      fieldOrUpdateData instanceof ExternalFieldPath\n    ) {\n      validateAtLeastNumberOfArgs('WriteBatch.update', arguments, 3);\n      ref = validateReference(\n        'WriteBatch.update',\n        documentRef,\n        this._firestore\n      );\n      parsed = parseUpdateVarargs(\n        this._firestore._dataReader,\n        'WriteBatch.update',\n        ref._key,\n        fieldOrUpdateData,\n        value,\n        moreFieldsAndValues\n      );\n    } else {\n      validateExactNumberOfArgs('WriteBatch.update', arguments, 2);\n      ref = validateReference(\n        'WriteBatch.update',\n        documentRef,\n        this._firestore\n      );\n      parsed = parseUpdateData(\n        this._firestore._dataReader,\n        'WriteBatch.update',\n        ref._key,\n        fieldOrUpdateData\n      );\n    }\n\n    this._mutations = this._mutations.concat(\n      parsed.toMutations(ref._key, Precondition.exists(true))\n    );\n    return this;\n  }\n\n  delete(documentRef: firestore.DocumentReference<unknown>): WriteBatch {\n    validateExactNumberOfArgs('WriteBatch.delete', arguments, 1);\n    this.verifyNotCommitted();\n    const ref = validateReference(\n      'WriteBatch.delete',\n      documentRef,\n      this._firestore\n    );\n    this._mutations = this._mutations.concat(\n      new DeleteMutation(ref._key, Precondition.none())\n    );\n    return this;\n  }\n\n  commit(): Promise<void> {\n    this.verifyNotCommitted();\n    this._committed = true;\n    if (this._mutations.length > 0) {\n      return this._firestore.ensureClientConfigured().write(this._mutations);\n    }\n\n    return Promise.resolve();\n  }\n\n  private verifyNotCommitted(): void {\n    if (this._committed) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        'A write batch can no longer be used after commit() ' +\n          'has been called.'\n      );\n    }\n  }\n}\n\n/**\n * A reference to a particular document in a collection in the database.\n */\nexport class DocumentReference<T = firestore.DocumentData>\n  extends DocumentKeyReference<T>\n  implements firestore.DocumentReference<T> {\n  private _firestoreClient: FirestoreClient;\n\n  constructor(\n    public _key: DocumentKey,\n    readonly firestore: Firestore,\n    readonly _converter: firestore.FirestoreDataConverter<T> | null\n  ) {\n    super(firestore._databaseId, _key, _converter);\n    this._firestoreClient = this.firestore.ensureClientConfigured();\n  }\n\n  static forPath<U>(\n    path: ResourcePath,\n    firestore: Firestore,\n    converter: firestore.FirestoreDataConverter<U> | null\n  ): DocumentReference<U> {\n    if (path.length % 2 !== 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Invalid document reference. Document ' +\n          'references must have an even number of segments, but ' +\n          `${path.canonicalString()} has ${path.length}`\n      );\n    }\n    return new DocumentReference(new DocumentKey(path), firestore, converter);\n  }\n\n  get id(): string {\n    return this._key.path.lastSegment();\n  }\n\n  get parent(): firestore.CollectionReference<T> {\n    return new CollectionReference(\n      this._key.path.popLast(),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  get path(): string {\n    return this._key.path.canonicalString();\n  }\n\n  collection(\n    pathString: string\n  ): firestore.CollectionReference<firestore.DocumentData> {\n    validateExactNumberOfArgs('DocumentReference.collection', arguments, 1);\n    validateArgType(\n      'DocumentReference.collection',\n      'non-empty string',\n      1,\n      pathString\n    );\n    if (!pathString) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Must provide a non-empty collection name to collection()'\n      );\n    }\n    const path = ResourcePath.fromString(pathString);\n    return new CollectionReference(\n      this._key.path.child(path),\n      this.firestore,\n      /* converter= */ null\n    );\n  }\n\n  isEqual(other: firestore.DocumentReference<T>): boolean {\n    if (!(other instanceof DocumentReference)) {\n      throw invalidClassError('isEqual', 'DocumentReference', 1, other);\n    }\n    return (\n      this.firestore === other.firestore &&\n      this._key.isEqual(other._key) &&\n      this._converter === other._converter\n    );\n  }\n\n  set(value: Partial<T>, options: firestore.SetOptions): Promise<void>;\n  set(value: T): Promise<void>;\n  set(value: T | Partial<T>, options?: firestore.SetOptions): Promise<void> {\n    validateBetweenNumberOfArgs('DocumentReference.set', arguments, 1, 2);\n    options = validateSetOptions('DocumentReference.set', options);\n    const convertedValue = applyFirestoreDataConverter(\n      this._converter,\n      value,\n      options\n    );\n    const parsed = parseSetData(\n      this.firestore._dataReader,\n      'DocumentReference.set',\n      this._key,\n      convertedValue,\n      this._converter !== null,\n      options\n    );\n    return this._firestoreClient.write(\n      parsed.toMutations(this._key, Precondition.none())\n    );\n  }\n\n  update(value: firestore.UpdateData): Promise<void>;\n  update(\n    field: string | ExternalFieldPath,\n    value: unknown,\n    ...moreFieldsAndValues: unknown[]\n  ): Promise<void>;\n  update(\n    fieldOrUpdateData: string | ExternalFieldPath | firestore.UpdateData,\n    value?: unknown,\n    ...moreFieldsAndValues: unknown[]\n  ): Promise<void> {\n    let parsed;\n\n    if (\n      typeof fieldOrUpdateData === 'string' ||\n      fieldOrUpdateData instanceof ExternalFieldPath\n    ) {\n      validateAtLeastNumberOfArgs('DocumentReference.update', arguments, 2);\n      parsed = parseUpdateVarargs(\n        this.firestore._dataReader,\n        'DocumentReference.update',\n        this._key,\n        fieldOrUpdateData,\n        value,\n        moreFieldsAndValues\n      );\n    } else {\n      validateExactNumberOfArgs('DocumentReference.update', arguments, 1);\n      parsed = parseUpdateData(\n        this.firestore._dataReader,\n        'DocumentReference.update',\n        this._key,\n        fieldOrUpdateData\n      );\n    }\n\n    return this._firestoreClient.write(\n      parsed.toMutations(this._key, Precondition.exists(true))\n    );\n  }\n\n  delete(): Promise<void> {\n    validateExactNumberOfArgs('DocumentReference.delete', arguments, 0);\n    return this._firestoreClient.write([\n      new DeleteMutation(this._key, Precondition.none())\n    ]);\n  }\n\n  onSnapshot(\n    observer: PartialObserver<firestore.DocumentSnapshot<T>>\n  ): Unsubscribe;\n  onSnapshot(\n    options: firestore.SnapshotListenOptions,\n    observer: PartialObserver<firestore.DocumentSnapshot<T>>\n  ): Unsubscribe;\n  onSnapshot(\n    onNext: NextFn<firestore.DocumentSnapshot<T>>,\n    onError?: ErrorFn,\n    onCompletion?: CompleteFn\n  ): Unsubscribe;\n  onSnapshot(\n    options: firestore.SnapshotListenOptions,\n    onNext: NextFn<firestore.DocumentSnapshot<T>>,\n    onError?: ErrorFn,\n    onCompletion?: CompleteFn\n  ): Unsubscribe;\n\n  onSnapshot(...args: unknown[]): Unsubscribe {\n    validateBetweenNumberOfArgs(\n      'DocumentReference.onSnapshot',\n      arguments,\n      1,\n      4\n    );\n    let options: ListenOptions = {\n      includeMetadataChanges: false\n    };\n    let currArg = 0;\n    if (\n      typeof args[currArg] === 'object' &&\n      !isPartialObserver(args[currArg])\n    ) {\n      options = args[currArg] as firestore.SnapshotListenOptions;\n      validateOptionNames('DocumentReference.onSnapshot', options, [\n        'includeMetadataChanges'\n      ]);\n      validateNamedOptionalType(\n        'DocumentReference.onSnapshot',\n        'boolean',\n        'includeMetadataChanges',\n        options.includeMetadataChanges\n      );\n      currArg++;\n    }\n\n    const internalOptions = {\n      includeMetadataChanges: options.includeMetadataChanges\n    };\n\n    if (isPartialObserver(args[currArg])) {\n      const userObserver = args[currArg] as PartialObserver<\n        firestore.DocumentSnapshot<T>\n      >;\n      args[currArg] = userObserver.next?.bind(userObserver);\n      args[currArg + 1] = userObserver.error?.bind(userObserver);\n      args[currArg + 2] = userObserver.complete?.bind(userObserver);\n    } else {\n      validateArgType(\n        'DocumentReference.onSnapshot',\n        'function',\n        currArg,\n        args[currArg]\n      );\n      validateOptionalArgType(\n        'DocumentReference.onSnapshot',\n        'function',\n        currArg + 1,\n        args[currArg + 1]\n      );\n      validateOptionalArgType(\n        'DocumentReference.onSnapshot',\n        'function',\n        currArg + 2,\n        args[currArg + 2]\n      );\n    }\n\n    const observer: PartialObserver<ViewSnapshot> = {\n      next: snapshot => {\n        if (args[currArg]) {\n          (args[currArg] as NextFn<firestore.DocumentSnapshot<T>>)(\n            this._convertToDocSnapshot(snapshot)\n          );\n        }\n      },\n      error: args[currArg + 1] as ErrorFn,\n      complete: args[currArg + 2] as CompleteFn\n    };\n\n    return this._firestoreClient.listen(\n      newQueryForPath(this._key.path),\n      internalOptions,\n      observer\n    );\n  }\n\n  get(options?: firestore.GetOptions): Promise<firestore.DocumentSnapshot<T>> {\n    validateBetweenNumberOfArgs('DocumentReference.get', arguments, 0, 1);\n    validateGetOptions('DocumentReference.get', options);\n\n    const firestoreClient = this.firestore.ensureClientConfigured();\n    if (options && options.source === 'cache') {\n      return firestoreClient\n        .getDocumentFromLocalCache(this._key)\n        .then(\n          doc =>\n            new DocumentSnapshot(\n              this.firestore,\n              this._key,\n              doc,\n              /*fromCache=*/ true,\n              doc instanceof Document ? doc.hasLocalMutations : false,\n              this._converter\n            )\n        );\n    } else {\n      return firestoreClient\n        .getDocumentViaSnapshotListener(this._key, options)\n        .then(snapshot => this._convertToDocSnapshot(snapshot));\n    }\n  }\n\n  withConverter<U>(\n    converter: firestore.FirestoreDataConverter<U>\n  ): firestore.DocumentReference<U> {\n    return new DocumentReference<U>(this._key, this.firestore, converter);\n  }\n\n  /**\n   * Converts a ViewSnapshot that contains the current document to a\n   * DocumentSnapshot.\n   */\n  private _convertToDocSnapshot(snapshot: ViewSnapshot): DocumentSnapshot<T> {\n    debugAssert(\n      snapshot.docs.size <= 1,\n      'Too many documents returned on a document query'\n    );\n    const doc = snapshot.docs.get(this._key);\n\n    return new DocumentSnapshot(\n      this.firestore,\n      this._key,\n      doc,\n      snapshot.fromCache,\n      snapshot.hasPendingWrites,\n      this._converter\n    );\n  }\n}\n\nexport class SnapshotMetadata implements firestore.SnapshotMetadata {\n  constructor(\n    readonly hasPendingWrites: boolean,\n    readonly fromCache: boolean\n  ) {}\n\n  isEqual(other: firestore.SnapshotMetadata): boolean {\n    return (\n      this.hasPendingWrites === other.hasPendingWrites &&\n      this.fromCache === other.fromCache\n    );\n  }\n}\n\n/**\n * Options interface that can be provided to configure the deserialization of\n * DocumentSnapshots.\n */\nexport interface SnapshotOptions extends firestore.SnapshotOptions {}\n\nexport class DocumentSnapshot<T = firestore.DocumentData>\n  implements firestore.DocumentSnapshot<T> {\n  constructor(\n    private _firestore: Firestore,\n    private _key: DocumentKey,\n    public _document: Document | null,\n    private _fromCache: boolean,\n    private _hasPendingWrites: boolean,\n    private readonly _converter: firestore.FirestoreDataConverter<T> | null\n  ) {}\n\n  data(options?: firestore.SnapshotOptions): T | undefined {\n    validateBetweenNumberOfArgs('DocumentSnapshot.data', arguments, 0, 1);\n    options = validateSnapshotOptions('DocumentSnapshot.data', options);\n    if (!this._document) {\n      return undefined;\n    } else {\n      // We only want to use the converter and create a new DocumentSnapshot\n      // if a converter has been provided.\n      if (this._converter) {\n        const snapshot = new QueryDocumentSnapshot(\n          this._firestore,\n          this._key,\n          this._document,\n          this._fromCache,\n          this._hasPendingWrites,\n          /* converter= */ null\n        );\n        return this._converter.fromFirestore(snapshot, options);\n      } else {\n        const userDataWriter = new UserDataWriter(\n          this._firestore._databaseId,\n          this._firestore._areTimestampsInSnapshotsEnabled(),\n          options.serverTimestamps || 'none',\n          key =>\n            new DocumentReference(key, this._firestore, /* converter= */ null)\n        );\n        return userDataWriter.convertValue(this._document.toProto()) as T;\n      }\n    }\n  }\n\n  get(\n    fieldPath: string | ExternalFieldPath,\n    options?: firestore.SnapshotOptions\n  ): unknown {\n    validateBetweenNumberOfArgs('DocumentSnapshot.get', arguments, 1, 2);\n    options = validateSnapshotOptions('DocumentSnapshot.get', options);\n    if (this._document) {\n      const value = this._document\n        .data()\n        .field(\n          fieldPathFromArgument('DocumentSnapshot.get', fieldPath, this._key)\n        );\n      if (value !== null) {\n        const userDataWriter = new UserDataWriter(\n          this._firestore._databaseId,\n          this._firestore._areTimestampsInSnapshotsEnabled(),\n          options.serverTimestamps || 'none',\n          key => new DocumentReference(key, this._firestore, this._converter)\n        );\n        return userDataWriter.convertValue(value);\n      }\n    }\n    return undefined;\n  }\n\n  get id(): string {\n    return this._key.path.lastSegment();\n  }\n\n  get ref(): firestore.DocumentReference<T> {\n    return new DocumentReference<T>(\n      this._key,\n      this._firestore,\n      this._converter\n    );\n  }\n\n  get exists(): boolean {\n    return this._document !== null;\n  }\n\n  get metadata(): firestore.SnapshotMetadata {\n    return new SnapshotMetadata(this._hasPendingWrites, this._fromCache);\n  }\n\n  isEqual(other: firestore.DocumentSnapshot<T>): boolean {\n    if (!(other instanceof DocumentSnapshot)) {\n      throw invalidClassError('isEqual', 'DocumentSnapshot', 1, other);\n    }\n    return (\n      this._firestore === other._firestore &&\n      this._fromCache === other._fromCache &&\n      this._key.isEqual(other._key) &&\n      (this._document === null\n        ? other._document === null\n        : this._document.isEqual(other._document)) &&\n      this._converter === other._converter\n    );\n  }\n}\n\nexport class QueryDocumentSnapshot<T = firestore.DocumentData>\n  extends DocumentSnapshot<T>\n  implements firestore.QueryDocumentSnapshot<T> {\n  data(options?: SnapshotOptions): T {\n    const data = super.data(options);\n    debugAssert(\n      data !== undefined,\n      'Document in a QueryDocumentSnapshot should exist'\n    );\n    return data;\n  }\n}\n\nexport function newQueryFilter(\n  query: InternalQuery,\n  methodName: string,\n  dataReader: UserDataReader,\n  databaseId: DatabaseId,\n  fieldPath: FieldPath,\n  op: Operator,\n  value: unknown\n): FieldFilter {\n  let fieldValue: api.Value;\n  if (fieldPath.isKeyField()) {\n    if (op === Operator.ARRAY_CONTAINS || op === Operator.ARRAY_CONTAINS_ANY) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid Query. You can't perform '${op}' ` +\n          'queries on FieldPath.documentId().'\n      );\n    } else if (op === Operator.IN || op === Operator.NOT_IN) {\n      validateDisjunctiveFilterElements(value, op);\n      const referenceList: api.Value[] = [];\n      for (const arrayValue of value as api.Value[]) {\n        referenceList.push(parseDocumentIdValue(databaseId, query, arrayValue));\n      }\n      fieldValue = { arrayValue: { values: referenceList } };\n    } else {\n      fieldValue = parseDocumentIdValue(databaseId, query, value);\n    }\n  } else {\n    if (\n      op === Operator.IN ||\n      op === Operator.NOT_IN ||\n      op === Operator.ARRAY_CONTAINS_ANY\n    ) {\n      validateDisjunctiveFilterElements(value, op);\n    }\n    fieldValue = parseQueryValue(\n      dataReader,\n      methodName,\n      value,\n      /* allowArrays= */ op === Operator.IN || op === Operator.NOT_IN\n    );\n  }\n  const filter = FieldFilter.create(fieldPath, op, fieldValue);\n  validateNewFilter(query, filter);\n  return filter;\n}\n\nexport function newQueryOrderBy(\n  query: InternalQuery,\n  fieldPath: FieldPath,\n  direction: Direction\n): OrderBy {\n  if (query.startAt !== null) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      'Invalid query. You must not call startAt() or startAfter() before ' +\n        'calling orderBy().'\n    );\n  }\n  if (query.endAt !== null) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      'Invalid query. You must not call endAt() or endBefore() before ' +\n        'calling orderBy().'\n    );\n  }\n  const orderBy = new OrderBy(fieldPath, direction);\n  validateNewOrderBy(query, orderBy);\n  return orderBy;\n}\n\n/**\n * Create a Bound from a query and a document.\n *\n * Note that the Bound will always include the key of the document\n * and so only the provided document will compare equal to the returned\n * position.\n *\n * Will throw if the document does not contain all fields of the order by\n * of the query or if any of the fields in the order by are an uncommitted\n * server timestamp.\n */\nexport function newQueryBoundFromDocument(\n  query: InternalQuery,\n  databaseId: DatabaseId,\n  methodName: string,\n  doc: Document | null,\n  before: boolean\n): Bound {\n  if (!doc) {\n    throw new FirestoreError(\n      Code.NOT_FOUND,\n      `Can't use a DocumentSnapshot that doesn't exist for ` +\n        `${methodName}().`\n    );\n  }\n\n  const components: api.Value[] = [];\n\n  // Because people expect to continue/end a query at the exact document\n  // provided, we need to use the implicit sort order rather than the explicit\n  // sort order, because it's guaranteed to contain the document key. That way\n  // the position becomes unambiguous and the query continues/ends exactly at\n  // the provided document. Without the key (by using the explicit sort\n  // orders), multiple documents could match the position, yielding duplicate\n  // results.\n  for (const orderBy of queryOrderBy(query)) {\n    if (orderBy.field.isKeyField()) {\n      components.push(refValue(databaseId, doc.key));\n    } else {\n      const value = doc.field(orderBy.field);\n      if (isServerTimestamp(value)) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          'Invalid query. You are trying to start or end a query using a ' +\n            'document for which the field \"' +\n            orderBy.field +\n            '\" is an uncommitted server timestamp. (Since the value of ' +\n            'this field is unknown, you cannot start/end a query with it.)'\n        );\n      } else if (value !== null) {\n        components.push(value);\n      } else {\n        const field = orderBy.field.canonicalString();\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `Invalid query. You are trying to start or end a query using a ` +\n            `document for which the field '${field}' (used as the ` +\n            `orderBy) does not exist.`\n        );\n      }\n    }\n  }\n  return new Bound(components, before);\n}\n\n/**\n * Converts a list of field values to a Bound for the given query.\n */\nexport function newQueryBoundFromFields(\n  query: InternalQuery,\n  databaseId: DatabaseId,\n  dataReader: UserDataReader,\n  methodName: string,\n  values: unknown[],\n  before: boolean\n): Bound {\n  // Use explicit order by's because it has to match the query the user made\n  const orderBy = query.explicitOrderBy;\n  if (values.length > orderBy.length) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Too many arguments provided to ${methodName}(). ` +\n        `The number of arguments must be less than or equal to the ` +\n        `number of orderBy() clauses`\n    );\n  }\n\n  const components: api.Value[] = [];\n  for (let i = 0; i < values.length; i++) {\n    const rawValue = values[i];\n    const orderByComponent = orderBy[i];\n    if (orderByComponent.field.isKeyField()) {\n      if (typeof rawValue !== 'string') {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `Invalid query. Expected a string for document ID in ` +\n            `${methodName}(), but got a ${typeof rawValue}`\n        );\n      }\n      if (!isCollectionGroupQuery(query) && rawValue.indexOf('/') !== -1) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `Invalid query. When querying a collection and ordering by FieldPath.documentId(), ` +\n            `the value passed to ${methodName}() must be a plain document ID, but ` +\n            `'${rawValue}' contains a slash.`\n        );\n      }\n      const path = query.path.child(ResourcePath.fromString(rawValue));\n      if (!DocumentKey.isDocumentKey(path)) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `Invalid query. When querying a collection group and ordering by ` +\n            `FieldPath.documentId(), the value passed to ${methodName}() must result in a ` +\n            `valid document path, but '${path}' is not because it contains an odd number ` +\n            `of segments.`\n        );\n      }\n      const key = new DocumentKey(path);\n      components.push(refValue(databaseId, key));\n    } else {\n      const wrapped = parseQueryValue(dataReader, methodName, rawValue);\n      components.push(wrapped);\n    }\n  }\n\n  return new Bound(components, before);\n}\n\n/**\n * Parses the given documentIdValue into a ReferenceValue, throwing\n * appropriate errors if the value is anything other than a DocumentReference\n * or String, or if the string is malformed.\n */\nfunction parseDocumentIdValue(\n  databaseId: DatabaseId,\n  query: InternalQuery,\n  documentIdValue: unknown\n): api.Value {\n  if (typeof documentIdValue === 'string') {\n    if (documentIdValue === '') {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Invalid query. When querying with FieldPath.documentId(), you ' +\n          'must provide a valid document ID, but it was an empty string.'\n      );\n    }\n    if (!isCollectionGroupQuery(query) && documentIdValue.indexOf('/') !== -1) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid query. When querying a collection by ` +\n          `FieldPath.documentId(), you must provide a plain document ID, but ` +\n          `'${documentIdValue}' contains a '/' character.`\n      );\n    }\n    const path = query.path.child(ResourcePath.fromString(documentIdValue));\n    if (!DocumentKey.isDocumentKey(path)) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid query. When querying a collection group by ` +\n          `FieldPath.documentId(), the value provided must result in a valid document path, ` +\n          `but '${path}' is not because it has an odd number of segments (${path.length}).`\n      );\n    }\n    return refValue(databaseId, new DocumentKey(path));\n  } else if (documentIdValue instanceof DocumentKeyReference) {\n    return refValue(databaseId, documentIdValue._key);\n  } else {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Invalid query. When querying with FieldPath.documentId(), you must provide a valid ` +\n        `string or a DocumentReference, but it was: ` +\n        `${valueDescription(documentIdValue)}.`\n    );\n  }\n}\n\n/**\n * Validates that the value passed into a disjunctive filter satisfies all\n * array requirements.\n */\nfunction validateDisjunctiveFilterElements(\n  value: unknown,\n  operator: Operator\n): void {\n  if (!Array.isArray(value) || value.length === 0) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      'Invalid Query. A non-empty array is required for ' +\n        `'${operator.toString()}' filters.`\n    );\n  }\n  if (value.length > 10) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Invalid Query. '${operator.toString()}' filters support a ` +\n        'maximum of 10 elements in the value array.'\n    );\n  }\n  if (operator === Operator.IN || operator === Operator.ARRAY_CONTAINS_ANY) {\n    if (value.indexOf(null) >= 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid Query. '${operator.toString()}' filters cannot contain 'null' ` +\n          'in the value array.'\n      );\n    }\n    if (value.filter(element => Number.isNaN(element)).length > 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid Query. '${operator.toString()}' filters cannot contain 'NaN' ` +\n          'in the value array.'\n      );\n    }\n  }\n}\n\n/**\n * Given an operator, returns the set of operators that cannot be used with it.\n *\n * Operators in a query must adhere to the following set of rules:\n * 1. Only one array operator is allowed.\n * 2. Only one disjunctive operator is allowed.\n * 3. NOT_EQUAL cannot be used with another NOT_EQUAL operator.\n * 4. NOT_IN cannot be used with array, disjunctive, or NOT_EQUAL operators.\n *\n * Array operators: ARRAY_CONTAINS, ARRAY_CONTAINS_ANY\n * Disjunctive operators: IN, ARRAY_CONTAINS_ANY, NOT_IN\n */\nfunction conflictingOps(op: Operator): Operator[] {\n  switch (op) {\n    case Operator.NOT_EQUAL:\n      return [Operator.NOT_EQUAL, Operator.NOT_IN];\n    case Operator.ARRAY_CONTAINS:\n      return [\n        Operator.ARRAY_CONTAINS,\n        Operator.ARRAY_CONTAINS_ANY,\n        Operator.NOT_IN\n      ];\n    case Operator.IN:\n      return [Operator.ARRAY_CONTAINS_ANY, Operator.IN, Operator.NOT_IN];\n    case Operator.ARRAY_CONTAINS_ANY:\n      return [\n        Operator.ARRAY_CONTAINS,\n        Operator.ARRAY_CONTAINS_ANY,\n        Operator.IN,\n        Operator.NOT_IN\n      ];\n    case Operator.NOT_IN:\n      return [\n        Operator.ARRAY_CONTAINS,\n        Operator.ARRAY_CONTAINS_ANY,\n        Operator.IN,\n        Operator.NOT_IN,\n        Operator.NOT_EQUAL\n      ];\n    default:\n      return [];\n  }\n}\n\nfunction validateNewFilter(query: InternalQuery, filter: Filter): void {\n  debugAssert(filter instanceof FieldFilter, 'Only FieldFilters are supported');\n\n  if (filter.isInequality()) {\n    const existingField = query.getInequalityFilterField();\n    if (existingField !== null && !existingField.isEqual(filter.field)) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Invalid query. All where filters with an inequality' +\n          ' (<, <=, >, or >=) must be on the same field. But you have' +\n          ` inequality filters on '${existingField.toString()}'` +\n          ` and '${filter.field.toString()}'`\n      );\n    }\n\n    const firstOrderByField = query.getFirstOrderByField();\n    if (firstOrderByField !== null) {\n      validateOrderByAndInequalityMatch(query, filter.field, firstOrderByField);\n    }\n  }\n\n  const conflictingOp = query.findFilterOperator(conflictingOps(filter.op));\n  if (conflictingOp !== null) {\n    // Special case when it's a duplicate op to give a slightly clearer error message.\n    if (conflictingOp === filter.op) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Invalid query. You cannot use more than one ' +\n          `'${filter.op.toString()}' filter.`\n      );\n    } else {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid query. You cannot use '${filter.op.toString()}' filters ` +\n          `with '${conflictingOp.toString()}' filters.`\n      );\n    }\n  }\n}\n\nfunction validateNewOrderBy(query: InternalQuery, orderBy: OrderBy): void {\n  if (query.getFirstOrderByField() === null) {\n    // This is the first order by. It must match any inequality.\n    const inequalityField = query.getInequalityFilterField();\n    if (inequalityField !== null) {\n      validateOrderByAndInequalityMatch(query, inequalityField, orderBy.field);\n    }\n  }\n}\n\nfunction validateOrderByAndInequalityMatch(\n  baseQuery: InternalQuery,\n  inequality: FieldPath,\n  orderBy: FieldPath\n): void {\n  if (!orderBy.isEqual(inequality)) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Invalid query. You have a where filter with an inequality ` +\n        `(<, <=, >, or >=) on field '${inequality.toString()}' ` +\n        `and so you must also use '${inequality.toString()}' ` +\n        `as your first orderBy(), but your first orderBy() ` +\n        `is on field '${orderBy.toString()}' instead.`\n    );\n  }\n}\n\nexport function validateHasExplicitOrderByForLimitToLast(\n  query: InternalQuery\n): void {\n  if (query.hasLimitToLast() && query.explicitOrderBy.length === 0) {\n    throw new FirestoreError(\n      Code.UNIMPLEMENTED,\n      'limitToLast() queries require specifying at least one orderBy() clause'\n    );\n  }\n}\n\nexport class Query<T = firestore.DocumentData> implements firestore.Query<T> {\n  constructor(\n    public _query: InternalQuery,\n    readonly firestore: Firestore,\n    protected readonly _converter: firestore.FirestoreDataConverter<T> | null\n  ) {}\n\n  where(\n    field: string | ExternalFieldPath,\n    opStr: firestore.WhereFilterOp,\n    value: unknown\n  ): firestore.Query<T> {\n    validateExactNumberOfArgs('Query.where', arguments, 3);\n    validateDefined('Query.where', 3, value);\n\n    // TODO(ne-queries): Add 'not-in' and '!=' to validation.\n    let op: Operator;\n    if ((opStr as unknown) === 'not-in' || (opStr as unknown) === '!=') {\n      op = opStr as Operator;\n    } else {\n      // Enumerated from the WhereFilterOp type in index.d.ts.\n      const whereFilterOpEnums = [\n        Operator.LESS_THAN,\n        Operator.LESS_THAN_OR_EQUAL,\n        Operator.EQUAL,\n        Operator.GREATER_THAN_OR_EQUAL,\n        Operator.GREATER_THAN,\n        Operator.ARRAY_CONTAINS,\n        Operator.IN,\n        Operator.ARRAY_CONTAINS_ANY\n      ];\n      op = validateStringEnum('Query.where', whereFilterOpEnums, 2, opStr);\n    }\n\n    const fieldPath = fieldPathFromArgument('Query.where', field);\n    const filter = newQueryFilter(\n      this._query,\n      'Query.where',\n      this.firestore._dataReader,\n      this.firestore._databaseId,\n      fieldPath,\n      op,\n      value\n    );\n    return new Query(\n      queryWithAddedFilter(this._query, filter),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  orderBy(\n    field: string | ExternalFieldPath,\n    directionStr?: firestore.OrderByDirection\n  ): firestore.Query<T> {\n    validateBetweenNumberOfArgs('Query.orderBy', arguments, 1, 2);\n    validateOptionalArgType(\n      'Query.orderBy',\n      'non-empty string',\n      2,\n      directionStr\n    );\n    let direction: Direction;\n    if (directionStr === undefined || directionStr === 'asc') {\n      direction = Direction.ASCENDING;\n    } else if (directionStr === 'desc') {\n      direction = Direction.DESCENDING;\n    } else {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Function Query.orderBy() has unknown direction '${directionStr}', ` +\n          `expected 'asc' or 'desc'.`\n      );\n    }\n    const fieldPath = fieldPathFromArgument('Query.orderBy', field);\n    const orderBy = newQueryOrderBy(this._query, fieldPath, direction);\n    return new Query(\n      queryWithAddedOrderBy(this._query, orderBy),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  limit(n: number): firestore.Query<T> {\n    validateExactNumberOfArgs('Query.limit', arguments, 1);\n    validateArgType('Query.limit', 'number', 1, n);\n    validatePositiveNumber('Query.limit', 1, n);\n    return new Query(\n      queryWithLimit(this._query, n, LimitType.First),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  limitToLast(n: number): firestore.Query<T> {\n    validateExactNumberOfArgs('Query.limitToLast', arguments, 1);\n    validateArgType('Query.limitToLast', 'number', 1, n);\n    validatePositiveNumber('Query.limitToLast', 1, n);\n    return new Query(\n      queryWithLimit(this._query, n, LimitType.Last),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  startAt(\n    docOrField: unknown | firestore.DocumentSnapshot<unknown>,\n    ...fields: unknown[]\n  ): firestore.Query<T> {\n    validateAtLeastNumberOfArgs('Query.startAt', arguments, 1);\n    const bound = this.boundFromDocOrFields(\n      'Query.startAt',\n      docOrField,\n      fields,\n      /*before=*/ true\n    );\n    return new Query(\n      queryWithStartAt(this._query, bound),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  startAfter(\n    docOrField: unknown | firestore.DocumentSnapshot<unknown>,\n    ...fields: unknown[]\n  ): firestore.Query<T> {\n    validateAtLeastNumberOfArgs('Query.startAfter', arguments, 1);\n    const bound = this.boundFromDocOrFields(\n      'Query.startAfter',\n      docOrField,\n      fields,\n      /*before=*/ false\n    );\n    return new Query(\n      queryWithStartAt(this._query, bound),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  endBefore(\n    docOrField: unknown | firestore.DocumentSnapshot<unknown>,\n    ...fields: unknown[]\n  ): firestore.Query<T> {\n    validateAtLeastNumberOfArgs('Query.endBefore', arguments, 1);\n    const bound = this.boundFromDocOrFields(\n      'Query.endBefore',\n      docOrField,\n      fields,\n      /*before=*/ true\n    );\n    return new Query(\n      queryWithEndAt(this._query, bound),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  endAt(\n    docOrField: unknown | firestore.DocumentSnapshot<unknown>,\n    ...fields: unknown[]\n  ): firestore.Query<T> {\n    validateAtLeastNumberOfArgs('Query.endAt', arguments, 1);\n    const bound = this.boundFromDocOrFields(\n      'Query.endAt',\n      docOrField,\n      fields,\n      /*before=*/ false\n    );\n    return new Query(\n      queryWithEndAt(this._query, bound),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  isEqual(other: firestore.Query<T>): boolean {\n    if (!(other instanceof Query)) {\n      throw invalidClassError('isEqual', 'Query', 1, other);\n    }\n    return (\n      this.firestore === other.firestore &&\n      queryEquals(this._query, other._query) &&\n      this._converter === other._converter\n    );\n  }\n\n  withConverter<U>(\n    converter: firestore.FirestoreDataConverter<U>\n  ): firestore.Query<U> {\n    return new Query<U>(this._query, this.firestore, converter);\n  }\n\n  /** Helper function to create a bound from a document or fields */\n  private boundFromDocOrFields(\n    methodName: string,\n    docOrField: unknown | firestore.DocumentSnapshot<T>,\n    fields: unknown[],\n    before: boolean\n  ): Bound {\n    validateDefined(methodName, 1, docOrField);\n    if (docOrField instanceof DocumentSnapshot) {\n      validateExactNumberOfArgs(methodName, [docOrField, ...fields], 1);\n      return newQueryBoundFromDocument(\n        this._query,\n        this.firestore._databaseId,\n        methodName,\n        docOrField._document,\n        before\n      );\n    } else {\n      const allFields = [docOrField].concat(fields);\n      return newQueryBoundFromFields(\n        this._query,\n        this.firestore._databaseId,\n        this.firestore._dataReader,\n        methodName,\n        allFields,\n        before\n      );\n    }\n  }\n\n  onSnapshot(\n    observer: PartialObserver<firestore.QuerySnapshot<T>>\n  ): Unsubscribe;\n  onSnapshot(\n    options: firestore.SnapshotListenOptions,\n    observer: PartialObserver<firestore.QuerySnapshot<T>>\n  ): Unsubscribe;\n  onSnapshot(\n    onNext: NextFn<firestore.QuerySnapshot<T>>,\n    onError?: ErrorFn,\n    onCompletion?: CompleteFn\n  ): Unsubscribe;\n  onSnapshot(\n    options: firestore.SnapshotListenOptions,\n    onNext: NextFn<firestore.QuerySnapshot<T>>,\n    onError?: ErrorFn,\n    onCompletion?: CompleteFn\n  ): Unsubscribe;\n\n  onSnapshot(...args: unknown[]): Unsubscribe {\n    validateBetweenNumberOfArgs('Query.onSnapshot', arguments, 1, 4);\n    let options: ListenOptions = {};\n    let currArg = 0;\n    if (\n      typeof args[currArg] === 'object' &&\n      !isPartialObserver(args[currArg])\n    ) {\n      options = args[currArg] as firestore.SnapshotListenOptions;\n      validateOptionNames('Query.onSnapshot', options, [\n        'includeMetadataChanges'\n      ]);\n      validateNamedOptionalType(\n        'Query.onSnapshot',\n        'boolean',\n        'includeMetadataChanges',\n        options.includeMetadataChanges\n      );\n      currArg++;\n    }\n\n    if (isPartialObserver(args[currArg])) {\n      const userObserver = args[currArg] as PartialObserver<\n        firestore.QuerySnapshot<T>\n      >;\n      args[currArg] = userObserver.next?.bind(userObserver);\n      args[currArg + 1] = userObserver.error?.bind(userObserver);\n      args[currArg + 2] = userObserver.complete?.bind(userObserver);\n    } else {\n      validateArgType('Query.onSnapshot', 'function', currArg, args[currArg]);\n      validateOptionalArgType(\n        'Query.onSnapshot',\n        'function',\n        currArg + 1,\n        args[currArg + 1]\n      );\n      validateOptionalArgType(\n        'Query.onSnapshot',\n        'function',\n        currArg + 2,\n        args[currArg + 2]\n      );\n    }\n\n    const observer: PartialObserver<ViewSnapshot> = {\n      next: snapshot => {\n        if (args[currArg]) {\n          (args[currArg] as NextFn<firestore.QuerySnapshot<T>>)(\n            new QuerySnapshot(\n              this.firestore,\n              this._query,\n              snapshot,\n              this._converter\n            )\n          );\n        }\n      },\n      error: args[currArg + 1] as ErrorFn,\n      complete: args[currArg + 2] as CompleteFn\n    };\n\n    validateHasExplicitOrderByForLimitToLast(this._query);\n    const firestoreClient = this.firestore.ensureClientConfigured();\n    return firestoreClient.listen(this._query, options, observer);\n  }\n\n  get(options?: firestore.GetOptions): Promise<firestore.QuerySnapshot<T>> {\n    validateBetweenNumberOfArgs('Query.get', arguments, 0, 1);\n    validateGetOptions('Query.get', options);\n    validateHasExplicitOrderByForLimitToLast(this._query);\n\n    const firestoreClient = this.firestore.ensureClientConfigured();\n    return (options && options.source === 'cache'\n      ? firestoreClient.getDocumentsFromLocalCache(this._query)\n      : firestoreClient.getDocumentsViaSnapshotListener(this._query, options)\n    ).then(\n      snap =>\n        new QuerySnapshot(this.firestore, this._query, snap, this._converter)\n    );\n  }\n}\n\nexport class QuerySnapshot<T = firestore.DocumentData>\n  implements firestore.QuerySnapshot<T> {\n  private _cachedChanges: Array<firestore.DocumentChange<T>> | null = null;\n  private _cachedChangesIncludeMetadataChanges: boolean | null = null;\n\n  readonly metadata: firestore.SnapshotMetadata;\n\n  constructor(\n    private readonly _firestore: Firestore,\n    private readonly _originalQuery: InternalQuery,\n    private readonly _snapshot: ViewSnapshot,\n    private readonly _converter: firestore.FirestoreDataConverter<T> | null\n  ) {\n    this.metadata = new SnapshotMetadata(\n      _snapshot.hasPendingWrites,\n      _snapshot.fromCache\n    );\n  }\n\n  get docs(): Array<firestore.QueryDocumentSnapshot<T>> {\n    const result: Array<firestore.QueryDocumentSnapshot<T>> = [];\n    this.forEach(doc => result.push(doc));\n    return result;\n  }\n\n  get empty(): boolean {\n    return this._snapshot.docs.isEmpty();\n  }\n\n  get size(): number {\n    return this._snapshot.docs.size;\n  }\n\n  forEach(\n    callback: (result: firestore.QueryDocumentSnapshot<T>) => void,\n    thisArg?: unknown\n  ): void {\n    validateBetweenNumberOfArgs('QuerySnapshot.forEach', arguments, 1, 2);\n    validateArgType('QuerySnapshot.forEach', 'function', 1, callback);\n    this._snapshot.docs.forEach(doc => {\n      callback.call(\n        thisArg,\n        this.convertToDocumentImpl(\n          doc,\n          this.metadata.fromCache,\n          this._snapshot.mutatedKeys.has(doc.key)\n        )\n      );\n    });\n  }\n\n  get query(): firestore.Query<T> {\n    return new Query(this._originalQuery, this._firestore, this._converter);\n  }\n\n  docChanges(\n    options?: firestore.SnapshotListenOptions\n  ): Array<firestore.DocumentChange<T>> {\n    if (options) {\n      validateOptionNames('QuerySnapshot.docChanges', options, [\n        'includeMetadataChanges'\n      ]);\n      validateNamedOptionalType(\n        'QuerySnapshot.docChanges',\n        'boolean',\n        'includeMetadataChanges',\n        options.includeMetadataChanges\n      );\n    }\n\n    const includeMetadataChanges = !!(\n      options && options.includeMetadataChanges\n    );\n\n    if (includeMetadataChanges && this._snapshot.excludesMetadataChanges) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'To include metadata changes with your document changes, you must ' +\n          'also pass { includeMetadataChanges:true } to onSnapshot().'\n      );\n    }\n\n    if (\n      !this._cachedChanges ||\n      this._cachedChangesIncludeMetadataChanges !== includeMetadataChanges\n    ) {\n      this._cachedChanges = changesFromSnapshot<QueryDocumentSnapshot<T>>(\n        this._snapshot,\n        includeMetadataChanges,\n        this.convertToDocumentImpl.bind(this)\n      );\n      this._cachedChangesIncludeMetadataChanges = includeMetadataChanges;\n    }\n\n    return this._cachedChanges;\n  }\n\n  /** Check the equality. The call can be very expensive. */\n  isEqual(other: firestore.QuerySnapshot<T>): boolean {\n    if (!(other instanceof QuerySnapshot)) {\n      throw invalidClassError('isEqual', 'QuerySnapshot', 1, other);\n    }\n\n    return (\n      this._firestore === other._firestore &&\n      queryEquals(this._originalQuery, other._originalQuery) &&\n      this._snapshot.isEqual(other._snapshot) &&\n      this._converter === other._converter\n    );\n  }\n\n  private convertToDocumentImpl(\n    doc: Document,\n    fromCache: boolean,\n    hasPendingWrites: boolean\n  ): QueryDocumentSnapshot<T> {\n    return new QueryDocumentSnapshot(\n      this._firestore,\n      doc.key,\n      doc,\n      fromCache,\n      hasPendingWrites,\n      this._converter\n    );\n  }\n}\n\nexport class CollectionReference<T = firestore.DocumentData> extends Query<T>\n  implements firestore.CollectionReference<T> {\n  constructor(\n    readonly _path: ResourcePath,\n    firestore: Firestore,\n    _converter: firestore.FirestoreDataConverter<T> | null\n  ) {\n    super(newQueryForPath(_path), firestore, _converter);\n    if (_path.length % 2 !== 1) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Invalid collection reference. Collection ' +\n          'references must have an odd number of segments, but ' +\n          `${_path.canonicalString()} has ${_path.length}`\n      );\n    }\n  }\n\n  get id(): string {\n    return this._query.path.lastSegment();\n  }\n\n  get parent(): firestore.DocumentReference<firestore.DocumentData> | null {\n    const parentPath = this._query.path.popLast();\n    if (parentPath.isEmpty()) {\n      return null;\n    } else {\n      return new DocumentReference<firestore.DocumentData>(\n        new DocumentKey(parentPath),\n        this.firestore,\n        /* converter= */ null\n      );\n    }\n  }\n\n  get path(): string {\n    return this._query.path.canonicalString();\n  }\n\n  doc(pathString?: string): firestore.DocumentReference<T> {\n    validateBetweenNumberOfArgs('CollectionReference.doc', arguments, 0, 1);\n    // We allow omission of 'pathString' but explicitly prohibit passing in both\n    // 'undefined' and 'null'.\n    if (arguments.length === 0) {\n      pathString = AutoId.newId();\n    }\n    validateArgType(\n      'CollectionReference.doc',\n      'non-empty string',\n      1,\n      pathString\n    );\n    const path = ResourcePath.fromString(pathString!);\n    return DocumentReference.forPath<T>(\n      this._query.path.child(path),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  add(value: T): Promise<firestore.DocumentReference<T>> {\n    validateExactNumberOfArgs('CollectionReference.add', arguments, 1);\n    const convertedValue = this._converter\n      ? this._converter.toFirestore(value)\n      : value;\n    validateArgType('CollectionReference.add', 'object', 1, convertedValue);\n    const docRef = this.doc();\n    return docRef.set(value).then(() => docRef);\n  }\n\n  withConverter<U>(\n    converter: firestore.FirestoreDataConverter<U>\n  ): firestore.CollectionReference<U> {\n    return new CollectionReference<U>(this._path, this.firestore, converter);\n  }\n}\n\nfunction validateSetOptions(\n  methodName: string,\n  options: firestore.SetOptions | undefined\n): firestore.SetOptions {\n  if (options === undefined) {\n    return {\n      merge: false\n    };\n  }\n\n  validateOptionNames(methodName, options, ['merge', 'mergeFields']);\n  validateNamedOptionalType(methodName, 'boolean', 'merge', options.merge);\n  validateOptionalArrayElements(\n    methodName,\n    'mergeFields',\n    'a string or a FieldPath',\n    options.mergeFields,\n    element =>\n      typeof element === 'string' || element instanceof ExternalFieldPath\n  );\n\n  if (options.mergeFields !== undefined && options.merge !== undefined) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Invalid options passed to function ${methodName}(): You cannot specify both \"merge\" ` +\n        `and \"mergeFields\".`\n    );\n  }\n\n  return options;\n}\n\nfunction validateSnapshotOptions(\n  methodName: string,\n  options: firestore.SnapshotOptions | undefined\n): firestore.SnapshotOptions {\n  if (options === undefined) {\n    return {};\n  }\n\n  validateOptionNames(methodName, options, ['serverTimestamps']);\n  validateNamedOptionalPropertyEquals(\n    methodName,\n    'options',\n    'serverTimestamps',\n    options.serverTimestamps,\n    ['estimate', 'previous', 'none']\n  );\n  return options;\n}\n\nfunction validateGetOptions(\n  methodName: string,\n  options: firestore.GetOptions | undefined\n): void {\n  validateOptionalArgType(methodName, 'object', 1, options);\n  if (options) {\n    validateOptionNames(methodName, options, ['source']);\n    validateNamedOptionalPropertyEquals(\n      methodName,\n      'options',\n      'source',\n      options.source,\n      ['default', 'server', 'cache']\n    );\n  }\n}\n\nfunction validateReference<T>(\n  methodName: string,\n  documentRef: firestore.DocumentReference<T>,\n  firestore: Firestore\n): DocumentKeyReference<T> {\n  if (!(documentRef instanceof DocumentKeyReference)) {\n    throw invalidClassError(methodName, 'DocumentReference', 1, documentRef);\n  } else if (documentRef.firestore !== firestore) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      'Provided document reference is from a different Firestore instance.'\n    );\n  } else {\n    return documentRef;\n  }\n}\n\n/**\n * Calculates the array of firestore.DocumentChange's for a given ViewSnapshot.\n *\n * Exported for testing.\n *\n * @param snapshot The ViewSnapshot that represents the expected state.\n * @param includeMetadataChanges Whether to include metadata changes.\n * @param converter A factory function that returns a QueryDocumentSnapshot.\n * @return An objecyt that matches the firestore.DocumentChange API.\n */\nexport function changesFromSnapshot<DocSnap>(\n  snapshot: ViewSnapshot,\n  includeMetadataChanges: boolean,\n  converter: (\n    doc: Document,\n    fromCache: boolean,\n    hasPendingWrite: boolean\n  ) => DocSnap\n): Array<{\n  type: firestore.DocumentChangeType;\n  doc: DocSnap;\n  oldIndex: number;\n  newIndex: number;\n}> {\n  if (snapshot.oldDocs.isEmpty()) {\n    // Special case the first snapshot because index calculation is easy and\n    // fast\n    let lastDoc: Document;\n    let index = 0;\n    return snapshot.docChanges.map(change => {\n      const doc = converter(\n        change.doc,\n        snapshot.fromCache,\n        snapshot.mutatedKeys.has(change.doc.key)\n      );\n      debugAssert(\n        change.type === ChangeType.Added,\n        'Invalid event type for first snapshot'\n      );\n      debugAssert(\n        !lastDoc || newQueryComparator(snapshot.query)(lastDoc, change.doc) < 0,\n        'Got added events in wrong order'\n      );\n      lastDoc = change.doc;\n      return {\n        type: 'added' as firestore.DocumentChangeType,\n        doc,\n        oldIndex: -1,\n        newIndex: index++\n      };\n    });\n  } else {\n    // A DocumentSet that is updated incrementally as changes are applied to use\n    // to lookup the index of a document.\n    let indexTracker = snapshot.oldDocs;\n    return snapshot.docChanges\n      .filter(\n        change => includeMetadataChanges || change.type !== ChangeType.Metadata\n      )\n      .map(change => {\n        const doc = converter(\n          change.doc,\n          snapshot.fromCache,\n          snapshot.mutatedKeys.has(change.doc.key)\n        );\n        let oldIndex = -1;\n        let newIndex = -1;\n        if (change.type !== ChangeType.Added) {\n          oldIndex = indexTracker.indexOf(change.doc.key);\n          debugAssert(oldIndex >= 0, 'Index for document not found');\n          indexTracker = indexTracker.delete(change.doc.key);\n        }\n        if (change.type !== ChangeType.Removed) {\n          indexTracker = indexTracker.add(change.doc);\n          newIndex = indexTracker.indexOf(change.doc.key);\n        }\n        return { type: resultChangeType(change.type), doc, oldIndex, newIndex };\n      });\n  }\n}\n\nfunction resultChangeType(type: ChangeType): firestore.DocumentChangeType {\n  switch (type) {\n    case ChangeType.Added:\n      return 'added';\n    case ChangeType.Modified:\n    case ChangeType.Metadata:\n      return 'modified';\n    case ChangeType.Removed:\n      return 'removed';\n    default:\n      return fail('Unknown change type: ' + type);\n  }\n}\n\n/**\n * Converts custom model object of type T into DocumentData by applying the\n * converter if it exists.\n *\n * This function is used when converting user objects to DocumentData\n * because we want to provide the user with a more specific error message if\n * their set() or fails due to invalid data originating from a toFirestore()\n * call.\n */\nexport function applyFirestoreDataConverter<T>(\n  converter: UntypedFirestoreDataConverter<T> | null,\n  value: T,\n  options?: firestore.SetOptions\n): firestore.DocumentData {\n  let convertedValue;\n  if (converter) {\n    if (options && (options.merge || options.mergeFields)) {\n      // Cast to `any` in order to satisfy the union type constraint on\n      // toFirestore().\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      convertedValue = (converter as any).toFirestore(value, options);\n    } else {\n      convertedValue = converter.toFirestore(value);\n    }\n  } else {\n    convertedValue = value as firestore.DocumentData;\n  }\n  return convertedValue;\n}\n\nfunction contains(obj: object, key: string): obj is { key: unknown } {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { FirebaseApp, FirebaseNamespace } from '@firebase/app-types';\nimport { FirebaseAuthInternalName } from '@firebase/auth-interop-types';\nimport { _FirebaseNamespace } from '@firebase/app-types/private';\nimport { Component, ComponentType, Provider } from '@firebase/component';\nimport {\n  CACHE_SIZE_UNLIMITED,\n  CollectionReference,\n  DocumentReference,\n  DocumentSnapshot,\n  Firestore,\n  Query,\n  QueryDocumentSnapshot,\n  QuerySnapshot,\n  Transaction,\n  WriteBatch\n} from './api/database';\nimport { Blob } from './api/blob';\nimport { FieldPath } from './api/field_path';\nimport { GeoPoint } from './api/geo_point';\nimport { Timestamp } from './api/timestamp';\nimport { FieldValue } from './api/field_value';\n\nconst firestoreNamespace = {\n  Firestore,\n  GeoPoint,\n  Timestamp,\n  Blob,\n  Transaction,\n  WriteBatch,\n  DocumentReference,\n  DocumentSnapshot,\n  Query,\n  QueryDocumentSnapshot,\n  QuerySnapshot,\n  CollectionReference,\n  FieldPath,\n  FieldValue,\n  setLogLevel: Firestore.setLogLevel,\n  CACHE_SIZE_UNLIMITED\n};\n\n/**\n * Configures Firestore as part of the Firebase SDK by calling registerService.\n *\n * @param firebase The FirebaseNamespace to register Firestore with\n * @param firestoreFactory A factory function that returns a new Firestore\n *    instance.\n */\nexport function configureForFirebase(\n  firebase: FirebaseNamespace,\n  firestoreFactory: (\n    app: FirebaseApp,\n    auth: Provider<FirebaseAuthInternalName>\n  ) => Firestore\n): void {\n  (firebase as _FirebaseNamespace).INTERNAL.registerComponent(\n    new Component(\n      'firestore',\n      container => {\n        const app = container.getProvider('app').getImmediate()!;\n        return firestoreFactory(app, container.getProvider('auth-internal'));\n      },\n      ComponentType.PUBLIC\n    ).setServiceProps({ ...firestoreNamespace })\n  );\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport firebase from '@firebase/app';\nimport { FirebaseNamespace } from '@firebase/app-types';\n\nimport { Firestore } from './src/api/database';\nimport {\n  MultiTabOfflineComponentProvider,\n  OnlineComponentProvider\n} from './src/core/component_provider';\nimport { configureForFirebase } from './src/config';\n\nimport './register-module';\nimport { name, version } from './package.json';\n\n/**\n * Registers the main Firestore ReactNative build with the components framework.\n * Persistence can be enabled via `firebase.firestore().enablePersistence()`.\n */\nexport function registerFirestore(instance: FirebaseNamespace): void {\n  configureForFirebase(instance, (app, auth) => {\n    const onlineComponentProvider = new OnlineComponentProvider();\n    const offlineComponentProvider = new MultiTabOfflineComponentProvider(\n      onlineComponentProvider\n    );\n    return new Firestore(\n      app,\n      auth,\n      offlineComponentProvider,\n      onlineComponentProvider\n    );\n  });\n  instance.registerVersion(name, version, 'rn');\n}\n\nregisterFirestore(firebase);\n"],"names":["__PRIVATE_logClient","Logger","__PRIVATE_getLogLevel","logLevel","__PRIVATE_logDebug","msg","obj","LogLevel","DEBUG","args","map","__PRIVATE_argToString","debug","__PRIVATE_logError","ERROR","error","__PRIVATE_logWarn","WARN","warn","value","JSON","stringify","e","fail","__PRIVATE_failure","message","Error","__PRIVATE_hardAssert","assertion","__PRIVATE_debugCast","constructor","__PRIVATE_randomBytes","__PRIVATE_nBytes","crypto","self","bytes","Uint8Array","getRandomValues","__PRIVATE_i","Math","floor","random","__PRIVATE_AutoId","[object Object]","__PRIVATE_chars","__PRIVATE_maxMultiple","length","__PRIVATE_autoId","charAt","__PRIVATE_primitiveComparator","left","right","__PRIVATE_arrayEquals","__PRIVATE_comparator","every","index","__PRIVATE_immediateSuccessor","s","__PRIVATE_DatabaseInfo","__PRIVATE_databaseId","persistenceKey","host","ssl","forceLongPolling","this","__PRIVATE_DatabaseId","projectId","database","i","other","__PRIVATE_objectSize","count","key","Object","prototype","hasOwnProperty","call","forEach","fn","__PRIVATE_isEmpty","__PRIVATE_ObjectMap","__PRIVATE_mapKeyFn","__PRIVATE_equalsFn","id","matches","__PRIVATE_inner","undefined","__PRIVATE_otherKey","get","push","splice","__PRIVATE__","entries","k","v","Code","OK","CANCELLED","UNKNOWN","INVALID_ARGUMENT","DEADLINE_EXCEEDED","NOT_FOUND","ALREADY_EXISTS","PERMISSION_DENIED","UNAUTHENTICATED","RESOURCE_EXHAUSTED","FAILED_PRECONDITION","ABORTED","OUT_OF_RANGE","UNIMPLEMENTED","INTERNAL","UNAVAILABLE","DATA_LOSS","FirestoreError","code","super","toString","name","Timestamp","seconds","nanoseconds","fromMillis","Date","now","date","getTime","milliseconds","toMillis","__PRIVATE_adjustedSeconds","String","padStart","__PRIVATE_SnapshotVersion","timestamp","__PRIVATE__compareTo","isEqual","__PRIVATE_BasePath","segments","offset","__PRIVATE_len","__PRIVATE_nameOrPath","slice","limit","__PRIVATE_segment","__PRIVATE_construct","size","__PRIVATE_potentialChild","end","p1","p2","min","ResourcePath","__PRIVATE_toArray","join","__PRIVATE_canonicalString","path","indexOf","split","filter","__PRIVATE_identifierRegExp","FieldPath","test","str","replace","__PRIVATE_isValidIdentifier","__PRIVATE_current","__PRIVATE_addCurrentSegment","__PRIVATE_inBackticks","c","next","__PRIVATE_DocumentKey","__PRIVATE_fromString","__PRIVATE_popFirst","collectionId","k1","k2","__PRIVATE_isNullOrUndefined","__PRIVATE_isNegativeZero","isSafeInteger","Number","isInteger","MAX_SAFE_INTEGER","MIN_SAFE_INTEGER","__PRIVATE_TargetImpl","collectionGroup","orderBy","filters","startAt","endAt","__PRIVATE_newTarget","__PRIVATE_canonifyTarget","target","__PRIVATE_targetImpl","__PRIVATE_memoizedCanonicalId","canonicalId","f","__PRIVATE_canonifyFilter","o","__PRIVATE_canonifyOrderBy","field","dir","__PRIVATE_canonifyBound","__PRIVATE_stringifyTarget","__PRIVATE_stringifyFilter","op","__PRIVATE_stringifyOrderBy","__PRIVATE_targetEquals","__PRIVATE_orderByEquals","__PRIVATE_f1","__PRIVATE_f2","__PRIVATE_valueEquals","__PRIVATE_boundEquals","__PRIVATE_isDocumentTarget","__PRIVATE_isDocumentKey","__PRIVATE_decodeBase64","__PRIVATE_encoded","fromCharCode","apply","base64","decodeStringToByteArray","__PRIVATE_ByteString","__PRIVATE_binaryString","array","__PRIVATE_binaryStringFromUint8Array","raw","charCodeAt","encodeByteArray","__PRIVATE_encodeBase64","buffer","__PRIVATE_uint8ArrayFromBinaryString","__PRIVATE_TargetData","targetId","__PRIVATE_purpose","sequenceNumber","__PRIVATE_snapshotVersion","lastLimboFreeSnapshotVersion","resumeToken","__PRIVATE_EMPTY_BYTE_STRING","ExistenceFilter","__PRIVATE_RpcCode","__PRIVATE_isPermanentError","__PRIVATE_mapCodeFromRpcCode","RpcCode","__PRIVATE_SortedMap","root","__PRIVATE_LLRBNode","EMPTY","__PRIVATE_insert","copy","__PRIVATE_BLACK","remove","node","cmp","__PRIVATE_prunedNodes","__PRIVATE_minKey","__PRIVATE_maxKey","action","__PRIVATE_inorderTraversal","__PRIVATE_descriptions","__PRIVATE_reverseTraversal","__PRIVATE_SortedMapIterator","__PRIVATE_startKey","__PRIVATE_isReverse","__PRIVATE_nodeStack","pop","result","color","RED","n","__PRIVATE_fixUp","__PRIVATE_isRed","__PRIVATE_moveRedLeft","__PRIVATE_removeMin","__PRIVATE_smallest","__PRIVATE_rotateRight","__PRIVATE_moveRedRight","__PRIVATE_rotateLeft","__PRIVATE_colorFlip","__PRIVATE_nl","__PRIVATE_nr","__PRIVATE_blackDepth","__PRIVATE_check","pow","__PRIVATE_SortedSet","data","__PRIVATE_elem","cb","range","__PRIVATE_iter","__PRIVATE_getIteratorFrom","__PRIVATE_hasNext","__PRIVATE_getNext","start","__PRIVATE_getIterator","__PRIVATE_SortedSetIterator","has","add","__PRIVATE_thisIt","__PRIVATE_otherIt","__PRIVATE_thisElem","__PRIVATE_otherElem","__PRIVATE_res","__PRIVATE_EMPTY_MAYBE_DOCUMENT_MAP","__PRIVATE_maybeDocumentMap","__PRIVATE_nullableMaybeDocumentMap","__PRIVATE_EMPTY_DOCUMENT_MAP","__PRIVATE_documentMap","__PRIVATE_EMPTY_DOCUMENT_VERSION_MAP","__PRIVATE_EMPTY_DOCUMENT_KEY_SET","__PRIVATE_documentKeySet","keys","set","__PRIVATE_EMPTY_TARGET_ID_SET","__PRIVATE_targetIdSet","__PRIVATE_DocumentSet","__PRIVATE_comp","__PRIVATE_d1","__PRIVATE_d2","__PRIVATE_keyedMap","__PRIVATE_sortedSet","__PRIVATE_oldSet","doc","delete","__PRIVATE_thisDoc","__PRIVATE_otherDoc","__PRIVATE_docStrings","__PRIVATE_newSet","__PRIVATE_DocumentChangeSet","__PRIVATE_change","__PRIVATE_oldChange","__PRIVATE_changeMap","type","__PRIVATE_changes","__PRIVATE_ViewSnapshot","query","docs","__PRIVATE_oldDocs","docChanges","__PRIVATE_mutatedKeys","fromCache","__PRIVATE_syncStateChanged","__PRIVATE_excludesMetadataChanges","documents","__PRIVATE_emptySet","hasPendingWrites","__PRIVATE_queryEquals","__PRIVATE_otherChanges","__PRIVATE_RemoteEvent","__PRIVATE_targetChanges","__PRIVATE_targetMismatches","__PRIVATE_documentUpdates","__PRIVATE_resolvedLimboDocuments","Map","TargetChange","__PRIVATE_createSynthesizedTargetChangeForCurrentChange","__PRIVATE_addedDocuments","__PRIVATE_modifiedDocuments","__PRIVATE_removedDocuments","__PRIVATE_DocumentWatchChange","__PRIVATE_updatedTargetIds","removedTargetIds","__PRIVATE_newDoc","__PRIVATE_ExistenceFilterChange","__PRIVATE_existenceFilter","__PRIVATE_WatchTargetChange","state","targetIds","cause","__PRIVATE_TargetState","__PRIVATE_snapshotChangesMap","Ht","__PRIVATE__current","__PRIVATE__resumeToken","he","__PRIVATE_pendingResponses","ae","__PRIVATE__hasPendingChanges","__PRIVATE_approximateByteSize","__PRIVATE_documentChanges","__PRIVATE_changeType","__PRIVATE_WatchChangeAggregator","__PRIVATE_metadataProvider","__PRIVATE_documentTargetMap","__PRIVATE_docChange","Document","__PRIVATE_addDocumentToTarget","__PRIVATE_NoDocument","__PRIVATE_removeDocumentFromTarget","targetChange","__PRIVATE_forEachTarget","__PRIVATE_targetState","__PRIVATE_ensureTargetState","__PRIVATE_isActiveTarget","__PRIVATE_updateResumeToken","__PRIVATE_recordTargetResponse","__PRIVATE_isPending","__PRIVATE_clearPendingChanges","removeTarget","__PRIVATE_markCurrent","__PRIVATE_resetTarget","__PRIVATE_targetStates","__PRIVATE_watchChange","__PRIVATE_expectedCount","__PRIVATE_targetData","__PRIVATE_targetDataForActiveTarget","__PRIVATE_getCurrentDocumentCountForTarget","__PRIVATE_pendingTargetResets","__PRIVATE_pendingDocumentUpdates","__PRIVATE_targetContainsDocument","__PRIVATE_hasPendingChanges","__PRIVATE_toTargetChange","__PRIVATE_pendingDocumentTargetMapping","__PRIVATE_targets","__PRIVATE_isOnlyLimboTarget","__PRIVATE_forEachWhile","__PRIVATE_remoteEvent","document","__PRIVATE_addDocumentChange","__PRIVATE_ensureDocumentTargetMapping","__PRIVATE_updatedDocument","__PRIVATE_removeDocumentChange","__PRIVATE_getRemoteKeysForTarget","__PRIVATE_recordPendingTargetRequest","__PRIVATE_targetMapping","__PRIVATE_targetActive","__PRIVATE_getTargetDataForTarget","__PRIVATE_isServerTimestamp","mapValue","fields","stringValue","__PRIVATE_getLocalWriteTime","__PRIVATE_localWriteTime","__PRIVATE_normalizeTimestamp","nanos","__PRIVATE_ISO_TIMESTAMP_REG_EXP","RegExp","__PRIVATE_typeOrder","__PRIVATE_leftType","booleanValue","timestampValue","__PRIVATE_leftTimestamp","__PRIVATE_rightTimestamp","__PRIVATE_timestampEquals","__PRIVATE_normalizeByteString","__PRIVATE_blobEquals","referenceValue","__PRIVATE_normalizeNumber","geoPointValue","latitude","longitude","__PRIVATE_geoPointEquals","integerValue","__PRIVATE_n1","__PRIVATE_n2","isNaN","__PRIVATE_numberEquals","arrayValue","values","__PRIVATE_leftMap","__PRIVATE_rightMap","__PRIVATE_objectEquals","__PRIVATE_arrayValueContains","__PRIVATE_haystack","__PRIVATE_needle","find","__PRIVATE_valueCompare","__PRIVATE_rightType","__PRIVATE_leftNumber","doubleValue","__PRIVATE_rightNumber","__PRIVATE_compareNumbers","__PRIVATE_compareTimestamps","__PRIVATE_leftBytes","__PRIVATE_rightBytes","__PRIVATE_compareTo","__PRIVATE_compareBlobs","__PRIVATE_leftPath","__PRIVATE_rightPath","__PRIVATE_leftSegments","__PRIVATE_rightSegments","__PRIVATE_comparison","__PRIVATE_compareReferences","__PRIVATE_compareGeoPoints","__PRIVATE_leftArray","__PRIVATE_rightArray","compare","__PRIVATE_compareArrays","__PRIVATE_leftKeys","__PRIVATE_rightKeys","sort","__PRIVATE_keyCompare","__PRIVATE_compareMaps","__PRIVATE_canonifyValue","__PRIVATE_normalizedTimestamp","__PRIVATE_canonifyTimestamp","toBase64","__PRIVATE_fromName","__PRIVATE_geoPoint","first","__PRIVATE_canonifyArray","__PRIVATE_sortedKeys","__PRIVATE_canonifyMap","__PRIVATE_fraction","exec","__PRIVATE_nanoStr","substr","__PRIVATE_parsedDate","blob","fromBase64String","fromUint8Array","__PRIVATE_refValue","isArray","__PRIVATE_isNullValue","__PRIVATE_isNanValue","__PRIVATE_isMapValue","__PRIVATE_DIRECTIONS","__PRIVATE_dirs","asc","desc","__PRIVATE_OPERATORS","__PRIVATE_ops","<","<=",">",">=","==","!=","array-contains","in","not-in","array-contains-any","__PRIVATE_JsonProtoSerializer","__PRIVATE_useProto3Json","__PRIVATE_toInteger","__PRIVATE_toDouble","serializer","Infinity","__PRIVATE_toNumber","__PRIVATE_toTimestamp","toISOString","__PRIVATE_toBytes","toUint8Array","toVersion","version","fromVersion","__PRIVATE_fromTimestamp","__PRIVATE_toResourceName","__PRIVATE_fullyQualifiedPrefixPath","child","__PRIVATE_fromResourceName","__PRIVATE_resource","__PRIVATE_isValidResourceName","__PRIVATE_toName","__PRIVATE_extractLocalPathFromResourceName","__PRIVATE_toQueryPath","__PRIVATE_fromQueryPath","__PRIVATE_resourceName","__PRIVATE_emptyPath","__PRIVATE_getEncodedDatabaseId","__PRIVATE_toMutationDocument","proto","__PRIVATE_fromMaybeDocument","found","updateTime","__PRIVATE_ObjectValue","__PRIVATE_fromFound","missing","readTime","__PRIVATE_fromMissing","__PRIVATE_fromWatchChange","__PRIVATE_fromWatchTargetChangeState","targetChangeType","__PRIVATE_fromBytes","__PRIVATE_causeProto","status","__PRIVATE_fromRpcStatus","documentChange","__PRIVATE_entityChange","documentDelete","__PRIVATE_docDelete","documentRemove","__PRIVATE_docRemove","__PRIVATE_toMutation","__PRIVATE_mutation","__PRIVATE_SetMutation","update","__PRIVATE_DeleteMutation","__PRIVATE_PatchMutation","updateMask","__PRIVATE_toDocumentMask","__PRIVATE_fieldMask","__PRIVATE_TransformMutation","transform","fieldTransforms","__PRIVATE_fieldTransform","__PRIVATE_ServerTimestampTransform","fieldPath","setToServerValue","__PRIVATE_ArrayUnionTransformOperation","appendMissingElements","elements","__PRIVATE_ArrayRemoveTransformOperation","removeAllFromArray","__PRIVATE_NumericIncrementTransformOperation","increment","__PRIVATE_operand","__PRIVATE_toFieldTransform","__PRIVATE_VerifyMutation","verify","__PRIVATE_precondition","__PRIVATE_isNone","currentDocument","exists","__PRIVATE_toPrecondition","__PRIVATE_fromMutation","Precondition","__PRIVATE_none","__PRIVATE_fromPrecondition","paths","fieldPaths","__PRIVATE_FieldMask","__PRIVATE_fromServerFormat","__PRIVATE_fromDocumentMask","FieldTransform","__PRIVATE_fromFieldTransform","__PRIVATE_fromWriteResults","__PRIVATE_protos","commitTime","transformResults","__PRIVATE_MutationResult","__PRIVATE_fromWriteResult","__PRIVATE_toDocumentsTarget","__PRIVATE_toQueryTarget","structuredQuery","parent","from","allDescendants","__PRIVATE_popLast","__PRIVATE_lastSegment","where","unaryFilter","__PRIVATE_toFieldPathReference","fieldFilter","__PRIVATE_toUnaryOrFieldFilter","compositeFilter","__PRIVATE_toFilter","__PRIVATE_orderBys","order","__PRIVATE_toPropertyOrder","direction","__PRIVATE_toOrder","val","__PRIVATE_toInt32Proto","__PRIVATE_toCursor","__PRIVATE_fromQueryTarget","__PRIVATE_fromCount","__PRIVATE_filterBy","__PRIVATE_fromFilter","__PRIVATE_fromUnaryFilter","__PRIVATE_fromFieldFilter","reduce","__PRIVATE_accum","concat","__PRIVATE_fromPropertyOrder","__PRIVATE_OrderBy","__PRIVATE_fromFieldPathReference","__PRIVATE_fromDirection","__PRIVATE_fromInt32Proto","__PRIVATE_fromCursor","__PRIVATE_queryToTarget","__PRIVATE_newQuery","__PRIVATE_toListenRequestLabels","__PRIVATE_toLabel","goog-listen-tags","cursor","before","position","__PRIVATE_Bound","__PRIVATE_fieldReference","FieldFilter","create","__PRIVATE_fromOperatorName","__PRIVATE_nanField","NaN","__PRIVATE_nullField","nullValue","__PRIVATE_notNanField","__PRIVATE_notNullField","__PRIVATE_canonicalFields","__PRIVATE_TransformOperation","__PRIVATE_applyTransformOperationToLocalView","previousValue","__type__","__local_write_time__","serverTimestamp","__PRIVATE_applyArrayUnionTransformOperation","__PRIVATE_applyArrayRemoveTransformOperation","__PRIVATE_baseValue","__PRIVATE_computeTransformOperationBaseValue","__PRIVATE_sum","asNumber","__PRIVATE_applyNumericIncrementTransformOperationToLocalView","__PRIVATE_applyTransformOperationToRemoteDocument","__PRIVATE_transformResult","__PRIVATE_isDouble","__PRIVATE_coercedFieldValuesArray","__PRIVATE_toUnion","some","element","__PRIVATE_toRemove","__PRIVATE_fieldMaskPath","__PRIVATE_isPrefixOf","__PRIVATE_l","r","__PRIVATE_fieldTransformEquals","__PRIVATE_transformOperationEquals","Be","__PRIVATE_preconditionIsValidForDocument","__PRIVATE_maybeDoc","__PRIVATE_Mutation","__PRIVATE_applyMutationToRemoteDocument","__PRIVATE_mutationResult","hasCommittedMutations","__PRIVATE_applySetMutationToRemoteDocument","__PRIVATE_UnknownDocument","__PRIVATE_newData","__PRIVATE_patchDocument","__PRIVATE_applyPatchMutationToRemoteDocument","__PRIVATE_requireDocument","__PRIVATE_baseDoc","__PRIVATE_serverTransformResults","__PRIVATE_transformObject","__PRIVATE_applyTransformMutationToRemoteDocument","__PRIVATE_applyDeleteMutationToRemoteDocument","__PRIVATE_applyMutationToLocalView","__PRIVATE_getPostMutationVersion","Ke","__PRIVATE_applySetMutationToLocalView","__PRIVATE_applyPatchMutationToLocalView","__PRIVATE_localTransformResults","__PRIVATE_applyTransformMutationToLocalView","__PRIVATE_applyDeleteMutationToLocalView","__PRIVATE_extractMutationBaseValue","__PRIVATE_baseObject","__PRIVATE_existingValue","__PRIVATE_coercedValue","__PRIVATE_ObjectValueBuilder","__PRIVATE_build","__PRIVATE_extractTransformMutationBaseValue","__PRIVATE_mutationEquals","empty","__PRIVATE_builder","newValue","__PRIVATE_patchObject","__PRIVATE_setOverlay","__PRIVATE_currentLevel","__PRIVATE_overlayMap","__PRIVATE_currentSegment","currentValue","__PRIVATE_mergedResult","__PRIVATE_applyOverlay","__PRIVATE_currentPath","__PRIVATE_currentOverlays","__PRIVATE_modified","__PRIVATE_resultAtPath","__PRIVATE_pathSegment","__PRIVATE_nested","__PRIVATE_extractFieldMask","__PRIVATE_nestedFields","__PRIVATE_nestedPath","__PRIVATE_MaybeDocument","__PRIVATE_objectValue","options","__PRIVATE_hasLocalMutations","__PRIVATE_cast","__PRIVATE_QueryImpl","__PRIVATE_explicitOrderBy","__PRIVATE_limitType","__PRIVATE_isKeyField","__PRIVATE_isInequality","__PRIVATE_operators","__PRIVATE_newQueryForPath","__PRIVATE_isCollectionGroupQuery","__PRIVATE_queryOrderBy","__PRIVATE_queryImpl","__PRIVATE_memoizedOrderBy","__PRIVATE_inequalityField","__PRIVATE_getInequalityFilterField","__PRIVATE_firstOrderByField","__PRIVATE_getFirstOrderByField","__PRIVATE_keyField","__PRIVATE_foundKeyOrdering","__PRIVATE_lastDirection","__PRIVATE_memoizedTarget","__PRIVATE_queryWithLimit","__PRIVATE_queryWithStartAt","bound","__PRIVATE_queryWithEndAt","__PRIVATE_canonifyQuery","__PRIVATE_stringifyQuery","__PRIVATE_queryMatches","__PRIVATE_docPath","__PRIVATE_hasCollectionId","__PRIVATE_isImmediateParentOf","__PRIVATE_queryMatchesPathAndCollectionGroup","__PRIVATE_queryMatchesOrderBy","__PRIVATE_queryMatchesFilters","__PRIVATE_sortsBeforeDocument","__PRIVATE_queryMatchesBounds","__PRIVATE_newQueryComparator","__PRIVATE_comparedOnKeyField","__PRIVATE_compareDocs","__PRIVATE_createKeyFieldInFilter","__PRIVATE_KeyFieldFilter","__PRIVATE_ArrayContainsFilter","__PRIVATE_InFilter","__PRIVATE_NotInFilter","__PRIVATE_ArrayContainsAnyFilter","__PRIVATE_KeyFieldInFilter","__PRIVATE_KeyFieldNotInFilter","__PRIVATE_matchesComparison","__PRIVATE_extractDocumentKeysFromArrayValue","p","__PRIVATE_orderByComponent","component","v1","v2","__PRIVATE_compareDocumentsByField","__PRIVATE_MutationBatch","batchId","baseMutations","mutations","__PRIVATE_docKey","__PRIVATE_batchResult","__PRIVATE_mutationResults","__PRIVATE_maybeDocs","__PRIVATE_mutatedDocuments","m","__PRIVATE_mutatedDocument","__PRIVATE_applyToLocalView","__PRIVATE_MutationBatchResult","batch","__PRIVATE_commitVersion","__PRIVATE_docVersions","results","__PRIVATE_versionMap","PersistencePromise","callback","__PRIVATE_isDone","__PRIVATE_nextCallback","__PRIVATE_catchCallback","__PRIVATE_nextFn","__PRIVATE_catchFn","__PRIVATE_callbackAttached","__PRIVATE_wrapFailure","__PRIVATE_wrapSuccess","resolve","reject","Promise","__PRIVATE_wrapUserFunction","all","__PRIVATE_resolvedCount","done","err","__PRIVATE_predicates","predicate","__PRIVATE_isTrue","collection","__PRIVATE_promises","__PRIVATE_waitFor","__PRIVATE_RemoteDocumentChangeBuffer","__PRIVATE__readTime","__PRIVATE_maybeDocument","__PRIVATE_assertNotApplied","transaction","__PRIVATE_documentKey","__PRIVATE_bufferedEntry","__PRIVATE_getFromCache","__PRIVATE_documentKeys","__PRIVATE_getAllFromCache","__PRIVATE_changesApplied","__PRIVATE_applyChanges","__PRIVATE_PRIMARY_LEASE_LOST_ERROR_MSG","__PRIVATE_PersistenceTransaction","listener","__PRIVATE_onCommittedListeners","__PRIVATE_LocalDocumentsView","__PRIVATE_remoteDocumentCache","__PRIVATE_mutationQueue","__PRIVATE_indexManager","__PRIVATE_getAllMutationBatchesAffectingDocumentKey","__PRIVATE_batches","__PRIVATE_getDocumentInternal","__PRIVATE_inBatches","__PRIVATE_getEntry","__PRIVATE_localView","getEntries","__PRIVATE_getLocalViewOfDocuments","__PRIVATE_baseDocs","__PRIVATE_getAllMutationBatchesAffectingDocumentKeys","__PRIVATE_applyLocalMutationsToDocuments","__PRIVATE_sinceReadTime","__PRIVATE_isDocumentQuery","__PRIVATE_getDocumentsMatchingDocumentQuery","__PRIVATE_getDocumentsMatchingCollectionGroupQuery","__PRIVATE_getDocumentsMatchingCollectionQuery","__PRIVATE_getDocument","__PRIVATE_getCollectionParents","__PRIVATE_parents","__PRIVATE_collectionQuery","__PRIVATE_asCollectionQueryAtPath","__PRIVATE_mutationBatches","__PRIVATE_getDocumentsMatchingQuery","__PRIVATE_queryResults","__PRIVATE_getAllMutationBatchesAffectingQuery","__PRIVATE_matchingMutationBatches","__PRIVATE_addMissingBaseDocuments","__PRIVATE_mergedDocuments","__PRIVATE_mutatedDoc","__PRIVATE_existingDocuments","__PRIVATE_missingBaseDocEntriesForPatching","__PRIVATE_missingBaseDocs","__PRIVATE_LocalViewChanges","__PRIVATE_addedKeys","__PRIVATE_removedKeys","__PRIVATE_viewSnapshot","__PRIVATE_ListenSequence","__PRIVATE_sequenceNumberSyncer","__PRIVATE_sequenceNumberHandler","__PRIVATE_setPreviousValue","__PRIVATE_writeNewSequenceNumber","__PRIVATE_writeSequenceNumber","__PRIVATE_externalPreviousValue","max","__PRIVATE_nextValue","__PRIVATE_Deferred","promise","__PRIVATE_ExponentialBackoff","__PRIVATE_queue","__PRIVATE_timerId","__PRIVATE_initialDelayMs","__PRIVATE_backoffFactor","__PRIVATE_maxDelayMs","reset","__PRIVATE_currentBaseMs","cancel","__PRIVATE_desiredDelayWithJitterMs","__PRIVATE_jitterDelayMs","__PRIVATE_delaySoFarMs","__PRIVATE_lastAttemptTime","__PRIVATE_remainingDelayMs","__PRIVATE_timerPromise","__PRIVATE_enqueueAfterDelay","__PRIVATE_skipDelay","__PRIVATE_SimpleDb","__PRIVATE_schemaConverter","__PRIVATE_getIOSVersion","getUA","__PRIVATE_wrapRequest","window","indexedDB","deleteDatabase","__PRIVATE_toPromise","__PRIVATE_isMockPersistence","__PRIVATE_ua","__PRIVATE_iOSVersion","__PRIVATE_isUnsupportedIOS","__PRIVATE_androidVersion","__PRIVATE_getAndroidVersion","__PRIVATE_isUnsupportedAndroid","process","env","__PRIVATE_USE_MOCK_PERSISTENCE","txn","store","__PRIVATE_iOSVersionRegex","match","__PRIVATE_androidVersionRegex","db","request","open","onsuccess","event","onblocked","__PRIVATE_IndexedDbTransactionError","onerror","onupgradeneeded","oldVersion","createOrUpgrade","__PRIVATE_versionchangelistener","onversionchange","__PRIVATE_versionChangeListener","mode","__PRIVATE_objectStores","__PRIVATE_transactionFn","__PRIVATE_readonly","__PRIVATE_attemptNumber","__PRIVATE_ensureDb","__PRIVATE_SimpleDbTransaction","__PRIVATE_transactionFnResult","catch","abort","__PRIVATE_completionPromise","__PRIVATE_retryable","close","__PRIVATE_IterationController","__PRIVATE_dbCursor","Vn","__PRIVATE_shouldStop","js","__PRIVATE_nextKey","__PRIVATE_isIndexedDbTransactionError","oncomplete","__PRIVATE_completionDeferred","onabort","__PRIVATE_checkForAndReportiOSError","objectStoreNames","Bs","aborted","__PRIVATE_storeName","objectStore","__PRIVATE_SimpleDbStore","__PRIVATE_keyOrValue","put","__PRIVATE_indexOrRange","__PRIVATE_iterateCursor","__PRIVATE_keysOnly","control","__PRIVATE_optionsOrCallback","__PRIVATE_cursorRequest","primaryKey","__PRIVATE_shouldContinue","continue","controller","__PRIVATE_userResult","__PRIVATE_userPromise","__PRIVATE_skipToKey","__PRIVATE_indexName","reverse","openKeyCursor","openCursor","__PRIVATE_reportedIOSError","__PRIVATE_IOS_ERROR","__PRIVATE_newError","setTimeout","__PRIVATE_getWindow","__PRIVATE_DelayedOperation","__PRIVATE_asyncQueue","__PRIVATE_targetTimeMs","__PRIVATE_removalCallback","__PRIVATE_deferred","then","bind","__PRIVATE_delayMs","__PRIVATE_targetTime","__PRIVATE_delayedOp","__PRIVATE_timerHandle","__PRIVATE_handleDelayElapsed","reason","clearTimeout","__PRIVATE_enqueueAndForget","__PRIVATE_AsyncQueue","visibilityState","__PRIVATE_backoff","__PRIVATE_skipBackoff","addEventListener","__PRIVATE_visibilityHandler","Ei","__PRIVATE__isShuttingDown","enqueue","__PRIVATE_verifyNotFailed","__PRIVATE_enqueueInternal","removeEventListener","__PRIVATE_enqueueEvenAfterShutdown","__PRIVATE_retryableOps","__PRIVATE_retryNextOp","shift","__PRIVATE_backoffAndRun","__PRIVATE_newTail","__PRIVATE_tail","__PRIVATE_operationInProgress","stack","includes","__PRIVATE_getMessageOrStack","__PRIVATE_timerIdsToSkip","__PRIVATE_createAndSchedule","__PRIVATE_removedOp","__PRIVATE_removeDelayedOperation","__PRIVATE_delayedOperations","__PRIVATE_currentTail","__PRIVATE_lastTimerId","__PRIVATE_drain","a","b","__PRIVATE_wrapInUserErrorIfRecoverable","__PRIVATE_bufferEntryComparator","__PRIVATE_aSequence","__PRIVATE_aIndex","__PRIVATE_bSequence","__PRIVATE_bIndex","__PRIVATE_seqCmp","__PRIVATE_RollingSequenceNumberBuffer","__PRIVATE_maxElements","__PRIVATE_previousIndex","__PRIVATE_entry","__PRIVATE_nextIndex","__PRIVATE_highestValue","last","maxValue","__PRIVATE_GC_DID_NOT_RUN","xi","$i","Mi","Oi","__PRIVATE_LruParams","__PRIVATE_cacheSizeCollectionThreshold","__PRIVATE_percentileToCollect","__PRIVATE_maximumSequenceNumbersToCollect","__PRIVATE_cacheSize","__PRIVATE_DEFAULT_COLLECTION_PERCENTILE","__PRIVATE_DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT","__PRIVATE_DEFAULT_CACHE_SIZE_BYTES","__PRIVATE_COLLECTION_DISABLED","__PRIVATE_LruScheduler","__PRIVATE_garbageCollector","__PRIVATE_gcTask","__PRIVATE_localStore","params","__PRIVATE_scheduleGC","tr","delay","__PRIVATE_hasRun","async","__PRIVATE_collectGarbage","__PRIVATE_ignoreIfPrimaryLeaseLoss","__PRIVATE_LruGarbageCollector","__PRIVATE_delegate","__PRIVATE_percentile","__PRIVATE_getSequenceNumberCount","targetCount","__PRIVATE_INVALID","__PRIVATE_addElement","__PRIVATE_forEachOrphanedDocumentSequenceNumber","upperBound","activeTargetIds","__PRIVATE_removeTargets","__PRIVATE_removeOrphanedDocuments","__PRIVATE_getCacheSize","__PRIVATE_runGarbageCollection","__PRIVATE_upperBoundSequenceNumber","__PRIVATE_sequenceNumbersToCollect","__PRIVATE_targetsRemoved","__PRIVATE_countedTargetsTs","__PRIVATE_foundUpperBoundTs","__PRIVATE_removedTargetsTs","__PRIVATE_removedDocumentsTs","__PRIVATE_startTs","__PRIVATE_calculateTargetCount","__PRIVATE_sequenceNumbers","__PRIVATE_nthSequenceNumber","__PRIVATE_numTargetsRemoved","__PRIVATE_documentsRemoved","__PRIVATE_encodeResourcePath","__PRIVATE_encodeSeparator","__PRIVATE_encodeSegment","__PRIVATE_resultBuf","__PRIVATE_escapeChar","__PRIVATE_decodeResourcePath","__PRIVATE_lastReasonableEscapeIndex","__PRIVATE_segmentBuilder","__PRIVATE_currentPiece","substring","LocalSerializer","__PRIVATE_remoteSerializer","__PRIVATE_fromDbRemoteDocument","__PRIVATE_localSerializer","__PRIVATE_remoteDoc","__PRIVATE_fromDocument","noDocument","__PRIVATE_fromSegments","__PRIVATE_fromDbTimestamp","unknownDocument","__PRIVATE_toDbRemoteDocument","__PRIVATE_dbReadTime","__PRIVATE_toDbTimestampKey","parentPath","__PRIVATE_toProto","__PRIVATE_toDocument","DbRemoteDocument","__PRIVATE_toDbTimestamp","DbNoDocument","DbUnknownDocument","__PRIVATE_fromDbTimestampKey","__PRIVATE_dbTimestampKey","DbTimestamp","__PRIVATE_dbTimestamp","__PRIVATE_fromDbMutationBatch","__PRIVATE_dbBatch","localWriteTimeMs","__PRIVATE_fromDbTarget","__PRIVATE_dbTarget","__PRIVATE_documentsTarget","lastListenSequenceNumber","__PRIVATE_toDbTarget","__PRIVATE_dbLastLimboFreeTimestamp","__PRIVATE_queryProto","DbTarget","__PRIVATE_IndexedDbMutationQueue","userId","__PRIVATE_referenceDelegate","user","uid","__PRIVATE_isAuthenticated","IDBKeyRange","NEGATIVE_INFINITY","POSITIVE_INFINITY","__PRIVATE_mutationsStore","__PRIVATE_iterate","DbMutationBatch","userMutationsIndex","__PRIVATE_documentStore","__PRIVATE_documentMutationsStore","__PRIVATE_mutationStore","__PRIVATE_serializedBaseMutations","__PRIVATE_serializedMutations","__PRIVATE_toDbMutationBatch","__PRIVATE_collectionParents","__PRIVATE_indexKey","DbDocumentMutation","PLACEHOLDER","__PRIVATE_addToCollectionParentIndex","__PRIVATE_addOnCommittedListener","__PRIVATE_documentKeysByBatchId","__PRIVATE_lookupMutationBatch","__PRIVATE_nextBatchId","lowerBound","__PRIVATE_foundBatch","__PRIVATE_loadAll","__PRIVATE_dbBatches","__PRIVATE_indexPrefix","prefixForPath","__PRIVATE_indexStart","__PRIVATE_userID","__PRIVATE_encodedPath","__PRIVATE_uniqueBatchIDs","__PRIVATE_batchID","__PRIVATE_lookupMutationBatches","__PRIVATE_queryPath","__PRIVATE_immediateChildrenLength","__PRIVATE_batchIDs","__PRIVATE_removeMutationBatch","__PRIVATE_simpleDbTransaction","__PRIVATE_removeCachedMutationKeys","__PRIVATE_markPotentiallyOrphaned","__PRIVATE_checkEmpty","__PRIVATE_startRange","prefixForUser","__PRIVATE_danglingMutationReferences","__PRIVATE_mutationQueueContainsKey","__PRIVATE_mutationQueuesStore","metadata","DbMutationQueue","__PRIVATE_containsKey","Js","keyPath","__PRIVATE_indexTxn","only","__PRIVATE_numDeleted","__PRIVATE_removePromise","__PRIVATE_IndexedDbPersistence","__PRIVATE_getStore","__PRIVATE_IndexedDbRemoteDocumentCache","__PRIVATE_remoteDocumentsStore","__PRIVATE_dbKey","__PRIVATE_sizeDelta","getMetadata","byteSize","__PRIVATE_setMetadata","__PRIVATE_dbRemoteDoc","__PRIVATE_maybeDecodeDocument","Mr","__PRIVATE_dbDocumentSize","__PRIVATE_forEachDbEntry","__PRIVATE_sizeMap","qr","Br","__PRIVATE_keyIter","__PRIVATE_potentialKeyRaw","__PRIVATE_potentialKey","__PRIVATE_skip","__PRIVATE_immediateChildrenPathLength","__PRIVATE_iterationOptions","__PRIVATE_collectionKey","__PRIVATE_readTimeKey","collectionReadTimeIndex","__PRIVATE_changedDocs","__PRIVATE_lastReadTime","__PRIVATE_documentsStore","readTimeIndex","Qr","__PRIVATE_trackRemovals","__PRIVATE_documentGlobalStore","DbRemoteDocumentGlobal","__PRIVATE_documentCache","__PRIVATE_previousSize","__PRIVATE_documentSizes","__PRIVATE_addEntry","__PRIVATE_deletedDoc","__PRIVATE_removeEntry","updateMetadata","__PRIVATE_getSizedEntry","__PRIVATE_getResult","__PRIVATE_getSizedEntries","__PRIVATE_maybeDocuments","__PRIVATE_MemoryIndexManager","__PRIVATE_MemoryCollectionParentIndex","collectionPath","__PRIVATE_collectionParentIndex","__PRIVATE_existingParents","__PRIVATE_added","SchemaConverter","createObjectStore","DbPrimaryClient","__PRIVATE_createPrimaryClientStore","autoIncrement","createIndex","userMutationsKeyPath","unique","__PRIVATE_createMutationQueue","__PRIVATE_createQueryCache","__PRIVATE_createRemoteDocumentCache","deleteObjectStore","DbTargetDocument","DbTargetGlobal","__PRIVATE_dropQueryCache","__PRIVATE_globalStore","__PRIVATE_writeEmptyTargetGlobalEntry","__PRIVATE_existingMutations","__PRIVATE_v3MutationsStore","__PRIVATE_writeAll","__PRIVATE_upgradeMutationBatchSchemaAndMigrateData","DbClientMetadata","__PRIVATE_createClientMetadataStore","removeAcknowledgedMutations","__PRIVATE_createDocumentGlobalStore","addDocumentGlobal","ensureSequenceNumbers","createCollectionParentIndex","contains","__PRIVATE_dropRemoteDocumentChangesStore","__PRIVATE_remoteDocumentStore","readTimeIndexPath","collectionReadTimeIndexPath","__PRIVATE_createRemoteDocumentReadTimeIndex","rewriteCanonicalIds","__PRIVATE_byteCount","__PRIVATE_queuesStore","__PRIVATE_queues","lastAcknowledgedBatchId","__PRIVATE_documentTargetStore","__PRIVATE_docSentinelKey","__PRIVATE_sentinelKey","__PRIVATE_maybeSentinel","__PRIVATE_writeSentinelKey","DbCollectionParent","__PRIVATE_collectionParentsStore","cache","__PRIVATE_pathSegments","__PRIVATE_targetStore","__PRIVATE_originalDbTarget","__PRIVATE_originalTargetData","__PRIVATE_updatedDbTarget","ownerId","allowTabSynchronization","leaseTimestampMs","lastStreamToken","highestTargetId","highestListenSequenceNumber","lastRemoteSnapshotVersion","documentTargetsIndex","documentTargetsKeyPath","queryTargetsIndexName","queryTargetsKeyPath","clientId","updateTimeMs","networkEnabled","inForeground","ALL_STORES","__PRIVATE_IndexedDbIndexManager","__PRIVATE_collectionParentsCache","__PRIVATE_collectionParent","__PRIVATE_parentPaths","__PRIVATE_TargetIdGenerator","__PRIVATE_lastId","__PRIVATE_IndexedDbTargetCache","__PRIVATE_retrieveMetadata","__PRIVATE_targetIdGenerator","__PRIVATE_saveMetadata","__PRIVATE_targetGlobal","__PRIVATE_saveTargetData","__PRIVATE_updateMetadataFromTargetData","__PRIVATE_removeMatchingKeysForTargetId","__PRIVATE_targetsStore","__PRIVATE_removeTargetData","__PRIVATE_globalTargetStore","updated","__PRIVATE_addReference","__PRIVATE_removeReference","__PRIVATE_PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG","__PRIVATE_IndexedDbTransaction","__PRIVATE_currentSequenceNumber","__PRIVATE_lruParams","__PRIVATE_forceOwningTab","__PRIVATE_isAvailable","__PRIVATE_IndexedDbLruDelegate","__PRIVATE_dbName","__PRIVATE_simpleDb","__PRIVATE_targetCache","localStorage","__PRIVATE_webStorage","__PRIVATE_updateClientMetadataAndTryBecomePrimary","isPrimary","__PRIVATE_attachVisibilityHandler","__PRIVATE_attachWindowUnloadHook","__PRIVATE_scheduleClientMetadataAndPrimaryLeaseRefreshes","runTransaction","__PRIVATE_getHighestSequenceNumber","__PRIVATE_listenSequence","__PRIVATE__started","__PRIVATE_primaryStateListener","__PRIVATE_primaryState","__PRIVATE_started","__PRIVATE_databaseDeletedListener","__PRIVATE_setVersionChangeListener","newVersion","__PRIVATE_clientMetadataStore","__PRIVATE_verifyPrimaryLease","__PRIVATE_success","__PRIVATE_enqueueRetryable","__PRIVATE_canActAsPrimary","__PRIVATE_releasePrimaryLeaseIfHeld","__PRIVATE_acquireOrExtendPrimaryLease","__PRIVATE_primaryClientStore","__PRIVATE_primaryClient","__PRIVATE_isLocalClient","__PRIVATE_isWithinAge","__PRIVATE_lastGarbageCollectionTime","__PRIVATE_inactiveClients","__PRIVATE_metadataStore","__PRIVATE_existingClients","active","__PRIVATE_filterActiveClients","__PRIVATE_inactive","__PRIVATE_client","__PRIVATE_inactiveClient","removeItem","__PRIVATE_zombiedClientLocalStorageKey","__PRIVATE_clientMetadataRefresher","__PRIVATE_maybeGarbageCollectMultiClientState","__PRIVATE_currentPrimary","__PRIVATE_isClientZombied","__PRIVATE_otherClient","__PRIVATE_otherClientHasBetterNetworkState","__PRIVATE_otherClientHasBetterVisibility","__PRIVATE_otherClientHasSameNetworkState","__PRIVATE_markClientZombied","__PRIVATE_detachVisibilityHandler","__PRIVATE_detachWindowUnloadHook","__PRIVATE_removeClientMetadata","__PRIVATE_removeClientZombiedEntry","__PRIVATE_clients","__PRIVATE_activityThresholdMs","__PRIVATE_clientMetadata","__PRIVATE_forUser","__PRIVATE_transactionOperation","__PRIVATE_simpleDbMode","__PRIVATE_persistenceTransaction","__PRIVATE_simpleDbTxn","__PRIVATE_holdsPrimaryLease","__PRIVATE_verifyAllowTabSynchronization","__PRIVATE_raiseOnCommittedEvent","__PRIVATE_newPrimary","__PRIVATE_maxAgeMs","__PRIVATE_documentVisibilityHandler","__PRIVATE_windowUnloadHandler","__PRIVATE_shutdown","__PRIVATE_isZombied","getItem","setItem","__PRIVATE_docCountPromise","__PRIVATE_orphanedDocumentCount","__PRIVATE_getTargetCache","__PRIVATE_getTargetCount","__PRIVATE_docCount","__PRIVATE_orphanedCount","__PRIVATE_forEachOrphanedDocument","__PRIVATE_iterateSerial","__PRIVATE_mutationQueuesContainKey","__PRIVATE_changeBuffer","__PRIVATE_getRemoteDocumentCache","__PRIVATE_newChangeBuffer","__PRIVATE_documentCount","__PRIVATE_isPinned","__PRIVATE_withSequenceNumber","__PRIVATE_updateTargetData","__PRIVATE_nextPath","__PRIVATE_nextToReport","__PRIVATE_getSize","__PRIVATE_sentinelRow","__PRIVATE_indexedDbStoragePrefix","__PRIVATE_isDefaultDatabase","__PRIVATE_LocalStoreImpl","persistence","__PRIVATE_queryEngine","__PRIVATE_initialUser","t","__PRIVATE_getMutationQueue","__PRIVATE_remoteDocuments","__PRIVATE_localDocuments","__PRIVATE_getIndexManager","__PRIVATE_setLocalDocumentsView","__PRIVATE_newMutationQueue","__PRIVATE_newLocalDocuments","__PRIVATE_oldBatches","__PRIVATE_getAllMutationBatches","__PRIVATE_promisedOldBatches","__PRIVATE_newBatches","__PRIVATE_removedBatchIds","__PRIVATE_addedBatchIds","__PRIVATE_changedKeys","__PRIVATE_getDocuments","__PRIVATE_affectedDocuments","Vh","yh","ph","__PRIVATE_existingDocs","__PRIVATE_addMutationBatch","__PRIVATE_applyToLocalDocumentSet","Nn","__PRIVATE_affected","__PRIVATE_documentBuffer","Gr","__PRIVATE_applyWriteToRemoteDocuments","__PRIVATE_performConsistencyCheck","__PRIVATE_affectedKeys","__PRIVATE_getHighestUnacknowledgedBatchId","__PRIVATE_getLastRemoteSnapshotVersion","__PRIVATE_remoteVersion","__PRIVATE_newTargetDataByTargetMap","__PRIVATE_targetDataByTarget","__PRIVATE_oldTargetData","__PRIVATE_removeMatchingKeys","__PRIVATE_addMatchingKeys","__PRIVATE_newTargetData","__PRIVATE_withResumeToken","__PRIVATE_shouldPersistTargetData","__PRIVATE_updatedKeys","__PRIVATE_existingDoc","__PRIVATE_updateLimboDocument","__PRIVATE_updateRemoteVersion","__PRIVATE_setTargetsMetadata","__PRIVATE_toMicroseconds","__PRIVATE_RESUME_TOKEN_MAX_AGE_MICROS","__PRIVATE_viewChanges","__PRIVATE_viewChange","__PRIVATE_updatedTargetData","__PRIVATE_withLastLimboFreeSnapshotVersion","__PRIVATE_afterBatchId","__PRIVATE_getNextMutationBatchAfterBatchId","__PRIVATE_getTargetData","__PRIVATE_cached","__PRIVATE_allocateTargetId","__PRIVATE_addTargetData","__PRIVATE_cachedTargetData","__PRIVATE_targetIdByTarget","__PRIVATE_keepPersistedTargetData","__PRIVATE_usePreviousResults","__PRIVATE_remoteKeys","__PRIVATE_getMatchingKeysForTargetId","qh","__PRIVATE_docKeys","__PRIVATE_promiseChain","__PRIVATE_ackVersion","__PRIVATE_applyToRemoteDocument","__PRIVATE_collect","__PRIVATE_getCachedTarget","__PRIVATE_localStoreImpl","__PRIVATE_targetCacheImpl","__PRIVATE_ReferenceSet","__PRIVATE_DocReference","__PRIVATE_compareByKey","__PRIVATE_compareByTargetId","__PRIVATE_refsByKey","ref","__PRIVATE_refsByTarget","__PRIVATE_removeRef","__PRIVATE_emptyKey","__PRIVATE_startRef","__PRIVATE_endRef","__PRIVATE_forEachInRange","__PRIVATE_firstRef","__PRIVATE_firstAfterOrEqual","__PRIVATE_targetOrBatchId","User","__PRIVATE_otherUser","__PRIVATE_OAuthToken","__PRIVATE_authHeaders","__PRIVATE_EmptyCredentialsProvider","__PRIVATE_changeListener","__PRIVATE_FirebaseCredentialsProvider","__PRIVATE_authProvider","__PRIVATE_tokenListener","__PRIVATE_tokenCounter","currentUser","__PRIVATE_getUser","__PRIVATE_receivedInitialUser","auth","getImmediate","optional","addAuthTokenListener","__PRIVATE_initialTokenCounter","forceRefresh","getToken","__PRIVATE_tokenData","accessToken","removeAuthTokenListener","__PRIVATE_currentUid","getUid","__PRIVATE_FirstPartyToken","__PRIVATE_gapi","__PRIVATE_sessionIndex","__PRIVATE_FIRST_PARTY","ea","headers","X-Goog-AuthUser","__PRIVATE_authHeader","__PRIVATE_getAuthHeaderValueForFirstParty","__PRIVATE_FirstPartyCredentialsProvider","__PRIVATE_PersistentStream","__PRIVATE_connectionTimerId","__PRIVATE_idleTimerId","__PRIVATE_connection","__PRIVATE_credentialsProvider","__PRIVATE_performBackoff","__PRIVATE_isStarted","__PRIVATE_isOpen","__PRIVATE_idleTimer","__PRIVATE_handleIdleCloseTimer","__PRIVATE_cancelIdleCheck","stream","send","__PRIVATE_finalState","__PRIVATE_closeCount","__PRIVATE_resetToMax","__PRIVATE_invalidateToken","__PRIVATE_tearDown","__PRIVATE_onClose","__PRIVATE_dispatchIfNotClosed","__PRIVATE_getCloseGuardedDispatcher","token","__PRIVATE_startStream","__PRIVATE_rpcError","__PRIVATE_handleStreamClose","__PRIVATE_startRpc","__PRIVATE_onOpen","onMessage","__PRIVATE_startCloseCount","__PRIVATE_PersistentListenStream","credentials","__PRIVATE_openStream","__PRIVATE_watchChangeProto","snapshot","__PRIVATE_versionFromListenResponse","__PRIVATE_onWatchChange","addTarget","__PRIVATE_toTarget","labels","__PRIVATE_sendRequest","__PRIVATE_PersistentWriteStream","Oa","__PRIVATE_handshakeComplete_","__PRIVATE_writeMutations","__PRIVATE_responseProto","streamToken","writeResults","__PRIVATE_onMutationResult","__PRIVATE_onHandshakeComplete","writes","__PRIVATE_DatastoreImpl","__PRIVATE_terminated","__PRIVATE_rpcName","__PRIVATE_verifyInitialized","__PRIVATE_invokeRPC","__PRIVATE_invokeStreamingRPC","__PRIVATE_OnlineStateTracker","__PRIVATE_onlineStateHandler","__PRIVATE_watchStreamFailures","__PRIVATE_setAndBroadcast","__PRIVATE_onlineStateTimer","__PRIVATE_logClientOfflineWarningIfNecessary","__PRIVATE_clearOnlineStateTimer","__PRIVATE_newState","__PRIVATE_shouldWarnClientIsOffline","details","__PRIVATE_RemoteStore","__PRIVATE_datastore","__PRIVATE_connectivityMonitor","Set","__PRIVATE_addCallback","__PRIVATE_canUseNetwork","__PRIVATE_restartNetwork","__PRIVATE_onlineStateTracker","__PRIVATE_watchStream","__PRIVATE_datastoreImpl","__PRIVATE_newPersistentWatchStream","Na","__PRIVATE_onWatchStreamOpen","ba","__PRIVATE_onWatchStreamClose","ka","__PRIVATE_onWatchStreamChange","__PRIVATE_writeStream","__PRIVATE_newPersistentWriteStream","__PRIVATE_onWriteStreamOpen","__PRIVATE_onWriteStreamClose","Ba","__PRIVATE_onWriteHandshakeComplete","qa","enableNetwork","__PRIVATE_offlineCauses","__PRIVATE_enableNetworkInternal","__PRIVATE_shouldStartWatchStream","__PRIVATE_startWatchStream","__PRIVATE_fillWritePipeline","__PRIVATE_disableNetworkInternal","stop","__PRIVATE_writePipeline","__PRIVATE_cleanUpWatchStreamState","__PRIVATE_listenTargets","__PRIVATE_sendWatchRequest","__PRIVATE_sendUnwatchRequest","__PRIVATE_markIdle","__PRIVATE_syncEngine","__PRIVATE_watchChangeAggregator","__PRIVATE_watch","__PRIVATE_unwatch","__PRIVATE_handleWatchStreamStart","__PRIVATE_handleWatchStreamFailure","__PRIVATE_handleTargetError","__PRIVATE_disableNetworkUntilRecovery","__PRIVATE_handleDocumentChange","__PRIVATE_handleExistenceFilter","__PRIVATE_handleTargetChange","__PRIVATE_raiseWatchSnapshot","__PRIVATE_createRemoteEvent","__PRIVATE_requestTargetData","__PRIVATE_applyRemoteEvent","__PRIVATE_rejectListen","__PRIVATE_lastBatchIdRetrieved","__PRIVATE_canAddToWritePipeline","__PRIVATE_nextMutationBatch","__PRIVATE_addToWritePipeline","__PRIVATE_shouldStartWriteStream","__PRIVATE_startWriteStream","__PRIVATE_handshakeComplete","__PRIVATE_writeHandshake","__PRIVATE_executeWithRecovery","__PRIVATE_applySuccessfulWrite","__PRIVATE_handleWriteError","__PRIVATE_inhibitBackoff","__PRIVATE_rejectFailedWrite","__PRIVATE_verifyOperationInProgress","__PRIVATE_handleCredentialChange","createWebStorageClientStateKey","createWebStorageMutationBatchKey","__PRIVATE_mutationKey","createWebStorageQueryTargetMetadataKey","__PRIVATE_MutationMetadata","__PRIVATE_mutationBatch","parse","__PRIVATE_validData","__PRIVATE_firestoreError","__PRIVATE_batchMetadata","__PRIVATE_QueryTargetMetadata","__PRIVATE_RemoteClientState","__PRIVATE_clientState","Array","__PRIVATE_activeTargetIdsSet","__PRIVATE_SharedOnlineState","onlineState","__PRIVATE_LocalClientState","__PRIVATE_WebStorageSharedClientState","__PRIVATE_localClientId","__PRIVATE_handleWebStorageEvent","__PRIVATE_escapedPersistenceKey","storage","__PRIVATE_localClientStorageKey","__PRIVATE_sequenceNumberKey","createWebStorageSequenceNumberKey","__PRIVATE_activeClients","__PRIVATE_clientStateKeyRe","__PRIVATE_mutationBatchKeyRe","__PRIVATE_queryTargetKeyRe","__PRIVATE_onlineStateKey","createWebStorageOnlineStateKey","__PRIVATE_storageListener","__PRIVATE_getActiveClients","__PRIVATE_storageItem","__PRIVATE_fromWebStorageEntry","__PRIVATE_persistClientState","__PRIVATE_onlineStateJSON","__PRIVATE_fromWebStorageOnlineState","__PRIVATE_handleOnlineStateEvent","__PRIVATE_earlyEvents","__PRIVATE_extractActiveQueryTargets","__PRIVATE_persistMutationState","__PRIVATE_removeMutationState","__PRIVATE_queryState","__PRIVATE_isActiveQueryTarget","__PRIVATE_localClientState","__PRIVATE_addQueryTarget","__PRIVATE_removeQueryTarget","__PRIVATE_persistQueryTargetState","__PRIVATE_addPendingMutation","__PRIVATE_persistOnlineState","__PRIVATE_storageEvent","storageArea","__PRIVATE_fromWebStorageClientStateKey","__PRIVATE_handleClientStateEvent","__PRIVATE_fromWebStorageClientState","__PRIVATE_mutationMetadata","__PRIVATE_fromWebStorageMutationMetadata","__PRIVATE_handleMutationBatchEvent","__PRIVATE_queryTargetMetadata","__PRIVATE_fromWebStorageQueryTargetMetadata","__PRIVATE_handleQueryTargetEvent","__PRIVATE_seqString","__PRIVATE_parsed","__PRIVATE_fromWebStorageSequenceNumber","Ic","__PRIVATE_toWebStorageJSON","__PRIVATE_mutationState","__PRIVATE_targetKey","__PRIVATE_targetMetadata","__PRIVATE_applyBatchState","__PRIVATE_applyTargetState","__PRIVATE_updatedClients","__PRIVATE_existingTargets","__PRIVATE_newTargets","__PRIVATE_addedTargets","__PRIVATE_removedTargets","__PRIVATE_applyActiveTargetsChange","__PRIVATE_activeTargets","__PRIVATE_kev","__PRIVATE_unionWith","__PRIVATE_MemorySharedClientState","__PRIVATE_localState","__PRIVATE_AddedLimboDocument","__PRIVATE_RemovedLimboDocument","__PRIVATE_View","__PRIVATE__syncedDocuments","__PRIVATE_docComparator","__PRIVATE_documentSet","Qc","__PRIVATE_previousChanges","__PRIVATE_changeSet","__PRIVATE_oldDocumentSet","__PRIVATE_newMutatedKeys","__PRIVATE_newDocumentSet","__PRIVATE_needsRefill","__PRIVATE_lastDocInLimit","__PRIVATE_hasLimitToFirst","__PRIVATE_firstDocInLimit","__PRIVATE_hasLimitToLast","__PRIVATE_newMaybeDoc","__PRIVATE_oldDoc","__PRIVATE_oldDocHadPendingMutations","__PRIVATE_newDocHasPendingMutations","__PRIVATE_changeApplied","track","__PRIVATE_shouldWaitForSyncedDocument","Uc","jc","Gc","Lt","__PRIVATE_updateLimboDocuments","__PRIVATE_getChanges","__PRIVATE_c1","__PRIVATE_c2","__PRIVATE_compareChangeType","__PRIVATE_applyTargetChange","__PRIVATE_limboChanges","__PRIVATE_newSyncState","__PRIVATE_limboDocuments","__PRIVATE_syncState","Yc","__PRIVATE_oldLimboDocuments","__PRIVATE_shouldBeInLimbo","__PRIVATE_queryResult","__PRIVATE_computeDocChanges","__PRIVATE_fromInitialDocuments","__PRIVATE_QueryView","view","__PRIVATE_LimboResolution","__PRIVATE_SyncEngineImpl","__PRIVATE_remoteStore","__PRIVATE_sharedClientState","__PRIVATE_maxConcurrentLimboResolutions","q","__PRIVATE_forSyncEngine","Tl","__PRIVATE__isPrimaryClient","__PRIVATE_syncEngineListener","__PRIVATE_assertSubscribed","__PRIVATE_queryView","__PRIVATE_queryViewsByQuery","__PRIVATE_addLocalQueryTarget","__PRIVATE_computeInitialSnapshot","__PRIVATE_allocateTarget","__PRIVATE_initializeViewAndComputeSnapshot","__PRIVATE_isPrimaryClient","listen","__PRIVATE_executeQuery","__PRIVATE_viewDocChanges","__PRIVATE_synthesizedTargetChange","__PRIVATE_updateTrackedLimbos","__PRIVATE_queriesByTarget","__PRIVATE_queries","__PRIVATE_removeLocalQueryTarget","__PRIVATE_releaseTarget","__PRIVATE_clearQueryState","__PRIVATE_unlisten","__PRIVATE_removeAndCleanupTarget","__PRIVATE_userCallback","__PRIVATE_localWrite","__PRIVATE_addMutationCallback","__PRIVATE_emitNewSnapsAndNotifyLocalStore","__PRIVATE_limboResolution","__PRIVATE_activeLimboResolutionsByTarget","__PRIVATE_receivedDocument","source","__PRIVATE_newViewSnapshots","__PRIVATE_applyOnlineStateChange","__PRIVATE_onOnlineStateChange","__PRIVATE_setOnlineState","__PRIVATE_updateQueryState","__PRIVATE_limboKey","__PRIVATE_activeLimboTargetsByKey","__PRIVATE_pumpEnqueuedLimboResolutions","__PRIVATE_mutationBatchResult","__PRIVATE_acknowledgeBatch","__PRIVATE_processUserCallback","__PRIVATE_triggerPendingWritesCallbacks","__PRIVATE_updateMutationState","__PRIVATE_rejectBatch","__PRIVATE_highestBatchId","__PRIVATE_callbacks","__PRIVATE_pendingWritesCallbacks","__PRIVATE_errorMessage","clear","__PRIVATE_newCallbacks","__PRIVATE_mutationUserCallbacks","__PRIVATE_toKey","__PRIVATE_onWatchError","__PRIVATE_limboDocumentRefs","__PRIVATE_removeReferencesForId","__PRIVATE_removeLimboTarget","__PRIVATE_limboTargetId","__PRIVATE_limboChange","__PRIVATE_trackLimboChange","__PRIVATE_enqueuedLimboResolutions","__PRIVATE_limboTargetIdGenerator","__PRIVATE_newSnaps","__PRIVATE_docChangesInAllViews","__PRIVATE_queriesProcessed","__PRIVATE_fromSnapshot","__PRIVATE_notifyLocalViewChanges","__PRIVATE_fnName","__PRIVATE_handleUserChange","__PRIVATE_rejectOutstandingPendingWritesCallbacks","__PRIVATE_keySet","__PRIVATE_syncedDocuments","__PRIVATE_synchronizeViewAndComputeSnapshot","__PRIVATE_syncEngineImpl","__PRIVATE_synchronizeWithPersistedState","__PRIVATE_batchState","__PRIVATE_mutationQueueImpl","__PRIVATE_lookupMutationKeys","__PRIVATE_lookupMutationDocuments","__PRIVATE_removeCachedMutationBatchMetadata","__PRIVATE_applyPrimaryState","__PRIVATE_getAllActiveQueryTargets","__PRIVATE_activeQueries","__PRIVATE_synchronizeQueryViewsAndRaiseSnapshots","__PRIVATE_isLocalQueryTarget","__PRIVATE_removeAllReferences","__PRIVATE_resetLimboDocuments","__PRIVATE_transitionToPrimary","__PRIVATE_synthesizeTargetToQuery","__PRIVATE_remoteDocumentCacheImpl","__PRIVATE_getNewDocumentChanges","__PRIVATE_lastDocumentChangeReadTime","__PRIVATE_synthesizedRemoteEvent","__PRIVATE_createSynthesizedRemoteEventForCurrentChange","__PRIVATE_removed","__PRIVATE_QueryListenersInfo","__PRIVATE_EventManager","subscribe","__PRIVATE_firstListen","__PRIVATE_queryInfo","__PRIVATE_viewSnap","onError","listeners","__PRIVATE_onViewSnapshot","__PRIVATE_raiseSnapshotsInSyncEvent","__PRIVATE_lastListen","__PRIVATE_viewSnaps","__PRIVATE_raisedEvent","observer","__PRIVATE_snapshotsInSyncListeners","__PRIVATE_QueryListener","__PRIVATE_queryObserver","__PRIVATE_snap","includeMetadataChanges","__PRIVATE_raisedInitialEvent","__PRIVATE_shouldRaiseEvent","__PRIVATE_shouldRaiseInitialEvent","__PRIVATE_raiseInitialEvent","__PRIVATE_maybeOnline","__PRIVATE_waitForSyncWhenOnline","__PRIVATE_hasPendingWritesChanged","__PRIVATE_IndexFreeQueryEngine","__PRIVATE_localDocumentsView","__PRIVATE_matchesAllDocuments","__PRIVATE_executeFullCollectionScan","__PRIVATE_previousResults","__PRIVATE_applyQuery","__PRIVATE_updatedResults","__PRIVATE_sortedPreviousResults","__PRIVATE_limboFreeSnapshotVersion","__PRIVATE_docAtLimitEdge","__PRIVATE_MemoryMutationQueue","__PRIVATE_batchesByDocumentKey","__PRIVATE_findMutationBatch","__PRIVATE_rawIndex","__PRIVATE_indexOfBatchId","__PRIVATE_findMutationBatches","prefix","__PRIVATE_startPath","__PRIVATE_rowKeyPath","__PRIVATE_indexOfExistingBatchId","__PRIVATE_references","__PRIVATE_MemoryRemoteDocumentCache","__PRIVATE_sizer","__PRIVATE_currentSize","iterator","__PRIVATE_MemoryTargetCache","__PRIVATE_forTargetCache","__PRIVATE_highestSequenceNumber","__PRIVATE_removals","__PRIVATE_addReferences","__PRIVATE_removeReferences","__PRIVATE_matchingKeys","__PRIVATE_referencesForId","__PRIVATE_MemoryPersistence","__PRIVATE_referenceDelegateFactory","__PRIVATE_documentSize","__PRIVATE_mutationQueues","__PRIVATE_MemoryTransaction","__PRIVATE_onTransactionStarted","__PRIVATE_onTransactionCommitted","__PRIVATE_or","__PRIVATE_MemoryEagerDelegate","E_","__PRIVATE__orphanedDocuments","__PRIVATE_localViewReferences","__PRIVATE_orphanedDocuments","__PRIVATE_isReferenced","__PRIVATE_StreamBridge","__PRIVATE_sendFn","__PRIVATE_closeFn","__PRIVATE_wrappedOnOpen","__PRIVATE_wrappedOnClose","__PRIVATE_wrappedOnMessage","__PRIVATE_RPC_NAME_URL_MAPPING","BatchGetDocuments","Commit","RunQuery","__PRIVATE_WebChannelConnection","__PRIVATE_databaseInfo","__PRIVATE_baseUrl","__PRIVATE_databaseRoot","__PRIVATE_req","url","__PRIVATE_makeUrl","__PRIVATE_modifyHeadersForRequest","__PRIVATE_performRPCRequest","response","__PRIVATE_header","__PRIVATE_urlRpcName","info","body","__PRIVATE_xhr","XhrIo","listenOnce","EventType","COMPLETE","getLastErrorCode","ErrorCode","NO_ERROR","json","getResponseJson","TIMEOUT","HTTP_ERROR","getStatus","getResponseText","__PRIVATE_responseError","__PRIVATE_firestoreErrorCode","__PRIVATE_serverError","toLowerCase","__PRIVATE_mapCodeFromHttpResponseErrorStatus","__PRIVATE_requestString","__PRIVATE_urlParts","__PRIVATE_webchannelTransport","createWebChannelTransport","httpSessionIdParam","initMessageHeaders","messageUrlParams","sendRawJson","supportsCrossDomainXhr","internalChannelParams","forwardChannelRequestTimeoutMs","isMobileCordova","isReactNative","isElectron","isIE","isUWP","isBrowserExtension","httpHeadersOverwriteParam","channel","createWebChannel","__PRIVATE_opened","closed","__PRIVATE_streamBridge","m_","A_","__PRIVATE_unguardedEventListen","param","WebChannel","OPEN","CLOSE","__PRIVATE_callOnClose","MESSAGE","__PRIVATE_msgData","__PRIVATE_msgDataOrError","__PRIVATE_mapCodeFromRpcStatus","__PRIVATE_callOnMessage","__PRIVATE_callOnOpen","__PRIVATE_BrowserConnectivityMonitor","__PRIVATE_onNetworkAvailable","__PRIVATE_onNetworkUnavailable","__PRIVATE_configureNetworkMonitoring","__PRIVATE_networkAvailableListener","__PRIVATE_networkUnavailableListener","__PRIVATE_NoopConnectivityMonitor","__PRIVATE_newSerializer","__PRIVATE_MEMORY_ONLY_PERSISTENCE_ERROR_MESSAGE","__PRIVATE_MemoryOfflineComponentProvider","__PRIVATE_cfg","__PRIVATE_createSharedClientState","__PRIVATE_createPersistence","__PRIVATE_gcScheduler","__PRIVATE_createGarbageCollectionScheduler","__PRIVATE_createLocalStore","__PRIVATE_persistenceSettings","__PRIVATE_durable","__PRIVATE_factory","__PRIVATE_IndexedDbOfflineComponentProvider","initialize","__PRIVATE_getLastReadTime","__PRIVATE_synchronizeLastDocumentChangeReadTime","synchronizeTabs","__PRIVATE_withCacheSize","cacheSizeBytes","__PRIVATE_indexedDbClearPersistence","__PRIVATE_MultiTabOfflineComponentProvider","__PRIVATE_onlineComponentProvider","Fc","kc","xc","rh","__PRIVATE_setPrimaryStateListener","__PRIVATE_OnlineComponentProvider","__PRIVATE_offlineComponentProvider","__PRIVATE_createDatastore","__PRIVATE_createRemoteStore","__PRIVATE_createSyncEngine","__PRIVATE_eventManager","__PRIVATE_createEventManager","__PRIVATE_newDatastore","__PRIVATE_newSyncEngine","__PRIVATE_isPartialObserver","__PRIVATE_methods","object","method","__PRIVATE_implementsAnyMethods","__PRIVATE_AsyncObserver","__PRIVATE_scheduleEvent","console","muted","eventHandler","__PRIVATE_validateNoArgs","functionName","__PRIVATE_formatPlural","__PRIVATE_validateExactNumberOfArgs","__PRIVATE_numberOfArgs","__PRIVATE_validateAtLeastNumberOfArgs","__PRIVATE_minNumberOfArgs","__PRIVATE_validateBetweenNumberOfArgs","__PRIVATE_maxNumberOfArgs","__PRIVATE_validateArgType","__PRIVATE_argument","__PRIVATE_validateType","__PRIVATE_ordinal","__PRIVATE_validateOptionalArgType","__PRIVATE_validateNamedType","__PRIVATE_optionName","__PRIVATE_validateNamedOptionalType","__PRIVATE_validateOptionalArrayElements","__PRIVATE_typeDescription","__PRIVATE_validator","__PRIVATE_valueDescription","__PRIVATE_validateArrayElements","__PRIVATE_validateNamedOptionalPropertyEquals","__PRIVATE_inputName","input","__PRIVATE_expected","__PRIVATE_expectedDescription","__PRIVATE_actualDescription","__PRIVATE_validateNamedPropertyEquals","__PRIVATE_validateStringEnum","__PRIVATE_enums","valid","__PRIVATE_isPlainObject","description","getPrototypeOf","__PRIVATE_customObjectName","__PRIVATE_tryGetCustomObjectType","__PRIVATE_validateDefined","__PRIVATE_validateOptionNames","__PRIVATE_optionNames","__PRIVATE_invalidClassError","__PRIVATE_validatePositiveNumber","num","__PRIVATE_assertUint8ArrayAvailable","Blob","__PRIVATE_byteString","__PRIVATE__byteString","arguments","__PRIVATE_BaseFieldPath","fieldNames","__PRIVATE_minNumberOfElements","__PRIVATE_validateNamedArrayAtLeastNumberOfElements","__PRIVATE__internalPath","__PRIVATE_InternalFieldPath","__PRIVATE_RESERVED","__PRIVATE_SerializableFieldValue","__PRIVATE_DeleteFieldValueImpl","__PRIVATE__methodName","context","__PRIVATE_dataSource","__PRIVATE_createError","__PRIVATE_createSentinelChildContext","__PRIVATE_fieldValue","__PRIVATE_arrayElement","__PRIVATE_ParseContext","af","cf","settings","__PRIVATE_targetDoc","methodName","lf","ignoreUndefinedProperties","__PRIVATE_ServerTimestampFieldValueImpl","__PRIVATE_ArrayUnionFieldValueImpl","__PRIVATE__elements","__PRIVATE_parseContext","__PRIVATE_parsedElements","__PRIVATE_parseData","arrayUnion","__PRIVATE_ArrayRemoveFieldValueImpl","__PRIVATE_NumericIncrementFieldValueImpl","__PRIVATE__operand","__PRIVATE_numericIncrement","FieldValue","__PRIVATE_FieldValueDelegate","__PRIVATE__delegate","__PRIVATE__toFieldTransform","GeoPoint","isFinite","__PRIVATE__lat","__PRIVATE__long","__PRIVATE_RESERVED_FIELD_REGEX","__PRIVATE_DocumentKeyReference","__PRIVATE__databaseId","__PRIVATE__key","__PRIVATE__converter","__PRIVATE_ParsedSetData","__PRIVATE_ParsedUpdateData","__PRIVATE_isWrite","__PRIVATE_validatePath","configuration","__PRIVATE_childPath","__PRIVATE_contextWith","__PRIVATE_validatePathSegment","__PRIVATE_hasConverter","__PRIVATE_UserDataReader","pf","__PRIVATE_parseSetData","__PRIVATE_userDataReader","__PRIVATE_createContext","merge","mergeFields","__PRIVATE_validatePlainObject","__PRIVATE_updateData","__PRIVATE_parseObject","__PRIVATE_validatedFieldPaths","__PRIVATE_stringOrFieldPath","__PRIVATE_fieldPathFromDotSeparatedString","__PRIVATE_fieldMaskContains","__PRIVATE_covers","__PRIVATE_parseUpdateData","__PRIVATE_fieldMaskPaths","__PRIVATE_childContext","__PRIVATE_childContextForFieldPath","__PRIVATE_parsedValue","mask","__PRIVATE_parseUpdateVarargs","moreFieldsAndValues","__PRIVATE_fieldPathFromArgument","__PRIVATE_parseQueryValue","__PRIVATE_allowArrays","__PRIVATE_looksLikeJsonObject","__PRIVATE_parseSentinelFieldValue","__PRIVATE_entryIndex","__PRIVATE_parsedEntry","__PRIVATE_childContextForArray","__PRIVATE_parseArray","fromDate","bytesValue","__PRIVATE_thisDb","__PRIVATE_otherDb","__PRIVATE_parseScalarValue","__PRIVATE_childContextForField","search","__PRIVATE_fromDotSeparatedString","__PRIVATE_hasPath","__PRIVATE_hasDocument","Transaction","__PRIVATE_ensureCommitNotCalled","__PRIVATE_invokeBatchGetDocumentsRpc","__PRIVATE_recordVersion","write","__PRIVATE_toMutations","__PRIVATE_writtenDocs","__PRIVATE_preconditionForUpdate","__PRIVATE_lastWriteError","__PRIVATE_unwritten","__PRIVATE_readVersions","__PRIVATE_invokeCommitRpc","__PRIVATE_committed","__PRIVATE_docVersion","__PRIVATE_existingVersion","__PRIVATE_TransactionRunner","updateFunction","__PRIVATE_runWithBackOff","__PRIVATE_tryRunUpdateFunction","commit","__PRIVATE_commitError","__PRIVATE_handleTransactionError","__PRIVATE_userPromiseError","__PRIVATE_retries","__PRIVATE_isRetryableTransactionError","__PRIVATE_FirestoreClient","__PRIVATE_newId","__PRIVATE_verifyNotTerminated","__PRIVATE_persistenceResult","__PRIVATE_initialized","__PRIVATE_setChangeListener","__PRIVATE_initializeComponents","__PRIVATE_initializationDone","__PRIVATE_setNetworkEnabled","__PRIVATE_componentConfiguration","ti","b_","j_","il","G_","__PRIVATE_eventMgr","__PRIVATE_setDatabaseDeletedListener","terminate","__PRIVATE_canFallback","K_","DOMException","__PRIVATE_isShuttingDown","disableNetwork","__PRIVATE_enqueueAndInitiateShutdown","__PRIVATE_removeChangeListener","__PRIVATE_registerPendingWritesCallback","__PRIVATE_wrappedObserver","__PRIVATE_mute","__PRIVATE_readDocument","__PRIVATE_enqueueReadDocumentFromCache","__PRIVATE_enqueueListen","Gl","__PRIVATE_enqueueReadDocumentViaSnapshotListener","__PRIVATE_enqueueExecuteQueryFromCache","__PRIVATE_enqueueExecuteQueryViaSnapshotListener","__PRIVATE_addSnapshotsInSyncListener","__PRIVATE_removeSnapshotsInSyncListener","Yf","run","__PRIVATE_eventManger","__PRIVATE_UserDataWriter","timestampsInSnapshots","__PRIVATE_serverTimestampBehavior","__PRIVATE_referenceFactory","__PRIVATE_convertTimestamp","__PRIVATE_convertServerTimestamp","__PRIVATE_convertReference","__PRIVATE_convertGeoPoint","__PRIVATE_convertArray","__PRIVATE_convertObject","__PRIVATE_convertValue","__PRIVATE_getPreviousValue","__PRIVATE_normalizedValue","toDate","__PRIVATE_resourcePath","CACHE_SIZE_UNLIMITED","__PRIVATE_FirestoreSettings","__PRIVATE_MINIMUM_CACHE_SIZE_BYTES","experimentalForceLongPolling","Firestore","__PRIVATE_databaseIdOrApp","__PRIVATE__offlineComponentProvider","__PRIVATE__onlineComponentProvider","__PRIVATE_ensureClientConfigured","__PRIVATE__firestoreClient","app","__PRIVATE__firebaseApp","__PRIVATE_databaseIdFromApp","__PRIVATE__persistenceKey","__PRIVATE__credentials","external","__PRIVATE__settings","Id","__PRIVATE__userDataReader","__PRIVATE_settingsLiteral","__PRIVATE_newSettings","__PRIVATE_makeCredentialsProvider","experimentalForceOwningTab","experimentalTabSynchronization","__PRIVATE_configureClient","Vo","__PRIVATE_clientTerminated","__PRIVATE__queue","__PRIVATE_enqueueAndForgetEvenAfterShutdown","clearPersistence","_removeServiceInstance","Pd","waitForPendingWrites","arg","__PRIVATE_makeDatabaseInfo","__PRIVATE_pathString","CollectionReference","DocumentReference","__PRIVATE_forPath","Query","__PRIVATE_newQueryForCollectionGroup","WriteBatch","SILENT","INFO","VERBOSE","level","__PRIVATE_newLevel","setLogLevel","__PRIVATE__firestore","__PRIVATE__transaction","documentRef","__PRIVATE_validateReference","__PRIVATE_lookup","DocumentSnapshot","__PRIVATE_validateSetOptions","__PRIVATE_convertedValue","__PRIVATE_applyFirestoreDataConverter","__PRIVATE__dataReader","__PRIVATE_fieldOrUpdateData","__PRIVATE_ExternalFieldPath","__PRIVATE_verifyNotCommitted","__PRIVATE__mutations","__PRIVATE__committed","firestore","converter","__PRIVATE_currArg","__PRIVATE_internalOptions","__PRIVATE_userObserver","complete","__PRIVATE__convertToDocSnapshot","__PRIVATE_validateGetOptions","__PRIVATE_firestoreClient","__PRIVATE_getDocumentFromLocalCache","__PRIVATE_getDocumentViaSnapshotListener","SnapshotMetadata","__PRIVATE__document","__PRIVATE__fromCache","__PRIVATE__hasPendingWrites","__PRIVATE_validateSnapshotOptions","QueryDocumentSnapshot","fromFirestore","__PRIVATE__areTimestampsInSnapshotsEnabled","serverTimestamps","__PRIVATE_newQueryFilter","__PRIVATE_dataReader","__PRIVATE_validateDisjunctiveFilterElements","__PRIVATE_referenceList","__PRIVATE_parseDocumentIdValue","__PRIVATE_existingField","__PRIVATE_validateOrderByAndInequalityMatch","__PRIVATE_conflictingOp","__PRIVATE_findFilterOperator","__PRIVATE_conflictingOps","__PRIVATE_validateNewFilter","__PRIVATE_newQueryOrderBy","__PRIVATE_validateNewOrderBy","__PRIVATE_documentIdValue","operator","__PRIVATE_baseQuery","__PRIVATE_inequality","__PRIVATE_validateHasExplicitOrderByForLimitToLast","__PRIVATE__query","opStr","__PRIVATE_newFilters","__PRIVATE_queryWithAddedFilter","directionStr","__PRIVATE_newOrderBy","__PRIVATE_queryWithAddedOrderBy","__PRIVATE_docOrField","__PRIVATE_boundFromDocOrFields","components","__PRIVATE_newQueryBoundFromDocument","__PRIVATE_allFields","__PRIVATE_rawValue","__PRIVATE_wrapped","__PRIVATE_newQueryBoundFromFields","QuerySnapshot","__PRIVATE_getDocumentsFromLocalCache","__PRIVATE_getDocumentsViaSnapshotListener","__PRIVATE__originalQuery","__PRIVATE__snapshot","thisArg","__PRIVATE_convertToDocumentImpl","__PRIVATE__cachedChanges","__PRIVATE__cachedChangesIncludeMetadataChanges","__PRIVATE_lastDoc","oldIndex","newIndex","__PRIVATE_indexTracker","__PRIVATE_resultChangeType","__PRIVATE_changesFromSnapshot","__PRIVATE__path","toFirestore","__PRIVATE_docRef","__PRIVATE_firestoreNamespace","__PRIVATE_registerFirestore","instance","firebase","__PRIVATE_firestoreFactory","registerComponent","Component","container","getProvider","setServiceProps","__PRIVATE_configureForFirebase","registerVersion"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;AAuBA,MAAMA,IAAY,IAAIC,EAAO;;;SAGbC;IACd,OAAOF,EAAUG;;;SAOHC,EAASC,MAAgBC;IACvC,IAAIN,EAAUG,YAAYI,EAASC,OAAO;QACxC,MAAMC,IAAOH,EAAII,IAAIC;QACrBX,EAAUY,MAAM,yBAA+BP,MAAUI;;;;SAI7CI,EAASR,MAAgBC;IACvC,IAAIN,EAAUG,YAAYI,EAASO,OAAO;QACxC,MAAML,IAAOH,EAAII,IAAIC;QACrBX,EAAUe,MAAM,yBAA+BV,MAAUI;;;;SAI7CO,EAAQX,MAAgBC;IACtC,IAAIN,EAAUG,YAAYI,EAASU,MAAM;QACvC,MAAMR,IAAOH,EAAII,IAAIC;QACrBX,EAAUkB,KAAK,yBAA+Bb,MAAUI;;;;;;GAO5D,UAASE,EAAYL;IACnB,IAAmB,mBAARA,GACT,OAAOA;IAEP;QACE,OC7CqBa,ID6CHb,GC5Cfc,KAAKC,UAAUF;MD6ClB,OAAOG;;QAEP,OAAOhB;;;;;;;;;;;;;;;;;;;QChDca;;;;;;;;;;;;;;;;;;;;;;;;;;aCUXI,EAAKC,IAAkB;;;IAGrC,MAAMC,IACJ,mDAA2DD;;;;IAM7D,MALAX,EAASY,IAKH,IAAIC,MAAMD;;;;;;;;aASFE,EACdC,GACAH;IAEKG,KACHL;;;;;;aAyBYM,EACdvB;;AAEAwB;IAMA,OAAOxB;;;;;;;;;;;;;;;;;;;;;;;aC9DOyB,EAAYC;;IAI1B,MAAMC;;IAEY,sBAATC,SAAyBA,KAAKD,UAAWC,KAAuB,WACnEC,IAAQ,IAAIC,WAAWJ;IAC7B,IAAIC,GACFA,EAAOI,gBAAgBF;;IAGvB,KAAK,IAAIG,IAAI,GAAGA,IAAIN,GAAQM,KAC1BH,EAAMG,KAAKC,KAAKC,MAAsB,MAAhBD,KAAKE;IAG/B,OAAON;;;;;;;;;;;;;;;;;;UCfIO;IACXC;;QAEE,MAAMC,IACJ,kEAEIC,IAAcN,KAAKC,MAAM,MAAMI,EAAME,UAAUF,EAAME;;gBAM3D,IAAIC,IAAS;QAEb,MAAOA,EAAOD,SADO,MACgB;YACnC,MAAMX,IAAQJ,EAAY;YAC1B,KAAK,IAAIO,IAAI,GAAGA,IAAIH,EAAMW,UAAUR;;;YAG9BS,EAAOD,SANM,MAMmBX,EAAMG,KAAKO,MAC7CE,KAAUH,EAAMI,OAAOb,EAAMG,KAAKM,EAAME;;QAM9C,OAAOC;;;;SAIKE,EAAuBC,GAASC;IAC9C,OAAID,IAAOC,KACD,IAEND,IAAOC,IACF,IAEF;;;0DAQOC,EACdF,GACAC,GACAE;IAEA,OAAIH,EAAKJ,WAAWK,EAAML,UAGnBI,EAAKI,MAAM,CAACnC,GAAOoC,MAAUF,EAAWlC,GAAOgC,EAAMI;;;;;;aAM9CC,EAAmBC;;IAEjC,OAAOA,IAAI;;;;;;;;;;;;;;;;;;UCnEAC;;;;;;;;;;;;;IAaXf,YACWgB,GACAC,GACAC,GACAC,GACAC;iBAJAJ,GACAK,sBAAAJ,GACAI,YAAAH,GACAG,WAAAF,GACAE,wBAAAD;;;;;;MAQAE;IAEXtB,YAAqBuB,GAAmBC;QAAnBH,iBAAAE,GACnBF,KAAKG,WAAWA,KANU;;IAS5BC;QACE,OAV0B,gBAUnBJ,KAAKG;;IAGdxB,QAAQ0B;QACN,OACEA,aAAiBJ,KACjBI,EAAMH,cAAcF,KAAKE,aACzBG,EAAMF,aAAaH,KAAKG;;IAI5BxB,EAAU0B;QACR,OACEpB,EAAoBe,KAAKE,WAAWG,EAAMH,cAC1CjB,EAAoBe,KAAKG,UAAUE,EAAMF;;;;;;;;;;;;;;;;;;;aC3C/BG,EAAchE;IAC5B,IAAIiE,IAAQ;IACZ,KAAK,MAAMC,KAAOlE,GACZmE,OAAOC,UAAUC,eAAeC,KAAKtE,GAAKkE,MAC5CD;IAGJ,OAAOA;;;SAGOM,EACdvE,GACAwE;IAEA,KAAK,MAAMN,KAAOlE,GACZmE,OAAOC,UAAUC,eAAeC,KAAKtE,GAAKkE,MAC5CM,EAAGN,GAAKlE,EAAIkE;;;SAKFO,EAAWzE;IAKzB,KAAK,MAAMkE,KAAOlE,GAChB,IAAImE,OAAOC,UAAUC,eAAeC,KAAKtE,GAAKkE,IAC5C,QAAO;IAGX,QAAO;;;;;;;;;;;;;;;;;;;;;;;;UC3BIQ;IAWXrC,YACUsC,GACAC;iBADAD,YACAC;;;;;;;QANVlB,SAEI;;2EAQJrB,IAAI6B;QACF,MAAMW,IAAKnB,KAAKiB,EAAST,IACnBY,IAAUpB,KAAKqB,EAAMF;QAC3B,SAAgBG,MAAZF,GAGJ,KAAK,OAAOG,GAAUpE,MAAUiE,GAC9B,IAAIpB,KAAKkB,EAASK,GAAUf,IAC1B,OAAOrD;;IAMbwB,IAAI6B;QACF,YAAyBc,MAAlBtB,KAAKwB,IAAIhB;;iDAIlB7B,IAAI6B,GAAcrD;QAChB,MAAMgE,IAAKnB,KAAKiB,EAAST,IACnBY,IAAUpB,KAAKqB,EAAMF;QAC3B,SAAgBG,MAAZF,GAAJ;YAIA,KAAK,IAAI9C,IAAI,GAAGA,IAAI8C,EAAQtC,QAAQR,KAClC,IAAI0B,KAAKkB,EAASE,EAAQ9C,GAAG,IAAIkC,IAE/B,aADAY,EAAQ9C,KAAK,EAACkC,GAAKrD;YAIvBiE,EAAQK,KAAK,EAACjB,GAAKrD;eATjB6C,KAAKqB,EAAMF,KAAM,EAAC,EAACX,GAAKrD;;;;WAe5BwB,OAAO6B;QACL,MAAMW,IAAKnB,KAAKiB,EAAST,IACnBY,IAAUpB,KAAKqB,EAAMF;QAC3B,SAAgBG,MAAZF,GACF,QAAO;QAET,KAAK,IAAI9C,IAAI,GAAGA,IAAI8C,EAAQtC,QAAQR,KAClC,IAAI0B,KAAKkB,EAASE,EAAQ9C,GAAG,IAAIkC,IAM/B,OALuB,MAAnBY,EAAQtC,gBACHkB,KAAKqB,EAAMF,KAElBC,EAAQM,OAAOpD,GAAG;SAEb;QAGX,QAAO;;IAGTK,QAAQmC;QACND,EAAQb,KAAKqB,GAAO,CAACM,GAAGC;YACtB,KAAK,OAAOC,GAAGC,MAAMF,GACnBd,EAAGe,GAAGC;;;IAKZnD;QACE,OAAOoC,EAAQf,KAAKqB;;;;;;;;;;;;;;;;;;;GCrFjB,OAAMU,IAAO;;;;IAIlBC,IAAI;;IAGJC,WAAW;;IAGXC,SAAS;;;;;;;IAQTC,kBAAkB;;;;;;;;IASlBC,mBAAmB;;IAGnBC,WAAW;;;;;IAMXC,gBAAgB;;;;;;;;IAShBC,mBAAmB;;;;;IAMnBC,iBAAiB;;;;;IAMjBC,oBAAoB;;;;;;;;;;;;;;;;;;;;;IAsBpBC,qBAAqB;;;;;;;;IASrBC,SAAS;;;;;;;;;;;;;;;;IAiBTC,cAAc;;IAGdC,eAAe;;;;;IAMfC,UAAU;;;;;;;;IASVC,aAAa;;IAGbC,WAAW;;;;;;;;UASAC,UAAuBvF;IAIlCiB,YAAqBuE,GAAqBzF;QACxC0F,MAAM1F,IADauC,YAAAkD,GAAqBlD,eAAAvC,GAH1CuC,YAAO;;;;QASLA,KAAKoD,WAAW,MAAM,GAAGpD,KAAKqD,eAAerD,KAAKkD,UAAUlD,KAAKvC;;;;;;;;;;;;;;;;;;;;;MCnJxD6F;IAeX3E,YAAqB4E,GAA0BC;QAC7C,IADmBxD,eAAAuD,GAA0BvD,mBAAAwD,GACzCA,IAAc,GAChB,MAAM,IAAIP,EACRlB,EAAKI,kBACL,yCAAyCqB;QAG7C,IAAIA,KAAe,KACjB,MAAM,IAAIP,EACRlB,EAAKI,kBACL,yCAAyCqB;QAG7C,IAAID,KA9BY,aA+Bd,MAAM,IAAIN,EACRlB,EAAKI,kBACL,qCAAqCoB;;gBAIzC,IAAIA,KAAW,cACb,MAAM,IAAIN,EACRlB,EAAKI,kBACL,qCAAqCoB;;IArC3C5E;QACE,OAAO2E,EAAUG,WAAWC,KAAKC;;IAGnChF,gBAAgBiF;QACd,OAAON,EAAUG,WAAWG,EAAKC;;IAGnClF,kBAAkBmF;QAChB,MAAMP,IAAUhF,KAAKC,MAAMsF,IAAe;QAE1C,OAAO,IAAIR,EAAUC,GAD2B,OAAjCO,IAAyB,MAAVP;;IAgChC5E;QACE,OAAO,IAAI+E,KAAK1D,KAAK+D;;IAGvBpF;QACE,OAAsB,MAAfqB,KAAKuD,UAAiBvD,KAAKwD,cAAc;;IAGlD7E,EAAW0B;QACT,OAAIL,KAAKuD,YAAYlD,EAAMkD,UAClBtE,EAAoBe,KAAKwD,aAAanD,EAAMmD,eAE9CvE,EAAoBe,KAAKuD,SAASlD,EAAMkD;;IAGjD5E,QAAQ0B;QACN,OACEA,EAAMkD,YAAYvD,KAAKuD,WAAWlD,EAAMmD,gBAAgBxD,KAAKwD;;IAIjE7E;QACE,OACE,uBACAqB,KAAKuD,UACL,mBACAvD,KAAKwD,cACL;;IAIJ7E;;;;;;;QAOE,MAAMqF,IAAkBhE,KAAKuD,WAnFb;;gBAuFhB,OAFyBU,OAAOD,GAAiBE,SAAS,IAAI,OAEpC,MADGD,OAAOjE,KAAKwD,aAAaU,SAAS,GAAG;;;;;;;;;;;;;;;;;;;;;;;UCpFzDC;IASXxF,YAA4ByF;QAAApE,iBAAAoE;;IAR5BzF,SAAqBxB;QACnB,OAAO,IAAIgH,EAAgBhH;;IAG7BwB;QACE,OAAO,IAAIwF,EAAgB,IAAIb,EAAU,GAAG;;IAK9C3E,EAAU0B;QACR,OAAOL,KAAKoE,UAAUC,EAAWhE,EAAM+D;;IAGzCzF,QAAQ0B;QACN,OAAOL,KAAKoE,UAAUE,QAAQjE,EAAM+D;;oFAItCzF;;QAEE,OAAgC,MAAzBqB,KAAKoE,UAAUb,UAAgBvD,KAAKoE,UAAUZ,cAAc;;IAGrE7E;QACE,OAAO,qBAAqBqB,KAAKoE,UAAUhB,aAAa;;IAG1DzE;QACE,OAAOqB,KAAKoE;;;;;;;;;;;;;;;;;;;;;;;AC5BhB,MAAeG;IAKb5F,YAAY6F,GAAoBC,GAAiB3F;aAChCwC,MAAXmD,IACFA,IAAS,IACAA,IAASD,EAAS1F,UAC3BvB,UAGa+D,MAAXxC,IACFA,IAAS0F,EAAS1F,SAAS2F,IAClB3F,IAAS0F,EAAS1F,SAAS2F,KACpClH;QAEFyC,KAAKwE,WAAWA,GAChBxE,KAAKyE,SAASA,GACdzE,KAAK0E,IAAM5F;;IAqBbA;QACE,OAAOkB,KAAK0E;;IAGd/F,QAAQ0B;QACN,OAA4C,MAArCkE,EAASlF,EAAWW,MAAMK;;IAGnC1B,MAAMgG;QACJ,MAAMH,IAAWxE,KAAKwE,SAASI,MAAM5E,KAAKyE,QAAQzE,KAAK6E;QAQvD,OAPIF,aAAsBJ,IACxBI,EAAW9D,QAAQiE;YACjBN,EAAS/C,KAAKqD;aAGhBN,EAAS/C,KAAKkD,IAET3E,KAAK+E,EAAUP;;kEAIhB7F;QACN,OAAOqB,KAAKyE,SAASzE,KAAKlB;;IAG5BH,EAASqG;QAMP,OALAA,SAAgB1D,MAAT0D,IAAqB,IAAIA,GAKzBhF,KAAK+E,EACV/E,KAAKwE,UACLxE,KAAKyE,SAASO,GACdhF,KAAKlB,SAASkG;;IAIlBrG;QAEE,OAAOqB,KAAK+E,EAAU/E,KAAKwE,UAAUxE,KAAKyE,QAAQzE,KAAKlB,SAAS;;IAGlEH;QAEE,OAAOqB,KAAKwE,SAASxE,KAAKyE;;IAG5B9F;QACE,OAAOqB,KAAKwB,IAAIxB,KAAKlB,SAAS;;IAGhCH,IAAIY;QAEF,OAAOS,KAAKwE,SAASxE,KAAKyE,SAASlF;;IAGrCZ;QACE,OAAuB,MAAhBqB,KAAKlB;;IAGdH,EAAW0B;QACT,IAAIA,EAAMvB,SAASkB,KAAKlB,QACtB,QAAO;QAGT,KAAK,IAAIR,IAAI,GAAGA,IAAI0B,KAAKlB,QAAQR,KAC/B,IAAI0B,KAAKwB,IAAIlD,OAAO+B,EAAMmB,IAAIlD,IAC5B,QAAO;QAIX,QAAO;;IAGTK,EAAoBsG;QAClB,IAAIjF,KAAKlB,SAAS,MAAMmG,EAAenG,QACrC,QAAO;QAGT,KAAK,IAAIR,IAAI,GAAGA,IAAI0B,KAAKlB,QAAQR,KAC/B,IAAI0B,KAAKwB,IAAIlD,OAAO2G,EAAezD,IAAIlD,IACrC,QAAO;QAIX,QAAO;;IAGTK,QAAQmC;QACN,KAAK,IAAIxC,IAAI0B,KAAKyE,QAAQS,IAAMlF,KAAK6E,SAASvG,IAAI4G,GAAK5G,KACrDwC,EAAGd,KAAKwE,SAASlG;;IAIrBK;QACE,OAAOqB,KAAKwE,SAASI,MAAM5E,KAAKyE,QAAQzE,KAAK6E;;IAG/ClG,SACEwG,GACAC;QAEA,MAAMV,IAAMnG,KAAK8G,IAAIF,EAAGrG,QAAQsG,EAAGtG;QACnC,KAAK,IAAIR,IAAI,GAAGA,IAAIoG,GAAKpG,KAAK;YAC5B,MAAMY,IAAOiG,EAAG3D,IAAIlD,IACda,IAAQiG,EAAG5D,IAAIlD;YACrB,IAAIY,IAAOC,GACT,QAAQ;YAEV,IAAID,IAAOC,GACT,OAAO;;QAGX,OAAIgG,EAAGrG,SAASsG,EAAGtG,UACT,IAENqG,EAAGrG,SAASsG,EAAGtG,SACV,IAEF;;;;;;;UAQEwG,UAAqBf;IACtB5F,EACR6F,GACAC,GACA3F;QAEA,OAAO,IAAIwG,EAAad,GAAUC,GAAQ3F;;IAG5CH;;;;QAKE,OAAOqB,KAAKuF,IAAUC,KAAK;;IAG7B7G;QACE,OAAOqB,KAAKyF;;;;WAMd9G,SAAkB+G;;;;QAKhB,IAAIA,EAAKC,QAAQ,SAAS,GACxB,MAAM,IAAI1C,EACRlB,EAAKI,kBACL,iBAAiBuD;;;gBAMrB,MAAMlB,IAAWkB,EAAKE,MAAM,KAAKC,OAAOf,KAAWA,EAAQhG,SAAS;QAEpE,OAAO,IAAIwG,EAAad;;IAG1B7F;QACE,OAAO,IAAI2G,EAAa;;;;AAI5B,MAAMQ,IAAmB;;gFAGZC,UAAkBxB;IACnB5F,EACR6F,GACAC,GACA3F;QAEA,OAAO,IAAIiH,EAAUvB,GAAUC,GAAQ3F;;;;;WAOjCH,SAAyBmG;QAC/B,OAAOgB,EAAiBE,KAAKlB;;IAG/BnG;QACE,OAAOqB,KAAKuF,IACT7I,IAAIuJ,MACHA,IAAMA,EAAIC,QAAQ,MAAM,QAAQA,QAAQ,KAAK,QACxCH,EAAUI,EAAkBF,OAC/BA,IAAM,MAAMA,IAAM;QAEbA,IAERT,KAAK;;IAGV7G;QACE,OAAOqB,KAAKyF;;;;WAMd9G;QACE,OAAuB,MAAhBqB,KAAKlB,UArQiB,eAqQDkB,KAAKwB,IAAI;;;;WAMvC7C;QACE,OAAO,IAAIoH,EAAU,EA5QQ;;;;;;;;;;;WAyR/BpH,SAAwB+G;QACtB,MAAMlB,IAAqB;QAC3B,IAAI4B,IAAU,IACV9H,IAAI;QAER,MAAM+H,IAAoB;YACxB,IAAuB,MAAnBD,EAAQtH,QACV,MAAM,IAAImE,EACRlB,EAAKI,kBACL,uBAAuBuD;YAI3BlB,EAAS/C,KAAK2E,IACdA,IAAU;;QAGZ,IAAIE,KAAc;QAElB,MAAOhI,IAAIoH,EAAK5G,UAAQ;YACtB,MAAMyH,IAAIb,EAAKpH;YACf,IAAU,SAANiI,GAAY;gBACd,IAAIjI,IAAI,MAAMoH,EAAK5G,QACjB,MAAM,IAAImE,EACRlB,EAAKI,kBACL,yCAAyCuD;gBAG7C,MAAMc,IAAOd,EAAKpH,IAAI;gBACtB,IAAe,SAATkI,KAA0B,QAATA,KAAyB,QAATA,GACrC,MAAM,IAAIvD,EACRlB,EAAKI,kBACL,uCAAuCuD;gBAG3CU,KAAWI,GACXlI,KAAK;mBACU,QAANiI,KACTD,KAAeA,GACfhI,OACe,QAANiI,KAAcD,KAIvBF,KAAWG,GACXjI,QAJA+H,KACA/H;;QAQJ,IAFA+H,KAEIC,GACF,MAAM,IAAIrD,EACRlB,EAAKI,kBACL,6BAA6BuD;QAIjC,OAAO,IAAIK,EAAUvB;;IAGvB7F;QACE,OAAO,IAAIoH,EAAU;;;;;;;;;;;;;;;;;;;UCrVZU;IACX9H,YAAqB+G;QAAA1F,YAAA0F;;IAQrB/G,SAAgB0E;QACd,OAAO,IAAIoD,EAAYnB,EAAaoB,EAAWrD,GAAMsD,EAAS;;6EAIhEhI,EAAgBiI;QACd,OACE5G,KAAK0F,KAAK5G,UAAU,KACpBkB,KAAK0F,KAAKlE,IAAIxB,KAAK0F,KAAK5G,SAAS,OAAO8H;;IAI5CjI,QAAQ0B;QACN,OACY,SAAVA,KAAqE,MAAnDiF,EAAajG,EAAWW,KAAK0F,MAAMrF,EAAMqF;;IAI/D/G;QACE,OAAOqB,KAAK0F,KAAKtC;;IAGnBzE,SAAkBkI,GAAiBC;QACjC,OAAOxB,EAAajG,EAAWwH,EAAGnB,MAAMoB,EAAGpB;;IAG7C/G,SAAqB+G;QACnB,OAAOA,EAAK5G,SAAS,KAAM;;;;;;;WAS7BH,SAAoB6F;QAClB,OAAO,IAAIiC,EAAY,IAAInB,EAAad,EAASI;;;;;;;;;;;;;;;;;;;;;;aC1CrCmC,EAAkB5J;IAChC,OAAOA,QAAAA;;;yDAIO6J,EAAe7J;;;IAG7B,QAAkB,MAAXA,KAAgB,IAAIA,MAAU,IAAA;;;;;;aAOvB8J,EAAc9J;IAC5B,OACmB,mBAAVA,KACP+J,OAAOC,UAAUhK,OAChB6J,EAAe7J,MAChBA,KAAS+J,OAAOE,oBAChBjK,KAAS+J,OAAOG;;;;;;;;;;;;;;;;;;;;MCOPC;IAEX3I,YACW+G,GACA6B,IAAiC,MACjCC,IAAqB,IACrBC,IAAoB,IACpB5C,IAAuB,MACvB6C,IAAwB,MACxBC,IAAsB;QANtB3H,YAAA0F,GACA1F,uBAAAuH,GACAvH,eAAAwH,GACAxH,eAAAyH,GACAzH,aAAA6E;QACA7E,eAAA0H,GACA1H,aAAA2H,GARX3H,SAAqC;;;;;;;;;;;aAoBvB4H,EACdlC,GACA6B,IAAiC,MACjCC,IAAqB,IACrBC,IAAoB,IACpB5C,IAAuB,MACvB6C,IAAwB,MACxBC,IAAsB;IAEtB,OAAO,IAAIL,EACT5B,GACA6B,GACAC,GACAC,GACA5C,GACA6C,GACAC;;;SAIYE,EAAeC;IAC7B,MAAMC,IAAalK,EAAUiK;IAE7B,IAAuC,SAAnCC,EAAWC,GAA8B;QAC3C,IAAIC,IAAcF,EAAWrC,KAAKD;QACC,SAA/BsC,EAAWR,oBACbU,KAAe,SAASF,EAAWR,kBAErCU,KAAe,OACfA,KAAeF,EAAWN,QAAQ/K,IAAIwL,KAAKC,GAAeD,IAAI1C,KAAK;QACnEyC,KAAe,QACfA,KAAeF,EAAWP,QAAQ9K,IAAI0L;YAAKC,QCq4Bfb,IDr4B+BY,GCu4B9CE,MAAM7C,MAAoB+B,EAAQe;gBAFnBf;WDr4BmChC,KAAK,MAE/DuB,EAAkBgB,EAAWlD,WAChCoD,KAAe,OACfA,KAAeF,EAAiB,QAE9BA,EAAWL,YACbO,KAAe;QACfA,KAAeO,GAAcT,EAAWL,WAEtCK,EAAWJ,UACbM,KAAe,QACfA,KAAeO,GAAcT,EAAWJ,SAE1CI,EAAWC,IAAsBC;;IAEnC,OAAOF,EAAWC;;;SAGJS,EAAgBX;IAC9B,IAAI7B,IAAM6B,EAAOpC,KAAKD;IAuBtB,OAtB+B,SAA3BqC,EAAOP,oBACTtB,KAAO,sBAAsB6B,EAAOP;IAElCO,EAAOL,QAAQ3I,SAAS,MAC1BmH,KAAO,eAAe6B,EAAOL,QAC1B/K,IAAIwL;QAAKQ,OC6mBP,IALuB7C,IDxmBAqC,GC6mBbI,MAAM7C,OAAqBI,EAAO8C,MAAMV,GACvDpC,EAAO1I;;YANqB0I;0EDvmBzBL,KAAK;IAELuB,EAAkBe,EAAOjD,WAC5BoB,KAAO,cAAc6B,EAAOjD,QAE1BiD,EAAON,QAAQ1I,SAAS,MAC1BmH,KAAO,eAAe6B,EAAON,QAC1B9K,IAAI0L;QAAKQ,OCy2BP,IADwBpB,IDx2BAY,GCy2BbE,MAAM7C,QAAsB+B,EAAQe;YADvBf;ODv2B1BhC,KAAK,WAENsC,EAAOJ,YACTzB,KAAO,gBAAgBuC,GAAcV,EAAOJ,WAE1CI,EAAOH,UACT1B,KAAO,cAAcuC,GAAcV,EAAOH;IAErC,UAAU1B;;;SAGH4C,EAAa3J,GAAcC;IACzC,IAAID,EAAK2F,UAAU1F,EAAM0F,OACvB,QAAO;IAGT,IAAI3F,EAAKsI,QAAQ1I,WAAWK,EAAMqI,QAAQ1I,QACxC,QAAO;IAGT,KAAK,IAAIR,IAAI,GAAGA,IAAIY,EAAKsI,QAAQ1I,QAAQR,KACvC,KAAKwK,GAAc5J,EAAKsI,QAAQlJ,IAAIa,EAAMqI,QAAQlJ,KAChD,QAAO;IAIX,IAAIY,EAAKuI,QAAQ3I,WAAWK,EAAMsI,QAAQ3I,QACxC,QAAO;IAGT,KAAK,IAAIR,IAAI,GAAGA,IAAIY,EAAKuI,QAAQ3I,QAAQR,KACvC,ICkjByByK,IDljBP7J,EAAKuI,QAAQnJ,ICkjBM0K,IDljBF7J,EAAMsI,QAAQnJ;ICyjBjDyK,EAAGJ,OAAOK,EAAGL,OACbI,EAAGT,MAAMhE,QAAQ0E,EAAGV,WACpBW,GAAYF,EAAG5L,OAAO6L,EAAG7L,QD1jBvB,QAAO;QCijBgB4L,GAAYC;ID7iBvC,OAAI9J,EAAKqI,oBAAoBpI,EAAMoI,sBAI9BrI,EAAKwG,KAAKpB,QAAQnF,EAAMuG,YAIxBwD,GAAYhK,EAAKwI,SAASvI,EAAMuI,YAI9BwB,GAAYhK,EAAKyI,OAAOxI,EAAMwI;;;SAGvBwB,GAAiBrB;IAC/B,OACErB,EAAY2C,EAActB,EAAOpC,SACN,SAA3BoC,EAAOP,mBACmB,MAA1BO,EAAOL,QAAQ3I;;;;;;;;;;;;;;;;;;;;;;SE3KHuK,GAAaC;IAC3B,OAAOrF,OAAOsF,aAAaC,MACzB;;;;IAIAC,EAAOC,wBAAwBJ,IATlB;;;;;;;;;;;;;;;;;;;;;;;;;;;;MCOJK;IAGXhL,YAAqCiL;iBAAAA;;IAErCjL,wBAAwB8K;QACtB,MAAMG,IAAeP,GAAaI;QAClC,OAAO,IAAIE,GAAWC;;IAGxBjL,sBAAsBkL;QACpB,MAAMD;;;;iBA4BiCC;YACzC,IAAID,IAAe;YACnB,KAAK,IAAItL,IAAI,GAAGA,IAAIuL,EAAM/K,UAAUR,GAClCsL,KAAgB3F,OAAOsF,aAAaM,EAAMvL;YAE5C,OAAOsL;;;;GAjCgBE,EAA2BD;QAChD,OAAO,IAAIF,GAAWC;;IAGxBjL;QACE,gBDTyBoL;YAC3B,MAAM5L,IAAkB;YACxB,KAAK,IAAIG,IAAI,GAAGA,IAAIyL,EAAIjL,QAAQR,KAC9BH,EAAMG,KAAKyL,EAAIC,WAAW1L;YAE5B,OAAOmL,EAAOQ,gBAAgB9L,IAnBf;SCuBN+L,CAAalK,KAAK4J;;IAG3BjL;QACE,gBA8BuCiL;YACzC,MAAMO,IAAS,IAAI/L,WAAWwL,EAAa9K;YAC3C,KAAK,IAAIR,IAAI,GAAGA,IAAIsL,EAAa9K,QAAQR,KACvC6L,EAAO7L,KAAKsL,EAAaI,WAAW1L;YAEtC,OAAO6L;;;;;;;;;;;;;;;;;;;;GAnCEC,EAA2BpK,KAAK4J;;IAGzCjL;QACE,OAAkC,IAA3BqB,KAAK4J,EAAa9K;;IAG3BH,EAAU0B;QACR,OAAOpB,EAAoBe,KAAK4J,GAAcvJ,EAAMuJ;;IAGtDjL,QAAQ0B;QACN,OAAOL,KAAK4J,MAAiBvJ,EAAMuJ;;;;AA/BrCD,OAAoC,IAAIA,GAAW;;MCUxCU;IACX1L;;IAEWmJ;;;;;IAKAwC;;IAEAC;;;;;IAKAC;;IAEAC,IAAmCtG,EAAgBkB;;;;UAKnDqF,IAAgDvG,EAAgBkB;;;;;;UAOhEsF,IAA0BhB,GAAWiB;QA1BrC5K,cAAA8H,GAKA9H,gBAAAsK,YAEAC,GAKAvK,sBAAAwK,YAEAC;QAKAzK,oCAAA0K,GAOA1K,mBAAA2K;;kFAIXhM,EAAmB6L;QACjB,OAAO,IAAIH,GACTrK,KAAK8H,QACL9H,KAAKsK,UACLtK,KAAKuK,GACLC,GACAxK,KAAKyK,GACLzK,KAAK0K,8BACL1K,KAAK2K;;;;;WAQThM,GACEgM,GACAF;QAEA,OAAO,IAAIJ,GACTrK,KAAK8H,QACL9H,KAAKsK,UACLtK,KAAKuK,GACLvK,KAAKwK,gBACLC,GACAzK,KAAK0K,8BACLC;;;;;WAQJhM,GACE+L;QAEA,OAAO,IAAIL,GACTrK,KAAK8H,QACL9H,KAAKsK,UACLtK,KAAKuK,GACLvK,KAAKwK,gBACLxK,KAAKyK,GACLC,GACA1K,KAAK2K;;;;;;;;;;;;;;;;;;;UCpGEE;;IAEXlM,YAAmB4B;QAAAP,aAAAO;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GCYrB,KAAKuK;;;;;;;;SA0BWC,GAAiB7H;IAC/B,QAAQA;MACN,KAAKnB,EAAKC;QACR,OAnCwFzE;;MAoC1F,KAAKwE,EAAKE;MACV,KAAKF,EAAKG;MACV,KAAKH,EAAKK;MACV,KAAKL,EAAKU;MACV,KAAKV,EAAKe;MACV,KAAKf,EAAKgB;;;cAGV,KAAKhB,EAAKS;QACR,QAAO;;MACT,KAAKT,EAAKI;MACV,KAAKJ,EAAKM;MACV,KAAKN,EAAKO;MACV,KAAKP,EAAKQ;MACV,KAAKR,EAAKW;;;;cAIV,KAAKX,EAAKY;MACV,KAAKZ,EAAKa;MACV,KAAKb,EAAKc;MACV,KAAKd,EAAKiB;QACR,QAAO;;MACT;QACE,OA5DwFzF;;;;;;;;;;;;;;;;;;;;;;;SAwG9EyN,GAAmB9H;IACjC,SAAa5B,MAAT4B;;;IAIF,OADArG,EAAS,4BACFkF,EAAKG;IAGd,QAAQgB;MACN,KAAK4H,GAAQ9I;QACX,OAAOD,EAAKC;;MACd,KAAK8I,GAAQ7I;QACX,OAAOF,EAAKE;;MACd,KAAK6I,GAAQ5I;QACX,OAAOH,EAAKG;;MACd,KAAK4I,GAAQ1I;QACX,OAAOL,EAAKK;;MACd,KAAK0I,GAAQrI;QACX,OAAOV,EAAKU;;MACd,KAAKqI,GAAQhI;QACX,OAAOf,EAAKe;;MACd,KAAKgI,GAAQ/H;QACX,OAAOhB,EAAKgB;;MACd,KAAK+H,GAAQtI;QACX,OAAOT,EAAKS;;MACd,KAAKsI,GAAQ3I;QACX,OAAOJ,EAAKI;;MACd,KAAK2I,GAAQzI;QACX,OAAON,EAAKM;;MACd,KAAKyI,GAAQxI;QACX,OAAOP,EAAKO;;MACd,KAAKwI,GAAQvI;QACX,OAAOR,EAAKQ;;MACd,KAAKuI,GAAQpI;QACX,OAAOX,EAAKW;;MACd,KAAKoI,GAAQnI;QACX,OAAOZ,EAAKY;;MACd,KAAKmI,GAAQlI;QACX,OAAOb,EAAKa;;MACd,KAAKkI,GAAQjI;QACX,OAAOd,EAAKc;;MACd,KAAKiI,GAAQ9H;QACX,OAAOjB,EAAKiB;;MACd;QACE,OApJwFzF;;;;;;;;;;;UAMzFuN,OAAAA,6BAEHG;AACAA,gCACAA;AACAA,oDACAA;AACAA,8CACAA;AACAA,iDACAA;AACAA,wDACAA;AACAA,2CACAA;AACAA,mCACAA,yCACAA;;;;;;;;;;;;;;;;;;;;MCNWC;IAIXvM,YACSU,GACP8L;iBADO9L,GAGPW,KAAKmL,OAAOA,KAAcC,GAASC;;;IAIrC1M,GAAO6B,GAAQrD;QACb,OAAO,IAAI+N,GACTlL,KAAKX,GACLW,KAAKmL,KACFG,GAAO9K,GAAKrD,GAAO6C,KAAKX,GACxBkM,KAAK,MAAM,MAAMH,GAASI,IAAO,MAAM;;;IAK9C7M,OAAO6B;QACL,OAAO,IAAI0K,GACTlL,KAAKX,GACLW,KAAKmL,KACFM,OAAOjL,GAAKR,KAAKX,GACjBkM,KAAK,MAAM,MAAMH,GAASI,IAAO,MAAM;;;IAK9C7M,IAAI6B;QACF,IAAIkL,IAAO1L,KAAKmL;QAChB,OAAQO,EAAK3K,OAAW;YACtB,MAAM4K,IAAM3L,KAAKX,EAAWmB,GAAKkL,EAAKlL;YACtC,IAAY,MAARmL,GACF,OAAOD,EAAKvO;YACHwO,IAAM,IACfD,IAAOA,EAAKxM,OACHyM,IAAM,MACfD,IAAOA,EAAKvM;;QAGhB,OAAO;;;;IAKTR,QAAQ6B;;QAEN,IAAIoL,IAAc,GACdF,IAAO1L,KAAKmL;QAChB,OAAQO,EAAK3K,OAAW;YACtB,MAAM4K,IAAM3L,KAAKX,EAAWmB,GAAKkL,EAAKlL;YACtC,IAAY,MAARmL,GACF,OAAOC,IAAcF,EAAKxM,KAAK8F;YACtB2G,IAAM,IACfD,IAAOA,EAAKxM;;YAGZ0M,KAAeF,EAAKxM,KAAK8F,OAAO,GAChC0G,IAAOA,EAAKvM;;;gBAIhB,QAAQ;;IAGVR;QACE,OAAOqB,KAAKmL,KAAKpK;;;IAInBiE;QACE,OAAOhF,KAAKmL,KAAKnG;;;IAInBrG;QACE,OAAOqB,KAAKmL,KAAKU;;;IAInBlN;QACE,OAAOqB,KAAKmL,KAAKW;;;;;;IAOnBnN,GAAoBoN;QAClB,OAAQ/L,KAAKmL,KAAwBa,GAAiBD;;IAGxDpN,QAAQmC;QACNd,KAAKgM,GAAiB,CAACnK,GAAGC,OACxBhB,EAAGe,GAAGC,KACC;;IAIXnD;QACE,MAAMsN,IAAyB;QAK/B,OAJAjM,KAAKgM,GAAiB,CAACnK,GAAGC,OACxBmK,EAAaxK,KAAK,GAAGI,KAAKC,OACnB,KAEF,IAAImK,EAAazG,KAAK;;;;;;;IAQ/B7G,GAAoBoN;QAClB,OAAQ/L,KAAKmL,KAAwBe,GAAiBH;;;IAIxDpN;QACE,OAAO,IAAIwN,GAAwBnM,KAAKmL,MAAM,MAAMnL,KAAKX,IAAY;;IAGvEV,GAAgB6B;QACd,OAAO,IAAI2L,GAAwBnM,KAAKmL,MAAM3K,GAAKR,KAAKX,IAAY;;IAGtEV;QACE,OAAO,IAAIwN,GAAwBnM,KAAKmL,MAAM,MAAMnL,KAAKX,IAAY;;IAGvEV,GAAuB6B;QACrB,OAAO,IAAI2L,GAAwBnM,KAAKmL,MAAM3K,GAAKR,KAAKX,IAAY;;;;;;MAK3D8M;IAIXxN,YACE+M,GACAU,GACA/M,GACAgN;QAEArM,KAAKqM,KAAYA,GACjBrM,KAAKsM,KAAY;QAEjB,IAAIX,IAAM;QACV,OAAQD,EAAK3K,OAOX,IANA4K,IAAMS,IAAW/M,EAAWqM,EAAKlL,KAAK4L,KAAY;;QAE9CC,MACFV,MAAQ,IAGNA,IAAM;;QAGND,IADE1L,KAAKqM,KACAX,EAAKxM,OAELwM,EAAKvM,YAET;YAAA,IAAY,MAARwM,GAAW;;;gBAGpB3L,KAAKsM,GAAU7K,KAAKiK;gBACpB;;;;YAIA1L,KAAKsM,GAAU7K,KAAKiK,IAElBA,IADE1L,KAAKqM,KACAX,EAAKvM,QAELuM,EAAKxM;;;IAMpBP;QAME,IAAI+M,IAAO1L,KAAKsM,GAAUC;QAC1B,MAAMC,IAAS;YAAEhM,KAAKkL,EAAKlL;YAAKrD,OAAOuO,EAAKvO;;QAE5C,IAAI6C,KAAKqM,IAEP,KADAX,IAAOA,EAAKxM,OACJwM,EAAK3K,OACXf,KAAKsM,GAAU7K,KAAKiK,IACpBA,IAAOA,EAAKvM,YAId,KADAuM,IAAOA,EAAKvM,QACJuM,EAAK3K,OACXf,KAAKsM,GAAU7K,KAAKiK;QACpBA,IAAOA,EAAKxM;QAIhB,OAAOsN;;IAGT7N;QACE,OAAOqB,KAAKsM,GAAUxN,SAAS;;IAGjCH;QACE,IAA8B,MAA1BqB,KAAKsM,GAAUxN,QACjB,OAAO;QAGT,MAAM4M,IAAO1L,KAAKsM,GAAUtM,KAAKsM,GAAUxN,SAAS;QACpD,OAAO;YAAE0B,KAAKkL,EAAKlL;YAAKrD,OAAOuO,EAAKvO;;;;;;;MAK3BiO;IAaXzM,YACS6B,GACArD,GACPsP,GACAvN,GACAC;QAJOa,WAAAQ,GACAR,aAAA7C,GAKP6C,KAAKyM,QAAiB,QAATA,IAAgBA,IAAQrB,GAASsB,KAC9C1M,KAAKd,OAAe,QAARA,IAAeA,IAAOkM,GAASC;QAC3CrL,KAAKb,QAAiB,QAATA,IAAgBA,IAAQiM,GAASC,OAC9CrL,KAAKgF,OAAOhF,KAAKd,KAAK8F,OAAO,IAAIhF,KAAKb,MAAM6F;;;IAI9CrG,KACE6B,GACArD,GACAsP,GACAvN,GACAC;QAEA,OAAO,IAAIiM,GACF,QAAP5K,IAAcA,IAAMR,KAAKQ,KAChB,QAATrD,IAAgBA,IAAQ6C,KAAK7C,OACpB,QAATsP,IAAgBA,IAAQzM,KAAKyM,OACrB,QAARvN,IAAeA,IAAOc,KAAKd,MAClB,QAATC,IAAgBA,IAAQa,KAAKb;;IAIjCR;QACE,QAAO;;;;;;IAOTA,GAAoBoN;QAClB,OACG/L,KAAKd,KAAwB8M,GAAiBD,MAC/CA,EAAO/L,KAAKQ,KAAKR,KAAK7C,UACrB6C,KAAKb,MAAyB6M,GAAiBD;;;;;;IAQpDpN,GAAoBoN;QAClB,OACG/L,KAAKb,MAAyB+M,GAAiBH,MAChDA,EAAO/L,KAAKQ,KAAKR,KAAK7C,UACrB6C,KAAKd,KAAwBgN,GAAiBH;;;IAK3CpN;QACN,OAAIqB,KAAKd,KAAK6B,MACLf,OAECA,KAAKd,KAAwBmG;;;IAKzC1G;QACE,OAAOqB,KAAKqF,MAAM7E;;;IAIpB7B;QACE,OAAIqB,KAAKb,MAAM4B,MACNf,KAAKQ,MAELR,KAAKb,MAAM2M;;;IAKtBnN,GAAO6B,GAAQrD,GAAUkC;QACvB,IAAIsN,IAAoB3M;QACxB,MAAM2L,IAAMtM,EAAWmB,GAAKmM,EAAEnM;QAc9B,OAZEmM,IADEhB,IAAM,IACJgB,EAAEpB,KAAK,MAAM,MAAM,MAAMoB,EAAEzN,KAAKoM,GAAO9K,GAAKrD,GAAOkC,IAAa,QACnD,MAARsM,IACLgB,EAAEpB,KAAK,MAAMpO,GAAO,MAAM,MAAM,QAEhCwP,EAAEpB,KACJ,MACA,MACA,MACA,MACAoB,EAAExN,MAAMmM,GAAO9K,GAAKrD,GAAOkC;QAGxBsN,EAAEC;;IAGHjO;QACN,IAAIqB,KAAKd,KAAK6B,KACZ,OAAOqK,GAASC;QAElB,IAAIsB,IAAoB3M;QAKxB,OAJK2M,EAAEzN,KAAK2N,QAAYF,EAAEzN,KAAKA,KAAK2N,SAClCF,IAAIA,EAAEG,OAERH,IAAIA,EAAEpB,KAAK,MAAM,MAAM,MAAOoB,EAAEzN,KAAwB6N,MAAa;QAC9DJ,EAAEC;;;IAIXjO,OACE6B,GACAnB;QAEA,IAAI2N,GACAL,IAAoB3M;QACxB,IAAIX,EAAWmB,GAAKmM,EAAEnM,OAAO,GACtBmM,EAAEzN,KAAK6B,OAAc4L,EAAEzN,KAAK2N,QAAYF,EAAEzN,KAAKA,KAAK2N,SACvDF,IAAIA,EAAEG;QAERH,IAAIA,EAAEpB,KAAK,MAAM,MAAM,MAAMoB,EAAEzN,KAAKuM,OAAOjL,GAAKnB,IAAa,YACxD;YAOL,IANIsN,EAAEzN,KAAK2N,SACTF,IAAIA,EAAEM,OAEHN,EAAExN,MAAM4B,OAAc4L,EAAExN,MAAM0N,QAAYF,EAAExN,MAAMD,KAAK2N,SAC1DF,IAAIA,EAAEO;YAEuB,MAA3B7N,EAAWmB,GAAKmM,EAAEnM,MAAY;gBAChC,IAAImM,EAAExN,MAAM4B,KACV,OAAOqK,GAASC;gBAEhB2B,IAAYL,EAAExN,MAAyBkG,OACvCsH,IAAIA,EAAEpB,KACJyB,EAASxM,KACTwM,EAAS7P,OACT,MACA,MACCwP,EAAExN,MAAyB4N;;YAIlCJ,IAAIA,EAAEpB,KAAK,MAAM,MAAM,MAAM,MAAMoB,EAAExN,MAAMsM,OAAOjL,GAAKnB;;QAEzD,OAAOsN,EAAEC;;IAGXjO;QACE,OAAOqB,KAAKyM;;;IAIN9N;QACN,IAAIgO,IAAoB3M;QAUxB,OATI2M,EAAExN,MAAM0N,SAAYF,EAAEzN,KAAK2N,SAC7BF,IAAIA,EAAEQ,OAEJR,EAAEzN,KAAK2N,QAAWF,EAAEzN,KAAKA,KAAK2N,SAChCF,IAAIA,EAAEM;QAEJN,EAAEzN,KAAK2N,QAAWF,EAAExN,MAAM0N,SAC5BF,IAAIA,EAAES,OAEDT;;IAGDhO;QACN,IAAIgO,IAAI3M,KAAKoN;QAYb,OAXIT,EAAExN,MAAMD,KAAK2N,SACfF,IAAIA,EAAEpB,KACJ,MACA,MACA,MACA,MACCoB,EAAExN,MAAyB8N,OAE9BN,IAAIA,EAAEQ;QACNR,IAAIA,EAAES,OAEDT;;IAGDhO;QACN,IAAIgO,IAAI3M,KAAKoN;QAKb,OAJIT,EAAEzN,KAAKA,KAAK2N,SACdF,IAAIA,EAAEM,MACNN,IAAIA,EAAES,OAEDT;;IAGDhO;QACN,MAAM0O,IAAKrN,KAAKuL,KAAK,MAAM,MAAMH,GAASsB,KAAK,MAAM1M,KAAKb,MAAMD;QAChE,OAAQc,KAAKb,MAAyBoM,KACpC,MACA,MACAvL,KAAKyM,OACLY,GACA;;IAII1O;QACN,MAAM2O,IAAKtN,KAAKuL,KAAK,MAAM,MAAMH,GAASsB,KAAK1M,KAAKd,KAAKC,OAAO;QAChE,OAAQa,KAAKd,KAAwBqM,KAAK,MAAM,MAAMvL,KAAKyM,OAAO,MAAMa;;IAGlE3O;QACN,MAAMO,IAAOc,KAAKd,KAAKqM,KAAK,MAAM,OAAOvL,KAAKd,KAAKuN,OAAO,MAAM,OAC1DtN,IAAQa,KAAKb,MAAMoM,KAAK,MAAM,OAAOvL,KAAKb,MAAMsN,OAAO,MAAM;QACnE,OAAOzM,KAAKuL,KAAK,MAAM,OAAOvL,KAAKyM,OAAOvN,GAAMC;;;IAIlDR;QACE,MAAM4O,IAAavN,KAAKwN;QACxB,OAAIjP,KAAKkP,IAAI,GAAKF,MAAevN,KAAKgF,OAAO;;;;IASrCrG;QACR,IAAIqB,KAAK6M,QAAW7M,KAAKd,KAAK2N,MAC5B,MAveetP;QAyejB,IAAIyC,KAAKb,MAAM0N,MACb,MA1eetP;QA4ejB,MAAMgQ,IAAcvN,KAAKd,KAAwBsO;QACjD,IAAID,MAAgBvN,KAAKb,MAAyBqO,MAChD,MA9eejQ;QAgff,OAAOgQ,KAAcvN,KAAK6M,OAAU,IAAI;;;;;;8DArPrCzB;WAAiC,MAEjCA,UAAM,GACNA,SAAQ;;;AAiUjBA,GAASC,QAAQ;;;IAzEjB1M;QAgBEqB,YAAO;;IAfPQ;QACE,MAxfiBjD;;IA0fnBJ;QACE,MA3fiBI;;IA6fnBkP;QACE,MA9fiBlP;;IAggBnB2B;QACE,MAjgBiB3B;;IAmgBnB4B;QACE,MApgBiB5B;;;IAygBnBoB,KACE6B,GACArD,GACAsP,GACAvN,GACAC;QAEA,OAAOa;;;IAITrB,GAAO6B,GAAQrD,GAAUkC;QACvB,OAAO,IAAI+L,GAAe5K,GAAKrD;;;IAIjCwB,OAAO6B,GAAQnB;QACb,OAAOW;;IAGTrB;QACE,QAAO;;IAGTA,GAAiBoN;QACf,QAAO;;IAGTpN,GAAiBoN;QACf,QAAO;;IAGTpN;QACE,OAAO;;IAGTA;QACE,OAAO;;IAGTA;QACE,QAAO;;;IAITA;QACE,QAAO;;IAGCA;QACR,OAAO;;;;;;;;;;;;;;;;;;;;;;;;;;;MC3jBE+O;IAGX/O,YAAoBU;iBAAAA,GAClBW,KAAK2N,OAAO,IAAIzC,GAAsBlL,KAAKX;;IAG7CV,IAAIiP;QACF,OAA+B,SAAxB5N,KAAK2N,KAAKnM,IAAIoM;;IAGvBjP;QACE,OAAOqB,KAAK2N,KAAK9B;;IAGnBlN;QACE,OAAOqB,KAAK2N,KAAK7B;;IAGnB9G;QACE,OAAOhF,KAAK2N,KAAK3I;;IAGnBrG,QAAQiP;QACN,OAAO5N,KAAK2N,KAAKhI,QAAQiI;;iEAI3BjP,QAAQkP;QACN7N,KAAK2N,KAAK3B,GAAiB,CAACnK,GAAMC,OAChC+L,EAAGhM,KACI;;4EAKXlD,GAAemP,GAAeD;QAC5B,MAAME,IAAO/N,KAAK2N,KAAKK,GAAgBF,EAAM;QAC7C,MAAOC,EAAKE,QAAW;YACrB,MAAML,IAAOG,EAAKG;YAClB,IAAIlO,KAAKX,EAAWuO,EAAKpN,KAAKsN,EAAM,OAAO,GACzC;YAEFD,EAAGD,EAAKpN;;;;;WAOZ7B,GAAakP,GAA0BM;QACrC,IAAIJ;QAMJ,KAJEA,SADYzM,MAAV6M,IACKnO,KAAK2N,KAAKK,GAAgBG,KAE1BnO,KAAK2N,KAAKS,MAEZL,EAAKE,QAAW;YAGrB,KADeJ,EADFE,EAAKG,KACK1N,MAErB;;;uEAMN7B,GAAkBiP;QAChB,MAAMG,IAAO/N,KAAK2N,KAAKK,GAAgBJ;QACvC,OAAOG,EAAKE,OAAYF,EAAKG,KAAU1N,MAAM;;IAG/C7B;QACE,OAAO,IAAI0P,GAAqBrO,KAAK2N,KAAKS;;IAG5CzP,GAAgB6B;QACd,OAAO,IAAI6N,GAAqBrO,KAAK2N,KAAKK,GAAgBxN;;4CAI5D7B,IAAIiP;QACF,OAAO5N,KAAKuL,KAAKvL,KAAK2N,KAAKlC,OAAOmC,GAAMtC,GAAOsC,IAAM;;iCAIvDjP,OAAOiP;QACL,OAAK5N,KAAKsO,IAAIV,KAGP5N,KAAKuL,KAAKvL,KAAK2N,KAAKlC,OAAOmC,MAFzB5N;;IAKXrB;QACE,OAAOqB,KAAK2N,KAAK5M;;IAGnBpC,GAAU0B;QACR,IAAImM,IAAuBxM;;gBAW3B,OARIwM,EAAOxH,OAAO3E,EAAM2E,SACtBwH,IAASnM,GACTA,IAAQL,OAGVK,EAAMQ,QAAQ+M;YACZpB,IAASA,EAAO+B,IAAIX;YAEfpB;;IAGT7N,QAAQ0B;QACN,MAAMA,aAAiBqN,KACrB,QAAO;QAET,IAAI1N,KAAKgF,SAAS3E,EAAM2E,MACtB,QAAO;QAGT,MAAMwJ,IAASxO,KAAK2N,KAAKS,MACnBK,IAAUpO,EAAMsN,KAAKS;QAC3B,MAAOI,EAAOP,QAAW;YACvB,MAAMS,IAAWF,EAAON,KAAU1N,KAC5BmO,IAAYF,EAAQP,KAAU1N;YACpC,IAA6C,MAAzCR,KAAKX,EAAWqP,GAAUC,IAC5B,QAAO;;QAGX,QAAO;;IAGThQ;QACE,MAAMiQ,IAAW;QAIjB,OAHA5O,KAAKa,QAAQyJ;YACXsE,EAAInN,KAAK6I;YAEJsE;;IAGTjQ;QACE,MAAM6N,IAAc;QAEpB,OADAxM,KAAKa,QAAQ+M,KAAQpB,EAAO/K,KAAKmM,KAC1B,eAAepB,EAAOpJ,aAAa;;IAGpCzE,KAAKgP;QACX,MAAMnB,IAAS,IAAIkB,GAAU1N,KAAKX;QAElC,OADAmN,EAAOmB,OAAOA,GACPnB;;;;MAIE6B;IACX1P,YAAoBoP;kBAAAA;;IAEpBpP;QACE,OAAOqB,KAAK+N,GAAKG,KAAU1N;;IAG7B7B;QACE,OAAOqB,KAAK+N,GAAKE;;;;;;;;;;;;;;;;;;;GC1JrB,OAAMY,KAA2B,IAAI3D,GACnCzE,EAAYpH;;SAEEyP;IACd,OAAOD;;;SAQOE;IACd,OAAOD;;;AAST,MAAME,KAAqB,IAAI9D,GAC7BzE,EAAYpH;;SAEE4P;IACd,OAAOD;;;AAIT,MAAME,KAA6B,IAAIhE,GACrCzE,EAAYpH;;AAOd,MAAM8P,KAAyB,IAAIzB,GAAUjH,EAAYpH;;SACzC+P,MAAkBC;IAChC,IAAIC,IAAMH;IACV,KAAK,MAAM3O,KAAO6O,GAChBC,IAAMA,EAAIf,IAAI/N;IAEhB,OAAO8O;;;AAIT,MAAMC,KAAsB,IAAI7B,GAAoBzO;;SACpCuQ;IACd,OAAOD;;;;;;;;;;;;;;;;;;;;;;;;UCpDIE;;IAcX9Q,YAAY+Q;;;QAIR1P,KAAKX,IADHqQ,IACgB,CAACC,GAAcC,MAC/BF,EAAKC,GAAIC,MAAOnJ,EAAYpH,EAAWsQ,EAAGnP,KAAKoP,EAAGpP,OAElC,CAACmP,GAAcC,MAC/BnJ,EAAYpH,EAAWsQ,EAAGnP,KAAKoP,EAAGpP;QAGtCR,KAAK6P,KAAWZ,MAChBjP,KAAK8P,KAAY,IAAI5E,GAA0BlL,KAAKX;;;;;WArBtDV,UAAgBoR;QACd,OAAO,IAAIN,GAAYM,EAAO1Q;;IAuBhCV,IAAI6B;QACF,OAAiC,QAA1BR,KAAK6P,GAASrO,IAAIhB;;IAG3B7B,IAAI6B;QACF,OAAOR,KAAK6P,GAASrO,IAAIhB;;IAG3B7B;QACE,OAAOqB,KAAK8P,GAAUjE;;IAGxBlN;QACE,OAAOqB,KAAK8P,GAAUhE;;IAGxBnN;QACE,OAAOqB,KAAK8P,GAAU/O;;;;;WAOxBpC,QAAQ6B;QACN,MAAMwP,IAAMhQ,KAAK6P,GAASrO,IAAIhB;QAC9B,OAAOwP,IAAMhQ,KAAK8P,GAAUnK,QAAQqK,MAAQ;;IAG9ChL;QACE,OAAOhF,KAAK8P,GAAU9K;;kEAIxBrG,QAAQkP;QACN7N,KAAK8P,GAAU9D,GAAiB,CAACnK,GAAGC,OAClC+L,EAAGhM,KACI;;8DAKXlD,IAAIqR;;QAEF,MAAMV,IAAMtP,KAAKiQ,OAAOD,EAAIxP;QAC5B,OAAO8O,EAAI/D,KACT+D,EAAIO,GAASvE,GAAO0E,EAAIxP,KAAKwP,IAC7BV,EAAIQ,GAAUxE,GAAO0E,GAAK;;kDAK9BrR,OAAO6B;QACL,MAAMwP,IAAMhQ,KAAKwB,IAAIhB;QACrB,OAAKwP,IAIEhQ,KAAKuL,KAAKvL,KAAK6P,GAASpE,OAAOjL,IAAMR,KAAK8P,GAAUrE,OAAOuE,MAHzDhQ;;IAMXrB,QAAQ0B;QACN,MAAMA,aAAiBoP,KACrB,QAAO;QAET,IAAIzP,KAAKgF,SAAS3E,EAAM2E,MACtB,QAAO;QAGT,MAAMwJ,IAASxO,KAAK8P,GAAU1B,MACxBK,IAAUpO,EAAMyP,GAAU1B;QAChC,MAAOI,EAAOP,QAAW;YACvB,MAAMiC,IAAU1B,EAAON,KAAU1N,KAC3B2P,IAAW1B,EAAQP,KAAU1N;YACnC,KAAK0P,EAAQ5L,QAAQ6L,IACnB,QAAO;;QAGX,QAAO;;IAGTxR;QACE,MAAMyR,IAAuB;QAI7B,OAHApQ,KAAKa,QAAQmP;YACXI,EAAW3O,KAAKuO,EAAI5M;YAEI,MAAtBgN,EAAWtR,SACN,mBAEA,sBAAsBsR,EAAW5K,KAAK,UAAU;;IAInD7G,KACNkR,GACAC;QAEA,MAAMO,IAAS,IAAIZ;QAInB,OAHAY,EAAOhR,IAAaW,KAAKX,GACzBgR,EAAOR,KAAWA,GAClBQ,EAAOP,KAAYA,GACZO;;;;;;;;;;;;;;;;;;;;;;;UClHEC;IAAb3R;QACEqB,UAAoB,IAAIkL,GACtBzE,EAAYpH;;IAGdV,MAAM4R;QACJ,MAAM/P,IAAM+P,EAAOP,IAAIxP,KACjBgQ,IAAYxQ,KAAKyQ,GAAUjP,IAAIhB;QAChCgQ;;0BAOHD,EAAOG,6BACPF,EAAUE,OAEV1Q,KAAKyQ,KAAYzQ,KAAKyQ,GAAUnF,GAAO9K,GAAK+P,0BAE5CA,EAAOG,4BACPF,EAAUE,OAEV1Q,KAAKyQ,KAAYzQ,KAAKyQ,GAAUnF,GAAO9K,GAAK;YAC1CkQ,MAAMF,EAAUE;YAChBV,KAAKO,EAAOP;kCAGdO,EAAOG,6BACPF,EAAUE,OAEV1Q,KAAKyQ,KAAYzQ,KAAKyQ,GAAUnF,GAAO9K,GAAK;YAC1CkQ;YACAV,KAAKO,EAAOP;kCAGdO,EAAOG,0BACPF,EAAUE,OAEV1Q,KAAKyQ,KAAYzQ,KAAKyQ,GAAUnF,GAAO9K,GAAK;YAC1CkQ;YACAV,KAAKO,EAAOP;iCAGdO,EAAOG,0BACPF,EAAUE,OAEV1Q,KAAKyQ,KAAYzQ,KAAKyQ,GAAUhF,OAAOjL,yBAEvC+P,EAAOG,6BACPF,EAAUE,OAEV1Q,KAAKyQ,KAAYzQ,KAAKyQ,GAAUnF,GAAO9K,GAAK;YAC1CkQ;YACAV,KAAKQ,EAAUR;+BAGjBO,EAAOG,4BACPF,EAAUE,OAEV1Q,KAAKyQ,KAAYzQ,KAAKyQ,GAAUnF,GAAO9K,GAAK;YAC1CkQ;YACAV,KAAKO,EAAOP;;;;;;;;;QAUdzS,MA/DAyC,KAAKyQ,KAAYzQ,KAAKyQ,GAAUnF,GAAO9K,GAAK+P;;IAwEhD5R;QACE,MAAMgS,IAAgC;QAMtC,OALA3Q,KAAKyQ,GAAUzE,GACb,CAACxL,GAAkB+P;YACjBI,EAAQlP,KAAK8O;YAGVI;;;;MAIEC;IACXjS,YACWkS,GACAC,GACAC,GACAC,GACAC,GACAC,GACAC,GACAC;QAPApR,aAAA6Q,GACA7Q,YAAA8Q,aACAC,GACA/Q,kBAAAgR,aACAC,GACAjR,iBAAAkR;kBACAC,aACAC;;sFAIXzS,UACEkS,GACAQ,GACAJ,GACAC;QAEA,MAAMP,IAAgC;QAKtC,OAJAU,EAAUxQ,QAAQmP;YAChBW,EAAQlP,KAAK;gBAAEiP;gBAAwBV,KAAAA;;YAGlC,IAAIY,GACTC,GACAQ,GACA5B,GAAY6B,GAASD,IACrBV,GACAM,GACAC;iCACwB;wCACO;;IAInCK;QACE,QAAQvR,KAAKiR,GAAYlQ;;IAG3BpC,QAAQ0B;QACN,MACEL,KAAKkR,cAAc7Q,EAAM6Q,aACzBlR,KAAKmR,OAAqB9Q,EAAM8Q,MAC/BnR,KAAKiR,GAAY3M,QAAQjE,EAAM4Q,OAC/BO,GAAYxR,KAAK6Q,OAAOxQ,EAAMwQ,UAC9B7Q,KAAK8Q,KAAKxM,QAAQjE,EAAMyQ,SACxB9Q,KAAK+Q,GAAQzM,QAAQjE,EAAM0Q,MAE5B,QAAO;QAET,MAAMJ,IAAgC3Q,KAAKgR,YACrCS,IAAqCpR,EAAM2Q;QACjD,IAAIL,EAAQ7R,WAAW2S,EAAa3S,QAClC,QAAO;QAET,KAAK,IAAIR,IAAI,GAAGA,IAAIqS,EAAQ7R,QAAQR,KAClC,IACEqS,EAAQrS,GAAGoS,SAASe,EAAanT,GAAGoS,SACnCC,EAAQrS,GAAG0R,IAAI1L,QAAQmN,EAAanT,GAAG0R,MAExC,QAAO;QAGX,QAAO;;;;;;;;;;;;;;;;;;;;;;;;UCzKE0B;IACX/S;;;;IAIW8L;;;;IAIAkH;;;;;IAKAC;;;;;IAKAC;;;;IAIAC;iBAlBArH,aAIAkH,aAKAC,aAKAC,aAIAC;;;;;;;;;IAUXnT,UACE2L,GACAlE;QAEA,MAAMuL,IAAgB,IAAII;QAQ1B,OAPAJ,EAAcrC,IACZhF,GACA0H,GAAaC,GACX3H,GACAlE,KAGG,IAAIsL,GACTvN,EAAgBkB,OAChBsM,GACAnC,MACAV,MACAM;;;;;;;;;;;UAaO4C;IACXrT;;;;;;;IAOWgM;;;;;;IAMAvE;;;;;IAKA8L;;;;;IAKAC;;;;;IAKAC;QArBApS,mBAAA2K,aAMAvE,aAKA8L,aAKAC,aAKAC;;;;;;WAQXzT,UACE2L,GACAlE;QAEA,OAAO,IAAI4L,GACTrI,GAAWiB,GACXxE,GACAgJ,MACAA,MACAA;;;;;;;;;;;;;;;;;;;;;;;;;UC1FOiD;IACX1T;;IAES2T;;IAEAC;;IAEA/R;;;;;IAKAgS;kBATAF,GAEAtS,wBAAAuS,GAEAvS,WAAAQ,aAKAgS;;;;MAIEC;IACX9T,YACS2L,GACAoI;QADA1S,gBAAAsK,aACAoI;;;;MAYEC;IACXhU;;IAESiU;;IAEAC;;;;;;;IAOAlI,IAA0BhB,GAAWiB;2DAErCkI,IAA+B;QAX/B9S,aAAA4S,GAEA5S,iBAAA6S,GAOA7S,mBAAA2K,GAEA3K,aAAA8S;;;;mDAKX,OAAMC;IAANpU;;;;;QAKEqB,UAA2B;;;;;;;QAQ3BA,UAGIgT;;QAGJhT,UAAmC2J,GAAWiB,GAC9C5K,WAAmB;;;;;;QAOnBA,WAA6B;;;;;;;;;WAU7BiT;QACE,OAAOjT,KAAKkT;;gEAIdvI;QACE,OAAO3K,KAAKmT;;6EAIdC;QACE,OAAiC,MAA1BpT,KAAKqT;;iFAIdC;QACE,OAAOtT,KAAKuT;;;;;WAOd5U,GAAkBgM;QACZA,EAAY6I,MAAwB,MACtCxT,KAAKuT,MAAqB,GAC1BvT,KAAKmT,KAAexI;;;;;;;WAUxBhM;QACE,IAAIuT,IAAiB9C,MACjB+C,IAAoB/C,MACpBgD,IAAmBhD;QAkBvB,OAhBApP,KAAKyT,GAAgB5S,QAAQ,CAACL,GAAKkT;YACjC,QAAQA;cACN;gBACExB,IAAiBA,EAAe3D,IAAI/N;gBACpC;;cACF;gBACE2R,IAAoBA,EAAkB5D,IAAI/N;gBAC1C;;cACF;gBACE4R,IAAmBA,EAAiB7D,IAAI/N;gBACxC;;cACF;gBACEjD;;YAIC,IAAIyU,GACThS,KAAKmT,IACLnT,KAAKkT,IACLhB,GACAC,GACAC;;;;WAOJzT;QACEqB,KAAKuT,MAAqB,GAC1BvT,KAAKyT,KAAkBT;;IAGzBrU,GAAkB6B,GAAkBkT;QAClC1T,KAAKuT,MAAqB,GAC1BvT,KAAKyT,KAAkBzT,KAAKyT,GAAgBnI,GAAO9K,GAAKkT;;IAG1D/U,GAAqB6B;QACnBR,KAAKuT,MAAqB,GAC1BvT,KAAKyT,KAAkBzT,KAAKyT,GAAgBhI,OAAOjL;;IAGrD7B;QACEqB,KAAKqT,MAAoB;;IAG3B1U;QACEqB,KAAKqT,MAAoB;;IAG3B1U;QACEqB,KAAKuT,MAAqB,GAC1BvT,KAAKkT,MAAW;;;;;;;MA2BPS;IACXhV,YAAoBiV;kBAAAA;;QAGpB5T,UAAuB,IAAI+R;;QAG3B/R,UAAiC8O;;QAGjC9O,UAAuC6T;;;;;;QAOvC7T,UAA8B,IAAI0N,GAAoBzO;;;;WAKtDN,GAAqBmV;QACnB,KAAK,MAAMxJ,KAAYwJ,EAAUxB,IAC3BwB,EAAUtB,cAAkBuB,KAC9B/T,KAAKgU,GAAoB1J,GAAUwJ,EAAUtB,MACpCsB,EAAUtB,cAAkByB,MACrCjU,KAAKkU,GACH5J,GACAwJ,EAAUtT,KACVsT,EAAUtB;QAKhB,KAAK,MAAMlI,KAAYwJ,EAAUvB,kBAC/BvS,KAAKkU,GAAyB5J,GAAUwJ,EAAUtT,KAAKsT,EAAUtB;;sFAKrE7T,GAAmBwV;QACjBnU,KAAKoU,GAAcD,GAAc7J;YAC/B,MAAM+J,IAAcrU,KAAKsU,GAAkBhK;YAC3C,QAAQ6J,EAAavB;cACnB;gBACM5S,KAAKuU,GAAejK,MACtB+J,EAAYG,GAAkBL,EAAaxJ;gBAE7C;;cACF;;;gBAGE0J,EAAYI,MACPJ,EAAYK;;;;gBAIfL,EAAYM,MAEdN,EAAYG,GAAkBL,EAAaxJ;gBAC3C;;cACF;;;;;gBAKE0J,EAAYI,MACPJ,EAAYK,MACf1U,KAAK4U,aAAatK;gBAMpB;;cACF;gBACMtK,KAAKuU,GAAejK,OACtB+J,EAAYQ,MACZR,EAAYG,GAAkBL,EAAaxJ;gBAE7C;;cACF;gBACM3K,KAAKuU,GAAejK;;;;gBAItBtK,KAAK8U,GAAYxK,IACjB+J,EAAYG,GAAkBL,EAAaxJ;gBAE7C;;cACF;gBACEpN;;;;;;;;WAURoB,GACEwV,GACArT;QAEIqT,EAAatB,UAAU/T,SAAS,IAClCqV,EAAatB,UAAUhS,QAAQC,KAE/Bd,KAAK+U,GAAalU,QAAQ,CAACc,GAAG2I;YACxBtK,KAAKuU,GAAejK,MACtBxJ,EAAGwJ;;;;;;;WAWX3L,GAAsBqW;QACpB,MAAM1K,IAAW0K,EAAY1K,UACvB2K,IAAgBD,EAAYtC,GAAgBnS,OAE5C2U,IAAalV,KAAKmV,GAA0B7K;QAClD,IAAI4K,GAAY;YACd,MAAMpN,IAASoN,EAAWpN;YAC1B,IAAIqB,GAAiBrB,IACnB,IAAsB,MAAlBmN,GAAqB;;;;;;;gBAOvB,MAAMzU,IAAM,IAAIiG,EAAYqB,EAAOpC;gBACnC1F,KAAKkU,GACH5J,GACA9J,GACA,IAAIyT,GAAWzT,GAAK2D,EAAgBkB;mBAxWpC1H,EA4WkB,MAAlBsX,SAIC;gBACejV,KAAKoV,GAAiC9K,OACtC2K;;;gBAGlBjV,KAAK8U,GAAYxK,IACjBtK,KAAKqV,KAAsBrV,KAAKqV,GAAoB9G,IAAIjE;;;;;;;WAUhE3L,GAAkB8L;QAChB,MAAMkH,IAAgB,IAAII;QAE1B/R,KAAK+U,GAAalU,QAAQ,CAACwT,GAAa/J;YACtC,MAAM4K,IAAalV,KAAKmV,GAA0B7K;YAClD,IAAI4K,GAAY;gBACd,IAAIb,EAAYjO,MAAW+C,GAAiB+L,EAAWpN,SAAS;;;;;;;;;oBAU9D,MAAMtH,IAAM,IAAIiG,EAAYyO,EAAWpN,OAAOpC;oBAEH,SAAzC1F,KAAKsV,GAAuB9T,IAAIhB,MAC/BR,KAAKuV,GAAuBjL,GAAU9J,MAEvCR,KAAKkU,GACH5J,GACA9J,GACA,IAAIyT,GAAWzT,GAAKiK;;gBAKtB4J,EAAYmB,OACd7D,EAAcrC,IAAIhF,GAAU+J,EAAYoB,OACxCpB,EAAYM;;;QAKlB,IAAI7C,IAAyB1C;;;;;;gBAO7BpP,KAAK0V,GAA6B7U,QAAQ,CAACL,GAAKmV;YAC9C,IAAIC,KAAoB;YAExBD,EAAQE,GAAavL;gBACnB,MAAM4K,IAAalV,KAAKmV,GAA0B7K;gBAClD,QACE4K,iCACAA,EAAW3K,MAEXqL,KAAoB,IACb;gBAMPA,MACF9D,IAAyBA,EAAuBvD,IAAI/N;;QAIxD,MAAMsV,IAAc,IAAIpE,GACtBjH,GACAkH,GACA3R,KAAKqV,IACLrV,KAAKsV,IACLxD;QAOF,OAJA9R,KAAKsV,KAAyBxG,MAC9B9O,KAAK0V,KAA+B7B,MACpC7T,KAAKqV,KAAsB,IAAI3H,GAAoBzO,IAE5C6W;;;;;;;IAQTnX,GAAoB2L,GAAoByL;QACtC,KAAK/V,KAAKuU,GAAejK,IACvB;QAGF,MAAMoJ,IAAa1T,KAAKuV,GAAuBjL,GAAUyL,EAASvV;QAI9CR,KAAKsU,GAAkBhK,GAC/B0L,GAAkBD,EAASvV,KAAKkT,IAE5C1T,KAAKsV,KAAyBtV,KAAKsV,GAAuBhK,GACxDyK,EAASvV,KACTuV,IAGF/V,KAAK0V,KAA+B1V,KAAK0V,GAA6BpK,GACpEyK,EAASvV,KACTR,KAAKiW,GAA4BF,EAASvV,KAAK+N,IAAIjE;;;;;;;;;;IAYvD3L,GACE2L,GACA9J,GACA0V;QAEA,KAAKlW,KAAKuU,GAAejK,IACvB;QAGF,MAAM+J,IAAcrU,KAAKsU,GAAkBhK;QACvCtK,KAAKuV,GAAuBjL,GAAU9J,KACxC6T,EAAY2B,GAAkBxV;;;QAI9B6T,EAAY8B,GAAqB3V,IAGnCR,KAAK0V,KAA+B1V,KAAK0V,GAA6BpK,GACpE9K,GACAR,KAAKiW,GAA4BzV,GAAKyP,OAAO3F,KAG3C4L,MACFlW,KAAKsV,KAAyBtV,KAAKsV,GAAuBhK,GACxD9K,GACA0V;;IAKNvX,aAAa2L;QACXtK,KAAK+U,GAAa9E,OAAO3F;;;;;;WAQnB3L,GAAiC2L;QACvC,MACM6J,IADcnU,KAAKsU,GAAkBhK,GACVmL;QACjC,OACEzV,KAAK4T,GAAiBwC,GAAuB9L,GAAUtF,OACvDmP,EAAajC,GAAelN,OAC5BmP,EAAa/B,GAAiBpN;;;;;WAQlCrG,GAA2B2L;QAELtK,KAAKsU,GAAkBhK,GAC/B+L;;IAGN1X,GAAkB2L;QACxB,IAAIkC,IAASxM,KAAK+U,GAAavT,IAAI8I;QAKnC,OAJKkC,MACHA,IAAS,IAAIuG,IACb/S,KAAK+U,GAAazF,IAAIhF,GAAUkC,KAE3BA;;IAGD7N,GAA4B6B;QAClC,IAAI8V,IAAgBtW,KAAK0V,GAA6BlU,IAAIhB;QAU1D,OARK8V,MACHA,IAAgB,IAAI5I,GAAoBzO,IACxCe,KAAK0V,KAA+B1V,KAAK0V,GAA6BpK,GACpE9K,GACA8V,KAIGA;;;;;;WAQC3X,GAAe2L;QACvB,MAAMiM,IAA4D,SAA7CvW,KAAKmV,GAA0B7K;QAIpD,OAHKiM,KACHna,EAxXU,yBAwXQ,4BAA4BkO,IAEzCiM;;;;;WAOC5X,GAA0B2L;QAClC,MAAM+J,IAAcrU,KAAK+U,GAAavT,IAAI8I;QAC1C,OAAO+J,KAAeA,EAAYK,KAC9B,OACA1U,KAAK4T,GAAiB4C,GAAuBlM;;;;;;WAQ3C3L,GAAY2L;QAKlBtK,KAAK+U,GAAazF,IAAIhF,GAAU,IAAIyI;QAKf/S,KAAK4T,GAAiBwC,GAAuB9L,GACrDzJ,QAAQL;YACnBR,KAAKkU,GAAyB5J,GAAU9J,wBAA0B;;;;;;WAO9D7B,GACN2L,GACA9J;QAGA,OADqBR,KAAK4T,GAAiBwC,GAAuB9L,GAC9CgE,IAAI9N;;;;AAI5B,SAASqT;IACP,OAAO,IAAI3I,GACTzE,EAAYpH;;;AAIhB,SAAS2T;IACP,OAAO,IAAI9H,GAAmCzE,EAAYpH;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;aCloB5CoX,GAAkBtZ;;IAEhC,OAPgC,sDAMlBA,QAAAA,aAAAA,EAAOuZ,uCAAUC,WAAU,IAAY,uCAAGC;;;;;;;;;SAkD1CC,GAAkB1Z;IAChC,MAAM2Z,IAAiBC,GACrB5Z,EAAMuZ,SAAUC,OAA4B,qBAAiB;IAE/D,OAAO,IAAIrT,EAAUwT,EAAevT,SAASuT,EAAeE;;;;;;;;;;;;;;;;;;;oECnE9D;MAAMC,KAAwB,IAAIC,OAChC;;0EAIcC,GAAUha;IACxB,OAAI,eAAeA,wBAER,kBAAkBA,2BAElB,kBAAkBA,KAAS,iBAAiBA,0BAE5C,oBAAoBA,6BAEpB,iBAAiBA,0BAEjB,gBAAgBA,wBAEhB,oBAAoBA,uBAEpB,mBAAmBA,4BAEnB,gBAAgBA,yBAEhB,cAAcA,IACnBsZ,GAAkBtZ,2DAnCSI;;;sFA6CnB0L,GAAY/J,GAAiBC;IAC3C,MAAMiY,IAAWD,GAAUjY;IAE3B,IAAIkY,MADcD,GAAUhY,IAE1B,QAAO;IAGT,QAAQiY;MACN;QACE,QAAO;;MACT;QACE,OAAOlY,EAAKmY,iBAAiBlY,EAAMkY;;MACrC;QACE,OAAOR,GAAkB3X,GAAMoF,QAAQuS,GAAkB1X;;MAC3D;QACE,OAwBN,SAAyBD,GAAiBC;YACxC,IACiC,mBAAxBD,EAAKoY,kBACoB,mBAAzBnY,EAAMmY,kBACbpY,EAAKoY,eAAexY,WAAWK,EAAMmY,eAAexY;;YAGpD,OAAOI,EAAKoY,mBAAmBnY,EAAMmY;YAGvC,MAAMC,IAAgBR,GAAmB7X,EAAoB,iBACvDsY,IAAiBT,GAAmB5X,EAAqB;YAC/D,OACEoY,EAAchU,YAAYiU,EAAejU,WACzCgU,EAAcP,UAAUQ,EAAeR;SAtC9BS,CAAgBvY,GAAMC;;MAC/B;QACE,OAAOD,EAAK0X,gBAAgBzX,EAAMyX;;MACpC;QACE,OA+CN,SAAoB1X,GAAiBC;YACnC,OAAOuY,GAAoBxY,EAAgB,YAAEoF,QAC3CoT,GAAoBvY,EAAiB;SAjD5BwY,CAAWzY,GAAMC;;MAC1B;QACE,OAAOD,EAAK0Y,mBAAmBzY,EAAMyY;;MACvC;QACE,OAkCN,SAAwB1Y,GAAiBC;YACvC,OACE0Y,GAAgB3Y,EAAK4Y,cAAeC,cAClCF,GAAgB1Y,EAAM2Y,cAAeC,aACvCF,GAAgB3Y,EAAK4Y,cAAeE,eAClCH,GAAgB1Y,EAAM2Y,cAAeE;SAvC9BC,CAAe/Y,GAAMC;;MAC9B;QACE,gBA+CuBD,GAAiBC;YAC5C,IAAI,kBAAkBD,KAAQ,kBAAkBC,GAC9C,OACE0Y,GAAgB3Y,EAAKgZ,kBAAkBL,GAAgB1Y,EAAM+Y;YAE1D,IAAI,iBAAiBhZ,KAAQ,iBAAiBC,GAAO;gBAC1D,MAAMgZ,IAAKN,GAAgB3Y,EAAiB,cACtCkZ,IAAKP,GAAgB1Y,EAAkB;gBAE7C,OAAIgZ,MAAOC,IACFpR,EAAemR,OAAQnR,EAAeoR,KAEtCC,MAAMF,MAAOE,MAAMD;;YAI9B,QAAO;SA/DIE,CAAapZ,GAAMC;;MAC5B;QACE,OAAOC,EACLF,EAAKqZ,WAAYC,UAAU,IAC3BrZ,EAAMoZ,WAAYC,UAAU,IAC5BvP;;MAEJ;QACE,OA0DN,SAAsB/J,GAAiBC;YACrC,MAAMsZ,IAAUvZ,EAAKwX,SAAUC,UAAU,IACnC+B,IAAWvZ,EAAMuX,SAAUC,UAAU;YAE3C,IAAIrW,EAAWmY,OAAanY,EAAWoY,IACrC,QAAO;YAGT,KAAK,MAAMlY,KAAOiY,GAChB,IAAIA,EAAQ9X,eAAeH,YAELc,MAAlBoX,EAASlY,OACRyI,GAAYwP,EAAQjY,IAAMkY,EAASlY,MAEpC,QAAO;YAIb,QAAO;;6EA5EImY,EAAazZ,GAAMC;;MAC5B;QACE,OAhF6B5B;;;;SA8JnBqb,GACdC,GACAC;IAEA,YACgExX,OAA7DuX,EAASL,UAAU,IAAIO,KAAKjX,KAAKmH,GAAYnH,GAAGgX;;;SAIrCE,GAAa9Z,GAAiBC;IAC5C,MAAMiY,IAAWD,GAAUjY,IACrB+Z,IAAY9B,GAAUhY;IAE5B,IAAIiY,MAAa6B,GACf,OAAOha,EAAoBmY,GAAU6B;IAGvC,QAAQ7B;MACN;QACE,OAAO;;MACT;QACE,OAAOnY,EAAoBC,EAAkB,cAAEC,EAAmB;;MACpE;QACE,OAyBN,SAAwBD,GAAiBC;YACvC,MAAM+Z,IAAarB,GAAgB3Y,EAAKgZ,gBAAgBhZ,EAAKia,cACvDC,IAAcvB,GAAgB1Y,EAAM+Y,gBAAgB/Y,EAAMga;YAEhE,OAAID,IAAaE,KACP,IACCF,IAAaE,IACf,IACEF,MAAeE,IACjB;;YAGHf,MAAMa,KACDb,MAAMe,KAAe,KAAK,IAE1B;SAxCAC,CAAena,GAAMC;;MAC9B;QACE,OAAOma,GAAkBpa,EAAoB,gBAAEC,EAAqB;;MACtE;QACE,OAAOma,GACLzC,GAAkB3X,IAClB2X,GAAkB1X;;MAEtB;QACE,OAAOF,EAAoBC,EAAiB,aAAEC,EAAkB;;MAClE;QACE,OAkFN,SACED,GACAC;YAEA,MAAMoa,IAAY7B,GAAoBxY,IAChCsa,IAAa9B,GAAoBvY;YACvC,OAAOoa,EAAUE,EAAUD;SAxFhBE,CAAaxa,EAAgB,YAAEC,EAAiB;;MACzD;QACE,OAsDN,SAA2Bwa,GAAkBC;YAC3C,MAAMC,IAAeF,EAAS/T,MAAM,MAC9BkU,IAAgBF,EAAUhU,MAAM;YACtC,KAAK,IAAItH,IAAI,GAAGA,IAAIub,EAAa/a,UAAUR,IAAIwb,EAAchb,QAAQR,KAAK;gBACxE,MAAMyb,IAAa9a,EAAoB4a,EAAavb,IAAIwb,EAAcxb;gBACtE,IAAmB,MAAfyb,GACF,OAAOA;;YAGX,OAAO9a,EAAoB4a,EAAa/a,QAAQgb,EAAchb;SA/DnDkb,CAAkB9a,EAAoB,gBAAEC,EAAqB;;MACtE;QACE,OAgEN,SAA0BD,GAAkBC;YAC1C,MAAM4a,IAAa9a,EACjB4Y,GAAgB3Y,EAAK6Y,WACrBF,GAAgB1Y,EAAM4Y;YAExB,IAAmB,MAAfgC,GACF,OAAOA;YAET,OAAO9a,EACL4Y,GAAgB3Y,EAAK8Y,YACrBH,GAAgB1Y,EAAM6Y;SA1EbiC,CAAiB/a,EAAmB,eAAEC,EAAoB;;MACnE;QACE,OAqFN,SAAuBD,GAAsBC;YAC3C,MAAM+a,IAAYhb,EAAKsZ,UAAU,IAC3B2B,IAAahb,EAAMqZ,UAAU;YAEnC,KAAK,IAAIla,IAAI,GAAGA,IAAI4b,EAAUpb,UAAUR,IAAI6b,EAAWrb,UAAUR,GAAG;gBAClE,MAAM8b,IAAUpB,GAAakB,EAAU5b,IAAI6b,EAAW7b;gBACtD,IAAI8b,GACF,OAAOA;;YAGX,OAAOnb,EAAoBib,EAAUpb,QAAQqb,EAAWrb;SA/F7Cub,CAAcnb,EAAgB,YAAEC,EAAiB;;MAC1D;QACE,OAgGN,SAAqBD,GAAoBC;YACvC,MAAMsZ,IAAUvZ,EAAKyX,UAAU,IACzB2D,IAAW7Z,OAAO4O,KAAKoJ,IACvBC,IAAWvZ,EAAMwX,UAAU,IAC3B4D,IAAY9Z,OAAO4O,KAAKqJ;;;;;YAM9B4B,EAASE,QACTD,EAAUC;YAEV,KAAK,IAAIlc,IAAI,GAAGA,IAAIgc,EAASxb,UAAUR,IAAIic,EAAUzb,UAAUR,GAAG;gBAChE,MAAMmc,IAAaxb,EAAoBqb,EAAShc,IAAIic,EAAUjc;gBAC9D,IAAmB,MAAfmc,GACF,OAAOA;gBAET,MAAML,IAAUpB,GAAaP,EAAQ6B,EAAShc,KAAKoa,EAAS6B,EAAUjc;gBACtE,IAAgB,MAAZ8b,GACF,OAAOA;;YAIX,OAAOnb,EAAoBqb,EAASxb,QAAQyb,EAAUzb;;;;;GAxH3C4b,EAAYxb,EAAc,UAAEC,EAAe;;MACpD;QACE,MA1M6B5B;;;;AAkOnC,SAAS+b,GAAkBpa,GAAqBC;IAC9C,IACkB,mBAATD,KACU,mBAAVC,KACPD,EAAKJ,WAAWK,EAAML,QAEtB,OAAOG,EAAoBC,GAAMC;IAGnC,MAAMoY,IAAgBR,GAAmB7X,IACnCsY,IAAiBT,GAAmB5X,IAEpC4a,IAAa9a,EACjBsY,EAAchU,SACdiU,EAAejU;IAEjB,OAAmB,MAAfwW,IACKA,IAEF9a,EAAoBsY,EAAcP,OAAOQ,EAAeR;;;SAkFjD/O,GAAY9K;IAC1B,OAAOwd,GAAcxd;;;AAGvB,SAASwd,GAAcxd;IACrB,OAAI,eAAeA,IACV,SACE,kBAAkBA,IACpB,KAAKA,EAAMka,eACT,kBAAkBla,IACpB,KAAKA,EAAM+a,eACT,iBAAiB/a,IACnB,KAAKA,EAAMgc,cACT,oBAAoBhc,IAuBjC,SAA2BiH;QACzB,MAAMwW,IAAsB7D,GAAmB3S;QAC/C,OAAO,QAAQwW,EAAoBrX,WAAWqX,EAAoB5D;KAxBzD6D,CAAkB1d,EAAqB,kBACrC,iBAAiBA,IACnBA,EAAMyZ,cACJ,gBAAgBzZ,IAgBpBua,GAfqBva,EAAiB,YAeN2d,aAd5B,oBAAoB3d,KA0BNya,IAzBEza,EAAqB;IA0BzCsJ,EAAYsU,EAASnD,GAAgBxU,cAzBjC,mBAAmBjG,IAqBvB,QADiB6d,IAnBE7d,EAAoB,eAoBvB4a,YAAYiD,EAAShD,eAnBjC,gBAAgB7a,IA4C7B,SAAuBob;QACrB,IAAI/L,IAAS,KACTyO,KAAQ;QACZ,KAAK,MAAM9d,KAASob,EAAWC,UAAU,IAClCyC,IAGHA,KAAQ,IAFRzO,KAAU,KAIZA,KAAUmO,GAAcxd;QAE1B,OAAOqP,IAAS;;;;;GAtDP0O,EAAc/d,EAAiB,cAC7B,cAAcA,IAwB3B,SAAqBuZ;;;QAGnB,MAAMyE,IAAa1a,OAAO4O,KAAKqH,EAASC,UAAU,IAAI6D;QAEtD,IAAIhO,IAAS,KACTyO,KAAQ;QACZ,KAAK,MAAMza,KAAO2a,GACXF,IAGHA,KAAQ,IAFRzO,KAAU,KAIZA,KAAU,GAAGhM,KAAOma,GAAcjE,EAASC,OAAQnW;QAErD,OAAOgM,IAAS;KAtCP4O,CAAYje,EAAe,YAjWHI;IAgXnC,IAA0Byd,GAICpD;;;SAiGXb,GACdnT;;;;IAOA,IAzcoDjG,IAocvCiG,IAKO,mBAATA,GAAmB;;;;QAK5B,IAAIoT,IAAQ;QACZ,MAAMqE,IAAWpE,GAAsBqE,KAAK1X;QAE5C,IAjdkDjG,IAgdrC0d,IACTA,EAAS,IAAI;;YAEf,IAAIE,IAAUF,EAAS;YACvBE,KAAWA,IAAU,aAAaC,OAAO,GAAG,IAC5CxE,IAAQ9P,OAAOqU;;;gBAIjB,MAAME,IAAa,IAAI/X,KAAKE;QAG5B,OAAO;YAAEL,SAFOhF,KAAKC,MAAMid,EAAW5X,YAAY;YAEhCmT,OAAAA;;;IAOlB,OAAO;QAAEzT,SAFOsU,GAAgBjU,EAAKL;QAEnByT,OADJa,GAAgBjU,EAAKoT;;;;;;;aASvBa,GAAgB1a;;IAE9B,OAAqB,mBAAVA,IACFA,IACmB,mBAAVA,IACT+J,OAAO/J,KAEP;;;+EAKKua,GAAoBgE;IAClC,OAAoB,mBAATA,IACF/R,GAAWgS,iBAAiBD,KAE5B/R,GAAWiS,eAAeF;;;6EAKrBG,GAASlc,GAAwBa;IAC/C,OAAO;QACLoX,gBAAgB,YAAYjY,EAAWO,uBACrCP,EAAWQ,sBACCK,EAAIkF,KAAKD;;;;6DAKX0B,GACdhK;IAEA,SAASA,KAAS,kBAAkBA;;;;;SAgBtB2e,GACd3e;IAEA,SAASA,KAAS,gBAAgBA;;;wDAWpB4e,GACd5e;IAEA,SAASA,KAAS,eAAeA;;;gDAInB6e,GACd7e;IAEA,SAASA,KAAS,iBAAiBA,KAASkb,MAAMnR,OAAO/J,EAAMgc;;;uDAIjD8C,GACd9e;IAEA,SAASA,KAAS,cAAcA;;;;;;;;;;;;;;;;;;GCphBlC,OAAM+e,KAAa;IACjB,MAAMC,IAA8C;QACpDC,KAA4B;QAC5BC,MAA6B;;IAC7B,OAAOF;EAJU,IAObG,KAAY;IAChB,MAAMC,IAA2C;QACjDC,KAA0B;QAC1BC,MAAmC;QACnCC,KAA6B;QAC7BC,MAAsC;QACtCC,MAAsB;QACtBC,MAA0B;QAC1BC,kBAA+B;QAC/BC,IAAmB;QACnBC,UAAuB;QACvBC,sBAAmC;;IACnC,OAAOV;EAZS;;;;;;;;;;;;;;;;MAiCLW;IACXve,YACWgB,GACAwd;iBADAxd,aACAwd;;;;;;;SA+CGC,GAAUjgB;IACxB,OAAO;QAAE+a,cAAc,KAAK/a;;;;;;;aAOdkgB,GACdC,GACAngB;IAEA,IAAImgB,EAAWH,IAAe;QAC5B,IAAI9E,MAAMlb,IACR,OAAO;YAAEgc,aAAa;;QACjB,IAAIhc,MAAUogB,IAAAA,GACnB,OAAO;YAAEpE,aAAa;;QACjB,IAAIhc,OAAWogB,IAAAA,GACpB,OAAO;YAAEpE,aAAa;;;IAG1B,OAAO;QAAEA,aAAanS,EAAe7J,KAAS,OAAOA;;;;;;;;aAQvCqgB,GACdF,GACAngB;IAEA,OAAO8J,EAAc9J,KAASigB,GAAUjgB,KAASkgB,GAASC,GAAYngB;;;;;aAMxDsgB,GACdH,GACAlZ;IAEA,IAAIkZ,EAAWH,IAAe;QAU5B,OAAO,GANW,IAAIzZ,KAAyB,MAApBU,EAAUb,SAAgBma,cAEnBxX,QAAQ,SAAS,IAAIA,QAAQ,KAAK,QAEnD,cAAc9B,EAAUZ,aAAaoB,OAAO;;IAI7D,OAAO;QACLrB,SAAS,KAAKa,EAAUb;QACxByT,OAAO5S,EAAUZ;;;;;;;;;SAgBPma,GACdL,GACAnf;IAEA,OAAImf,EAAWH,KACNhf,EAAM2c,aAEN3c,EAAMyf;;;;;aA0BDC,GACdP,GACAQ;IAEA,OAAOL,GAAYH,GAAYQ,EAAQL;;;SAGzBM,GAAYD;IAE1B,OA3OsBngB,IA0OTmgB,IACN3Z,EAAgB6Z,EApDzB,SAAuBpa;QACrB,MAAMQ,IAAY2S,GAAmBnT;QACrC,OAAO,IAAIN,EAAUc,EAAUb,SAASa,EAAU4S;KAkDbgH,CAAcF;;;SAGrCG,GACdte,GACA+F;IAEA,OA0EF,SAAkC/F;QAChC,OAAO,IAAI2F,EAAa,EACtB,YACA3F,EAAWO,WACX,aACAP,EAAWQ;KA/EN+d,CAAyBve,GAC7Bwe,MAAM,aACNA,MAAMzY,GACND;;;AAGL,SAAS2Y,GAAiB/a;IACxB,MAAMgb,IAAW/Y,EAAaoB,EAAWrD;IAKzC,OA9PsB1F,EA2PpB2gB,GAAoBD,KAGfA;;;SAGOE,GACdjB,GACA9c;IAEA,OAAOyd,GAAeX,EAAW3d,GAAYa,EAAIkF;;;SAGnCqV,GACduC,GACAja;IAEA,MAAMgb,IAAWD,GAAiB/a;IAgBlC,OA5RsB1F,EA8QpB0gB,EAAS7c,IAAI,OAAO8b,EAAW3d,EAAWO,YA9QtBvC,GAqRlB0gB,EAAS7c,IAAI,OAAO8b,EAAW3d,EAAWQ,YAC1Cke,EAAS7c,IAAI,OAAO8b,EAAW3d,EAAWQ;IAMvC,IAAIsG,EAAY+X,GAAiCH;;;AAG1D,SAASI,GACPnB,GACA5X;IAEA,OAAOuY,GAAeX,EAAW3d,GAAY+F;;;AAG/C,SAASgZ,GAAcrb;IACrB,MAAMsb,IAAeP,GAAiB/a;;;;;QAKtC,OAA4B,MAAxBsb,EAAa7f,SACRwG,EAAasZ,MAEfJ,GAAiCG;;;SAG1BE,GAAqBvB;IAOnC,OANa,IAAIhY,EAAa,EAC5B,YACAgY,EAAW3d,EAAWO,WACtB,aACAod,EAAW3d,EAAWQ,YAEZsF;;;AAYd,SAAS+Y,GACPG;IAMA,OA5UsBhhB,EAyUpBghB,EAAa7f,SAAS,KAA6B,gBAAxB6f,EAAand,IAAI,KAGvCmd,EAAahY,EAAS;;;wFAIfmY,GACdxB,GACA9c,GACAmW;IAEA,OAAO;QACLtT,MAAMkb,GAAOjB,GAAY9c;QACzBmW,QAAQA,EAAOoI,MAAMrI,SAASC;;;;SAiElBqI,GACd1B,GACA9Q;IAEA,OAAI,WAAWA,IArCjB,SACE8Q,GACAtN;QAEArS,IACIqS,EAAIiP,QAGMjP,EAAIiP,MAAM5b,MACV2M,EAAIiP,MAAMC;QACxB,MAAM1e,IAAMua,GAASuC,GAAYtN,EAAIiP,MAAM5b,OACrCya,IAAUC,GAAY/N,EAAIiP,MAAMC,aAChCvR,IAAO,IAAIwR,GAAY;YAAEzI,UAAU;gBAAEC,QAAQ3G,EAAIiP,MAAMtI;;;QAC7D,OAAO,IAAI5C,GAASvT,GAAKsd,GAASnQ,GAAM;KAyB/ByR,CAAU9B,GAAY9Q,KACpB,aAAaA,IAvB1B,SACE8Q,GACA9Q;QAEA7O,IACI6O,EAAO6S,UAGX1hB,IACI6O,EAAO8S;QAGX,MAAM9e,IAAMua,GAASuC,GAAY9Q,EAAO6S,UAClCvB,IAAUC,GAAYvR,EAAO8S;QACnC,OAAO,IAAIrL,GAAWzT,GAAKsd;KAUlByB,CAAYjC,GAAY9Q,KApbEjP;;;SAybrBiiB,GACdlC,GACA/M;IAEA,IAAIyE;IACJ,IAAI,kBAAkBzE,GAAQ;QACdA,EAAO4D;;;QAGrB,MAAMvB,IAsEV,SACEA;YAEA,OAAc,gBAAVA,uBAEiB,UAAVA,oBAEU,aAAVA,sBAEU,cAAVA,sBAEU,YAAVA,oBAnhBwBrV;SAkcnBkiB,CACZlP,EAAO4D,aAAauL,oBAAoB,cAEpC7M,IAAwBtC,EAAO4D,aAAatB,aAAa,IAEzDlI,aAlOR2S,GACAngB;YAEA,OAAImgB,EAAWH,MACbxf,OACY2D,MAAVnE,KAAwC,mBAAVA,IAGzBwM,GAAWgS,iBAAiBxe,KAAgB,QAEnDQ,OACY2D,MAAVnE,KAAuBA,aAAiBiB;YAGnCuL,GAAWiS,eAAeze,KAAgB,IAAIiB;SAoNjCuhB,CAAUrC,GAAY/M,EAAO4D,aAAaxJ,cACxDiV,IAAarP,EAAO4D,aAAcrB,OAClCA,IAAQ8M,KAvWlB,SAAuBC;YACrB,MAAM3c,SACY5B,MAAhBue,EAAO3c,OAAqBnB,EAAKG,UAAU8I,GAAmB6U,EAAO3c;YACvE,OAAO,IAAID,EAAeC,GAAM2c,EAAOpiB,WAAW;;;;;;;;;GAoWpBqiB,EAAcF;QAC1C5K,IAAc,IAAIrC,GAChBC,GACAC,GACAlI,GACAmI,KAAS;WAEN,IAAI,oBAAoBvC,GAAQ;QACvBA,EAAOwP;QACrB,MAAMC,IAAezP,EAAOwP;QACdC,EAAajK,UACbiK,EAAajK,SAAS1S,MAElC2c,EAAajK,SAASmJ;QAGxB,MAAM1e,IAAMua,GAASuC,GAAY0C,EAAajK,SAAS1S,OACjDya,IAAUC,GAAYiC,EAAajK,SAASmJ,aAC5CvR,IAAO,IAAIwR,GAAY;YAC3BzI,UAAU;gBAAEC,QAAQqJ,EAAajK,SAASY;;YAEtC3G,IAAM,IAAI+D,GAASvT,GAAKsd,GAASnQ,GAAM,KACvC2E,IAAmB0N,EAAanN,aAAa,IAC7CN,IAAmByN,EAAazN,oBAAoB;QAC1DyC,IAAc,IAAI3C,GAChBC,GACAC,GACAvC,EAAIxP,KACJwP;WAEG,IAAI,oBAAoBO,GAAQ;QACvBA,EAAO0P;QACrB,MAAMC,IAAY3P,EAAO0P;QACXC,EAAUnK;QACxB,MAAMvV,IAAMua,GAASuC,GAAY4C,EAAUnK,WACrC+H,IAAUoC,EAAUZ,WACtBvB,GAAYmC,EAAUZ,YACtBnb,EAAgBkB,OACd2K,IAAM,IAAIiE,GAAWzT,GAAKsd,IAC1BvL,IAAmB2N,EAAU3N,oBAAoB;QACvDyC,IAAc,IAAI3C,GAAoB,IAAIE,GAAkBvC,EAAIxP,KAAKwP;WAChE,IAAI,oBAAoBO,GAAQ;QACvBA,EAAO4P;QACrB,MAAMC,IAAY7P,EAAO4P;QACXC,EAAUrK;QACxB,MAAMvV,IAAMua,GAASuC,GAAY8C,EAAUrK,WACrCxD,IAAmB6N,EAAU7N,oBAAoB;QACvDyC,IAAc,IAAI3C,GAAoB,IAAIE,GAAkB/R,GAAK;WAC5D;QAAA,MAAI,YAAY+P,IAUrB,OAngBiChT;QAyfJ;YAEfgT,EAAO1K;YACrB,MAAMA,IAAS0K,EAAO1K;YACRA,EAAOyE;YACrB,MAAM/J,IAAQsF,EAAOtF,SAAS,GACxBmS,IAAkB,IAAI7H,GAAgBtK,IACtC+J,IAAWzE,EAAOyE;YACxB0K,IAAc,IAAIvC,GAAsBnI,GAAUoI;;;IAIpD,OAAOsC;;;SAwCOqL,GACd/C,GACAgD;IAEA,IAAI9T;IACJ,IAAI8T,aAAoBC,IACtB/T,IAAS;QACPgU,QAAQ1B,GAAmBxB,GAAYgD,EAAS9f,KAAK8f,EAASnjB;YAE3D,IAAImjB,aAAoBG,IAC7BjU,IAAS;QAAEyD,QAAQsO,GAAOjB,GAAYgD,EAAS9f;YAC1C,IAAI8f,aAAoBI,IAC7BlU,IAAS;QACPgU,QAAQ1B,GAAmBxB,GAAYgD,EAAS9f,KAAK8f,EAAS3S;QAC9DgT,YAAYC,GAAeN,EAASO;YAEjC,IAAIP,aAAoBQ,IAC7BtU,IAAS;QACPuU,WAAW;YACThL,UAAUwI,GAAOjB,GAAYgD,EAAS9f;YACtCwgB,iBAAiBV,EAASU,gBAAgBtkB,IAAIqkB,KA+HtD,SACEzD,GACA2D;gBAEA,MAAMF,IAAYE,EAAeF;gBACjC,IAAIA,aAAqBG,IACvB,OAAO;oBACLC,WAAWF,EAAe3Y,MAAM7C;oBAChC2b,kBAAkB;;gBAEf,IAAIL,aAAqBM,IAC9B,OAAO;oBACLF,WAAWF,EAAe3Y,MAAM7C;oBAChC6b,uBAAuB;wBACrB9I,QAAQuI,EAAUQ;;;gBAGjB,IAAIR,aAAqBS,IAC9B,OAAO;oBACLL,WAAWF,EAAe3Y,MAAM7C;oBAChCgc,oBAAoB;wBAClBjJ,QAAQuI,EAAUQ;;;gBAGjB,IAAIR,aAAqBW,IAC9B,OAAO;oBACLP,WAAWF,EAAe3Y,MAAM7C;oBAChCkc,WAAWZ,EAAUa;;gBAGvB,MA9tBiCrkB;aAkkB3BskB,CAAiBvE,GAAYyD;;YAI9B;QAAA,MAAIT,aAAoBwB,KAK7B,OA3kBiCvkB;QAukBjCiP,IAAS;YACPuV,QAAQxD,GAAOjB,GAAYgD,EAAS9f;;;IAUxC,OAJK8f,EAAS0B,GAAaC,OACzBzV,EAAO0V,kBA+CX,SACE5E,GACA0E;QAGA,YAAgC1gB,MAA5B0gB,EAAa9C,aACR;YACLA,YAAYrB,GAAUP,GAAY0E,EAAa9C;iBAEhB5d,MAAxB0gB,EAAaG,SACf;YAAEA,QAAQH,EAAaG;YAxoBG5kB;KA+kBR6kB,CAAe9E,GAAYgD,EAAS0B,MAGxDxV;;;SAGO6V,GACd/E,GACAyB;IAEA,MAAMiD,IAAejD,EAAMmD,kBAqD7B,SAA0BF;QACxB,YAAgC1gB,MAA5B0gB,EAAa9C,aACRoD,GAAapD,WAAWnB,GAAYiE,EAAa9C,oBACvB5d,MAAxB0gB,EAAaG,SACfG,GAAaH,OAAOH,EAAaG,UAEjCG,GAAaC;KA1DlBC,CAAiBzD,EAAMmD,mBACvBI,GAAaC;IAEjB,IAAIxD,EAAMyB,QAAQ;QACFzB,EAAMyB,OAAOnd;QAC3B,MAAM7C,IAAMua,GAASuC,GAAYyB,EAAMyB,OAAOnd,OACxClG,IAAQ,IAAIgiB,GAAY;YAC5BzI,UAAU;gBAAEC,QAAQoI,EAAMyB,OAAO7J;;;QAEnC,IAAIoI,EAAM4B,YAAY;YACpB,MAAME,aAmjBqB9B;gBAC/B,MAAM0D,IAAQ1D,EAAM2D,cAAc;gBAClC,OAAO,IAAIC,GAAUF,EAAM/lB,IAAIgJ,KAAQK,EAAU6c,EAAiBld;aArjB5Cmd,CAAiB9D,EAAM4B;YACzC,OAAO,IAAID,GAAclgB,GAAKrD,GAAO0jB,GAAWmB;;QAEhD,OAAO,IAAIzB,GAAY/f,GAAKrD,GAAO6kB;;IAEhC,IAAIjD,EAAM9O,QAAQ;QACvB,MAAMzP,IAAMua,GAASuC,GAAYyB,EAAM9O;QACvC,OAAO,IAAIwQ,GAAejgB,GAAKwhB;;IAC1B,IAAIjD,EAAMgC,WAAW;QAC1B,MAAMvgB,IAAMua,GAASuC,GAAYyB,EAAMgC,UAAmB,WACpDC,IAAkBjC,EAAMgC,UAAUC,gBAAiBtkB,IAAIqkB,KAoHjE,SACEzD,GACAyB;YAEA,IAAIgC,IAAuC;YAC3C,IAAI,sBAAsBhC,GACxBphB,EAC6B,mBAA3BohB,EAAMqC,mBAGRL,IAAY,IAAIG,SACX,IAAI,2BAA2BnC,GAAO;gBAC3C,MAAMvG,IAASuG,EAAMuC,sBAAuB9I,UAAU;gBACtDuI,IAAY,IAAIM,GAA6B7I;mBACxC,IAAI,wBAAwBuG,GAAO;gBACxC,MAAMvG,IAASuG,EAAM0C,mBAAoBjJ,UAAU;gBACnDuI,IAAY,IAAIS,GAA8BhJ;mBACrC,eAAeuG,IACxBgC,IAAY,IAAIW,GACdpE,GACAyB,EAAgB,aAGlBxhB;YAEF,MAAM4jB,IAAYpb,EAAU6c,EAAiB7D,EAAgB;YAC7D,OAAO,IAAI+D,GAAe3B,GAAWJ;SA7IjCgC,CAAmBzF,GAAYyD;QAMjC,OAJApjB,GAC0B,MAAxBqkB,EAAaG,SAGR,IAAIrB,GAAkBtgB,GAAKwgB;;IAC7B,IAAIjC,EAAMgD,QAAQ;QACvB,MAAMvhB,IAAMua,GAASuC,GAAYyB,EAAMgD;QACvC,OAAO,IAAID,GAAethB,GAAKwhB;;IAE/B,OA1nBiCzkB;;;SAirBrBylB,GACdC,GACAC;IAEA,OAAID,KAAUA,EAAOnkB,SAAS,KAhqBRnB,OAkqBH2D,MAAf4hB,IAGKD,EAAOvmB,IAAIqiB,KAlCtB,SACEA,GACAmE;;QAGA,IAAIpF,IAAUiB,EAAMG,aAChBnB,GAAYgB,EAAMG,cAClBnB,GAAYmF;QAEZpF,EAAQxZ,QAAQH,EAAgBkB;;;;;;QAMlCyY,IAAUC,GAAYmF;QAGxB,IAAIC,IAAuC;QAI3C,OAHIpE,EAAMoE,oBAAoBpE,EAAMoE,iBAAiBrkB,SAAS,MAC5DqkB,IAAmBpE,EAAMoE;QAEpB,IAAIC,GAAetF,GAASqF;KAYNE,CAAgBtE,GAAOmE,OAE3C;;;SAmEKI,GACdhG,GACAxV;IAEA,OAAO;QAAEuJ,WAAW,EAACoN,GAAYnB,GAAYxV,EAAOpC;;;;SAetC6d,GACdjG,GACAxV;;IAGA,MAAM0E,IAA0B;QAAEgX,iBAAiB;OAC7C9d,IAAOoC,EAAOpC;IACW,SAA3BoC,EAAOP,mBAKTiF,EAAOiX,SAAShF,GAAYnB,GAAY5X,IACxC8G,EAAOgX,gBAAiBE,OAAO,EAC7B;QACE9c,cAAckB,EAAOP;QACrBoc,iBAAgB;YAQpBnX,EAAOiX,SAAShF,GAAYnB,GAAY5X,EAAKke,MAC7CpX,EAAOgX,gBAAiBE,OAAO,EAAC;QAAE9c,cAAclB,EAAKme;;IAGvD,MAAMC,IAuIR,SAAkBrc;QAChB,IAAuB,MAAnBA,EAAQ3I,QACV;QAEF,MAAMmkB,IAASxb,EAAQ/K,IAAImJ;;iBA4IQA;YACnC,yBAAIA,EAAO8C,IAAuB;gBAChC,IAAIqT,GAAWnW,EAAO1I,QACpB,OAAO;oBACL4mB,aAAa;wBACXzb,OAAO0b,GAAqBne,EAAOyC;wBACnCK,IAAI;;;gBAGH,IAAIoT,GAAYlW,EAAO1I,QAC5B,OAAO;oBACL4mB,aAAa;wBACXzb,OAAO0b,GAAqBne,EAAOyC;wBACnCK,IAAI;;;mBAIL,6BAAI9C,EAAO8C,IAA2B;gBAC3C,IAAIqT,GAAWnW,EAAO1I,QACpB,OAAO;oBACL4mB,aAAa;wBACXzb,OAAO0b,GAAqBne,EAAOyC;wBACnCK,IAAI;;;gBAGH,IAAIoT,GAAYlW,EAAO1I,QAC5B,OAAO;oBACL4mB,aAAa;wBACXzb,OAAO0b,GAAqBne,EAAOyC;wBACnCK,IAAI;;;;YAKZ,OAAO;gBACLsb,aAAa;oBACX3b,OAAO0b,GAAqBne,EAAOyC;oBACnCK,KAxGyBA,IAwGN9C,EAAO8C,IAvGvB2T,GAAU3T;oBAwGbxL,OAAO0I,EAAO1I;;;;gBAzGWwL;SApEpBub,CAAqBre;QAE9B,IAAsB,MAAlBod,EAAOnkB,QACT,OAAOmkB,EAAO;QAEhB,OAAO;YAAEkB,iBAAiB;gBAAExb,IAAI;gBAAOlB,SAASwb;;;KArJlCmB,CAAStc,EAAOL;IAC1Bqc,MACFtX,EAAOgX,gBAAiBM,QAAQA;IAGlC,MAAMtc,IAmKR,SAAiB6c;QACf,IAAwB,MAApBA,EAASvlB,QACX;QAEF,OAAOulB,EAAS3nB,IAAI4nB;YAASC,OAqFtB;gBACLjc,OAAO0b,IAFqBxc,IApFe8c,GAsFPhc;gBACpCkc,YAlEwBjc,IAkEDf,EAAQe,KAjE1B2T,GAAW3T;;;gBA8DYf,GA/DJe;;KA5LVkc,CAAQ3c,EAAON;IAC3BA,MACFgF,EAAOgX,gBAAiBhc,UAAUA;IAGpC,MAAM3C,IAxsBR,SACEyY,GACAoH;QAEA,OAAIpH,EAAWH,MAAiBpW,EAAkB2d,KACzCA,IAEA;YAAEvnB,OAAOunB;;;;;GAisBJC,EAAarH,GAAYxV,EAAOjD;IAY9C,OAXc,SAAVA,MACF2H,EAAOgX,gBAAiB3e,QAAQA,IAG9BiD,EAAOJ,YACT8E,EAAOgX,gBAAiB9b,UAAUkd,GAAS9c,EAAOJ;IAEhDI,EAAOH,UACT6E,EAAOgX,gBAAiB7b,QAAQid,GAAS9c,EAAOH,SAG3C6E;;;SAGOqY,GAAgB/c;IAC9B,IAAIpC,IAAOgZ,GAAc5W,EAAc;IAEvC,MAAM+I,IAAQ/I,EAAO0b,iBACfsB,IAAYjU,EAAM6S,OAAO7S,EAAM6S,KAAK5kB,SAAS;IACnD,IAAIyI,IAAiC;IACrC,IAAIud,IAAY,GAAG;QAxzBGnnB,EA0zBJ,MAAdmnB;QAGF,MAAMpB,IAAO7S,EAAM6S,KAAM;QACrBA,EAAKC,iBACPpc,IAAkBmc,EAAK9c,eAEvBlB,IAAOA,EAAKyY,MAAMuF,EAAK9c;;IAI3B,IAAIme,IAAqB;IACrBlU,EAAMiT,UACRiB,IA0GJ,SAASC,EAAWnf;QAClB,OAAKA,SAE6BvE,MAAvBuE,EAAOke,cACT,EAACkB,GAAgBpf,YACQvE,MAAvBuE,EAAOoe,cACT,EAACiB,GAAgBrf,YACYvE,MAA3BuE,EAAOse,kBACTte,EAAOse,gBACX1c,QAAS/K,IAAIwL,KAAK8c,EAAW9c,IAC7Bid,OAAO,CAACC,GAAOhf,MAAYgf,EAAMC,OAAOjf,MAh9BV7I,MAw8B1B;KA5GIynB,CAAWnU,EAAMiT;IAG9B,IAAItc,IAAqB;IACrBqJ,EAAMrJ,YACRA,IAAoBqJ,EAAMrJ,QA6HZ9K,IAAI4nB;QAASgB,OAwFtB,IAAIC,GACTC,IAF8Bhe,IAvFe8c,GAyFR;;iBAlEvC/b;YAEA,QAAQA;cACN,KAAK;gBACH;;cACF,KAAK;gBACH;;cACF;gBACE;;SA2DFkd,CAAcje,EAAQgd;YAHQhd;;IAjNhC,IAAI3C,IAAuB;IACvBgM,EAAMhM,UACRA,IAxuBJ,SACE6f;QAEA,IAAIlY;QAMJ,OAJEA,IADiB,mBAARkY,IACAA,EAAIvnB,QAEJunB,GAEJ3d,EAAkByF,KAAU,OAAOA;KA+tBhCkZ,CAAe7U,EAAMhM;IAG/B,IAAI6C,IAAwB;IACxBmJ,EAAMnJ,YACRA,IAAUie,GAAW9U,EAAMnJ;IAG7B,IAAIC,IAAsB;IAK1B,OAJIkJ,EAAMlJ,UACRA,IAAQge,GAAW9U,EAAMlJ,SAGpBie,GACLC,GACEngB,GACA6B,GACAC,GACAud,GACAlgB,qBAEA6C,GACAC;;;SAKUme,GACdxI,GACApI;IAEA,MAAM/X,IAUR,SACEmgB,GACA/S;QAEA,QAAQA;UACN;YACE,OAAO;;UACT;YACE,OAAO;;UACT;YACE,OAAO;;UACT;YACE,OA35B+BhN;;KAq4BrBwoB,CAAQzI,GAAYpI,EAAW3K;IAC7C,OAAa,QAATpN,IACK,OAEA;QACL6oB,oBAAoB7oB;;;;AAuF1B,SAASynB,GAASqB;IAChB,OAAO;QACLC,QAAQD,EAAOC;QACf1N,QAAQyN,EAAOE;;;;AAInB,SAASR,GAAWM;IAClB,MAAMC,MAAWD,EAAOC,QAClBC,IAAWF,EAAOzN,UAAU;IAClC,OAAO,IAAI4N,GAAMD,GAAUD;;;;SAwDblC,GAAqBte;IACnC,OAAO;QAAEyb,WAAWzb,EAAKD;;;;SAGX+f,GACda;IAEA,OAAOtgB,EAAU6c,EAAiByD,EAAyB;;;SAkB7CnB,GAAgBrf;IAC9B,OAAOygB,GAAYC,OACjBf,GAAuB3f,EAAOoe,YAAmB,iBAxDpBtb;QAC/B,QAAQA;UACN,KAAK;YACH;;UACF,KAAK;YACH;;UACF,KAAK;YACH;;UACF,KAAK;YACH;;UACF,KAAK;YACH;;UACF,KAAK;YACH;;UACF,KAAK;YACH;;UACF,KAAK;YACH;;UACF,KAAK;YACH;;UACF,KAAK;YACH;;UACF,KAAK;UAEL;YACE,OA/hC+BpL;;KA+jCjCipB,CAAiB3gB,EAAOoe,YAAgB,KACxCpe,EAAOoe,YAAmB;;;SAgDdgB,GAAgBpf;IAC9B,QAAQA,EAAOke,YAAgB;MAC7B,KAAK;QACH,MAAM0C,IAAWjB,GAAuB3f,EAAOke,YAAmB;QAClE,OAAOuC,GAAYC,OAAOE,sBAA0B;YAClDtN,aAAauN;;;MAEjB,KAAK;QACH,MAAMC,IAAYnB,GAAuB3f,EAAOke,YAAmB;QACnE,OAAOuC,GAAYC,OAAOI,sBAA2B;YACnDC,WAAW;;;MAEf,KAAK;QACH,MAAMC,IAAcrB,GAAuB3f,EAAOke,YAAmB;QACrE,OAAOuC,GAAYC,OAAOM,0BAAiC;YACzD1N,aAAauN;;;MAEjB,KAAK;QACH,MAAMI,IAAetB,GAAuB3f,EAAOke,YAAmB;QACtE,OAAOuC,GAAYC,OAAOO,0BAAkC;YAC1DF,WAAW;;;MAEf,KAAK;MAEL;QACE,OAzoC+BrpB;;;;SA6oCrBqjB,GAAeC;IAC7B,MAAMkG,IAA4B;IAIlC,OAHAlG,EAAUlK,OAAO9V,QAAQyH,KACvBye,EAAgBtlB,KAAK6G,EAAM7C,OAEtB;QACLid,YAAYqE;;;;SASAzI,GAAoB5Y;;IAElC,OACEA,EAAK5G,UAAU,KACC,eAAhB4G,EAAKlE,IAAI,MACO,gBAAhBkE,EAAKlE,IAAI;;;;;;;;;;;;;;;;;;;gEChqCAwlB;IAAbroB;;;QAGEqB,eAAYsB;;;;;;;aAOE2lB,GACdlG,GACAmG,GACApQ;IAEA,OAAIiK,aAAqBG,cHOzBpK,GACAoQ;QAEA,MAAMxQ,IAAyB;YAC7BC,QAAQ;gBACNwQ,UAAY;oBACVvQ,aApB0B;;gBAsB5BwQ,sBAAwB;oBACtB9P,gBAAgB;wBACd/T,SAASuT,EAAevT;wBACxByT,OAAOF,EAAetT;;;;;QAU9B,OAJI0jB,MACFxQ,EAASC,OAA0B,qBAAIuQ,IAGlC;YAAExQ,UAAAA;;;;;;;;GG3BA2Q,EAAgBvQ,GAAgBoQ,KAC9BnG,aAAqBM,KACvBiG,GAAkCvG,GAAWmG,KAC3CnG,aAAqBS,KACvB+F,GAAmCxG,GAAWmG,cAuJvDnG,GACAmG;;;;QAKA,MAAMM,IAAYC,GAChB1G,GACAmG,IAEIQ,IAAMC,GAASH,KAAaG,GAAS5G,EAAUa;QACrD,OAAIza,GAAUqgB,MAAcrgB,GAAU4Z,EAAUa,MACvCxE,GAAUsK,KAEVrK,GAAS0D,EAAUzD,YAAYoK;KA/J/BE,CACL7G,GACAmG;;;;;;aASUW,GACd9G,GACAmG,GACAY;;;;IAKA,OAAI/G,aAAqBM,KAChBiG,GAAkCvG,GAAWmG,KAC3CnG,aAAqBS,KACvB+F,GAAmCxG,GAAWmG,KAOhDY;;;;;;;;;;;;;;;;;aAkBOL,GACd1G,GACAmG;IAEA,OAAInG,aAAqBW,KFsdlBva,GADgBhK,IEpdL+pB,eF8clB/pB;QAEA,SAASA,KAAS,iBAAiBA;;8EAKR4qB,EAAS5qB,KErdD+pB,IAAiB;QAAEhP,cAAc;QAE7D;QFkdgB/a;;;;MEnbZ+jB,WAAiC8F;;8DAGjC3F,WAAqC2F;IAChDroB,YAAqB4iB;QACnBpe,SADmBnD,gBAAAuhB;;;;AAKvB,SAAS+F,GACPvG,GACAmG;IAEA,MAAM1O,IAASwP,GAAwBd;IACvC,KAAK,MAAMe,KAAWlH,EAAUQ,UACzB/I,EAAO0P,KAAKC,KAAWlf,GAAYkf,GAASF,OAC/CzP,EAAO/W,KAAKwmB;IAGhB,OAAO;QAAE1P,YAAY;YAAEC,QAAAA;;;;;+DAIZgJ,WAAsCwF;IACjDroB,YAAqB4iB;QACnBpe,SADmBnD,gBAAAuhB;;;;AAKvB,SAASgG,GACPxG,GACAmG;IAEA,IAAI1O,IAASwP,GAAwBd;IACrC,KAAK,MAAMkB,KAAYrH,EAAUQ,UAC/B/I,IAASA,EAAO3S,OAAOsiB,MAAYlf,GAAYkf,GAASC;IAE1D,OAAO;QAAE7P,YAAY;YAAEC,QAAAA;;;;;;;;;;UASZkJ,WAA2CsF;IACtDroB,YACW2e,GACAsE;QAETze,SAHSnD,kBAAAsd,aACAsE;;;;AA6Bb,SAAS+F,GAASxqB;IAChB,OAAO0a,GAAgB1a,EAAM+a,gBAAgB/a,EAAMgc;;;AAGrD,SAAS6O,GAAwB7qB;IAC/B,OAAO2e,GAAQ3e,MAAUA,EAAMob,WAAWC,SACtCrb,EAAMob,WAAWC,OAAO5T,UACxB;;;;;;;;;;;;;;;;;;;;;;;;;;;;UClLO+d;IACXhkB,YAAqBgY;QAAA3W,cAAA2W;;;QAGnBA,EAAO6D,KAAKzU,EAAU1G;;;;;;;WAcxBV,GAAOwiB;QACL,KAAK,MAAMkH,KAAiBroB,KAAK2W,QAC/B,IAAI0R,EAAcC,EAAWnH,IAC3B,QAAO;QAGX,QAAO;;IAGTxiB,QAAQ0B;QACN,OAAOjB,EAAYY,KAAK2W,QAAQtW,EAAMsW,QAAQ,CAAC4R,GAAGC,MAAMD,EAAEjkB,QAAQkkB;;;;yEAKzD1F;IACXnkB,YACW2J,GACAyY;QADA/gB,aAAAsI,GACAtI,iBAAA+gB;;;;SAIG0H,GACdvpB,GACAC;IAEA,OACED,EAAKoJ,MAAMhE,QAAQnF,EAAMmJ,mBDqB3BpJ,GACAC;QAEA,OACED,aAAgBmiB,MAChBliB,aAAiBkiB,MAIjBniB,aAAgBsiB,MAChBriB,aAAiBqiB,KAHVpiB,EAAYF,EAAKqiB,UAAUpiB,EAAMoiB,UAAUtY,MAOlD/J,aAAgBwiB,MAChBviB,aAAiBuiB,KAEVzY,GAAY/J,EAAK0iB,IAASziB,EAAMyiB,MAIvC1iB,aAAgBgiB,MAChB/hB,aAAiB+hB;KC1CjBwH,CAAyBxpB,EAAK6hB,WAAW5hB,EAAM4hB;;;4EAKtCqC;IACXzkB;;;;;;;;;;;IAWWmf;;;;;;;;IAQAqF;QARAnjB,eAAA8d,GAQA9d,wBAAAmjB;;;;;;;;UAiBAb;IACX3jB,YACWugB,GACAiD;QADAniB,kBAAAkf,GACAlf,cAAAmiB;;gDASXxjB;QACE,OAAO,IAAI2jB;;8DAIb3jB,cAAcwjB;QACZ,OAAO,IAAIG,QAAahhB,GAAW6gB;;kFAIrCxjB,kBAAkBmf;QAChB,OAAO,IAAIwE,GAAaxE;;0DAI1B6K;QACE,YAA2BrnB,MAApBtB,KAAKkf,mBAA4C5d,MAAhBtB,KAAKmiB;;IAG/CxjB,QAAQ0B;QACN,OACEL,KAAKmiB,WAAW9hB,EAAM8hB,WACrBniB,KAAKkf,eACA7e,EAAM6e,cAAclf,KAAKkf,WAAW5a,QAAQjE,EAAM6e,eACnD7e,EAAM6e;;;;;;;aASD0J,GACd5G,GACA6G;IAEA,YAAgCvnB,MAA5B0gB,EAAa9C,aAEb2J,aAAoB9U,MACpB8U,EAAS/K,QAAQxZ,QAAQ0d,EAAa9C,mBAEP5d,MAAxB0gB,EAAaG,UACfH,EAAaG,WAAW0G,aAAoB9U;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;UAwDjC+U;;;;;;;;;;;;;;;aAoBNC,GACdzI,GACAuI,GACAG;IAGA,OAAI1I,aAAoBC,KAkL1B,SACED,GACAuI,GACAG;;;;QAUA,OAAO,IAAIjV,GAASuM,EAAS9f,KAAKwoB,EAAelL,SAASwC,EAASnjB,OAAO;YACxE8rB,wBAAuB;;KA/LhBC,CAAiC5I,GAAUuI,GAAUG,KACnD1I,aAAoBI,KA0OjC,SACEJ,GACAuI,GACAG;QAOA,KAAKJ,GAA+BtI,EAAS0B,IAAc6G;;;;;QAKzD,OAAO,IAAIM,GAAgB7I,EAAS9f,KAAKwoB,EAAelL;QAG1D,MAAMsL,IAAUC,GAAc/I,GAAUuI;QACxC,OAAO,IAAI9U,GAASuM,EAAS9f,KAAKwoB,EAAelL,SAASsL,GAAS;YACjEH,wBAAuB;;KA7PhBK,CACLhJ,GACAuI,GACAG,KAEO1I,aAAoBQ,KAqUjC,SACER,GACAuI,GACAG;QAOA,IALArrB,EACqC,QAAnCqrB,EAAe7F,oBAIZyF,GAA+BtI,EAAS0B,IAAc6G;;;;;QAKzD,OAAO,IAAIM,GAAgB7I,EAAS9f,KAAKwoB,EAAelL;QAG1D,MAAM9N,IAAMuZ,GAAgBjJ,GAAUuI,IAChC1F;;;;;;;;;;;QAgGR,SACEnC,GACAwI,GACAC;YAEA,MAAMtG,IAAgC;YACtCxlB,EACEqjB,EAAgBliB,WAAW2qB,EAAuB3qB;YAKpD,KAAK,IAAIR,IAAI,GAAGA,IAAImrB,EAAuB3qB,QAAQR,KAAK;gBACtD,MAAM2iB,IAAiBD,EAAgB1iB,IACjCyiB,IAAYE,EAAeF;gBACjC,IAAImG,IAAkC;gBAClCsC,aAAmBzV,OACrBmT,IAAgBsC,EAAQlhB,MAAM2Y,EAAe3Y,SAE/C6a,EAAiB1hB,KACfomB,GACE9G,GACAmG,GACAuC,EAAuBnrB;;YAI7B,OAAO6kB;;;;;;;;;;;;;;GA3HkBsG,EACvBnJ,EAASU,iBACT6H,GACAG,EAAgC,mBAG5BlL,IAAUkL,EAAelL,SACzBsL,IAAUM,GAAgBpJ,GAAUtQ,EAAIrC,QAAQwV;QACtD,OAAO,IAAIpP,GAASuM,EAAS9f,KAAKsd,GAASsL,GAAS;YAClDH,wBAAuB;;KAhWhBU,CACLrJ,GACAuI,GACAG,KA4hBN,SACE1I,GACAuI,GACAG;;;;QAWA,OAAO,IAAI/U,GAAWqM,EAAS9f,KAAKwoB,EAAelL,SAAS;YAC1DmL,wBAAuB;;KApiBhBW,CACLtJ,GACAuI,GACAG;;;;;;;;;;;;;;;;;;aAqBUa,GACdvJ,GACAuI,GACAW,GACA1S;IAIA,OAAIwJ,aAAoBC,KAiJ1B,SACED,GACAuI;QAEA,KAAKD,GAA+BtI,EAAS0B,IAAc6G,IACzD,OAAOA;QAGT,MAAM/K,IAAUgM,GAAuBjB;QACvC,OAAO,IAAI9U,GAASuM,EAAS9f,KAAKsd,GAASwC,EAASnjB,OAAO;YACzD4sB,KAAmB;;;;;;;;;;;;;;;GA1JZC,EAA4B1J,GAAUuI,KACpCvI,aAAoBI,KA+MjC,SACEJ,GACAuI;QAEA,KAAKD,GAA+BtI,EAAS0B,IAAc6G,IACzD,OAAOA;QAGT,MAAM/K,IAAUgM,GAAuBjB,IACjCO,IAAUC,GAAc/I,GAAUuI;QACxC,OAAO,IAAI9U,GAASuM,EAAS9f,KAAKsd,GAASsL,GAAS;YAClDW,KAAmB;;;;;;;GAzNZE,EAA8B3J,GAAUuI,KACtCvI,aAAoBQ,KAsTjC,SACER,GACAuI,GACA/R,GACA0S;QAEA,KAAKZ,GAA+BtI,EAAS0B,IAAc6G,IACzD,OAAOA;QAGT,MAAM7Y,IAAMuZ,GAAgBjJ,GAAUuI,IAChC1F,IAmHR,SACEnC,GACAlK,GACA+R,GACAW;YAEA,MAAMrG,IAAgC;YACtC,KAAK,MAAMlC,KAAkBD,GAAiB;gBAC5C,MAAMD,IAAYE,EAAeF;gBAEjC,IAAImG,IAAkC;gBAClC2B,aAAoB9U,OACtBmT,IAAgB2B,EAASvgB,MAAM2Y,EAAe3Y,SAG1B,SAAlB4e,KAA0BsC,aAAmBzV;;;;;gBAK/CmT,IAAgBsC,EAAQlhB,MAAM2Y,EAAe3Y,SAG/C6a,EAAiB1hB,KACfwlB,GACElG,GACAmG,GACApQ;;YAIN,OAAOqM;SAlJkB+G,CACvB5J,EAASU,iBACTlK,GACA+R,GACAW,IAEIJ,IAAUM,GAAgBpJ,GAAUtQ,EAAIrC,QAAQwV;QACtD,OAAO,IAAIpP,GAASuM,EAAS9f,KAAKwP,EAAI8N,SAASsL,GAAS;YACtDW,KAAmB;;KAxUZI,CACL7J,GACAuI,GACA/R,GACA0S,KA+fN,SACElJ,GACAuI;QAEA,KAAKD,GAA+BtI,EAAS0B,IAAc6G,IACzD,OAAOA;QAST,OAAO,IAAI5U,GAAWqM,EAAS9f,KAAK2D,EAAgBkB;;;;;;;;GAtgB3C+kB,EAA+B9J,GAAUuI;;;;;;;;;;;;;;;;;;aAoBpCwB,GACd/J,GACAuI;IAEA,OAAIvI,aAAoBQ,KAyS1B,SACER,GACAuI;QAEA,IAAIyB,IAAwC;QAC5C,KAAK,MAAMrJ,KAAkBX,EAASU,iBAAiB;YACrD,MAAMuJ,IACJ1B,aAAoB9U,KAChB8U,EAASvgB,MAAM2Y,EAAe3Y,cAC9BhH,GACAkpB,IAAe/C,GACnBxG,EAAeF,WACfwJ,KAAiB;YAGC,QAAhBC,MAEAF,IADgB,QAAdA,KACW,IAAIG,IAAqBnb,IACpC2R,EAAe3Y,OACfkiB,KAGWF,EAAWhb,IAAI2R,EAAe3Y,OAAOkiB;;QAIxD,OAAOF,IAAaA,EAAWI,OAAU;;;;;;;GAlUhCC,EAAkCrK,GAAUuI,KAE9C;;;SAGO+B,GAAe1rB,GAAgBC;IAC7C,OAAID,EAAKwR,SAASvR,EAAMuR,WAInBxR,EAAKsB,IAAI8D,QAAQnF,EAAMqB,WAIvBtB,EAAK8iB,GAAa1d,QAAQnF,EAAM6iB,wBAIjC9iB,EAAKwR,OACCxR,EAAqB/B,MAAMmH,QAASnF,EAAsBhC,2BAGhE+B,EAAKwR,OAEJxR,EAAuByO,KAAKrJ,QAASnF,EAAwBwO,SAC7DzO,EAAuB2hB,GAAUvc,QAC/BnF,EAAwB0hB,4BAK3B3hB,EAAKwR,QACAtR,EACJF,EAA2B8hB,iBAC3B9hB,EAA2B8hB,iBAC5B,CAACuH,GAAGC,MAAMC,GAAqBF,GAAGC;;;;;;;;GAyBxC,UAASsB,GACPjB;IAEA,OAAIA,aAAoB9U,KACf8U,EAAS/K,UAET3Z,EAAgBkB;;;;;;UAQdkb,WAAoBuI;IAC/BnqB,YACW6B,GACArD,GACA6kB;QAET7e,SAJSnD,WAAAQ,GACAR,aAAA7C,aACA6kB,GAKFhiB;;;;MAgDE0gB,WAAsBoI;IACjCnqB,YACW6B,GACAmN,GACAkT,GACAmB;QAET7e,SALSnD,WAAAQ,GACAR,YAAA2N,aACAkT,aACAmB,GAKFhiB;;;;AA+CX,SAASqpB,GACP/I,GACAuI;IAEA,IAAIlb;IAMJ,OAJEA,IADEkb,aAAoB9U,KACf8U,EAASlb,SAETwR,GAAY0L,SAKvB,SAAqBvK,GAAyB3S;QAC5C,MAAMmd,IAAU,IAAIL,GAAmB9c;QAWvC,OAVA2S,EAASO,GAAUlK,OAAO9V,QAAQsgB;YAChC,KAAKA,EAAUpgB,KAAW;gBACxB,MAAMgqB,IAAWzK,EAAS3S,KAAKrF,MAAM6Y;gBACpB,SAAb4J,IACFD,EAAQxb,IAAI6R,GAAW4J,KAEvBD,EAAQ7a,OAAOkR;;YAId2J,EAAQJ;;;;;;;;;;GAfRM,EAAY1K,GAAU3S;;;MA2BlBmT,WAA0BgI;IAQrCnqB,YACW6B,GACAwgB;QAET7d,SAHSnD,WAAAQ,GACAR,uBAAAghB,GATFhhB;;;;QAKTA,UAAwBsiB,GAAaH,QAAO;;;;AAoG9C,SAASoH,GACPjJ,GACAuI;IAUA,OAAOA;;;AA0FT,SAASa,GACPpJ,GACA3S,GACAwV;IAOA,MAAM2H,IAAU,IAAIL,GAAmB9c;IACvC,KAAK,IAAIrP,IAAI,GAAGA,IAAIgiB,EAASU,gBAAgBliB,QAAQR,KAAK;QACxD,MAAM2iB,IAAiBX,EAASU,gBAAgB1iB;QAChDwsB,EAAQxb,IAAI2R,EAAe3Y,OAAO6a,EAAiB7kB;;IAErD,OAAOwsB,EAAQJ;;;oEAIJjK,WAAuBqI;IAClCnqB,YAAqB6B,GAA2BwhB;QAC9C7e,SADmBnD,WAAAQ,aAA2BwhB,GAIvChiB;;;;MA8CE8hB,WAAuBgH;IAClCnqB,YAAqB6B,GAA2BwhB;QAC9C7e,SADmBnD,WAAAQ,aAA2BwhB,GAIvChiB;;;;;;;;;;;;;;;;;;;;;;;UC1zBEmf;IACXxgB,YAAqBogB;QAAA/e,aAAA+e;;IAOrBpgB;QACE,OAAO,IAAIwgB,GAAY;YAAEzI,UAAU;;;;;;;;WASrC/X,MAAM+G;QACJ,IAAIA,EAAK3E,KACP,OAAOf,KAAK+e;QACP;YACL,IAAI5hB,IAAmB6C,KAAK+e;YAC5B,KAAK,IAAIzgB,IAAI,GAAGA,IAAIoH,EAAK5G,SAAS,KAAKR,GAAG;gBACxC,KAAKnB,EAAMuZ,SAAUC,QACnB,OAAO;gBAGT,IADAxZ,IAAQA,EAAMuZ,SAAUC,OAAOjR,EAAKlE,IAAIlD,MACnC2d,GAAW9e,IACd,OAAO;;YAKX,OADAA,KAASA,EAAMuZ,SAAUC,UAAU,IAAIjR,EAAKme,MACrC1mB,KAAS;;;IAIpBwB,QAAQ0B;QACN,OAAO4I,GAAYjJ,KAAK+e,OAAO1e,EAAM0e;;;;;;;UAe5B0L;;;;IAOX9rB,YAA6B2rB,IAA0BnL,GAAY0L;kBAAtCP;;QAL7BtqB,UAAqB,IAAI+R;;;;;;;;WAczBpT,IAAI+G,GAAiBvI;QAMnB,OADA6C,KAAKirB,GAAWvlB,GAAMvI,IACf6C;;;;;;;;WAUTrB,OAAO+G;QAML,OADA1F,KAAKirB,GAAWvlB,GAAM,OACf1F;;;;;WAODrB,GAAW+G,GAAiBvI;QAClC,IAAI+tB,IAAelrB,KAAKmrB;QAExB,KAAK,IAAI7sB,IAAI,GAAGA,IAAIoH,EAAK5G,SAAS,KAAKR,GAAG;YACxC,MAAM8sB,IAAiB1lB,EAAKlE,IAAIlD;YAChC,IAAI+sB,IAAeH,EAAa1pB,IAAI4pB;YAEhCC,aAAwBtZ;;YAE1BmZ,IAAeG,IAEfA,8BACAlU,GAAUkU;;YAGVA,IAAe,IAAItZ,IACjBtR,OAAOmB,QAAQypB,EAAa3U,SAAUC,UAAU,MAElDuU,EAAa5b,IAAI8b,GAAgBC,IACjCH,IAAeG;;YAGfA,IAAe,IAAItZ,KACnBmZ,EAAa5b,IAAI8b,GAAgBC,IACjCH,IAAeG;;QAInBH,EAAa5b,IAAI5J,EAAKme,KAAe1mB;;iEAIvCwB;QACE,MAAM2sB,IAAetrB,KAAKurB,GACxBxlB,EAAU6Y,KACV5e,KAAKmrB;QAEP,OAAoB,QAAhBG,IACK,IAAInM,GAAYmM,KAEhBtrB,KAAKsqB;;;;;;;;;;;;;WAgBR3rB,GACN6sB,GACAC;QAEA,IAAIC,KAAW;QAEf,MAAMnB,IAAgBvqB,KAAKsqB,GAAWhiB,MAAMkjB,IACtCG,IAAe1P,GAAWsO;0BAGvBA,EAAc7T,SAASC,UAC5B;QAkBJ,OAhBA8U,EAAgB5qB,QAAQ,CAAC1D,GAAOyuB;YAC9B,IAAIzuB,aAAiB4U,KAAK;gBACxB,MAAM8Z,IAAS7rB,KAAKurB,GAAaC,EAAYrN,MAAMyN,IAAczuB;gBACnD,QAAV0uB,MACFF,EAAaC,KAAeC,GAC5BH,KAAW;mBAEM,SAAVvuB,KACTwuB,EAAaC,KAAezuB,GAC5BuuB,KAAW,KACFC,EAAahrB,eAAeirB,cAC9BD,EAAaC,IACpBF,KAAW;YAIRA,IAAW;YAAEhV,UAAU;gBAAEC,QAAQgV;;YAAmB;;;;;;aAO/CG,GAAiB3uB;IAC/B,MAAMwZ,IAAsB;IAsB5B,OArBA9V,EAAQ1D,EAAOwZ,UAAU,IAAI,CAACnW,GAAKrD;QACjC,MAAMquB,IAAc,IAAIzlB,EAAU,EAACvF;QACnC,IAAIyb,GAAW9e,IAAQ;YACrB,MACM4uB,IADaD,GAAiB3uB,EAAe,UACnBwZ;YAChC,IAA4B,MAAxBoV,EAAajtB;;YAEf6X,EAAOlV,KAAK+pB;;;YAIZ,KAAK,MAAMQ,KAAcD,GACvBpV,EAAOlV,KAAK+pB,EAAYrN,MAAM6N;;;;QAMlCrV,EAAOlV,KAAK+pB;QAGT,IAAI7I,GAAUhM;;;;;;;;;;;;;;;;;;;;;;UCpODsV;IACpBttB,YAAqB6B,GAA2Bsd;QAA3B9d,WAAAQ,GAA2BR,eAAA8d;;;;;;;UAiBrC/J,WAAiBkY;IAI5BttB,YACE6B,GACAsd,GACiBoO,GACjBC;QAEAhpB,MAAM3C,GAAKsd,cAHMoO,GAIjBlsB,KAAKosB,OAAsBD,EAAQC,IACnCpsB,KAAKipB,0BAA0BkD,EAAQlD;;IAGzCtqB,MAAM+G;QACJ,OAAO1F,KAAKksB,GAAY5jB,MAAM5C;;IAGhC/G;QACE,OAAOqB,KAAKksB;;IAGdvtB;QACE,OAAOqB,KAAKksB,GAAYnN;;IAG1BpgB,QAAQ0B;QACN,OACEA,aAAiB0T,MACjB/T,KAAKQ,IAAI8D,QAAQjE,EAAMG,QACvBR,KAAK8d,QAAQxZ,QAAQjE,EAAMyd,YAC3B9d,KAAKosB,OAAsB/rB,EAAM+rB,MACjCpsB,KAAKipB,0BAA0B5oB,EAAM4oB,yBACrCjpB,KAAKksB,GAAY5nB,QAAQjE,EAAM6rB;;IAInCvtB;QACE,OACE,YAAYqB,KAAKQ,QACfR,KAAK8d,YACF9d,KAAKksB,GAAY9oB,mCACCpD,KAAKosB,iCACDpsB,KAAKipB;;IAIpC1X;QACE,OAAOvR,KAAKosB,MAAqBpsB,KAAKipB;;;;;;;;;;;;;MA2B7BhV,WAAmBgY;IAG9BttB,YACE6B,GACAsd,GACAqO;QAEAhpB,MAAM3C,GAAKsd,IACX9d,KAAKipB,2BAA2BkD,MAAWA,EAAQlD;;IAGrDtqB;QACE,OAAO,cAAcqB,KAAKQ,QAAQR,KAAK8d;;IAGzCvM;QACE,OAAOvR,KAAKipB;;IAGdtqB,QAAQ0B;QACN,OACEA,aAAiB4T,MACjB5T,EAAM4oB,0BAA0BjpB,KAAKipB,yBACrC5oB,EAAMyd,QAAQxZ,QAAQtE,KAAK8d,YAC3Bzd,EAAMG,IAAI8D,QAAQtE,KAAKQ;;;;;;;UAShB2oB,WAAwB8C;IACnCttB;QACE,OAAO,mBAAmBqB,KAAKQ,QAAQR,KAAK8d;;IAG9CvM;QACE,QAAO;;IAGT5S,QAAQ0B;QACN,OACEA,aAAiB8oB,MACjB9oB,EAAMyd,QAAQxZ,QAAQtE,KAAK8d,YAC3Bzd,EAAMG,IAAI8D,QAAQtE,KAAKQ;;;;;;;;;;;;;;;;;;;;;;;;;aCxJb6rB,GACd/vB;;AAEAwB;IAEA,MAAMxB,aAAewB,IACnB,MAAIA,EAAYuF,SAAS/G,EAAIwB,YAAYuF,OACjC,IAAIJ,EACRlB,EAAKI,kBAEH,4DAAIrE,EAAYuF,2CAGd,IAAIJ,EACRlB,EAAKI,kBACL,kBAAkBrE,EAAYuF,mBAAmB/G,EAAIwB,YAAYuF;IAIvE,OAAO/G;;;;;;;;;;;;;;;;;;;;;;;;;UpB8CIgwB;;;;;IAUX3tB,YACW+G,GACA6B,IAAiC,MACjCglB,IAA6B,IAC7B9kB,IAAoB,IACpB5C,IAAuB,MACvB2nB,sBACA9kB,IAAwB,MACxBC,IAAsB;QAPtB3H,YAAA0F,GACA1F,uBAAAuH,aACAglB,GACAvsB,eAAAyH,GACAzH,aAAA6E;kBACA2nB,GACAxsB,eAAA0H,GACA1H,aAAA2H,GAjBX3H,UAAoC;;QAGpCA,UAAgC,MAgB1BA,KAAK0H,SAML1H,KAAK2H;;;;;;;WAcXhJ,GAAwB+G;QACtB,OAAO,IAAI4mB,GACT5mB;6BACqB,MACrB1F,KAAKusB,GAAgB3nB,SACrB5E,KAAKyH,QAAQ7C,SACb5E,KAAK6E,OACL7E,KAAKwsB,IACLxsB,KAAK0H,SACL1H,KAAK2H;;IAIThJ;QACE,OAC0B,MAAxBqB,KAAKyH,QAAQ3I,UACE,SAAfkB,KAAK6E,SACW,QAAhB7E,KAAK0H,WACS,QAAd1H,KAAK2H,UAC4B,MAAhC3H,KAAKusB,GAAgBztB,UACa,MAAhCkB,KAAKusB,GAAgBztB,UACpBkB,KAAKusB,GAAgB,GAAGjkB,MAAMmkB;;IAItC9tB;QACE,QAAQoI,EAAkB/G,KAAK6E,8BAAU7E,KAAKwsB;;IAGhD7tB;QACE,QAAQoI,EAAkB/G,KAAK6E,6BAAU7E,KAAKwsB;;IAGhD7tB;QACE,OAAOqB,KAAKusB,GAAgBztB,SAAS,IACjCkB,KAAKusB,GAAgB,GAAGjkB,QACxB;;IAGN3J;QACE,KAAK,MAAMkH,KAAU7F,KAAKyH,SAKxB,IAAI5B,EAAO6mB,MACT,OAAO7mB,EAAOyC;QAGlB,OAAO;;IAGT3J,GAAmBguB;QACjB,KAAK,MAAM9mB,KAAU7F,KAAKyH,SAKxB,IAAIklB,EAAUhnB,QAAQE,EAAO8C,OAAO,GAClC,OAAO9C,EAAO8C;QAGlB,OAAO;;;;wEAKKkd,GACdngB,GACA6B,GACAglB,GACA9kB,GACA5C,GACA2nB,GACA9kB,GACAC;IAEA,OAAO,IAAI2kB,GACT5mB,GACA6B,GACAglB,GACA9kB,GACA5C,GACA2nB,GACA9kB,GACAC;;;qFAKYilB,GAAgBlnB;IAC9B,OAAO,IAAI4mB,GAAU5mB;;;;;;;;;;;SA2BPmnB,GAAuBhc;IACrC,OAAiC,SAA1BA,EAAMtJ;;;;;;;aAQCulB,GAAajc;IAC3B,MAAMkc,IAAYV,GAAKxb,GAAOyb;IAC9B,IAAkC,SAA9BS,EAAUC,IAA0B;QACtCD,EAAUC,KAAkB;QAE5B,MAAMC,IAAkBF,EAAUG,MAC5BC,IAAoBJ,EAAUK;QACpC,IAAwB,SAApBH,KAAkD,SAAtBE;;;;QAIzBF,EAAgBR,OACnBM,EAAUC,GAAgBvrB,KAAK,IAAI8jB,GAAQ0H,KAE7CF,EAAUC,GAAgBvrB,KACxB,IAAI8jB,GAAQxf,EAAUsnB,mCAEnB;YAOL,IAAIC,KAAmB;YACvB,KAAK,MAAM9lB,KAAWulB,EAAUR,IAC9BQ,EAAUC,GAAgBvrB,KAAK+F,IAC3BA,EAAQc,MAAMmkB,QAChBa,KAAmB;YAGvB,KAAKA,GAAkB;;;gBAGrB,MAAMC,IACJR,EAAUR,GAAgBztB,SAAS,IAC/BiuB,EAAUR,GAAgBQ,EAAUR,GAAgBztB,SAAS,GAC1DyJ;gBAETwkB,EAAUC,GAAgBvrB,KACxB,IAAI8jB,GAAQxf,EAAUsnB,KAAYE;;;;IAK1C,OAAOR,EAAUC;;;;;aAMHpH,GAAc/U;IAC5B,MAAMkc,IAAYV,GAAKxb,GAAOyb;IAC9B,KAAKS,EAAUS,IACb,wBAAIT,EAAUP,IACZO,EAAUS,KAAiB5lB,EACzBmlB,EAAUrnB,MACVqnB,EAAUxlB,iBACVulB,GAAaC,IACbA,EAAUtlB,SACVslB,EAAUloB,OACVkoB,EAAUrlB,SACVqlB,EAAUplB,aAEP;;QAEL,MAAM0c,IAAW;QACjB,KAAK,MAAM7c,KAAWslB,GAAaC,IAAY;YAC7C,MAAMxkB,gCACJf,EAAQe;YAGV8b,EAAS5iB,KAAK,IAAI8jB,GAAQ/d,EAAQc,OAAOC;;;gBAI3C,MAAMb,IAAUqlB,EAAUplB,QACtB,IAAIye,GAAM2G,EAAUplB,MAAMwe,WAAW4G,EAAUplB,MAAMue,UACrD,MACEve,IAAQolB,EAAUrlB,UACpB,IAAI0e,GAAM2G,EAAUrlB,QAAQye,WAAW4G,EAAUrlB,QAAQwe,UACzD;;QAGJ6G,EAAUS,KAAiB5lB,EACzBmlB,EAAUrnB,MACVqnB,EAAUxlB,iBACV8c,GACA0I,EAAUtlB,SACVslB,EAAUloB,OACV6C,GACAC;;IAIN,OAAOolB,EAAUS;;;SAiDHC,GACd5c,GACAhM,GACA2nB;IAEA,OAAO,IAAIF,GACTzb,EAAMnL,MACNmL,EAAMtJ,iBACNsJ,EAAM0b,GAAgB3nB,SACtBiM,EAAMpJ,QAAQ7C,SACdC,GACA2nB,GACA3b,EAAMnJ,SACNmJ,EAAMlJ;;;SAIM+lB,GAAiB7c,GAAc8c;IAC7C,OAAO,IAAIrB,GACTzb,EAAMnL,MACNmL,EAAMtJ,iBACNsJ,EAAM0b,GAAgB3nB,SACtBiM,EAAMpJ,QAAQ7C,SACdiM,EAAMhM,OACNgM,EAAM2b,IACNmB,GACA9c,EAAMlJ;;;SAIMimB,GAAe/c,GAAc8c;IAC3C,OAAO,IAAIrB,GACTzb,EAAMnL,MACNmL,EAAMtJ,iBACNsJ,EAAM0b,GAAgB3nB,SACtBiM,EAAMpJ,QAAQ7C,SACdiM,EAAMhM,OACNgM,EAAM2b,IACN3b,EAAMnJ,SACNimB;;;SAIYnc,GAAYtS,GAAaC;IACvC,OACE0J,EAAa+c,GAAc1mB,IAAO0mB,GAAczmB,OAChDD,EAAKstB,OAAcrtB,EAAMqtB;;;;;;SAObqB,GAAchd;IAC5B,OAAO,GAAGhJ,EAAe+d,GAAc/U,UAAcA,EAAM2b;;;SAG7CsB,GAAejd;IAC7B,OAAO,gBAAgBpI,EAAgBmd,GAAc/U,kBACnDA,EAAM2b;;;0EAKMuB,GAAald,GAAcb;IACzC,OAQF,SACEa,GACAb;QAEA,MAAMge,IAAUhe,EAAIxP,IAAIkF;QACxB,OAA8B,SAA1BmL,EAAMtJ,kBAINyI,EAAIxP,IAAIytB,EAAgBpd,EAAMtJ,oBAC9BsJ,EAAMnL,KAAK4iB,EAAW0F,KAEfvnB,EAAY2C,EAAcyH,EAAMnL,QAElCmL,EAAMnL,KAAKpB,QAAQ0pB,KAGnBnd,EAAMnL,KAAKwoB,EAAoBF;;;;;GAxBtCG,EAAmCtd,GAAOb,MAgC9C,SAA6Ba,GAAcb;QACzC,KAAK,MAAMxI,KAAWqJ,EAAM0b;;QAE1B,KAAK/kB,EAAQc,MAAMmkB,OAA6C,SAA7Bzc,EAAI1H,MAAMd,EAAQc,QACnD,QAAO;QAGX,QAAO;KAtCL8lB,CAAoBvd,GAAOb,MAyC/B,SAA6Ba,GAAcb;QACzC,KAAK,MAAMnK,KAAUgL,EAAMpJ,SACzB,KAAK5B,EAAOzE,QAAQ4O,IAClB,QAAO;QAGX,QAAO;;mEA9CLqe,EAAoBxd,GAAOb,MAkD/B,SAA4Ba,GAAcb;QACxC,IACEa,EAAMnJ,YACL4mB,GAAoBzd,EAAMnJ,SAASolB,GAAajc,IAAQb,IAEzD,QAAO;QAET,IACEa,EAAMlJ,SACN2mB,GAAoBzd,EAAMlJ,OAAOmlB,GAAajc,IAAQb,IAEtD,QAAO;QAET,QAAO;;;;;GA9DLue,EAAmB1d,GAAOb;;;SAqEdwe,GACd3d;IAEA,OAAO,CAAClB,GAAcC;QACpB,IAAI6e,KAAqB;QACzB,KAAK,MAAMjnB,KAAWslB,GAAajc,IAAQ;YACzC,MAAMnB,IAAOgf,GAAYlnB,GAASmI,GAAIC;YACtC,IAAa,MAATF,GACF,OAAOA;YAET+e,IAAqBA,KAAsBjnB,EAAQc,MAAMmkB;;QAO3D,OAAO;;;;MAqBEnG;IACX3nB,YACS2J,GACAK,GACAxL;QAEPgG,SAJOnD,aAAAsI,GACAtI,UAAA2I,GACA3I,aAAA7C;;;;WAQTwB,cAAc2J,GAAkBK,GAAcxL;QAC5C,IAAImL,EAAMmkB,KACR,yBAAI9jB,+BAAsBA,IACjB3I,KAAK2uB,GAAuBrmB,GAAOK,GAAIxL,KAUvC,IAAIyxB,GAAetmB,GAAOK,GAAIxL;QAElC,IAAI4e,GAAY5e,IAAQ;YAC7B,yBAAIwL,8BAAyBA;;YAE3B,MAAM,IAAI1F,EACRlB,EAAKI,kBACL;YAGJ,OAAO,IAAImkB,GAAYhe,GAAOK,GAAIxL;;QAC7B,IAAI6e,GAAW7e,IAAQ;YAC5B,yBAAIwL,8BAAyBA;;YAE3B,MAAM,IAAI1F,EACRlB,EAAKI,kBACL;YAGJ,OAAO,IAAImkB,GAAYhe,GAAOK,GAAIxL;;QAC7B,iDAAIwL,IACF,IAAIkmB,GAAoBvmB,GAAOnL,uBAC7BwL,IAKF,IAAImmB,GAASxmB,GAAOnL,+BAClBwL,IAKF,IAAIomB,GAAYzmB,GAAOnL,uDACrBwL,IAKF,IAAIqmB,GAAuB1mB,GAAOnL,KAElC,IAAImpB,GAAYhe,GAAOK,GAAIxL;;IAI9BwB,UACN2J,GACAK,GACAxL;QAaA,yBAAOwL,IACH,IAAIsmB,GAAiB3mB,GAAOnL,KAC5B,IAAI+xB,GAAoB5mB,GAAOnL;;IAGrCwB,QAAQqR;QACN,MAAM3P,IAAQ2P,EAAI1H,MAAMtI,KAAKsI;;gBAE7B,gCAAItI,KAAK2I,KAEK,SAAVtI,KACAL,KAAKmvB,GAAkBnW,MAAqBhZ,KAAK7C,UAMzC,SAAVkD,KACA8W,GAAUnX,KAAK7C,WAAWga,GAAU9W,MACpCL,KAAKmvB,GAAkBnW,GAAa3Y,GAAOL,KAAK7C;;;IAI1CwB,GAAkBob;QAC1B,QAAQ/Z,KAAK2I;UACX;YACE,OAAOoR,IAAa;;UACtB;YACE,OAAOA,KAAc;;UACvB;YACE,OAAsB,MAAfA;;UACT;YACE,OAAsB,MAAfA;;UACT;YACE,OAAOA,IAAa;;UACtB;YACE,OAAOA,KAAc;;UACvB;YACE,OA9pBDxc;;;IAkqBLoB;QACE,OACE,2IAMEgH,QAAQ3F,KAAK2I,OAAO;;;;SAKZR,GAAetC;;;;IAQ7B,OACEA,EAAOyC,MAAM7C,MACbI,EAAO8C,GAAGvF,aACV6E,GAAYpC,EAAO1I;;;MA6BVyxB,WAAuBtI;IAGlC3nB,YAAY2J,GAAkBK,GAAcxL;QAC1CgG,MAAMmF,GAAOK,GAAIxL,IAKjB6C,KAAKQ,MAAMiG,EAAYsU,EAAS5d,EAAMya;;IAGxCjZ,QAAQqR;QACN,MAAM+J,IAAatT,EAAYpH,EAAW2Q,EAAIxP,KAAKR,KAAKQ;QACxD,OAAOR,KAAKmvB,GAAkBpV;;;;gEAKrBkV,WAAyB3I;IAGpC3nB,YAAY2J,GAAkBnL;QAC5BgG,MAAMmF,mBAAoBnL,IAC1B6C,KAAKqP,OAAO+f,mBAA+CjyB;;IAG7DwB,QAAQqR;QACN,OAAOhQ,KAAKqP,KAAK6Y,KAAK1nB,KAAOA,EAAI8D,QAAQ0L,EAAIxP;;;;4EAKpC0uB,WAA4B5I;IAGvC3nB,YAAY2J,GAAkBnL;QAC5BgG,MAAMmF,2BAAwBnL,IAC9B6C,KAAKqP,OAAO+f,2BAAmDjyB;;IAGjEwB,QAAQqR;QACN,QAAQhQ,KAAKqP,KAAK6Y,KAAK1nB,KAAOA,EAAI8D,QAAQ0L,EAAIxP;;;;AAIlD,SAAS4uB,GACPzmB,GACAxL;;IAMA,uBAAQA,EAAMob,yCAAYC,WAAU,IAAI9b,IAAIoF,KAMnC2E,EAAYsU,EAASjZ,EAAE8V;;;mEAKrBiX,WAA4BvI;IACvC3nB,YAAY2J,GAAkBnL;QAC5BgG,MAAMmF,2CAAgCnL;;IAGxCwB,QAAQqR;QACN,MAAM3P,IAAQ2P,EAAI1H,MAAMtI,KAAKsI;QAC7B,OAAOwT,GAAQzb,MAAUuY,GAAmBvY,EAAMkY,YAAYvY,KAAK7C;;;;uDAK1D2xB,WAAiBxI;IAC5B3nB,YAAY2J,GAAkBnL;QAC5BgG,MAAMmF,mBAAoBnL;;IAI5BwB,QAAQqR;QACN,MAAM3P,IAAQ2P,EAAI1H,MAAMtI,KAAKsI;QAC7B,OAAiB,SAAVjI,KAAkBuY,GAAmB5Y,KAAK7C,MAAiB,YAAEkD;;;;2DAK3D0uB,WAAoBzI;IAC/B3nB,YAAY2J,GAAkBnL;QAC5BgG,MAAMmF,2BAAwBnL;;IAIhCwB,QAAQqR;QACN,MAAM3P,IAAQ2P,EAAI1H,MAAMtI,KAAKsI;QAC7B,OAAiB,SAAVjI,MAAmBuY,GAAmB5Y,KAAK7C,MAAiB,YAAEkD;;;;uEAK5D2uB,WAA+B1I;IAC1C3nB,YAAY2J,GAAkBnL;QAC5BgG,MAAMmF,mDAAoCnL;;IAI5CwB,QAAQqR;QACN,MAAM3P,IAAQ2P,EAAI1H,MAAMtI,KAAKsI;QAC7B,UAAKwT,GAAQzb,OAAWA,EAAMkY,WAAWC,WAGlCnY,EAAMkY,WAAWC,OAAO0P,KAAKxD,KAClC9L,GAAmB5Y,KAAK7C,MAAiB,YAAEunB;;;;;;;;;;;;;;;;;UA2BpC0B;IACXznB,YAAqBwnB,GAAgCD;QAAhClmB,gBAAAmmB,GAAgCnmB,cAAAkmB;;;;SAGvC1d,GAAcmlB;;IAE5B,OAAO,GAAGA,EAAMzH,SAAS,MAAM,OAAOyH,EAAMxH,SACzCzpB,IAAI2yB,KAAKpnB,GAAYonB,IACrB7pB,KAAK;;;;;;aAOM8oB,GACdX,GACAnmB,GACAwI;IAMA,IAAI+J,IAAa;IACjB,KAAK,IAAIzb,IAAI,GAAGA,IAAIqvB,EAAMxH,SAASrnB,QAAQR,KAAK;QAC9C,MAAMgxB,IAAmB9nB,EAAQlJ,IAC3BixB,IAAY5B,EAAMxH,SAAS7nB;QACjC,IAAIgxB,EAAiBhnB,MAAMmkB,KAKzB1S,IAAatT,EAAYpH,EACvBoH,EAAYsU,EAASwU,EAAU3X,iBAC/B5H,EAAIxP,WAED;YAMLuZ,IAAaf,GAAauW,GALTvf,EAAI1H,MAAMgnB,EAAiBhnB;;QAU9C,gCAHIgnB,EAAiB/mB,QACnBwR,MAA2B,IAEV,MAAfA,GACF;;IAGJ,OAAO4T,EAAMzH,SAASnM,KAAc,IAAIA,IAAa;;;SAGvC7Q,GAAYhK,GAAoBC;IAC9C,IAAa,SAATD,GACF,OAAiB,SAAVC;IACF,IAAc,SAAVA,GACT,QAAO;IAGT,IACED,EAAKgnB,WAAW/mB,EAAM+mB,UACtBhnB,EAAKinB,SAASrnB,WAAWK,EAAMgnB,SAASrnB,QAExC,QAAO;IAET,KAAK,IAAIR,IAAI,GAAGA,IAAIY,EAAKinB,SAASrnB,QAAQR,KAAK;QAG7C,KAAK2K,GAFgB/J,EAAKinB,SAAS7nB,IACba,EAAMgnB,SAAS7nB,KAEnC,QAAO;;IAGX,QAAO;;;;;UAMIinB;IACX5mB,YACW2J,GACAC;QADAvI,aAAAsI,GACAtI,WAAAuI;;;;SAIGmmB,GACdlnB,GACAmI,GACAC;IAEA,MAAMmK,IAAavS,EAAQc,MAAMmkB,MAC7BhmB,EAAYpH,EAAWsQ,EAAGnP,KAAKoP,EAAGpP,gBmBl3BtC8H,GACAqH,GACAC;QAEA,MAAM4f,IAAK7f,EAAGrH,MAAMA,IACdmnB,IAAK7f,EAAGtH,MAAMA;QACpB,OAAW,SAAPknB,KAAsB,SAAPC,IACVzW,GAAawW,GAAIC,KA5FnBlyB;KnBw8BHmyB,CAAwBloB,EAAQc,OAAOqH,GAAIC;IAC/C,QAAQpI,EAAQe;MACd;QACE,OAAOwR;;MACT;QACE,QAAQ,IAAIA;;MACd;QACE,OA38BCxc;;;;SAw9BSuL,GAAc5J,GAAeC;IAC3C,OAAOD,EAAKqJ,QAAQpJ,EAAMoJ,OAAOrJ,EAAKoJ,MAAMhE,QAAQnF,EAAMmJ;;;;;;;;;;;;;;;;;;;;;;MqB58B/CqnB;;;;;;;;;;;;IAYXhxB,YACSixB,GACA9Y,GACA+Y,GACAC;QAHA9vB,eAAA4vB,aACA9Y,GACA9W,qBAAA6vB,GACA7vB,iBAAA8vB;;;;;;;;;;WAcTnxB,GACEoxB,GACAlH,GACAmH;QAUA,MAAMC,IAAkBD,EAAYC;QAQpC,KAAK,IAAI3xB,IAAI,GAAGA,IAAI0B,KAAK8vB,UAAUhxB,QAAQR,KAAK;YAC9C,MAAMgiB,IAAWtgB,KAAK8vB,UAAUxxB;YAChC,IAAIgiB,EAAS9f,IAAI8D,QAAQyrB,IAAS;gBAEhClH,IAAWE,GACTzI,GACAuI,GAHqBoH,EAAgB3xB;;;QAQ3C,OAAOuqB;;;;;;;;WAUTlqB,GACEoxB,GACAlH;;;QAYA,KAAK,MAAMvI,KAAYtgB,KAAK6vB,eACtBvP,EAAS9f,IAAI8D,QAAQyrB,OACvBlH,IAAWgB,GACTvJ,GACAuI,GACAA,GACA7oB,KAAK8W;QAKX,MAAM0S,IAAUX;;gBAGhB,KAAK,MAAMvI,KAAYtgB,KAAK8vB,WACtBxP,EAAS9f,IAAI8D,QAAQyrB,OACvBlH,IAAWgB,GACTvJ,GACAuI,GACAW,GACAxpB,KAAK8W;QAIX,OAAO+R;;;;;WAOTlqB,GAAwBuxB;;;;QAItB,IAAIC,IAAmBD;QAUvB,OATAlwB,KAAK8vB,UAAUjvB,QAAQuvB;YACrB,MAAMC,IAAkBrwB,KAAKswB,GAC3BF,EAAE5vB,KACF0vB,EAAU1uB,IAAI4uB,EAAE5vB;YAEd6vB,MACFF,IAAmBA,EAAiB7kB,GAAO8kB,EAAE5vB,KAAK6vB;YAG/CF;;IAGTxxB;QACE,OAAOqB,KAAK8vB,UAAU3K,OACpB,CAAC9V,GAAM+gB,MAAM/gB,EAAKd,IAAI6hB,EAAE5vB,MACxB4O;;IAIJzQ,QAAQ0B;QACN,OACEL,KAAK4vB,YAAYvvB,EAAMuvB,WACvBxwB,EAAYY,KAAK8vB,WAAWzvB,EAAMyvB,WAAW,CAACvH,GAAGC,MAC/CoC,GAAerC,GAAGC,OAEpBppB,EAAYY,KAAK6vB,eAAexvB,EAAMwvB,eAAe,CAACtH,GAAGC,MACvDoC,GAAerC,GAAGC;;;;qEAOb+H;IACX5xB,YACW6xB,GACAC,GACAR;;;;;IAKAS;QAPA1wB,aAAAwwB,aACAC,aACAR,aAKAS;;;;;;WAQX/xB,YACE6xB,GACAC,GACAE;QAzKChzB,EA4KC6yB,EAAMV,UAAUhxB,WAAW6xB,EAAQ7xB;QAOrC,IAAI8xB,IblKC1hB;QamKL,MAAM4gB,IAAYU,EAAMV;QACxB,KAAK,IAAIxxB,IAAI,GAAGA,IAAIwxB,EAAUhxB,QAAQR,KACpCsyB,IAAaA,EAAWtlB,GAAOwkB,EAAUxxB,GAAGkC,KAAKmwB,EAAQryB,GAAGwf;QAG9D,OAAO,IAAIyS,GAAoBC,GAAOC,GAAeE,GAASC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;UClMrDC;IAeXlyB,YAAYmyB;;;QAZZ9wB,UAAqD,MACrDA,UAAkD;;QAG1CA,mBAAwBsB,GACxBtB,kBAA2BsB,GACnCtB,WAAiB;;;QAIjBA,WAA2B,GAGzB8wB,EACE3zB;YACE6C,KAAK+wB,MAAS,GACd/wB,KAAKwM,SAASrP,GACV6C,KAAKgxB;;;YAGPhxB,KAAKgxB;WAGTj0B;YACEiD,KAAK+wB,MAAS,GACd/wB,KAAKjD,QAAQA,GACTiD,KAAKixB,MACPjxB,KAAKixB,GAAcl0B;;;IAM3B4B,MACEmC;QAEA,OAAOd,KAAKwG,UAAKlF,GAAWR;;IAG9BnC,KACEuyB,GACAC;QAMA,OAJInxB,KAAKoxB,MACP7zB,KAEFyC,KAAKoxB,MAAmB,GACpBpxB,KAAK+wB,KACF/wB,KAAKjD,QAGDiD,KAAKqxB,GAAYF,GAASnxB,KAAKjD,SAF/BiD,KAAKsxB,GAAYJ,GAAQlxB,KAAY,UAKvC,IAAI6wB,GAAsB,CAACU,GAASC;YACzCxxB,KAAKgxB,KAAgB7zB;gBACnB6C,KAAKsxB,GAAYJ,GAAQ/zB,GAAOqJ,KAAK+qB,GAASC;eAEhDxxB,KAAKixB,KAAiBl0B;gBACpBiD,KAAKqxB,GAAYF,GAASp0B,GAAOyJ,KAAK+qB,GAASC;;;;IAMvD7yB;QACE,OAAO,IAAI8yB,QAAQ,CAACF,GAASC;YAC3BxxB,KAAKwG,KAAK+qB,GAASC;;;IAIf7yB,GACNmC;QAEA;YACE,MAAM0L,IAAS1L;YACf,OAAI0L,aAAkBqkB,KACbrkB,IAEAqkB,GAAmBU,QAAQ/kB;UAEpC,OAAOlP;YACP,OAAOuzB,GAAmBW,OAAUl0B;;;IAIhCqB,GACNuyB,GACA/zB;QAEA,OAAI+zB,IACKlxB,KAAK0xB,GAAiB,MAAMR,EAAO/zB,MAGnC0zB,GAAmBU,QAAYp0B;;IAIlCwB,GACNwyB,GACAp0B;QAEA,OAAIo0B,IACKnxB,KAAK0xB,GAAiB,MAAMP,EAAQp0B,MAEpC8zB,GAAmBW,OAAUz0B;;IAMxC4B,eAAkB6N;QAChB,OAAO,IAAIqkB,GAA6B,CAACU,GAASC;YAChDD,EAAQ/kB;;;IAIZ7N,cAAiB5B;QACf,OAAO,IAAI8zB,GAAsB,CAACU,GAASC;YACzCA,EAAOz0B;;;IAIX4B;;;IAGEgzB;QAEA,OAAO,IAAId,GAAyB,CAACU,GAASC;YAC5C,IAAIvc,IAAgB,GAChB2c,IAAgB,GAChBC,KAAO;YAEXF,EAAI9wB,QAAQsnB;kBACRlT,GACFkT,EAAQ3hB,KACN;sBACIorB,GACEC,KAAQD,MAAkB3c,KAC5Bsc;mBAGJO,KAAON,EAAOM;gBAIlBD,KAAO,GACHD,MAAkB3c,KACpBsc;;;;;;;;WAWN5yB,UACEozB;QAEA,IAAI1C,IAAiCwB,GAAmBU,SACtD;QAEF,KAAK,MAAMS,KAAaD,GACtB1C,IAAIA,EAAE7oB,KAAKyrB,KACLA,IACKpB,GAAmBU,QAAiBU,KAEpCD;QAIb,OAAO3C;;IAkBT1wB,eACEuzB,GACAhqB;QAEA,MAAMiqB,IAA4C;QAIlD,OAHAD,EAAWrxB,QAAQ,CAAC2nB,GAAG/oB;YACrB0yB,EAAS1wB,KAAKyG,EAAEtH,KAAKZ,MAAMwoB,GAAG/oB;YAEzBO,KAAKoyB,GAAQD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;UC3MFE;IAAtB1zB;;;QAGEqB,UAGI,IAAIgB,EACNR,KAAOA,EAAI4C,YACX,CAACmlB,GAAGC,MAAMD,EAAEjkB,QAAQkkB,KAMtBxoB,WAAyB;;IAgBzBsf,aAAuBniB;QAQrB6C,KAAKsyB,KAAYn1B;;IAGnBmiB;QAKE,OAAOtf,KAAKsyB;;;;;;;WASd3zB,GAAS4zB,GAA8BjT;QACrCtf,KAAKwyB,MACLxyB,KAAKsf,WAAWA,GAChBtf,KAAK2Q,GAAQrB,IAAIijB,EAAc/xB,KAAK+xB;;;;;;;WAStC5zB,GAAY6B,GAAkB8e;QAC5Btf,KAAKwyB,MACDlT,MACFtf,KAAKsf,WAAWA,IAElBtf,KAAK2Q,GAAQrB,IAAI9O,GAAK;;;;;;;;;;;;WAcxB7B,GACE8zB,GACAC;QAEA1yB,KAAKwyB;QACL,MAAMG,IAAgB3yB,KAAK2Q,GAAQnP,IAAIkxB;QACvC,YAAsBpxB,MAAlBqxB,IACK9B,GAAmBU,QAA8BoB,KAEjD3yB,KAAK4yB,GAAaH,GAAaC;;;;;;;;;;;;WAe1C/zB,WACE8zB,GACAI;QAEA,OAAO7yB,KAAK8yB,GAAgBL,GAAaI;;;;;WAO3Cl0B,MAAM8zB;QAGJ,OAFAzyB,KAAKwyB,MACLxyB,KAAK+yB,MAAiB,GACf/yB,KAAKgzB,GAAaP;;yDAIjB9zB;;;;;;;;;;;;;;;;;;GC7IL,OAAMs0B,KACX;;;;;;;;;UAWoBC;IAAtBv0B;QACEqB,UAA2D;;IAI3DrB,GAAuBw0B;QACrBnzB,KAAKozB,GAAqB3xB,KAAK0xB;;IAGjCx0B;QACEqB,KAAKozB,GAAqBvyB,QAAQsyB,KAAYA;;;;;;;;;;;;;;;;;;;;;;;;;UCGrCE;IACX10B,YACW20B,GACAC,GACAC;kBAFAF,aACAC,aACAC;;;;;;;WASX70B,GACE8zB,GACAjyB;QAEA,OAAOR,KAAKuzB,GACTE,GAA0ChB,GAAajyB,GACvDgG,KAAKktB,KAAW1zB,KAAK2zB,GAAoBlB,GAAajyB,GAAKkzB;;6EAIxD/0B,GACN8zB,GACAjyB,GACAozB;QAEA,OAAO5zB,KAAKszB,GAAoBO,GAASpB,GAAajyB,GAAKgG,KAAKwJ;YAC9D,KAAK,MAAMwgB,KAASoD,GAClB5jB,IAAMwgB,EAAMF,GAAiB9vB,GAAKwP;YAEpC,OAAOA;;;;;IAMHrR,GACN8zB,GACA3hB,GACA4iB;QAEA,IAAI/C,IAAU5hB;QAOd,OANA+B,EAAKjQ,QAAQ,CAACL,GAAKszB;YACjB,KAAK,MAAMtD,KAASkD,GAClBI,IAAYtD,EAAMF,GAAiB9vB,GAAKszB;YAE1CnD,IAAUA,EAAQrlB,GAAO9K,GAAKszB;YAEzBnD;;;;;;;WASThyB,GACE8zB,GACApjB;QAEA,OAAOrP,KAAKszB,GACTS,WAAWtB,GAAapjB,GACxB7I,KAAKsK,KAAQ9Q,KAAKg0B,GAAwBvB,GAAa3hB;;;;;WAO5DnS,GACE8zB,GACAwB;QAEA,OAAOj0B,KAAKuzB,GACTW,GAA2CzB,GAAawB,GACxDztB,KAAKktB;YACJ,MAAM5iB,IAAO9Q,KAAKm0B,GAChB1B,GACAwB,GACAP;YAEF,IAAI/C,IAAU7hB;YASd,OARAgC,EAAKjQ,QAAQ,CAACL,GAAKqoB;;gBAEZA,MACHA,IAAW,IAAI5U,GAAWzT,GAAK2D,EAAgBkB,SAEjDsrB,IAAUA,EAAQrlB,GAAO9K,GAAKqoB;gBAGzB8H;;;;;;;;;;WAYbhyB,GACE8zB,GACA5hB,GACAujB;;;;;QAEA,gBzByE4BvjB;YAC9B,OACEpK,EAAY2C,EAAcyH,EAAMnL,SACN,SAA1BmL,EAAMtJ,mBACmB,MAAzBsJ,EAAMpJ,QAAQ3I;SyB7EVu1B,CAAgBxjB,KACX7Q,KAAKs0B,GAAkC7B,GAAa5hB,EAAMnL,QACxDmnB,GAAuBhc,KACzB7Q,KAAKu0B,GACV9B,GACA5hB,GACAujB,KAGKp0B,KAAKw0B,GACV/B,GACA5hB,GACAujB;;IAKEz1B,GACN8zB,GACAzE;;QAGA,OAAOhuB,KAAKy0B,GAAYhC,GAAa,IAAIhsB,EAAYunB,IAAUxnB,KAC7DqiB;YACE,IAAIrc,IAASyC;YAIb,OAHI4Z,aAAoB9U,OACtBvH,IAASA,EAAOlB,GAAOud,EAASroB,KAAKqoB,KAEhCrc;;;IAKL7N,GACN8zB,GACA5hB,GACAujB;QAMA,MAAMxtB,IAAeiK,EAAMtJ;QAC3B,IAAIopB,IAAU1hB;QACd,OAAOjP,KAAKwzB,GACTkB,GAAqBjC,GAAa7rB,GAClCJ,KAAKmuB,KAGG9D,GAAmBhwB,QAAQ8zB,GAAUlR;YAC1C,MAAMmR,IAAkB/jB,EAAMgkB,GAC5BpR,EAAOtF,MAAMvX;YAEf,OAAO5G,KAAKw0B,GACV/B,GACAmC,GACAR,GACA5tB,KAAKgiB;gBACLA,EAAE3nB,QAAQ,CAACL,GAAKwP;oBACd2gB,IAAUA,EAAQrlB,GAAO9K,GAAKwP;;;WAGjCxJ,KAAK,MAAMmqB;;IAIZhyB,GACN8zB,GACA5hB,GACAujB;;QAGA,IAAIzD,GACAmE;QACJ,OAAO90B,KAAKszB,GACTyB,GAA0BtC,GAAa5hB,GAAOujB,GAC9C5tB,KAAKwuB,MACJrE,IAAUqE,GACHh1B,KAAKuzB,GAAc0B,GACxBxC,GACA5hB,KAGHrK,KAAK0uB,MACJJ,IAAkBI;QAOXl1B,KAAKm1B,GACV1C,GACAqC,GACAnE,GACAnqB,KAAK4uB;YACLzE,IAAUyE;YAEV,KAAK,MAAM5E,KAASsE,GAClB,KAAK,MAAMxU,KAAYkQ,EAAMV,WAAW;gBACtC,MAAMtvB,IAAM8f,EAAS9f,KACfgpB,IAAUmH,EAAQnvB,IAAIhB,IACtB60B,IAAaxL,GACjBvJ,GACAkJ,GACAA,GACAgH,EAAM1Z;gBAGN6Z,IADE0E,aAAsBthB,KACd4c,EAAQrlB,GAAO9K,GAAK60B,KAEpB1E,EAAQllB,OAAOjL;;aAMlCgG,KAAK;;;QAGJmqB,EAAQ9vB,QAAQ,CAACL,GAAKwP;YACf+d,GAAald,GAAOb,OACvB2gB,IAAUA,EAAQllB,OAAOjL;YAItBmwB;;IAILhyB,GACN8zB,GACAyC,GACAI;QAEA,IAAIC,IAAmCnmB;QACvC,KAAK,MAAMohB,KAAS0E,GAClB,KAAK,MAAM5U,KAAYkQ,EAAMV,WAEzBxP,aAAoBI,MACoB,SAAxC4U,EAAkB9zB,IAAI8e,EAAS9f,SAE/B+0B,IAAmCA,EAAiChnB,IAClE+R,EAAS9f;QAMjB,IAAI40B,IAAkBE;QACtB,OAAOt1B,KAAKszB,GACTS,WAAWtB,GAAa8C,GACxB/uB,KAAKgvB,MACJA,EAAgB30B,QAAQ,CAACL,GAAKwP;YAChB,SAARA,KAAgBA,aAAe+D,OACjCqhB,IAAkBA,EAAgB9pB,GAAO9K,GAAKwP;YAG3ColB;;;;;;;;;;;;;;;;;;;;;;;;UCvSFK;IACX92B,YACW2L,GACA4G,GACAwkB,GACAC;QAHA31B,gBAAAsK,GACAtK,iBAAAkR,aACAwkB,aACAC;;IAGXh3B,UACE2L,GACAsrB;QAEA,IAAIF,IAAYtmB,MACZumB,IAAcvmB;QAElB,KAAK,MAAM0E,KAAa8hB,EAAa5kB,YACnC,QAAQ8C,EAAUpD;UAChB;YACEglB,IAAYA,EAAUnnB,IAAIuF,EAAU9D,IAAIxP;YACxC;;UACF;YACEm1B,IAAcA,EAAYpnB,IAAIuF,EAAU9D,IAAIxP;;;QAOlD,OAAO,IAAIi1B,GACTnrB,GACAsrB,EAAa1kB,WACbwkB,GACAC;;;;;;;;;;;;;;;;;;;;;;;;;UCnBOE;IAOXl3B,YACUuoB,GACR4O;QADQ91B,qBAAAknB,GAGJ4O,MACFA,EAAqBC,KAAwBvrB,KAC3CxK,KAAKg2B,GAAiBxrB,IACxBxK,KAAKi2B,KAAyBzrB,KAC5BsrB,EAAqBI,GAAoB1rB;;IAIvC7L,GACNw3B;QAGA,OADAn2B,KAAKknB,gBAAgB3oB,KAAK63B,IAAID,GAAuBn2B,KAAKknB,gBACnDlnB,KAAKknB;;IAGdvoB;QACE,MAAM03B,MAAcr2B,KAAKknB;QAIzB,OAHIlnB,KAAKi2B,MACPj2B,KAAKi2B,GAAuBI,IAEvBA;;;;AA9BTR,SAAiD;;;;;;;;;;;;;;;;;;MCftCS;IAMX33B;QACEqB,KAAKu2B,UAAU,IAAI9E,QAAQ,CAACF,GAAsBC;YAChDxxB,KAAKuxB,UAAUA,GACfvxB,KAAKwxB,SAASA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;MCQPgF;IAMX73B;;;;IAImB83B;;;;IAIAC;;;;;;IAMAC,IApCoB;;;;UAyCpBC,IAvCU;;;;;UA6CVC,IA1CgB;kBAqBhBJ,aAIAC,aAMAC,aAKAC,aAMAC,GA9BnB72B,UAAgC,GAChCA,UAAsD;;QAEtDA,UAA0B0D,KAAKC,OA6B7B3D,KAAK82B;;;;;;;;WAUPn4B;QACEqB,KAAK+2B,KAAgB;;;;;WAOvBp4B;QACEqB,KAAK+2B,KAAgB/2B,KAAK62B;;;;;;WAQ5Bl4B,GAAcgK;;QAEZ3I,KAAKg3B;;;QAIL,MAAMC,IAA2B14B,KAAKC,MACpCwB,KAAK+2B,KAAgB/2B,KAAKk3B,OAItBC,IAAe54B,KAAK63B,IAAI,GAAG1yB,KAAKC,QAAQ3D,KAAKo3B,KAG7CC,IAAmB94B,KAAK63B,IAC5B,GACAa,IAA2BE;;gBAGzBE,IAAmB,KACrBj7B,EAtGU,sBAwGR,mBAAmBi7B,qBACDr3B,KAAK+2B,6BACCE,uBACLE;QAIvBn3B,KAAKs3B,KAAet3B,KAAKy2B,GAAMc,GAC7Bv3B,KAAK02B,IACLW,GACA,OACEr3B,KAAKo3B,KAAkB1zB,KAAKC,OACrBgF;;;QAMX3I,KAAK+2B,MAAiB/2B,KAAK42B,IACvB52B,KAAK+2B,KAAgB/2B,KAAK22B,OAC5B32B,KAAK+2B,KAAgB/2B,KAAK22B,KAExB32B,KAAK+2B,KAAgB/2B,KAAK62B,OAC5B72B,KAAK+2B,KAAgB/2B,KAAK62B;;IAI9Bl4B;QAC4B,SAAtBqB,KAAKs3B,OACPt3B,KAAKs3B,GAAaE,MAClBx3B,KAAKs3B,KAAe;;IAIxB34B;QAC4B,SAAtBqB,KAAKs3B,OACPt3B,KAAKs3B,GAAaN,UAClBh3B,KAAKs3B,KAAe;;sFAKhB34B;QACN,QAAQJ,KAAKE,WAAW,MAAOuB,KAAK+2B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;MCjH3BU;;;;;;;;;;IA6GX94B,YACmB0E,GACAya,GACA4Z;QAFA13B,YAAAqD,GACArD,eAAA8d,aACA4Z;;;;;QAYE,SALAD,GAASE,GAAcC,QAMxC/6B,EACE;;8CAzHN8B,cAAc0E;QAEZ,OADAjH,EAjCY,YAiCM,sBAAsBiH,IACjCw0B,GAAkBC,OAAOC,UAAUC,eAAe30B,IAAO40B;;iFAIlEt5B;QACE,IAAyB,sBAAdo5B,WACT,QAAO;QAGT,IAAIN,GAASS,MACX,QAAO;;;;;;;;gBAWT,MAAMC,IAAKP,KAaLQ,IAAaX,GAASE,GAAcQ,IACpCE,IAAmB,IAAID,KAAcA,IAAa,IAGlDE,IAAiBb,GAASc,GAAkBJ,IAC5CK,IAAuB,IAAIF,KAAkBA,IAAiB;;;;;;;;;gBAEpE,SACEH,EAAGxyB,QAAQ,WAAW,KACtBwyB,EAAGxyB,QAAQ,cAAc,KACzBwyB,EAAGxyB,QAAQ,WAAW,KACtB0yB,KACAG;;;;;WAYJ75B;;QACE,OACqB,sBAAZ85B,WAC+B,yBAAtCA,QAAQC,kCAAKC;;sEAKjBh6B,UACEi6B,GACAC;QAEA,OAAOD,EAAIC,MAA0BA;;;;IAKvCl6B,UAAqBw5B;QACnB,MAAMW,IAAkBX,EAAGY,MAAM,oCAC3Bjb,IAAUgb,IACZA,EAAgB,GAAGlzB,MAAM,KAAKhB,MAAM,GAAG,GAAGY,KAAK,OAC/C;QACJ,OAAO0B,OAAO4W;;;;IAKhBnf,UAAyBw5B;QACvB,MAAMa,IAAsBb,EAAGY,MAAM,sBAC/Bjb,IAAUkb,IACZA,EAAoB,GAAGpzB,MAAM,KAAKhB,MAAM,GAAG,GAAGY,KAAK,OACnD;QACJ,OAAO0B,OAAO4W;;;;WAwChBnf;QAsEE,OArEKqB,KAAKi5B,OACR78B,EAtKU,YAsKQ,qBAAqB4D,KAAKqD,OAC5CrD,KAAKi5B,WAAW,IAAIxH,QAAqB,CAACF,GAASC;;;;;;YAMjD,MAAM0H,IAAUnB,UAAUoB,KAAKn5B,KAAKqD,MAAMrD,KAAK8d;YAE/Cob,EAAQE,YAAaC;gBACnB,MAAMJ,IAAMI,EAAMvxB,OAA4B0E;gBAC9C+kB,EAAQ0H;eAGVC,EAAQI,YAAY;gBAClB9H,EACE,IAAI+H,GACF;eAMNL,EAAQM,UAAWH;gBACjB,MAAMt8B,IAAuBs8B,EAAMvxB,OAA4B/K;gBAC5C,mBAAfA,EAAMsG,OACRmuB,EACE,IAAIvuB,EACFlB,EAAKW,qBACL,2VAQJ8uB,EAAO,IAAI+H,GAA0Bx8B;eAIzCm8B,EAAQO,kBAAmBJ;gBACzBj9B,EAhNM,YAkNJ,eAAe4D,KAAKqD,OAAO,oCAC3Bg2B,EAAMK;gBAER,MAAMT,IAAMI,EAAMvxB,OAA4B0E;gBAC9CxM,KAAK03B,GACFiC,gBACCV,GACAC,EAAoB,aACpBG,EAAMK,YACN15B,KAAK8d,SAENtX,KAAK;oBACJpK,EA9NE,YAgOA,iCAAiC4D,KAAK8d,UAAU;;;aAOxD9d,KAAK45B,OACP55B,KAAKi5B,GAAGY,kBAAkBR,KAASr5B,KAAK45B,GAAuBP,KAE1Dr5B,KAAKi5B;;IAGdt6B,GACEm7B;QAEA95B,KAAK45B,KAAwBE,GACzB95B,KAAKi5B,OACPj5B,KAAKi5B,GAAGY,kBAAmBR,KAClBS,EAAsBT;;IAKnC16B,qBACEo7B,GACAC,GACAC;QAEA,MAAMC,IAAoB,eAATH;QACjB,IAAII,IAAgB;QAEpB,SAAa;cACTA;YAEF;gBACEn6B,KAAKi5B,WAAWj5B,KAAKo6B;gBAErB,MAAM3H,IAAc4H,GAAoBlB,KACtCn5B,KAAKi5B,IACLiB,IAAW,aAAa,aACxBF,IAEIM,IAAsBL,EAAcxH,GACvC8H,MAAMx9B;;gBAEL01B,EAAY+H,MAAMz9B,IAKX8zB,GAAmBW,OAAUz0B,KAErCk7B;;;gBAUH,OANAqC,EAAoBC,MAAM;;;;sBAKpB9H,EAAYgI,IACXH;cACP,OAAOv9B;;;;;;gBAOP,MAAM29B,IACW,oBAAf39B,EAAMsG,QACN82B,IAnSsB;gBA6SxB,IATA/9B,EA1SQ,YA4SN,oDACAW,EAAMU,SACNi9B;gBAGF16B,KAAK26B,UAEAD,GACH,OAAOjJ,QAAQD,OAAOz0B;;;;IAM9B4B;QACMqB,KAAKi5B,MACPj5B,KAAKi5B,GAAG0B,SAEV36B,KAAKi5B,UAAK33B;;;;;;;;UASDs5B;IAIXj8B,YAAoBk8B;kBAAAA,GAHpB76B,WAAqB,GACrBA,UAAsC;;IAItC86B;QACE,OAAO96B,KAAK+6B;;IAGdC;QACE,OAAOh7B,KAAKi7B;;IAGdhV,WAAW9oB;QACT6C,KAAK66B,KAAW19B;;;;WAMlBwB;QACEqB,KAAK+6B,MAAa;;;;;WAOpBp8B,GAAK6B;QACHR,KAAKi7B,KAAUz6B;;;;;;WAQjB7B;QACE,OAAOk5B,GAAkB73B,KAAK66B,GAAS5qB;;;;oFA6B9BspB,WAAkCt2B;IAG7CtE,YAAYmU;QACV3P,MAAMpB,EAAKgB,aAAa,mCAAmC+P,IAH7D9S,YAAO;;;;sEAQOk7B,GAA4B59B;;;IAG1C,OAAkB,gCAAXA,EAAE+F;;;;;;UAOEg3B;IAoBX17B,YAA6B8zB;QAAAzyB,mBAAAyyB,GAnBrBzyB,gBAAU;;;;QAKlBA,UAAsC,IAAIs2B,IAexCt2B,KAAKyyB,YAAY0I,aAAa;YAC5Bn7B,KAAKo7B,GAAmB7J;WAE1BvxB,KAAKyyB,YAAY4I,UAAU;YACrB5I,EAAY11B,QACdiD,KAAKo7B,GAAmB5J,OACtB,IAAI+H,GAA0B9G,EAAY11B,UAG5CiD,KAAKo7B,GAAmB7J;WAG5BvxB,KAAKyyB,YAAY+G,UAAWH;YAC1B,MAAMt8B,IAAQu+B,GACXjC,EAAMvxB,OAA4B;YAErC9H,KAAKo7B,GAAmB5J,OAAO,IAAI+H,GAA0Bx8B;;;IA7BjE4B,YACEs6B,GACAc,GACAwB;QAEA;YACE,OAAO,IAAIlB,GAAoBpB,EAAGxG,YAAY8I,GAAkBxB;UAChE,OAAOz8B;YACP,MAAM,IAAIi8B,GAA0Bj8B;;;IAyBxCk+B;QACE,OAAOx7B,KAAKo7B,GAAmB7E;;IAGjC53B,MAAM5B;QACAA,KACFiD,KAAKo7B,GAAmB5J,OAAOz0B,IAG5BiD,KAAKy7B,YACRr/B,EAjdU,YAmdR,yBACAW,IAAQA,EAAMU,UAAU;QAE1BuC,KAAKy7B,WAAU,GACfz7B,KAAKyyB,YAAY+H;;;;;;;;;;WAarB77B,MACE+8B;QAEA,MAAM7C,IAAQ74B,KAAKyyB,YAAYkJ,YAAYD;QAE3C,OAAO,IAAIE,GAAkC/C;;;;;;;;;;;;;UAcpC+C;IAIXj9B,YAAoBk6B;QAAA74B,aAAA64B;;IAWpBl6B,IACEk9B,GACA1+B;QAEA,IAAI+7B;QAQJ,YAPc53B,MAAVnE,KACFf,EA5gBU,YA4gBQ,OAAO4D,KAAK64B,MAAMx1B,MAAMw4B,GAAY1+B,IACtD+7B,IAAUl5B,KAAK64B,MAAMiD,IAAI3+B,GAAO0+B,OAEhCz/B,EA/gBU,YA+gBQ,OAAO4D,KAAK64B,MAAMx1B,MAAM,cAAcw4B;QACxD3C,IAAUl5B,KAAK64B,MAAMiD,IAAID,KAEpBhE,GAAkBqB;;;;;;;;WAU3Bv6B,IAAIxB;QACFf,EA7hBY,YA6hBM,OAAO4D,KAAK64B,MAAMx1B,MAAMlG,GAAOA;QAEjD,OAAO06B,GADS73B,KAAK64B,MAAMtqB,IAAIpR;;;;;;;;WAWjCwB,IAAI6B;;;QAIF,OAAOq3B,GAHS73B,KAAK64B,MAAMr3B,IAAIhB,IAGEgG,KAAKgG;;aAErBlL,MAAXkL,MACFA,IAAS,OAEXpQ,EAljBU,YAkjBQ,OAAO4D,KAAK64B,MAAMx1B,MAAM7C,GAAKgM,IACxCA;;IAIX7N,OAAO6B;QACLpE,EAxjBY,YAwjBM,UAAU4D,KAAK64B,MAAMx1B,MAAM7C;QAE7C,OAAOq3B,GADS73B,KAAK64B,MAAM5oB,OAAOzP;;;;;;;WAUpC7B;QACEvC,EApkBY,YAokBM,SAAS4D,KAAK64B,MAAMx1B;QAEtC,OAAOw0B,GADS73B,KAAK64B,MAAMt4B;;IAO7B5B,GACEo9B,GACAjuB;QAEA,MAAMmY,IAASjmB,KAAKimB,OAAOjmB,KAAKmsB,QAAQ4P,GAAcjuB,KAChD6iB,IAAuB;QAC7B,OAAO3wB,KAAKg8B,GAAc/V,GAAQ,CAACzlB,GAAKrD;YACtCwzB,EAAQlvB,KAAKtE;WACZqJ,KAAK,MACCmqB;;IAOXhyB,GACEo9B,GACAjuB;QAEA1R,EAhmBY,YAgmBM,cAAc4D,KAAK64B,MAAMx1B;QAC3C,MAAM8oB,IAAUnsB,KAAKmsB,QAAQ4P,GAAcjuB;QAC3Cqe,EAAQ8P,MAAW;QACnB,MAAMhW,IAASjmB,KAAKimB,OAAOkG;QAC3B,OAAOnsB,KAAKg8B,GAAc/V,GAAQ,CAACzlB,GAAKrD,GAAO++B,MAOtCA,EAAQjsB;;IAuBnBtR,GACEw9B,GACArL;QAEA,IAAI3E;QACC2E,IAIH3E,IAAUgQ,KAHVhQ,IAAU,IACV2E,IAAWqL;QAIb,MAAMlW,IAASjmB,KAAKimB,OAAOkG;QAC3B,OAAOnsB,KAAKg8B,GAAc/V,GAAQ6K;;;;;;;;;WAWpCnyB,GACEmyB;QAEA,MAAMsL,IAAgBp8B,KAAKimB,OAAO;QAClC,OAAO,IAAI4K,GAAmB,CAACU,GAASC;YACtC4K,EAAc5C,UAAWH;gBACvB,MAAMt8B,IAAQu+B,GACXjC,EAAMvxB,OAA4B;gBAErC0pB,EAAOz0B;eAETq/B,EAAchD,YAAaC;gBACzB,MAAMpT,IAA8BoT,EAAMvxB,OAAsB0E;gBAC3DyZ,IAKL6K,EAAS7K,EAAOoW,YAAuBpW,EAAO9oB,OAAOqJ,KACnD81B;oBACMA,IACFrW,EAAOsW,aAEPhL;qBATJA;;;;IAiBA5yB,GACNy9B,GACAt7B;QAEA,MAAM6vB,IAA2C;QACjD,OAAO,IAAIE,GAAmB,CAACU,GAASC;YACtC4K,EAAc5C,UAAWH;gBACvB7H,EAAQ6H,EAAMvxB,OAAsB/K;eAEtCq/B,EAAchD,YAAaC;gBACzB,MAAMpT,IAA8BoT,EAAMvxB,OAAsB0E;gBAChE,KAAKyZ,GAEH,YADAsL;gBAGF,MAAMiL,IAAa,IAAI5B,GAAoB3U,IACrCwW,IAAa37B,EACjBmlB,EAAOoW,YACPpW,EAAO9oB,OACPq/B;gBAEF,IAAIC,aAAsB5L,IAAoB;oBAC5C,MAAM6L,IAAwCD,EAAWlC,MACvDzI,MACE0K,EAAW3K,QACJhB,GAAmBW,OAAOM;oBAGrCnB,EAAQlvB,KAAKi7B;;gBAEXF,EAAWzL,KACbQ,MACkC,SAAzBiL,EAAWG,KACpB1W,EAAOsW,aAEPtW,EAAOsW,SAASC,EAAWG;;WAG9Bn2B,KAAK,MACCqqB,GAAmBuB,GAAQzB;;IAI9BhyB,QACNo9B,GACAjuB;QAEA,IAAI8uB,SAAgCt7B;QAYpC,YAXqBA,MAAjBy6B,MAC0B,mBAAjBA,IACTa,IAAYb,IAMZjuB,IAAQiuB,IAGL;YAAEx8B,OAAOq9B;YAAW9uB,OAAAA;;;IAGrBnP,OAAOwtB;QACb,IAAI3H,IAAgC;QAIpC,IAHI2H,EAAQ0Q,YACVrY,IAAY,SAEV2H,EAAQ5sB,OAAO;YACjB,MAAMA,IAAQS,KAAK64B,MAAMt5B,MAAM4sB,EAAQ5sB;YACvC,OAAI4sB,EAAQ8P,KACH18B,EAAMu9B,cAAc3Q,EAAQre,OAAO0W,KAEnCjlB,EAAMw9B,WAAW5Q,EAAQre,OAAO0W;;QAGzC,OAAOxkB,KAAK64B,MAAMkE,WAAW5Q,EAAQre,OAAO0W;;;;;;;GASlD,UAASqT,GAAeqB;IACtB,OAAO,IAAIrI,GAAsB,CAACU,GAASC;QACzC0H,EAAQE,YAAaC;YACnB,MAAM7sB,IAAU6sB,EAAMvxB,OAAsB0E;YAC5C+kB,EAAQ/kB;WAGV0sB,EAAQM,UAAWH;YACjB,MAAMt8B,IAAQu+B,GACXjC,EAAMvxB,OAA4B;YAErC0pB,EAAOz0B;;;;;0CAMb;IAAIigC,MAAmB;;AACvB,SAAS1B,GAA0Bv+B;IACjC,MAAMq7B,IAAaX,GAASE,GAAcC;IAC1C,IAAIQ,KAAc,QAAQA,IAAa,IAAI;QACzC,MAAM6E,IACJ;QACF,IAAIlgC,EAAMU,QAAQkI,QAAQs3B,MAAc,GAAG;;YAEzC,MAAMC,IAAW,IAAIj6B,EACnB,YACA,6CAA6Cg6B;YAY/C,OARKD,OACHA,MAAmB;;;YAGnBG,WAAW;gBACT,MAAMD;eACL,KAEEA;;;IAGX,OAAOngC;;;;;;;;;;;;;;;;;;;iFC/zBOqgC;;;IAGd,OAAyB,sBAAXtF,SAAyBA,SAAS;;;mFAIlCrD;;;IAGd,OAA2B,sBAAb1e,WAA2BA,WAAW;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;MCiEzCsnB;IAOX1+B,YACmB2+B,GACR5G,GACA6G,GACQ50B,GACA60B;kBAJAF,aACR5G,aACA6G,GACQv9B,UAAA2I,aACA60B,GAPnBx9B,UAA4B,IAAIs2B;QAmFhCt2B,YAAOA,KAAKy9B,GAASlH,QAAQmH,KAAKC,KAAK39B,KAAKy9B,GAASlH;;;;QAvEnDv2B,KAAKy9B,GAASlH,QAAQgE,MAAMzI;;;;;;;;;;;;;;;WAiB9BnzB,UACE2+B,GACA5G,GACAkH,GACAj1B,GACA60B;QAEA,MAAMK,IAAan6B,KAAKC,QAAQi6B,GAC1BE,IAAY,IAAIT,GACpBC,GACA5G,GACAmH,GACAl1B,GACA60B;QAGF,OADAM,EAAU3vB,MAAMyvB,IACTE;;;;;WAODn/B,MAAMi/B;QACZ59B,KAAK+9B,KAAcZ,WAAW,MAAMn9B,KAAKg+B,MAAsBJ;;;;;WAOjEj/B;QACE,OAAOqB,KAAKg+B;;;;;;;;WAUdr/B,OAAOs/B;QACoB,SAArBj+B,KAAK+9B,OACP/9B,KAAKk+B,gBACLl+B,KAAKy9B,GAASjM,OACZ,IAAIvuB,EACFlB,EAAKE,WACL,yBAAyBg8B,IAAS,OAAOA,IAAS;;IAQlDt/B;QACNqB,KAAKs9B,GAAWa,GAAiB,MACN,SAArBn+B,KAAK+9B,MACP/9B,KAAKk+B,gBACEl+B,KAAK2I,KAAK+0B,KAAKlxB,KACbxM,KAAKy9B,GAASlM,QAAQ/kB,OAGxBilB,QAAQF;;IAKb5yB;QACmB,SAArBqB,KAAK+9B,OACP/9B,KAAKw9B,GAAgBx9B,OACrBk+B,aAAal+B,KAAK+9B,KAClB/9B,KAAK+9B,KAAc;;;;MAKZK;IA4CXz/B;;QA1CAqB,UAAiCyxB,QAAQF;;;QAIzCvxB,UAAmD;;;QAInDA,WAAmC;;;QAInCA,UAA8D;;QAG9DA,UAAwB;;;QAIxBA,WAA8B;;QAG9BA,UAAoC;;QAGpCA,UAAkB,IAAIw2B,GAAmBx2B;;;;QAKzCA,UAAwC;YACtC,MAAM+V,IAAW0e;YACb1e,KACF3Z,EAvNU,cAyNR,iCACA2Z,EAASsoB,kBAGbr+B,KAAKs+B,GAAQC;;QAIb,MAAMxoB,IAAW0e;QACb1e,KAAiD,qBAA9BA,EAASyoB,oBAC9BzoB,EAASyoB,iBAAiB,oBAAoBx+B,KAAKy+B;;;;IAMvDC;QACE,OAAO1+B,KAAK2+B;;;;;WAOdhgC,GAAoCgK;;QAElC3I,KAAK4+B,QAAQj2B;;;;;WAOfhK,GACEgK;QAEA3I,KAAK6+B;;QAEL7+B,KAAK8+B,GAAgBn2B;;;;;WAOfhK,GACNgK;QAGA,OADA3I,KAAK6+B,MACE7+B,KAAK8+B,GAAgBn2B;;;;;;;;WAU9BhK,SAAiCgK;QAE/B,IADA3I,KAAK6+B,OACA7+B,KAAK2+B,IAAiB;YACzB3+B,KAAK2+B,MAAkB;YACvB,MAAM5oB,IAAW0e;YACb1e,KAAoD,qBAAjCA,EAASgpB,uBAC9BhpB,EAASgpB,oBACP,oBACA/+B,KAAKy+B;kBAGHz+B,KAAKg/B,GAAyBr2B;;;;;;WAQxChK,QAA2BgK;QAEzB,OADA3I,KAAK6+B,MACD7+B,KAAK2+B,KAEA,IAAIlN,QAAWF,WAEjBvxB,KAAK8+B,GAAgBn2B;;;;;;;;;WAW9BhK,GAAiBgK;QACf3I,KAAKi/B,GAAax9B,KAAKkH,IACvB3I,KAAKm+B,GAAiB,MAAMn+B,KAAKk/B;;;;;WAO3BvgC;QACN,IAAiC,MAA7BqB,KAAKi/B,GAAangC,QAAtB;YAIA;sBACQkB,KAAKi/B,GAAa,MACxBj/B,KAAKi/B,GAAaE,SAClBn/B,KAAKs+B,GAAQxH;cACb,OAAOx5B;gBACP,KAAI49B,GAA4B59B,IAG9B,MAAMA;;gCAFNlB,EA5UQ,cA4UU,4CAA4CkB;;YAM9D0C,KAAKi/B,GAAangC,SAAS;;;;;;;;;;;YAW7BkB,KAAKs+B,GAAQc,GAAc,MAAMp/B,KAAKk/B;;;IAIlCvgC,GAAmCgK;QACzC,MAAM02B,IAAUr/B,KAAKs/B,GAAK5B,KAAK,OAC7B19B,KAAKu/B,MAAsB,GACpB52B,IACJ4xB,MAAOx9B;YACNiD,KAAKxC,KAAUT,GACfiD,KAAKu/B,MAAsB;;;;YAO3B,MALA1iC,EAAS;;;;;;YA+JnB,SAA2BE;gBACzB,IAAIU,IAAUV,EAAMU,WAAW;gBAC3BV,EAAMyiC,UAEN/hC,IADEV,EAAMyiC,MAAMC,SAAS1iC,EAAMU,WACnBV,EAAMyiC,QAENziC,EAAMU,UAAU,OAAOV,EAAMyiC;gBAG3C,OAAO/hC;;;;;;;;;;;;;;;;;GAzKiBiiC,EAAkB3iC,KAM5BA;WAEP2gC,KAAKlxB,MACJxM,KAAKu/B,MAAsB,GACpB/yB;QAIb,OADAxM,KAAKs/B,KAAOD,GACLA;;;;;;WAQT1gC,GACE+3B,GACAkH,GACAj1B;QAEA3I,KAAK6+B;;QAQD7+B,KAAK2/B,GAAeh6B,QAAQ+wB,MAAY,MAC1CkH,IAAU;QAGZ,MAAME,IAAYT,GAAiBuC,GACjC5/B,MACA02B,GACAkH,GACAj1B,GACAk3B,KACE7/B,KAAK8/B,GAAuBD;QAGhC,OADA7/B,KAAK+/B,GAAkBt+B,KAAKq8B,IACrBA;;IAGDn/B;QACFqB,KAAKxC,MACPD;;;;;;;WAUJoB;;;;WAWAA;;;;;QAKE,IAAIqhC;QACJ;YACEA,IAAchgC,KAAKs/B,UACbU;iBACCA,MAAgBhgC,KAAKs/B;;;;;WAOhC3gC,GAAyB+3B;QACvB,KAAK,MAAM/tB,KAAM3I,KAAK+/B,IACpB,IAAIp3B,EAAG+tB,OAAYA,GACjB,QAAO;QAGX,QAAO;;;;;;;;WAUT/3B,GAA6BshC;;QAE3B,OAAOjgC,KAAKkgC,KAAQxC,KAAK;;YAEvB19B,KAAK+/B,GAAkBvlB,KAAK,CAAC2lB,GAAGC,MAAMD,EAAE5C,KAAe6C,EAAE7C;YAEzD,KAAK,MAAM50B,KAAM3I,KAAK+/B,IAEpB,IADAp3B,EAAG6uB,0BACCyI,KAA+Bt3B,EAAG+tB,OAAYuJ,GAChD;YAIJ,OAAOjgC,KAAKkgC;;;;;WAOhBvhC,GAAqB+3B;QACnB12B,KAAK2/B,GAAel+B,KAAKi1B;;iEAInB/3B,GAAuBgK;;QAE7B,MAAMpJ,IAAQS,KAAK+/B,GAAkBp6B,QAAQgD;QAE7C3I,KAAK+/B,GAAkBr+B,OAAOnC,GAAO;;;;;;;aAQzB8gC,GACd/iC,GACAjB;IAGA,IADAQ,EA3fc,cA2fI,GAAGR,MAAQiB,MACzB49B,GAA4B59B,IAC9B,OAAO,IAAI2F,EAAelB,EAAKgB,aAAa,GAAG1G,MAAQiB;IAEvD,MAAMA;;;ACtbV,SAASgjC,IACNC,GAAWC,KACXC,GAAWC;IAEZ,MAAMC,IAAS1hC,EAAoBshC,GAAWE;IAC9C,OAAe,MAAXE,IAGK1hC,EAAoBuhC,GAAQE,KAE5BC;;;;;;;GASX,OAAMC;IAOJjiC,YAA6BkiC;kBAAAA,GANrB7gC,cAAiC,IAAI0N,GAC3C4yB,KAGFtgC,UAAwB;;IAIhBrB;QACN,SAASqB,KAAK8gC;;IAGhBniC,GAAW6L;QACT,MAAMu2B,IAAqB,EAACv2B,GAAgBxK,KAAKghC;QACjD,IAAIhhC,KAAKmK,OAAOnF,OAAOhF,KAAK6gC,IAC1B7gC,KAAKmK,SAASnK,KAAKmK,OAAOoE,IAAIwyB,SACzB;YACL,MAAME,IAAejhC,KAAKmK,OAAO+2B;YAC7BZ,GAAsBS,GAAOE,KAAgB,MAC/CjhC,KAAKmK,SAASnK,KAAKmK,OAAO8F,OAAOgxB,GAAc1yB,IAAIwyB;;;IAKzDI;;;;;;;QAOE,OAAOnhC,KAAKmK,OAAO+2B,OAAQ;;;;AAiB/B,MAAME,KAA6B;IACjCC,KAAQ;IACRC,IAA0B;IAC1BC,IAAgB;IAChBC,IAAkB;;;MAGPC;IA2BX9iC;;;IAGW+iC;;IAEAC;;;IAGAC;kBALAF,aAEAC,aAGAC;;IA5BXjjC,UAAqBkjC;QACnB,OAAO,IAAIJ,GACTI,GACAJ,GAAUK,IACVL,GAAUM;;;;AAVdN,SAAuC,GACvCA,QAA2C,SAC3CA,QAA2C,UAC3CA,QAAwD,IACxDA,QAAkE,KAUlEA,QAAqC,IAAIA,GACvCA,GAAUO,IACVP,GAAUK,IACVL,GAAUM;AAGZN,QAAsC,IAAIA,GACxCA,GAAUQ,IACV,GACA;;;;;;MAwBSC;IAIXvjC,YACmBwjC,GACA7E;kBADA6E,aACA7E,GALnBt9B,WAA0B,GAOxBA,KAAKoiC,KAAS;;IAGhBzjC,MAAM0jC;QAMFriC,KAAKmiC,GAAiBG,OAAOZ,OAC7BD,GAAUQ,MAEVjiC,KAAKuiC,GAAWF;;IAIpB1jC;QACMqB,KAAKoiC,OACPpiC,KAAKoiC,GAAOpL,UACZh3B,KAAKoiC,KAAS;;IAIlBI;QACE,OAAuB,SAAhBxiC,KAAKoiC;;IAGNzjC,GAAW0jC;QAKjB,MAAMI,IAAQziC,KAAK0iC,KA9CK,MAFA;QAiDxBtmC,EACE,uBACA,mCAAmCqmC,QAErCziC,KAAKoiC,KAASpiC,KAAKs9B,GAAW/F,yDAE5BkL,GACAE;YACE3iC,KAAKoiC,KAAS,MACdpiC,KAAK0iC,MAAS;YACd;sBACQL,EAAWO,GAAe5iC,KAAKmiC;cACrC,OAAO7kC;gBACH49B,GAA4B59B,KAC9BlB,EAlPI,uBAoPF,wDACAkB,WAGIulC,GAAyBvlC;;kBAG7B0C,KAAKuiC,GAAWF;;;;;8DAOjBS;IACXnkC,YACmBokC,GACRT;kBADQS,GACR/iC,cAAAsiC;;iGAIX3jC,GACEi6B,GACAoK;QAEA,OAAOhjC,KAAK+iC,GAASE,GAAuBrK,GAAKpyB,KAAK08B,KAC7C3kC,KAAKC,MAAOwkC,IAAa,MAASE;;oFAK7CvkC,GACEi6B,GACAjsB;QAEA,IAAU,MAANA,GACF,OAAOkkB,GAAmBU,QAAQsE,GAAesN;QAGnD,MAAMh5B,IAAS,IAAIy2B,GAA4Bj0B;QAC/C,OAAO3M,KAAK+iC,GACT3uB,GAAcwkB,GAAK9wB,KAAUqC,EAAOi5B,GAAWt7B,EAAO0C,iBACtDhE,KAAK,MACGxG,KAAK+iC,GAASM,GACnBzK,GACApuB,KAAkBL,EAAOi5B,GAAW54B,KAGvChE,KAAK,MAAM2D,EAAOg3B;;;;;WAOvBxiC,GACEi6B,GACA0K,GACAC;QAEA,OAAOvjC,KAAK+iC,GAASS,GAAc5K,GAAK0K,GAAYC;;;;;WAOtD5kC,GACEi6B,GACA0K;QAEA,OAAOtjC,KAAK+iC,GAASU,GAAwB7K,GAAK0K;;IAGpD3kC,GACEi6B,GACA2K;QAEA,OACEvjC,KAAKsiC,OAAOZ,OAAiCD,GAAUQ,MAEvD7lC,EAAS,uBAAuB;QACzBy0B,GAAmBU,QAAQ6P,OAG7BphC,KAAK0jC,GAAa9K,GAAKpyB,KAAKq7B,KAC7BA,IAAY7hC,KAAKsiC,OAAOZ,MAC1BtlC,EACE,uBACA,0CAA0CylC,+BACb7hC,KAAKsiC,OAAOZ;QAEpCN,MAEAphC,KAAK2jC,GAAqB/K,GAAK2K;;IAK5C5kC,GAAai6B;QACX,OAAO54B,KAAK+iC,GAASW,GAAa9K;;IAG5Bj6B,GACNi6B,GACA2K;QAEA,IAAIK,GACAC,GAAkCC,GAElCC,GACFC,GACAC,GACAC;QACF,MAAMC,IAAUzgC,KAAKC;QACrB,OAAO3D,KAAKokC,GAAqBxL,GAAK54B,KAAKsiC,OAAOX,IAC/Cn7B,KAAK69B;;QAEAA,IAAkBrkC,KAAKsiC,OAAOV,MAChCxlC,EACE,uBAEE,8DAAqB4D,KAAKsiC,OAAOV,aACzByC;QAEZR,IAA2B7jC,KAAKsiC,OAC7BV,MAEHiC,IAA2BQ,GAE7BN,IAAmBrgC,KAAKC,OAEjB3D,KAAKskC,GAAkB1L,GAAKiL,KAEpCr9B,KAAK88B,MACJM,IAA2BN,GAC3BU,IAAoBtgC,KAAKC;QAElB3D,KAAKwjC,GACV5K,GACAgL,GACAL,KAGH/8B,KAAK+9B,MACJT,IAAiBS,GACjBN,IAAmBvgC,KAAKC,OAEjB3D,KAAKyjC,GAAwB7K,GAAKgL,KAE1Cp9B,KAAKg+B;YAGJ,IAFAN,IAAqBxgC,KAAKC,OAEtBzH,OAAiBK,EAASC,OAAO;gBAWnCJ,EAAS,uBARP,gDAAwB2nC,IAAmBI,yCACPN,WACjCG,IAAoBD,KAAvB,SACA,aAAaD,mBACVG,IAAmBD,KAAtB,SACA,aAAaQ,qBACVN,IAAqBD,KAAxB,SACA,mBAAmBC,IAAqBC;;YAI5C,OAAOtT,GAAmBU,QAAoB;gBAC5C8P,KAAQ;gBACRC,IAA0BuC;gBAC1BtC,IAAAuC;gBACAtC,IAAAgD;;;;;;;;;;;;;;;;;;;;;;;;;SCvXMC,GAAmB/+B;IACjC,IAAI8G,IAAS;IACb,KAAK,IAAIlO,IAAI,GAAGA,IAAIoH,EAAK5G,QAAQR,KAC3BkO,EAAO1N,SAAS,MAClB0N,IAASk4B,GAAgBl4B,KAE3BA,IAASm4B,GAAcj/B,EAAKlE,IAAIlD,IAAIkO;IAEtC,OAAOk4B,GAAgBl4B;;;wEAIzB,UAASm4B,GAAc7/B,GAAiB8/B;IACtC,IAAIp4B,IAASo4B;IACb,MAAM9lC,IAASgG,EAAQhG;IACvB,KAAK,IAAIR,IAAI,GAAGA,IAAIQ,GAAQR,KAAK;QAC/B,MAAMiI,IAAIzB,EAAQ9F,OAAOV;QACzB,QAAQiI;UACN,KAAK;YACHiG,KAAUq4B;YACV;;UACF,KA7Ba;YA8BXr4B,KAAUq4B;YACV;;UACF;YACEr4B,KAAUjG;;;IAGhB,OAAOiG;;;qDAIT,UAASk4B,GAAgBl4B;IACvB,OAAOA,IAAAA;;;;;;;;aASOs4B,GAAmBp/B;;;IAGjC,MAAM5G,IAAS4G,EAAK5G;IAEpB,IArFoCnB,EAoFzBmB,KAAU,IACN,MAAXA,GAKF,OAJAnB,EAxDe,QAyDb+H,EAAK1G,OAAO,MAxDW,QAwDU0G,EAAK1G,OAAO,KAGxCsG,EAAasZ;;;QAKtB,MAAMmmB,IAA4BjmC,IAAS,GAErC0F,IAAqB;IAC3B,IAAIwgC,IAAiB;IAErB,KAAK,IAAI72B,IAAQ,GAAGA,IAAQrP,KAAU;;;QAGpC,MAAMoG,IAAMQ,EAAKC,QAzEF,KAyEsBwI;SACjCjJ,IAAM,KAAKA,IAAM6/B,MACnBxnC;QAIF,QADamI,EAAK1G,OAAOkG,IAAM;UAE7B,KA/EuB;YAgFrB,MAAM+/B,IAAev/B,EAAKw/B,UAAU/2B,GAAOjJ;YAC3C,IAAIJ;YAC0B,MAA1BkgC,EAAelmC;;;YAGjBgG,IAAUmgC,KAEVD,KAAkBC,GAClBngC,IAAUkgC,GACVA,IAAiB,KAEnBxgC,EAAS/C,KAAKqD;YACd;;UACF,KA5Fa;YA6FXkgC,KAAkBt/B,EAAKw/B,UAAU/2B,GAAOjJ,IACxC8/B,KAAkB;YAClB;;UACF,KA/FgB;;YAiGdA,KAAkBt/B,EAAKw/B,UAAU/2B,GAAOjJ,IAAM;YAC9C;;UACF;YACE3H;;QAGJ4Q,IAAQjJ,IAAM;;IAGhB,OAAO,IAAII,EAAad;;;;;;;;;;;;;;;;;;;6DCxHb2gC;IACXxmC,YAAqBymC;kBAAAA;;;;8EAIPC,GACdC,GACAC;IAEA,IAAIA,EAAUxvB,UACZ,gBpB+VFuH,GACAvH,GACAkT;QAEA,MAAMzoB,IAAMua,GAASuC,GAAYvH,EAAc,OACzC+H,IAAUC,GAAYhI,EAASmJ,aAC/BvR,IAAO,IAAIwR,GAAY;YAAEzI,UAAU;gBAAEC,QAAQZ,EAASY;;;QAC5D,OAAO,IAAI5C,GAASvT,GAAKsd,GAASnQ,GAAM;YACtCsb,yBAAyBA;;KoBvWlBuc,CACLF,EAAgBF,IAChBG,EAAUxvB,YACRwvB,EAAUtc;IAET,IAAIsc,EAAUE,YAAY;QAC/B,MAAMjlC,IAAMiG,EAAYi/B,EAAaH,EAAUE,WAAW//B,OACpDoY,IAAU6nB,GAAgBJ,EAAUE,WAAWnmB;QACrD,OAAO,IAAIrL,GAAWzT,GAAKsd,GAAS;YAClCmL,yBAAyBsc,EAAUtc;;;IAEhC,IAAIsc,EAAUK,iBAAiB;QACpC,MAAMplC,IAAMiG,EAAYi/B,EAAaH,EAAUK,gBAAgBlgC,OACzDoY,IAAU6nB,GAAgBJ,EAAUK,gBAAgB9nB;QAC1D,OAAO,IAAIqL,GAAgB3oB,GAAKsd;;IAEhC,OAtDiBvgB;;;wDA2DLsoC,GACdP,GACAzc,GACAvJ;IAEA,MAAMwmB,IAAaC,GAAiBzmB,IAC9B0mB,IAAand,EAASroB,IAAIkF,KAAKke,IAAUre;IAC/C,IAAIsjB,aAAoB9U,IAAU;QAChC,MAAM/D,apBmTRsN,GACAvH;YAMA,OAAO;gBACL1S,MAAMkb,GAAOjB,GAAYvH,EAASvV;gBAClCmW,QAAQZ,EAASkwB,KAAUvvB,SAASC;gBACpCuI,YAAYzB,GAAYH,GAAYvH,EAAS+H,QAAQL;;SoB7TzCyoB,CAAWZ,EAAgBF,IAAkBvc,IACnDI,IAAwBJ,EAASI;QACvC,OAAO,IAAIkd;+BACc;0BACL,MAClBn2B,GACAiZ,GACA6c,GACAE;;IAEG,IAAInd,aAAoB5U,IAAY;QACzC,MAAMvO,IAAOmjB,EAASroB,IAAIkF,KAAKH,KACzB+Z,IAAW8mB,GAAcvd,EAAS/K,UAClCmL,IAAwBJ,EAASI;QACvC,OAAO,IAAIkd;+BACc,MACvB,IAAIE,GAAa3gC,GAAM4Z;wBACP,MAChB2J,GACA6c,GACAE;;IAEG,IAAInd,aAAoBM,IAAiB;QAC9C,MAAMzjB,IAAOmjB,EAASroB,IAAIkF,KAAKH,KACzB+Z,IAAW8mB,GAAcvd,EAAS/K;QACxC,OAAO,IAAIqoB,GACT,IAAIG,GAAkB5gC,GAAM4Z;0BACV;wBACF;sCACa,GAC7BwmB,GACAE;;IAGF,OArGiBzoC;;;SAyGLwoC,GACdt7B;IAEA,MAAMrG,IAAYqG,EAAgBgT;IAClC,OAAO,EAACrZ,EAAUb,SAASa,EAAUZ;;;SAGvB+iC,GACdC;IAEA,MAAMpiC,IAAY,IAAId,EAAUkjC,EAAe,IAAIA,EAAe;IAClE,OAAOriC,EAAgB6Z,EAAc5Z;;;AAGvC,SAASgiC,GAAc37B;IACrB,MAAMrG,IAAYqG,EAAgBgT;IAClC,OAAO,IAAIgpB,GAAYriC,EAAUb,SAASa,EAAUZ;;;AAGtD,SAASmiC,GAAgBe;IACvB,MAAMtiC,IAAY,IAAId,EAAUojC,EAAYnjC,SAASmjC,EAAYljC;IACjE,OAAOW,EAAgB6Z,EAAc5Z;;;;;SAyBvBuiC,GACdrB,GACAsB;IAEA,MAAM/W,KAAiB+W,EAAQ/W,iBAAiB,IAAInzB,IAAI0zB,KACtD/N,GAAaijB,EAAgBF,IAAkBhV,KAE3CN,IAAY8W,EAAQ9W,UAAUpzB,IAAI0zB,KACtC/N,GAAaijB,EAAgBF,IAAkBhV,KAE3ChsB,IAAYd,EAAUG,WAAWmjC,EAAQC;IAC/C,OAAO,IAAIlX,GACTiX,EAAQhX,SACRxrB,GACAyrB,GACAC;;;mDAKYgX,GAAaC;IAC3B,MAAMjpB,IAAU6nB,GAAgBoB,EAASznB,WACnC5U,SACsCpJ,MAA1CylC,EAASr8B,+BACLi7B,GAAgBoB,EAASr8B,gCACzBvG,EAAgBkB;IAEtB,IAAIyC;QpB0lBJk/B;IoBplBA,YA4DsD1lC,MAjElCylC,EAASl2B,MAiEWQ,apB1NlB1T,EAsvBV,OAJZqpC,IoBxlB+BD,EAASl2B,OpB0lBVQ,UAAWvS;IoB1lBvCgJ,IpBgmBK8d,GAAcgH,GAAgBlO,GADxBsoB,EAAgB31B,UAAW,SoB7lBtCvJ,IAAS+c,GAAgBkiB,EAASl2B,QAE7B,IAAIxG,GACTvC,GACAi/B,EAASz8B,2BAETy8B,EAASE,0BACTnpB,GACApT,GACAf,GAAWgS,iBAAiBorB,EAASp8B;;;wEAKzBu8B,GACd5B,GACApwB;IASA,MAAMwxB,IAAcN,GAAclxB,EAAWzK,IACvC08B,IAA2Bf,GAC/BlxB,EAAWxK;IAEb,IAAI08B;IAEFA,IADEj+B,GAAiB+L,EAAWpN,UACjBwb,GACXgiB,EAAgBF,IAChBlwB,EAAWpN,UAGAyb,GACX+hB,EAAgBF,IAChBlwB,EAAWpN;;;QAMf,MAAM6C,IAAcuK,EAAWvK,YAAYmQ;;QAG3C,OAAO,IAAIusB,GACTnyB,EAAW5K,UACXzC,EAAeqN,EAAWpN,SAC1B4+B,GACA/7B,GACAuK,EAAW1K,gBACX28B,GACAC;;;;;;;;;;;;;;;;;;;;;;;MChNSE;IAeX3oC;;;;;IAKU4oC,GACSjqB,GACAkW,GACAgU;QAHTxnC,cAAAunC,GACSvnC,kBAAAsd,aACAkW,aACAgU;;;;;;;;;;;;;QAVnBxnC,UAAgC;;;;;;WAkBhCrB,UACE8oC,GACAnqB,GACAkW,GACAgU;;;;;QAMA7pC,EAAwB,OAAb8pC,EAAKC;QAChB,MAAMH,IAASE,EAAKE,OAAoBF,EAAKC,MAAO;QACpD,OAAO,IAAIJ,GACTC,GACAjqB,GACAkW,GACAgU;;IAIJ7oC,GAAW8zB;QACT,IAAI5H,KAAQ;QACZ,MAAM/c,IAAQ85B,YAAYja,MACxB,EAAC3tB,KAAKunC,QAAQrgC,OAAO2gC,qBACrB,EAAC7nC,KAAKunC,QAAQrgC,OAAO4gC;QAEvB,OAAOC,GAAetV,GACnBuV,GACC;YAAEzoC,OAAO0oC,GAAgBC;YAAoBp6B,OAAAA;WAC7C,CAACtN,GAAKrD,GAAO++B;YACXrR,KAAQ,GACRqR,EAAQrK;WAGXrrB,KAAK,MAAMqkB;;IAGhBlsB,GACE8zB,GACA3b,GACA+Y,GACAC;QAEA,MAAMqY,IAAgBC,GAAuB3V,IACvC4V,IAAgBN,GAAetV;;;;;;;;;;QAYrC,OAAO4V,EAAc95B,IAAI,IAAW/H,KAAKopB;YAnGhCjyB,EAqGc,mBAAZiyB;YAIT,MAAMY,IAAQ,IAAIb,GAChBC,GACA9Y,GACA+Y,GACAC,IAEI8W,aDIVtB,GACAiC,GACA/W;gBAEA,MAAM8X,IAA0B9X,EAAMX,cAAcnzB,IAAI0zB,KACtD/P,GAAWilB,EAAgBF,IAAkBhV,KAEzCmY,IAAsB/X,EAAMV,UAAUpzB,IAAI0zB,KAC9C/P,GAAWilB,EAAgBF,IAAkBhV;gBAE/C,OAAO,IAAI6X,GACTV,GACA/W,EAAMZ,SACNY,EAAM1Z,GAAe/S,YACrBukC,GACAC;aCnBkBC,CAAkBxoC,KAAKsd,YAAYtd,KAAKunC,QAAQ/W,IAE1D2B,IAA4C;YAClD,IAAIsW,IAAoB,IAAI/6B,GAAwB,CAAC6a,GAAGC,MACtDvpB,EAAoBspB,EAAE9iB,KAAmB+iB,EAAE/iB;YAE7C,KAAK,MAAM6a,KAAYwP,GAAW;gBAChC,MAAM4Y,IAAWC,GAAmBnoC,IAClCR,KAAKunC,QACLjnB,EAAS9f,IAAIkF,MACbkqB;gBAEF6Y,IAAoBA,EAAkBl6B,IAAI+R,EAAS9f,IAAIkF,KAAKke,MAC5DuO,EAAS1wB,KAAK4mC,EAAcvM,IAAI8K,KAChCzU,EAAS1wB,KACP0mC,EAAcrM,IAAI4M,GAAUC,GAAmBC;;YAcnD,OAVAH,EAAkB5nC,QAAQ4iB;gBACxB0O,EAAS1wB,KACPzB,KAAKwzB,GAAaqV,GAA2BpW,GAAahP;gBAI9DgP,EAAYqW,GAAuB;gBACjC9oC,KAAK+oC,GAAsBnZ,KAAWY,EAAMnhB;gBAGvCwhB,GAAmBuB,GAAQD,GAAU3rB,KAAK,MAAMgqB;;;IAI3D7xB,GACE8zB,GACA7C;QAEA,OAAOmY,GAAetV,GACnBjxB,IAAIouB,GACJppB,KAAKogC,KACAA,KACFjpC,EACEipC,EAAQW,WAAWvnC,KAAKunC,SAGnBZ,GAAoB3mC,KAAKsd,YAAYspB,MAEvC;;;;;;;;;IAWbjoC,GACE8zB,GACA7C;QAEA,OAAI5vB,KAAK+oC,GAAsBnZ,KACtBiB,GAAmBU,QACxBvxB,KAAK+oC,GAAsBnZ,MAGtB5vB,KAAKgpC,GAAoBvW,GAAa7C,GAASppB,KAAKgqB;YACzD,IAAIA,GAAO;gBACT,MAAMnhB,IAAOmhB,EAAMnhB;gBAEnB,OADArP,KAAK+oC,GAAsBnZ,KAAWvgB,GAC/BA;;YAEP,OAAO;;;IAMf1Q,GACE8zB,GACA7C;QAEA,MAAMqZ,IAAcrZ,IAAU,GAExB9hB,IAAQ85B,YAAYsB,WAAW,EAAClpC,KAAKunC,QAAQ0B;QACnD,IAAIE,IAAmC;QACvC,OAAOpB,GAAetV,GACnBuV,GACC;YAAEzoC,OAAO0oC,GAAgBC;YAAoBp6B,OAAAA;WAC7C,CAACtN,GAAKomC,GAAS1K;YACT0K,EAAQW,WAAWvnC,KAAKunC,WAC1B5pC,EACEipC,EAAQhX,WAAWqZ,IAGrBE,IAAaxC,GAAoB3mC,KAAKsd,YAAYspB,KAEpD1K,EAAQrK;WAGXrrB,KAAK,MAAM2iC;;IAGhBxqC,GACE8zB;QAEA,MAAM3kB,IAAQ85B,YAAYtE,WAAW,EACnCtjC,KAAKunC,QACLrgC,OAAO4gC;QAGT,IAAIlY,KfnOuB;QeoO3B,OAAOmY,GAAetV,GACnBuV,GACC;YAAEzoC,OAAO0oC,GAAgBC;YAAoBp6B,OAAAA;YAAO+uB,UAAS;WAC7D,CAACr8B,GAAKomC,GAAS1K;YACbtM,IAAUgX,EAAQhX,SAClBsM,EAAQrK;WAGXrrB,KAAK,MAAMopB;;IAGhBjxB,GACE8zB;QAEA,MAAM3kB,IAAQ85B,YAAYja,MACxB,EAAC3tB,KAAKunC,SfnPmB,KeoPzB,EAACvnC,KAAKunC,QAAQrgC,OAAO4gC;QAEvB,OAAOC,GAAetV,GACnB2W,GAAQnB,GAAgBC,oBAAoBp6B,GAC5CtH,KAAK6iC,KACJA,EAAU3sC,IAAIkqC,KAAWD,GAAoB3mC,KAAKsd,YAAYspB;;IAIpEjoC,GACE8zB,GACAC;;;QAIA,MAAM4W,IAAcX,GAAmBY,cACrCvpC,KAAKunC,QACL7U,EAAYhtB,OAER8jC,IAAa5B,YAAYsB,WAAWI,IAEpC3Y,IAA2B;QACjC,OAAOyX,GAAuB3V,GAC3BuV,GAAQ;YAAEl6B,OAAO07B;WAAc,CAACd,GAAU/mC,GAAGu6B;YAC5C,OAAOuN,GAAQC,GAAa9Z,KAAW8Y,GASjChjC,IAAOo/B,GAAmB4E;;;;;;;;wBAChC,IAAID,MAAWzpC,KAAKunC,UAAW7U,EAAYhtB,KAAKpB,QAAQoB;;YAKxD,OAAOqiC,GAAetV,GACnBjxB,IAAIouB,GACJppB,KAAK8Z;gBACJ,KAAKA,GACH,MA/SQ/iB;gBAsTVI,EACE2iB,EAASinB,WAAWvnC,KAAKunC,SAG3B5W,EAAQlvB,KAAKklC,GAAoB3mC,KAAKsd,YAAYgD;;YAnBpD4b,EAAQrK;WAsBXrrB,KAAK,MAAMmqB;;IAGhBhyB,GACE8zB,GACAI;QAEA,IAAI8W,IAAiB,IAAIj8B,GAAmBzO;QAE5C,MAAMkzB,IAA4C;QAiClD,OAhCAU,EAAahyB,QAAQ6xB;YACnB,MAAM8W,IAAab,GAAmBY,cACpCvpC,KAAKunC,QACL7U,EAAYhtB,OAERoI,IAAQ85B,YAAYsB,WAAWM,IAE/BjT,IAAU6R,GAAuB3V,GAAauV,GAClD;gBAAEl6B,OAAAA;eACF,CAAC46B,GAAU/mC,GAAGu6B;gBACZ,OAAOuN,GAAQC,GAAaE,KAAWlB,GASjChjC,IAAOo/B,GAAmB4E;;;;;;;;gCAC5BD,MAAWzpC,KAAKunC,UAAW7U,EAAYhtB,KAAKpB,QAAQoB,KAKxDikC,IAAiBA,EAAep7B,IAAIq7B,KAJlC1N,EAAQrK;;YAQdM,EAAS1wB,KAAK80B;YAGT1F,GAAmBuB,GAAQD,GAAU3rB,KAAK,MAC/CxG,KAAK6pC,GAAsBpX,GAAakX;;IAI5ChrC,GACE8zB,GACA5hB;QAWA,MAAMi5B,IAAYj5B,EAAMnL,MAClBqkC,IAA0BD,EAAUhrC,SAAS,GAa7CwqC,IAAcX,GAAmBY,cACrCvpC,KAAKunC,QACLuC,IAEIN,IAAa5B,YAAYsB,WAAWI;;;;QAK1C,IAAIK,IAAiB,IAAIj8B,GAAmBzO;QAC5C,OAAOmpC,GAAuB3V,GAC3BuV,GAAQ;YAAEl6B,OAAO07B;WAAc,CAACd,GAAU/mC,GAAGu6B;YAC5C,OAAOuN,GAAQC,GAAaE,KAAWlB,GACjChjC,IAAOo/B,GAAmB4E;YAC5BD,MAAWzpC,KAAKunC,UAAWuC,EAAUxhB,EAAW5iB;;;;;;YAShDA,EAAK5G,WAAWirC,MAGpBJ,IAAiBA,EAAep7B,IAAIq7B,MAXlC1N,EAAQrK;WAaXrrB,KAAK,MAAMxG,KAAK6pC,GAAsBpX,GAAakX;;IAGhDhrC,GACN8zB,GACAuX;QAEA,MAAMrZ,IAA2B,IAC3BwB,IAA4C;;QAsBlD,OApBA6X,EAASnpC,QAAQ+uB;YACfuC,EAAS1wB,KACPsmC,GAAetV,GACZjxB,IAAIouB,GACJppB,KAAK8Z;gBACJ,IAAiB,SAAbA,GACF,MAnbQ/iB;gBAybVI,EACE2iB,EAASinB,WAAWvnC,KAAKunC,SAG3B5W,EAAQlvB,KAAKklC,GAAoB3mC,KAAKsd,YAAYgD;;YAInDuQ,GAAmBuB,GAAQD,GAAU3rB,KAAK,MAAMmqB;;IAGzDhyB,GACE8zB,GACAjC;QAEA,OAAOyZ,GACJxX,EAAqCyX,IACtClqC,KAAKunC,QACL/W,GACAhqB,KAAK4L,MACLqgB,EAAYqW,GAAuB;YACjC9oC,KAAKmqC,GAAyB3Z,EAAMZ;YAE/BiB,GAAmBhwB,QACxBuR,GACC5R,KACQR,KAAKwnC,GAAkB4C,GAC5B3X,GACAjyB;;;;;;;;;;;IAgBV7B,GAAyBixB;eAChB5vB,KAAK+oC,GAAsBnZ;;IAGpCjxB,GACEi6B;QAEA,OAAO54B,KAAKqqC,GAAWzR,GAAKpyB,KAAKqkB;YAC/B,KAAKA,GACH,OAAOgG,GAAmBU;;;wBAK5B,MAAM+Y,IAAa1C,YAAYsB,WAC7BP,GAAmB4B,cAAcvqC,KAAKunC,UAElCiD,IAA6C;YACnD,OAAOpC,GAAuBxP,GAC3BoP,GAAQ;gBAAEl6B,OAAOw8B;eAAc,CAAC9pC,GAAKmB,GAAGu6B;gBAEvC,IADe17B,EAAI,OACJR,KAAKunC,QAGb;oBACL,MAAM7hC,IAAOo/B,GAAmBtkC,EAAI;oBACpCgqC,EAA2B/oC,KAAKiE;uBAJhCw2B,EAAQrK;eAOXrrB,KAAK;gBACJ7I,EACwC,MAAtC6sC,EAA2B1rC;;;;IASrCH,GACEi6B,GACAp4B;QAEA,OAAOiqC,GAAyB7R,GAAK54B,KAAKunC,QAAQ/mC;;;;IAK5C7B,GACN8zB;QAEA,OAAOiY,GAAoBjY,GACxBjxB,IAAIxB,KAAKunC,QACT/gC,KAAMmkC,KAEHA,KACA,IAAIC,GACF5qC,KAAKunC,Sf/gBc;6BeihBE;;;;;;;GAWjC,UAASkD,GACP7R,GACA2O,GACA/mC;IAEA,MAAMkoC,IAAWC,GAAmBY,cAAchC,GAAQ/mC,EAAIkF,OACxDgkC,IAAchB,EAAS,IACvB4B,IAAa1C,YAAYsB,WAAWR;IAC1C,IAAImC,KAAc;IAClB,OAAOzC,GAAuBxP,GAC3BoP,GAAQ;QAAEl6B,OAAOw8B;QAAYQ,KAAU;OAAQ,CAACtqC,GAAKrD,GAAO++B;QAC3D,OAAOuN,GAAQsB,eAAqBppC,KAAKnB;QACrCipC,MAAWlC,KAAUwD,MAAYrB,MACnCmB,KAAc,IAEhB3O,EAAQrK;OAETrrB,KAAK,MAAMqkC;;;;;;;;SAyBAZ,GACdrR,GACA2O,GACA/W;IAEA,MAAM6X,IAAgBzP,EAAIC,MACxBoP,GAAgBpP,QAEZmS,IAAWpS,EAAIC,MACnB8P,GAAmB9P,QAEf1G,IAA4C,IAE5CrkB,IAAQ85B,YAAYqD,KAAKza,EAAMZ;IACrC,IAAIsb,IAAa;IACjB,MAAMC,IAAgB9C,EAAcL,GAClC;QAAEl6B,OAAAA;OACF,CAACtN,GAAKrD,GAAO++B,OACXgP,KACOhP,EAAQjsB;IAGnBkiB,EAAS1wB,KACP0pC,EAAc3kC,KAAK;QAzlBV7I,EA2lBU,MAAfutC;;IAMN,MAAM94B,IAAkC;IACxC,KAAK,MAAMkO,KAAYkQ,EAAMV,WAAW;QACtC,MAAM4Y,IAAWC,GAAmBnoC,IAClC+mC,GACAjnB,EAAS9f,IAAIkF,MACb8qB,EAAMZ;QAERuC,EAAS1wB,KAAKupC,EAAS/6B,OAAOy4B,KAC9Bt2B,EAAiB3Q,KAAK6e,EAAS9f;;IAEjC,OAAOqwB,GAAmBuB,GAAQD,GAAU3rB,KAAK,MAAM4L;;;;;GAMzD,UAAS21B,GACPnP;IAEA,OAAOwS,GAAqBC,GAC1BzS,GACAqP,GAAgBpP;;;;;GAOpB,UAASuP,GACPxP;IAEA,OAAOwS,GAAqBC,GAG1BzS,GAAK+P,GAAmB9P;;;;;GAM5B,UAAS6R,GACP9R;IAEA,OAAOwS,GAAqBC,GAC1BzS,GACAgS,GAAgB/R;;;;;;;;;;;;;;;;;;UC7nBPyS;;;;;IAKX3sC,YACW2e,GACQkW;QADRxzB,kBAAAsd,aACQkW;;;;;;;WASX70B,GACN8zB,GACAjyB,GACAwP;QAGA,OADsBu7B,GAAqB9Y,GACtBqJ,IAAI0P,GAAMhrC,IAAMwP;;;;;;;WAS/BrR,GACN8zB,GACAC;QAEA,MAAMmG,IAAQ0S,GAAqB9Y,IAC7BjyB,IAAMgrC,GAAM9Y;QAClB,OAAOmG,EAAM5oB,OAAOzP;;;;;;;WASd7B,eACN8zB,GACAgZ;QAEA,OAAOzrC,KAAK0rC,YAAYjZ,GAAajsB,KAAKmkC,MACxCA,EAASgB,YAAYF,GACdzrC,KAAK4rC,GAAYnZ,GAAakY;;IAIzChsC,GACE8zB,GACAC;QAEA,OAAO6Y,GAAqB9Y,GACzBjxB,IAAIgqC,GAAM9Y,IACVlsB,KAAKqlC,KACG7rC,KAAK8rC,GAAoBD;;;;;;;WAUtCltC,GACE8zB,GACAC;QAEA,OAAO6Y,GAAqB9Y,GACzBjxB,IAAIgqC,GAAM9Y,IACVlsB,KAAKqlC;YACJ,MAAM77B,IAAMhQ,KAAK8rC,GAAoBD;YACrC,OAAO77B,IACH;gBACE+7B,IAAe/7B;gBACfhL,MAAMgnC;gBAER;;;IAIVrtC,WACE8zB,GACAI;QAEA,IAAIlC,IAAU5hB;QACd,OAAO/O,KAAKisC,GACVxZ,GACAI,GACA,CAACryB,GAAKqrC;YACJ,MAAM77B,IAAMhQ,KAAK8rC,GAAoBD;YACrClb,IAAUA,EAAQrlB,GAAO9K,GAAKwP;WAEhCxJ,KAAK,MAAMmqB;;;;;;;;;WAWfhyB,GACE8zB,GACAI;QAEA,IAAIlC,IAAU5hB,MACVm9B,IAAU,IAAIhhC,GAA+BzE,EAAYpH;QAC7D,OAAOW,KAAKisC,GACVxZ,GACAI,GACA,CAACryB,GAAKqrC;YACJ,MAAM77B,IAAMhQ,KAAK8rC,GAAoBD;YACjC77B,KACF2gB,IAAUA,EAAQrlB,GAAO9K,GAAKwP,IAC9Bk8B,IAAUA,EAAQ5gC,GAAO9K,GAAKwrC,WAE9Brb,IAAUA,EAAQrlB,GAAO9K,GAAK,OAC9B0rC,IAAUA,EAAQ5gC,GAAO9K,GAAK;WAGlCgG,KAAK,OACE;YAAE2lC,IAAgBxb;YAASyb,IAAAF;;;IAI9BvtC,GACN8zB,GACAI,GACA/B;QAEA,IAAI+B,EAAa9xB,KACf,OAAO8vB,GAAmBU;QAG5B,MAAMzjB,IAAQ85B,YAAYja,MACxBkF,EAAa5X,QAASvV,KAAKH,KAC3BstB,EAAaqO,OAAQx7B,KAAKH,MAEtB8mC,IAAUxZ,EAAazkB;QAC7B,IAAI6sB,IAA8BoR,EAAQn+B;QAE1C,OAAOq9B,GAAqB9Y,GACzBuV,GAAQ;YAAEl6B,OAAAA;WAAS,CAACw+B,GAAiBT,GAAa3P;YACjD,MAAMqQ,IAAe9lC,EAAYi/B,EAAa4G;;wBAG9C,MAAOrR,KAAWx0B,EAAYpH,KAAqBktC,KAAgB,KACjEzb,KAAmB,OACnBmK,IAAUoR,EAAQn+B;YAGhB+sB,KAAWA,EAAS32B,QAAQioC;;YAE9Bzb,KAAmB+a,IACnB5Q,IAAUoR,EAAQp+B,OAAYo+B,EAAQn+B,OAAY;;YAIhD+sB,IACFiB,EAAQsQ,GAAKvR,EAASv1B,KAAKH,OAE3B22B,EAAQrK;WAGXrrB,KAAK;;;YAGJ,MAAOy0B,KACLnK,KAAmB,OACnBmK,IAAUoR,EAAQp+B,OAAYo+B,EAAQn+B,OAAY;;;IAK1DvP,GACE8zB,GACA5hB,GACAujB;QAMA,IAAIzD,IAAU1hB;QAEd,MAAMw9B,IAA8B57B,EAAMnL,KAAK5G,SAAS,GAElD4tC,IAAmC;QACzC,IAAItY,EAAc9vB,QAAQH,EAAgBkB,QAAQ;;;YAGhD,MAAM+G,IAAWyE,EAAMnL,KAAKH;YAC5BmnC,EAAiB5+B,QAAQ85B,YAAYsB,WAAW98B;eAC3C;;;;YAIL,MAAMugC,IAAgB97B,EAAMnL,KAAKH,KAC3BqnC,IAAc7G,GAAiB3R;YACrCsY,EAAiB5+B,QAAQ85B,YAAYsB,WACnC,EAACyD,GAAeC;yBACJ,IAEdF,EAAiBntC,QAAQ4mC,GAAiB0G;;QAG5C,OAAOtB,GAAqB9Y,GACzBuV,GAAQ0E,GAAkB,CAAClsC,GAAKqrC,GAAa3P;;;;;;YAM5C,IAAI17B,EAAI1B,WAAW2tC,GACjB;YAGF,MAAM5jB,IAAWwc,GAAqBrlC,KAAKsd,YAAYuuB;YAClDh7B,EAAMnL,KAAK4iB,EAAWO,EAASroB,IAAIkF,QAGtCmjB,aAAoB9U,MACpBga,GAAald,GAAOgY,OAEpB8H,IAAUA,EAAQrlB,GAAOud,EAASroB,KAAKqoB,MALvCqT,EAAQrK;WAQXrrB,KAAK,MAAMmqB;;;;;;;IAQhBhyB,GACE8zB,GACA2B;QAKA,IAAI0Y,IAAch+B,MAEdi+B,IAAehH,GAAiB3R;QAEpC,MAAM4Y,IAAiBzB,GAAqB9Y,IACtC3kB,IAAQ85B,YAAYsB,WAAW6D,IAAc;QACnD,OAAOC,EACJhF,GACC;YAAEzoC,OAAO4mC,GAAiB8G;YAAen/B,OAAAA;WACzC,CAACnM,GAAGkqC;;;YAGF,MAAM77B,IAAMq1B,GAAqBrlC,KAAKsd,YAAYuuB;YAClDiB,IAAcA,EAAYxhC,GAAO0E,EAAIxP,KAAKwP,IAC1C+8B,IAAelB,EAAqB;WAGvCrlC,KAAK,OACG;YACL0mC,IAAAJ;YACAxtB,UAAUinB,GAAmBwG;;;;;;;;IAUrCpuC,GACE8zB;QAEA,MAAMua,IAAiBzB,GAAqB9Y;;gBAG5C,IAAInT,IAAWnb,EAAgBkB;QAE/B,OAAO2nC,EACJhF,GACC;YAAEzoC,OAAO4mC,GAAiB8G;YAAepQ,UAAS;WAClD,CAACr8B,GAAKqrC,GAAa3P;YACb2P,EAAYvsB,aACdA,IAAWinB,GAAmBsF,EAAYvsB,YAE5C4c,EAAQrK;WAGXrrB,KAAK,MAAM8Y;;IAGhB3gB,GAAgBwtB;QAGd,OAAO,IAAImf,GAA6BjZ,GACtCryB,QACEmsB,KAAWA,EAAQghB;;IAIzBxuC,GAAQi6B;QACN,OAAO54B,KAAK0rC,YAAY9S,GAAKpyB,KAAKmkC,KAAYA,EAASgB;;IAGjDhtC,YACNi6B;QAEA,OAAOwU,GAAoBxU,GACxBp3B,IAAI6rC,GAAuB7sC,KAC3BgG,KAAKmkC,MA/UDhtC,IAgVUgtC,IACNA;;IAILhsC,GACNi6B,GACA+R;QAEA,OAAOyC,GAAoBxU,GAAKkD,IAAIuR,GAAuB7sC,KAAKmqC;;;;;WAO1DhsC,GACNktC;QAEA,IAAIA,GAAa;YACf,MAAM77B,IAAMq1B,GAAqBrlC,KAAKsd,YAAYuuB;YAClD,OACE77B,aAAeiE,MACfjE,EAAI8N,QAAQxZ,QAAQH,EAAgBkB,SAI7B,OAGF2K;;QAET,OAAO;;;;;;;;;;GAuIX,UAASo9B,GACPxU;IAEA,OAAOwS,GAAqBC,GAG1BzS,GAAKyU,GAAuBxU;;;;;GAMhC,UAAS0S,GACP3S;IAEA,OAAOwS,GAAqBC,GAC1BzS,GACAuN,GAAiBtN;;;AAIrB,SAAS2S,GAAMzb;IACb,OAAOA,EAAOrqB,KAAKH;;;;;aAMLymC,GAAeh8B;IAC7B,IAAI7S;IACJ,IAAI6S,EAAI+F,UACN5Y,IAAQ6S,EAAI+F,eACP,IAAI/F,EAAI41B,iBACbzoC,IAAQ6S,EAAI41B,sBACP;QAAA,KAAI51B,EAAIy1B,YAGb,MA/iB0BloC;QA6iB1BJ,IAAQ6S,EAAIy1B;;IAId,OAAOroC,KAAKC,UAAUF,GAAO2B;;;;;;;;;;;;;;;;;;;;;GApK7BwsC,SAA4C,cAAcjZ;;;;;;IAYxD1zB,YACmB2uC,GACAH;QAEjBhqC,mBAHiBmqC,aACAH;;QAZnBntC,UAA0D,IAAIgB,EAC5DR,KAAOA,EAAI4C,YACX,CAACmlB,GAAGC,MAAMD,EAAEjkB,QAAQkkB;;IAeZ7pB,GACR8zB;QAEA,MAAMN,IAA4C;QAElD,IAAIsZ,IAAY,GAEZhD,IAAoB,IAAI/6B,GAAwB,CAAC6a,GAAGC,MACtDvpB,EAAoBspB,EAAE9iB,KAAmB+iB,EAAE/iB;QAwD7C,OArDAzF,KAAK2Q,GAAQ9P,QAAQ,CAACL,GAAK+xB;YACzB,MAAMgb,IAAevtC,KAAKwtC,GAAchsC,IAAIhB;YAK5C,IAAI+xB,GAAe;gBAKjB,MAAMviB,IAAM61B,GACV7lC,KAAKstC,GAAchwB,YACnBiV,GACAvyB,KAAKsf;gBAEPmpB,IAAoBA,EAAkBl6B,IAAI/N,EAAIkF,KAAKke;gBAEnD,MAAM5e,IAAOgnC,GAAeh8B;gBAC5By7B,KAAazmC,OACbmtB,EAAS1wB,KAAKzB,KAAKstC,GAAcG,GAAShb,GAAajyB,GAAKwP;mBAG5D,IADAy7B,QACIzrC,KAAKmtC,IAAe;;;;;gBAKtB,MAAMO,IAAa7H,GACjB7lC,KAAKstC,GAAchwB,YACnB,IAAIrJ,GAAWzT,GAAK2D,EAAgBkB,QACpCrF,KAAKsf;gBAEP6S,EAAS1wB,KACPzB,KAAKstC,GAAcG,GAAShb,GAAajyB,GAAKktC;mBAGhDvb,EAAS1wB,KAAKzB,KAAKstC,GAAcK,GAAYlb,GAAajyB;YAKhEioC,EAAkB5nC,QAAQ4iB;YACxB0O,EAAS1wB,KACPzB,KAAKstC,GAAc9Z,GAAaqV,GAC9BpW,GACAhP;YAKN0O,EAAS1wB,KAAKzB,KAAKstC,GAAcM,eAAenb,GAAagZ,KAEtD5a,GAAmBuB,GAAQD;;IAG1BxzB,GACR8zB,GACAC;;QAGA,OAAO1yB,KAAKstC,GACTO,GAAcpb,GAAaC,GAC3BlsB,KAAKsnC,KACc,SAAdA,KACF9tC,KAAKwtC,GAAcl+B,IAAIojB,GAAa,IAC7B,SAEP1yB,KAAKwtC,GAAcl+B,IAAIojB,GAAaob,EAAU9oC;QACvC8oC,EAAUvb;;IAKf5zB,GACR8zB,GACAI;;;QAIA,OAAO7yB,KAAKstC,GACTS,GAAgBtb,GAAaI,GAC7BrsB,KAAK,EAAG2lC,IAAA6B,GAAgB5B,IAAAF;;;;QAIvBA,EAAQrrC,QAAQ,CAAC6xB,GAAa1tB;YAC5BhF,KAAKwtC,GAAcl+B,IAAIojB,GAAa1tB;YAE/BgpC;;;;MCtgBJC;IAAbtvC;QACEqB,UAAgC,IAAIkuC;;IAEpCvvC,GACE8zB,GACA0b;QAGA,OADAnuC,KAAKouC,GAAsB7/B,IAAI4/B,IACxBtd,GAAmBU;;IAG5B5yB,GACE8zB,GACA7rB;QAEA,OAAOiqB,GAAmBU,QACxBvxB,KAAKouC,GAAsBra,WAAWntB;;;;;;;;UAU/BsnC;IAAbvvC;QACUqB,aAAQ;;;IAKhBrB,IAAIwvC;QAEF,MAAMvnC,IAAeunC,EAAetqB,KAC9BmiB,IAAamI,EAAevqB,KAC5ByqB,IACJruC,KAAKT,MAAMqH,MACX,IAAI8G,GAAwBpI,EAAajG,IACrCivC,KAASD,EAAgB//B,IAAI03B;QAEnC,OADAhmC,KAAKT,MAAMqH,KAAgBynC,EAAgB9/B,IAAIy3B,IACxCsI;;IAGT3vC,IAAIwvC;QACF,MAAMvnC,IAAeunC,EAAetqB,KAC9BmiB,IAAamI,EAAevqB,KAC5ByqB,IAAkBruC,KAAKT,MAAMqH;QACnC,OAAOynC,KAAmBA,EAAgB//B,IAAI03B;;IAGhDrnC,WAAWiI;QAIT,QAFE5G,KAAKT,MAAMqH,MACX,IAAI8G,GAAwBpI,EAAajG,IACxBkG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;MCpBVgpC;IACX5vC,YAA6B2e;QAAAtd,kBAAAsd;;;;;;;;WAS7B3e,gBACEs6B,GACAL,GACA7a,GACAF;QAhCYlgB,EAmCVogB,IAAcF,KACZE,KAAe,KACfF,KAtBsB;QA0B1B,MAAMqsB,IAAsB,IAAI7P,GAAoBzB;QAEhD7a,IAAc,KAAKF,KAAa,MA6SxC,SAAkCob;YAChCA,EAAGuV,kBAAkBC,GAAgB5V;;;;;;;GA7SjC6V,EAAyBzV,IA+Z/B,SAA6BA;YAC3BA,EAAGuV,kBAAkB5D,GAAgB/R,OAAO;gBAC1CkS,SAASH,GAAgBG;;YAGE9R,EAAGuV,kBAAkBvG,GAAgBpP,OAAO;gBACvEkS,SAAS9C,GAAgB8C;gBACzB4D,gBAAe;eAEIC,YACnB3G,GAAgBC,oBAChBD,GAAgB4G,sBAChB;gBAAEC,SAAQ;gBAGZ7V,EAAGuV,kBAAkB7F,GAAmB9P;;;;;GA7apCkW,EAAoB9V,IACpB+V,GAAiB/V,IA4gBvB,SAAmCA;YACjCA,EAAGuV,kBAAkBrI,GAAiBtN;;;;;GA5gBlCoW,EAA0BhW;;;gBAM5B,IAAI5J,IAAIwB,GAAmBU;QA+D3B,OA9DIxT,IAAc,KAAKF,KAAa;;;QAGd,MAAhBE,OAm4BV,SAAwBkb;YACtBA,EAAGiW,kBAAkBC,GAAiBtW,QACtCI,EAAGiW,kBAAkB7H,GAASxO,QAC9BI,EAAGiW,kBAAkBE,GAAevW;SAr4B9BwW,CAAepW,IACf+V,GAAiB/V,KAEnB5J,IAAIA,EAAE7oB,KAAK;;;;;;QAg5BjB,SACEoyB;YAEA,MAAM0W,IAAc1W,EAAIC,MACtBuW,GAAevW,QAEX8R,IAAW,IAAIyE;iCACE;0CACS,GAC9BjrC,EAAgBkB,MAAMoY;6BACL;YAEnB,OAAO6xB,EAAYxT,IAAIsT,GAAe5uC,KAAKmqC;;;;;GA55BtB4E,EAA4BrF,MAG3CnsB,IAAc,KAAKF,KAAa,MACd,MAAhBE;;;;;;;QAOFsR,IAAIA,EAAE7oB,KAAK,MAyZnB,SACEyyB,GACAL;YAKA,OAHyBA,EAAIC,MAC3BoP,GAAgBpP,OAEMuQ,KAAU5iC,KAAKgpC;gBACrCvW,EAAGiW,kBAAkBjH,GAAgBpP;gBAEdI,EAAGuV,kBAAkBvG,GAAgBpP,OAAO;oBACjEkS,SAAS9C,GAAgB8C;oBACzB4D,gBAAe;mBAEFC,YACb3G,GAAgBC,oBAChBD,GAAgB4G,sBAChB;oBAAEC,SAAQ;;gBAGZ,MAAMW,IAAmB7W,EAAIC,MAC3BoP,GAAgBpP,QAEZ6W,IAAWF,EAAkB9yC,IAAI4jB,KACrCmvB,EAAiB3T,IAAIxb;gBAGvB,OAAOuQ,GAAmBuB,GAAQsd;;;;;;;;;GAnb5BC,EAAyC1W,GAAIiR,MAIjD7a,IAAIA,EAAE7oB,KAAK;aAg8BjB,SAAmCyyB;gBACjCA,EAAGuV,kBAAkBoB,GAAiB/W,OAAO;oBAC3CkS,SAAS6E,GAAiB7E;;;kCAj8BtB8E;aAA0B5W;aAI1Blb,IAAc,KAAKF,KAAa,MAClCwR,IAAIA,EAAE7oB,KAAK,MAAMxG,KAAK8vC,4BAA4B5F;QAGhDnsB,IAAc,KAAKF,KAAa,MAClCwR,IAAIA,EAAE7oB,KAAK,OA0lBjB,SAAmCyyB;YACjCA,EAAGuV,kBAAkBnB,GAAuBxU;;;;;;;;;;GA1lBtCkX,EAA0B9W,IACnBj5B,KAAKgwC,kBAAkB9F,OAI9BnsB,IAAc,KAAKF,KAAa,MAClCwR,IAAIA,EAAE7oB,KAAK,MAAMxG,KAAKiwC,sBAAsB/F;QAG1CnsB,IAAc,KAAKF,KAAa,MAClCwR,IAAIA,EAAE7oB,KAAK,MACTxG,KAAKkwC,4BAA4BjX,GAAIiR,MAIrCnsB,IAAc,KAAKF,KAAa,MAClCwR,IAAIA,EAAE7oB,KAAK;;;;aA01BjB,SAAwCyyB;gBAClCA,EAAGsC,iBAAiB4U,SAAS,4BAC/BlX,EAAGiW,kBAAkB;aAx1BjBkB,CAA+BnX,IAo3BvC,SAA2CL;gBACzC,MAAMyX,IAAsBzX,EAAI+C,YAAYwK,GAAiBtN;gBAC7DwX,EAAoBzB,YAClBzI,GAAiB8G,eACjB9G,GAAiBmK,mBACjB;oBAAExB,SAAQ;oBAEZuB,EAAoBzB,YAClBzI,GAAiB0G,yBACjB1G,GAAiBoK,6BACjB;oBAAEzB,SAAQ;;;;;;;;GA73BN0B,EAAkC5X;aAIlC7a,IAAc,MAAMF,KAAa,OACnCwR,IAAIA,EAAE7oB,KAAK,MAAMxG,KAAKywC,oBAAoBvG,MAErC7a;;IAGD1wB,kBACNi6B;QAEA,IAAI8X,IAAY;QAChB,OAAO9X,EACJC,MAA6CsN,GAAiBtN,OAC9DmP,GAAQ,CAACrmC,GAAGqO;YACX0gC,KAAa1E,GAAeh8B;WAE7BxJ,KAAK;YACJ,MAAMmkC,IAAW,IAAI0C,GAAuBqD;YAC5C,OAAO9X,EACJC,MACCwU,GAAuBxU,OAExBiD,IAAIuR,GAAuB7sC,KAAKmqC;;;IAIjChsC,4BACNi6B;QAEA,MAAM+X,IAAc/X,EAAIC,MACtB+R,GAAgB/R,QAEZkP,IAAiBnP,EAAIC,MACzBoP,GAAgBpP;QAGlB,OAAO8X,EAAYvH,KAAU5iC,KAAKoqC,KACzB/f,GAAmBhwB,QAAQ+vC,GAASna;YACzC,MAAM3oB,IAAQ85B,YAAYja,MACxB,EAAC8I,EAAM8Q,SlB5Jc,KkB6JrB,EAAC9Q,EAAM8Q,QAAQ9Q,EAAMoa;YAGvB,OAAO9I,EACJqB,GAAQnB,GAAgBC,oBAAoBp6B,GAC5CtH,KAAK6iC,KACGxY,GAAmBhwB,QACxBwoC,GACCzC;gBACCjpC,EACEipC,EAAQW,WAAW9Q,EAAM8Q;gBAG3B,MAAM/W,IAAQmW,GAAoB3mC,KAAKsd,YAAYspB;gBAEnD,OAAOqD,GACLrR,GACAnC,EAAM8Q,QACN/W,GACAhqB,KAAK;;;;;;;WAYb7H,sBACNi6B;QAEA,MAAMkY,IAAsBlY,EAAIC,MAG9BsW,GAAiBtW,QACbmU,IAAiBpU,EAAIC,MACzBsN,GAAiBtN;QAMnB,OAJ0BD,EAAIC,MAC5BuW,GAAevW,OAGQr3B,IAAI4tC,GAAe5uC,KAAKgG,KAAKmkC;YAKpD,MAYMxY,IAA4C;YAClD,OAAO6a,EACJhF,GAAQ,CAACxnC,GAAKwP;gBACb,MAAMtK,IAAO,IAAIJ,EAAa9E,IACxBuwC,IA4EhB,SAAqBrrC;oBACnB,OAAO,EAAC,GAAG++B,GAAmB/+B;;;;GA7ECsrC,EAAYtrC;gBACnCysB,EAAS1wB,KACPqvC,EAAoBtvC,IAAIuvC,GAAgBvqC,KAAKyqC,KACtCA,IAGIpgB,GAAmBU,YAtBX,CACvB7rB,KAEOorC,EAAoBhV,IACzB,IAAIqT,GACF,GACA1K,GAAmB/+B,IACnBilC,EAAsC,8BAa3BuG,CAAiBxrC;eAO/Bc,KAAK,MAAMqqB,GAAmBuB,GAAQD;;;IAIrCxzB,4BACNs6B,GACAL;;QAGAK,EAAGuV,kBAAkB2C,GAAmBtY,OAAO;YAC7CkS,SAASoG,GAAmBpG;;QAG9B,MAAMqG,IAAyBxY,EAAIC,MAGjCsY,GAAmBtY,QAGfwY,IAAQ,IAAInD,IACZT,IACJU;YAEA,IAAIkD,EAAM9iC,IAAI4/B,IAAiB;gBAC7B,MAAMvnC,IAAeunC,EAAetqB,KAC9BmiB,IAAamI,EAAevqB;gBAClC,OAAOwtB,EAAuBtV,IAAI;oBAChCl1B,cAAAA;oBACA6c,QAAQghB,GAAmBuB;;;;;;QAMjC,OAAOpN,EACJC,MAA6CsN,GAAiBtN,OAC9DmP,GAAQ;YAAE8C,KAAU;WAAQ,CAACwG,GAAc3vC;YAC1C,MAAM+D,IAAO,IAAIJ,EAAagsC;YAC9B,OAAO7D,EAAS/nC,EAAKke;WAEtBpd,KAAK,MAEGoyB,EACJC,MACC8P,GAAmB9P,OAEpBmP,GAAQ;YAAE8C,KAAU;WAAQ,EAAErB,GAAQC,GAAa9Z,IAAUjuB;YAC5D,MAAM+D,IAAOo/B,GAAmB4E;YAChC,OAAO+D,EAAS/nC,EAAKke;;;IAKvBjlB,oBACNi6B;QAEA,MAAM2Y,IAAc3Y,EAAIC,MAA6BwO,GAASxO;QAC9D,OAAO0Y,EAAYvJ,GAAQ,CAACxnC,GAAKgxC;YAC/B,MAAMC,IAAqB3K,GAAa0K,IAClCE,IAAkBxK,GAAWlnC,KAAKsd,YAAYm0B;YACpD,OAAOF,EAAYzV,IAAI4V;;;;;MAYhBjL;IACX9nC,YAAmB4E,GAAwBC;QAAxBxD,eAAAuD,GAAwBvD,mBAAAwD;;;;;;;;;;;;UAkBhCirC;IAgBX9vC,YACSgzC;;IAEAC,GACAC;QAHA7xC,eAAA2xC,GAEA3xC,+BAAA4xC,GACA5xC,wBAAA6xC;;;;;;;;;;GAZFpD,YAAQ;;;;;AAMRA,SAAM;;MAuBF7D;IAOXjsC;;;;IAIS4oC;;;;;;;;;IASAsJ;;;;;;;;;;;;IAYAiB;QArBA9xC,cAAAunC,GASAvnC,+BAAA6wC,GAYA7wC,uBAAA8xC;;;;2CA9BFlH,YAAQ;;AAGRA,aAAU;;;;;;;;;MAyCN3C;IAaXtpC;;;;IAIS4oC;;;;IAIA3X;;;;;IAKAiX;;;;;;;;;;;;;IAaAhX;;;;;;IAMAC;QA5BA9vB,cAAAunC,GAIAvnC,eAAA4vB,GAKA5vB,wBAAA6mC,GAaA7mC,qBAAA6vB;QAMA7vB,iBAAA8vB;;;;2CA3CFmY,YAAQ;;AAGRA,aAAU;;AAGVA,wBAAqB;;AAGrBA,0BAAuB,EAAC,UAAU;;MAyG9BU;IA0CXhqC;;;;WAnCAA,qBAAqB4oC;QACnB,OAAO,EAACA;;;;;WAOV5oC,qBACE4oC,GACA7hC;QAEA,OAAO,EAAC6hC,GAAQ9C,GAAmB/+B;;;;;WAOrC/G,WACE4oC,GACA7hC,GACAkqB;QAEA,OAAO,EAAC2X,GAAQ9C,GAAmB/+B,IAAOkqB;;;;AA9BrC+Y,WAAQ;;;;;;;AAuCRA,iBAAc,IAAIA;;MAmBdtC;IACX1nC,YAAmB+G,GAAuB4Z;QAAvBtf,YAAA0F,GAAuB1F,gBAAAsf;;;;;;;UAO/BgnB;IACX3nC,YAAmB+G,GAAuBoY;QAAvB9d,YAAA0F,GAAuB1F,eAAA8d;;;;;;;;;;;;;;;;UAgB/BqoB;;;;;;IA8BXxnC;;;;;;IAMSinC;;;;;IAKAH;;;;;IAKA1vB;;;;;;;IAOAkT;;;;;IAMA3J;;;;;IAMA0mB;QA7BAhmC,uBAAA4lC,GAKA5lC,kBAAAylC,GAKAzlC,gBAAA+V,GAOA/V,6BAAAipB;QAMAjpB,gBAAAsf,GAMAtf,kBAAAgmC;;;;AAhEFG,WAAQ;;;;;;;AAQRA,mBAAgB,iBAEhBA,uBAAoB;;;;;;;;AASpBA,6BAA0B,2BAE1BA,iCAA8B,EAAC,cAAc;;;;;MAkDzCkH;;;;;IASX1uC,YAAmBgtC;QAAA3rC,gBAAA2rC;;;;AARZ0B,WAAQ,wBAERA,SAAM;;MAoCFhG;IAgBX1oC;;;;;;;;;IASS2L;;;;IAIArC;;;;;;IAMAqX;;;;;;;;;;;;;;;;;;IAkBA3U;;;;;;;;;;;;;;;IAeAs8B;;;;;;IAMAv8B;;;;;;;;IAQAmG;QAzDA7Q,gBAAAsK,GAIAtK,mBAAAiI,GAMAjI,gBAAAsf,GAkBAtf,mBAAA2K;QAeA3K,gCAAAinC,GAMAjnC,oCAAA0K,GAQA1K,aAAA6Q;;;;AAjFFw2B,WAAQ;;AAGRA,aAAU;;AAGVA,2BAAwB;;;;;;AAOxBA,yBAAsB,EAAC,eAAe;;;;;;;;;;;;MAwFlC8H;IAaXxwC;;;;IAIS2L;;;;IAIA5E;;;;;;IAMA8E;QAVAxK,gBAAAsK,GAIAtK,YAAA0F,GAMA1F,sBAAAwK;;;;2CAzBF2kC,YAAQ;;AAGRA,aAAU,EAAC,YAAY;;AAGvBA,0BAAuB;;AAGvBA,4BAAyB,EAAC,QAAQ;;;;;;;;MAoC9BC;IAQXzwC;;;;;;IAMSozC;;;;;;IAMAC;;;;;;;;;IASAC;;;;IAIA/O;QAnBAljC,uBAAA+xC,GAMA/xC,mCAAAgyC,GASAhyC,iCAAAiyC;QAIAjyC,mBAAAkjC;;;;;;;GA5BFkM,UAAM,mBACNA,WAAQ;;;;;;;;MA4CJ+B;IAOXxyC;;;;IAISiI;;;;;IAKA6c;QALAzjB,oBAAA4G,GAKA5G,cAAAyjB;;;;0CAIX,UAASurB,GAAiB/V;IACKA,EAAGuV,kBAAkBW,GAAiBtW,OAAO;QACxEkS,SAASoE,GAAiBpE;OAEP6D,YACnBO,GAAiB+C,sBACjB/C,GAAiBgD,wBACjB;QAAErD,SAAQ;;;IAGQ7V,EAAGuV,kBAAkBnH,GAASxO,OAAO;QACvDkS,SAAS1D,GAAS0D;OAIR6D,YACVvH,GAAS+K,uBACT/K,GAASgL,qBACT;QAAEvD,SAAQ;QAEZ7V,EAAGuV,kBAAkBY,GAAevW;;;AAtC7BsY,WAAQ;;AAGRA,aAAU,EAAC,gBAAgB;;MA8FvBvB;IAOXjxC;;;;IAKS2zC;;IAEAC;;IAEAC;;IAEAC;QANAzyC,gBAAAsyC,GAEAtyC,oBAAAuyC,GAEAvyC,sBAAAwyC,GAEAxyC,oBAAAyyC;;;;0CAhBF7C,YAAQ;;AAGRA,aAAU;;AA2BZ,MAqCM8C,KAXY,KAJA,KAJA,KAlBA,EACvB9H,GAAgB/R,OAChBoP,GAAgBpP,OAChB8P,GAAmB9P,OACnBsN,GAAiBtN,OACjBwO,GAASxO,OACT4V,GAAgB5V,OAChBuW,GAAevW,OACfsW,GAAiBtW,SAUqB+W,GAAiB/W,SAIjBwU,GAAuBxU,SAIvBsY,GAAmBtY;;;;;;;;;;;;;;;;;;;;;;;MCvjC9C8Z;IAAbh0C;;;;;;;;QAQEqB,UAAiC,IAAIkuC;;;;;;;;WASrCvvC,GACE8zB,GACA0b;QAGA,KAAKnuC,KAAK4yC,GAAuBtkC,IAAI6/B,IAAiB;YACpD,MAAMvnC,IAAeunC,EAAetqB,KAC9BmiB,IAAamI,EAAevqB;YAElC6O,EAAYqW,GAAuB;;;gBAGjC9oC,KAAK4yC,GAAuBrkC,IAAI4/B;;YAGlC,MAAM0E,IAAuC;gBAC3CjsC,cAAAA;gBACA6c,QAAQghB,GAAmBuB;;YAE7B,OAAOoL,GAAuB3e,GAAaqJ,IAAI+W;;QAEjD,OAAOhiB,GAAmBU;;IAG5B5yB,GACE8zB,GACA7rB;QAEA,MAAMksC,IAAc,IACdhlC,IAAQ85B,YAAYja,MACxB,EAAC/mB,GAAc,MACf,EAACpH,EAAmBoH,IAAe;wBACpB;wBACA;QAEjB,OAAOwqC,GAAuB3e,GAC3B2W,GAAQt7B,GACRtH,KAAK5E;YACJ,KAAK,MAAMm/B,KAASn/B,GAAS;;;;;gBAK3B,IAAIm/B,EAAMn6B,iBAAiBA,GACzB;gBAEFksC,EAAYrxC,KAAKqjC,GAAmB/D,EAAMtd;;YAE5C,OAAOqvB;;;;;;;;GASf,UAAS1B,GACPxY;IAEA,OAAOwS,GAAqBC,GAG1BzS,GAAKuY,GAAmBtY;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;MC/Efka;IACXp0C,YAAoBq0C;kBAAAA;;IAEpBr0C;QAEE,OADAqB,KAAKgzC,MApBM,GAqBJhzC,KAAKgzC;;IAGdr0C;;;;;QAKE,OAAO,IAAIo0C,GAAkB;;IAG/Bp0C;;QAEE,OAAO,IAAIo0C,IAAkB;;;;;;;;;;;;;;;;;;;UCJpBE;IACXt0C,YACmB6oC,GACTlqB;kBADSkqB,GACTxnC,kBAAAsd;;;;;;;;IAUV3e,GACE8zB;QAEA,OAAOzyB,KAAKkzC,GAAiBzgB,GAAajsB,KAAKmkC;YAC7C,MAAMwI,IAAoB,IAAIJ,GAAkBpI,EAASoH;YAEzD,OADApH,EAASoH,kBAAkBoB,EAAkB3sC,QACtCxG,KAAKozC,GAAa3gB,GAAakY,GAAUnkC,KAC9C,MAAMmkC,EAASoH;;;IAKrBpzC,GACE8zB;QAEA,OAAOzyB,KAAKkzC,GAAiBzgB,GAAajsB,KAAKmkC,KACtCxmC,EAAgB6Z,EACrB,IAAI1a,EACFqnC,EAASsH,0BAA0B1uC,SACnConC,EAASsH,0BAA0BzuC;;IAM3C7E,GACE8zB;QAEA,OAAOzyB,KAAKkzC,GAAiBzgB,GAAajsB,KACxC6sC,KAAgBA,EAAarB;;IAIjCrzC,GACE8zB,GACAuf,GACAC;QAEA,OAAOjyC,KAAKkzC,GAAiBzgB,GAAajsB,KAAKmkC,MAC7CA,EAASqH,8BAA8BA,GACnCC,MACFtH,EAASsH,4BAA4BA,EAA0Bx0B;QAE7Du0B,IAA8BrH,EAASqH,gCACzCrH,EAASqH,8BAA8BA,IAElChyC,KAAKozC,GAAa3gB,GAAakY;;IAI1ChsC,GACE8zB,GACAvd;QAEA,OAAOlV,KAAKszC,GAAe7gB,GAAavd,GAAY1O,KAAK,MAChDxG,KAAKkzC,GAAiBzgB,GAAajsB,KAAKmkC,MAC7CA,EAASzH,eAAe,GACxBljC,KAAKuzC,GAA6Br+B,GAAYy1B;QACvC3qC,KAAKozC,GAAa3gB,GAAakY;;IAK5ChsC,GACE8zB,GACAvd;QAEA,OAAOlV,KAAKszC,GAAe7gB,GAAavd;;IAG1CvW,GACE8zB,GACAvd;QAEA,OAAOlV,KAAKwzC,GAA8B/gB,GAAavd,EAAW5K,UAC/D9D,KAAK,MAAMitC,GAAahhB,GAAaxiB,OAAOiF,EAAW5K,WACvD9D,KAAK,MAAMxG,KAAKkzC,GAAiBzgB,IACjCjsB,KAAKmkC,MACJhtC,EACEgtC,EAASzH,cAAc;QAGzByH,EAASzH,eAAe,GACjBljC,KAAKozC,GAAa3gB,GAAakY;;;;;;WAS5ChsC,GACEi6B,GACA0K,GACAC;QAEA,IAAIhjC,IAAQ;QACZ,MAAM4xB,IAA4C;QAClD,OAAOshB,GAAa7a,GACjBoP,GAAQ,CAACxnC,GAAKrD;YACb,MAAM+X,IAAa4xB,GAAa3pC;YAE9B+X,EAAW1K,kBAAkB84B,KACgB,SAA7CC,EAAgB/hC,IAAI0T,EAAW5K,cAE/B/J,KACA4xB,EAAS1wB,KAAKzB,KAAK0zC,GAAiB9a,GAAK1jB;WAG5C1O,KAAK,MAAMqqB,GAAmBuB,GAAQD,IACtC3rB,KAAK,MAAMjG;;;;WAMhB5B,GACEi6B,GACA1wB;QAEA,OAAOurC,GAAa7a,GAAKoP,GAAQ,CAACxnC,GAAKrD;YACrC,MAAM+X,IAAa4xB,GAAa3pC;YAChC+K,EAAEgN;;;IAIEvW,GACN8zB;QAEA,OAAOkhB,GAAkBlhB,GACtBjxB,IAAI4tC,GAAe5uC,KACnBgG,KAAKmkC,MAtJFhtC,EAuJsB,SAAbgtC,IACJA;;IAILhsC,GACN8zB,GACAkY;QAEA,OAAOgJ,GAAkBlhB,GAAaqJ,IAAIsT,GAAe5uC,KAAKmqC;;IAGxDhsC,GACN8zB,GACAvd;QAEA,OAAOu+B,GAAahhB,GAAaqJ,IAC/BoL,GAAWlnC,KAAKsd,YAAYpI;;;;;;WASxBvW,GACNuW,GACAy1B;QAEA,IAAIiJ,KAAU;QAUd,OATI1+B,EAAW5K,WAAWqgC,EAASoH,oBACjCpH,EAASoH,kBAAkB78B,EAAW5K,UACtCspC,KAAU;QAGR1+B,EAAW1K,iBAAiBmgC,EAASqH,gCACvCrH,EAASqH,8BAA8B98B,EAAW1K;QAClDopC,KAAU,IAELA;;IAGTj1C,GACE8zB;QAEA,OAAOzyB,KAAKkzC,GAAiBzgB,GAAajsB,KACxCmkC,KAAYA,EAASzH;;IAIzBvkC,GACE8zB,GACA3qB;;;;QAKA,MAAMG,IAAcJ,EAAeC,IAC7BgG,IAAQ85B,YAAYja,MACxB,EAAC1lB,GAAaf,OAAO2gC,qBACrB,EAAC5/B,GAAaf,OAAO4gC;QAEvB,IAAIt7B,IAA4B;QAChC,OAAOinC,GAAahhB,GACjBuV,GACC;YAAEl6B,OAAAA;YAAOvO,OAAO8nC,GAAS+K;WACzB,CAAC5xC,GAAKrD,GAAO++B;YACX,MAAMjd,IAAQ6nB,GAAa3pC;;;wBAGvB0L,EAAaf,GAAQmX,EAAMnX,YAC7B0E,IAASyS,GACTid,EAAQrK;WAIbrrB,KAAK,MAAMgG;;IAGhB7N,GACEi6B,GACAvpB,GACA/E;;;QAIA,MAAM6nB,IAA4C,IAC5C0G,IAAQiY,GAAoBlY;QAMlC,OALAvpB,EAAKxO,QAAQL;YACX,MAAMkF,IAAO++B,GAAmBjkC,EAAIkF;YACpCysB,EAAS1wB,KAAKo3B,EAAMiD,IAAI,IAAIqT,GAAiB7kC,GAAU5E,MACvDysB,EAAS1wB,KAAKzB,KAAKwnC,GAAkBqM,GAAajb,GAAKtuB,GAAU9J;YAE5DqwB,GAAmBuB,GAAQD;;IAGpCxzB,GACEi6B,GACAvpB,GACA/E;;;QAIA,MAAMuuB,IAAQiY,GAAoBlY;QAClC,OAAO/H,GAAmBhwB,QAAQwO,GAAO7O;YACvC,MAAMkF,IAAO++B,GAAmBjkC,EAAIkF;YACpC,OAAOmrB,GAAmBuB,GAAQ,EAChCyG,EAAM5oB,OAAO,EAAC3F,GAAU5E,MACxB1F,KAAKwnC,GAAkBsM,GAAgBlb,GAAKtuB,GAAU9J;;;IAK5D7B,GACEi6B,GACAtuB;QAEA,MAAMuuB,IAAQiY,GAAoBlY,IAC5B9qB,IAAQ85B,YAAYja,MACxB,EAACrjB,KACD,EAACA,IAAW;wBACG;wBACA;QAEjB,OAAOuuB,EAAM5oB,OAAOnC;;IAGtBnP,GACEi6B,GACAtuB;QAEA,MAAMwD,IAAQ85B,YAAYja,MACxB,EAACrjB,KACD,EAACA,IAAW;wBACG;wBACA,IAEXuuB,IAAQiY,GAAoBlY;QAClC,IAAIpsB,IAAS4C;QAEb,OAAOypB,EACJmP,GAAQ;YAAEl6B,OAAAA;YAAOg9B,KAAU;WAAQ,CAACtqC,GAAKmB,GAAGu6B;YAC3C,MAAMx2B,IAAOo/B,GAAmBtkC,EAAI,KAC9BuvB,IAAS,IAAItpB,EAAYf;YAC/B8G,IAASA,EAAO+B,IAAIwhB;WAErBvpB,KAAK,MAAMgG;;IAGhB7N,GACEi6B,GACAp4B;QAEA,MAAMkF,IAAO++B,GAAmBjkC,EAAIkF,OAC9BoI,IAAQ85B,YAAYja,MACxB,EAACjoB,KACD,EAAClG,EAAmBkG;wBACL;wBACA;QAEjB,IAAInF,IAAQ;QACZ,OAAOuwC,MACJ9I,GACC;YACEzoC,OAAO4vC,GAAiB+C;YACxBpH,KAAU;YACVh9B,OAAAA;WAEF,EAAExD,GAAU5E,IAAO/D,GAAGu6B;;;;YAIH,MAAb5xB,MACF/J,KACA27B,EAAQrK;WAIbrrB,KAAK,MAAMjG,IAAQ;;;;;;;;;;IAWxB5B,GACE8zB,GACAnoB;QAEA,OAAOmpC,GAAahhB,GACjBjxB,IAAI8I,GACJ9D,KAAKyY,KACAA,IACK6nB,GAAa7nB,KAEb;;;;;;GASjB,UAASw0B,GACP7a;IAEA,OAAOwS,GAAqBC,GAC1BzS,GACAyO,GAASxO;;;;;GAOb,UAAS8a,GACP/a;IAEA,OAAOwS,GAAqBC,GAC1BzS,GACAwW,GAAevW;;;;;aAOHiY,GACdlY;IAEA,OAAOwS,GAAqBC,GAC1BzS,GACAuW,GAAiBtW;;;;;;;;;;;;;;;;;;GCpWrB,OAyBMkb,KACJ;;;;;UAoBWC,WAA6B9gB;IACxCv0B,YACWurC,GACA+J;QAET9wC,mBAHS+mC,aACA+J;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;UAoDA7I;IA+CXzsC;;;;;IAKmBizC,GAEAhyC,GACA0yC,GACjB4B,GACiBzd,GACAqB,GACA/hB,GACjBuH,GACiBwY;;;;;IAMAqe;QAEjB,IAjBiBn0C,+BAAA4xC,GAEA5xC,sBAAAJ,GACAI,gBAAAsyC;kBAEA7b,GACAz2B,cAAA83B,GACA93B,gBAAA+V,aAEA+f,aAMAqe,GAnDnBn0C,UAAgD;QAEhDA,WAAmB,GACXA,kBAAY,GACZA,uBAAiB;;QAIzBA,UAAmD,MAC3CA,qBAAe;;QAKvBA,UAAkE;;QAGlEA,UAAiE;;QAGjEA,UAAoCkH,OAAO2gC;;QAG3C7nC,UAAqD2B,KAAK8vB,QAAQF,YA8B3D6Z,GAAqBgJ,MACxB,MAAM,IAAInxC,EACRlB,EAAKc,eA5IX;QAiJE7C,KAAKwnC,KAAoB,IAAI6M,GAAqBr0C,MAAMk0C,IACxDl0C,KAAKs0C,KAAS10C,IAtIW,QAuIzBI,KAAKsd,aAAa,IAAI6nB,GAAgB7nB,IACtCtd,KAAKu0C,KAAW,IAAI9c,GAClBz3B,KAAKs0C,IJxMmB,II0MxB,IAAI/F,GAAgBvuC,KAAKsd;QAE3Btd,KAAKw0C,KAAc,IAAIvB,GACrBjzC,KAAKwnC,IACLxnC,KAAKsd,aAEPtd,KAAKwzB,KAAe,IAAImf,IACxB3yC,KAAKszB,KAAsB,IAAIgY,GAC7BtrC,KAAKsd,YACLtd,KAAKwzB;QAEHxzB,KAAK83B,UAAU93B,KAAK83B,OAAO2c,eAC7Bz0C,KAAK00C,KAAa10C,KAAK83B,OAAO2c,gBAE9Bz0C,KAAK00C,KAAa;SACK,MAAnBP,KACFt3C,EAvMQ,wBAyMN;;IAnGR8B,UACEi6B,GACAC;QAEA,IAAID,aAAeob,IACjB,OAAOvc,GAAS4T,GAAqBzS,EAAIsR,IAAqBrR;QAE9D,MArK0Ct7B;;;;;;WA8Q9CoB;;;;QAOE,OAAOqB,KAAK20C,KACTjX,KAAK;YACJ,KAAK19B,KAAK40C,cAAc50C,KAAK4xC;;;YAG3B,MAAM,IAAI3uC,EACRlB,EAAKW,qBACLqxC;YAQJ,OALA/zC,KAAK60C,MACL70C,KAAK80C,MAEL90C,KAAK+0C,MAEE/0C,KAAKg1C,eACV,kCACA,YACApc,KAAO54B,KAAKw0C,GAAYS,GAAyBrc;WAGpD8E,KAAKsU;YACJhyC,KAAKk1C,KAAiB,IAAIrf,GACxBmc,GACAhyC,KAAK81B;WAGR4H,KAAK;YACJ19B,KAAKm1C,MAAW;WAEjB5a,MAAM0D,MACLj+B,KAAKu0C,MAAYv0C,KAAKu0C,GAAS5Z,SACxBlJ,QAAQD,OAAOyM;;;;;;;;WAW5Bt/B,GACEy2C;QAOA,OALAp1C,KAAKo1C,KAAuBzS,MAAM0S;YAChC,IAAIr1C,KAAKs1C,IACP,OAAOF,EAAqBC;WAGzBD,EAAqBp1C,KAAK40C;;;;;;;WASnCj2C,GACE42C;QAEAv1C,KAAKu0C,GAASiB,GAAyB7S,MAAMtJ;;YAElB,SAArBA,EAAMoc,oBACFF;;;;;;;;WAWZ52C,GAAkB6zC;QACZxyC,KAAKwyC,mBAAmBA,MAC1BxyC,KAAKwyC,iBAAiBA;;;QAGtBxyC,KAAKy2B,GAAM0H,GAAiBwE;YACtB3iC,KAAKs1C,YACDt1C,KAAK20C;;;;;;;;WAYXh2C;QACN,OAAOqB,KAAKg1C,eACV,2CACA,aACApc,KACwB8c,GAAoB9c,GAEvCkD,IACC,IAAI8T,GACF5vC,KAAKsyC,UACL5uC,KAAKC,OACL3D,KAAKwyC,gBACLxyC,KAAKyyC,eAGRjsC,KAAK;YACJ,IAAIxG,KAAK40C,WACP,OAAO50C,KAAK21C,GAAmB/c,GAAKpyB,KAAKovC;gBAClCA,MACH51C,KAAK40C,aAAY,GACjB50C,KAAKy2B,GAAMof,GAAiB,MAC1B71C,KAAKo1C,IAAqB;;WAMnC5uC,KAAK,MAAMxG,KAAK81C,GAAgBld,IAChCpyB,KAAKsvC,KACA91C,KAAK40C,cAAckB,IACd91C,KAAK+1C,GAA0Bnd,GAAKpyB,KAAK,OAAM,OAC7CsvC,KACF91C,KAAKg2C,GAA4Bpd,GAAKpyB,KAAK,OAAM,KAO/D+zB,MAAMj9B;YACL,IAAI49B,GAA4B59B;;;YAI9B,OAHAlB,EAtWM,wBAsWY,kCAAkCkB,IAG7C0C,KAAK40C;YAGd,KAAK50C,KAAK4xC,yBACR,MAAMt0C;YAQR,OALAlB,EAhXQ,wBAkXN,0DACAkB;8BAEsB;WAEzBogC,KAAKkX;YACA50C,KAAK40C,cAAcA,KACrB50C,KAAKy2B,GAAMof,GAAiB,MAC1B71C,KAAKo1C,GAAqBR,KAG9B50C,KAAK40C,YAAYA;;;IAIfj2C,GACNi6B;QAGA,OADcqd,GAAmBrd,GACpBp3B,IAAIitC,GAAgBjuC,KAAKgG,KAAK0vC,KAClCrlB,GAAmBU,QAAQvxB,KAAKm2C,GAAcD;;IAIjDv3C,GACNi6B;QAGA,OADsB8c,GAAoB9c,GACrB3oB,OAAOjQ,KAAKsyC;;;;;;WAQ3B3zC;QACN,IACEqB,KAAK40C,cACJ50C,KAAKo2C,GAAYp2C,KAAKq2C,IAnZH,OAoZpB;YACAr2C,KAAKq2C,KAA4B3yC,KAAKC;YAEtC,MAAM2yC,UAAwBt2C,KAAKg1C,eACjC,uCACA,qBACApc;gBACE,MAAM2d,IAAgBnL,GAAqBC,GAGzCzS,GAAKgX,GAAiB/W;gBAExB,OAAO0d,EAAcnN,KAAU5iC,KAAKgwC;oBAClC,MAAMC,IAASz2C,KAAK02C,GAClBF,GAlaY,OAqaRG,IAAWH,EAAgB3wC,OAC/B+wC,MAAsC,MAA5BH,EAAO9wC,QAAQixC;;oBAI3B,OAAO/lB,GAAmBhwB,QACxB81C,GACCE,KACCN,EAActmC,OAAO4mC,EAAevE,WACtC9rC,KAAK,MAAMmwC;;eAGjBpc,MAAM,MAKC;;;;;;wBAQT,IAAIv6B,KAAK00C,IACP,KAAK,MAAMmC,KAAkBP,GAC3Bt2C,KAAK00C,GAAWoC,WACd92C,KAAK+2C,GAA6BF,EAAevE;;;;;;WAWnD3zC;QACNqB,KAAKg3C,KAA0Bh3C,KAAKy2B,GAAMc,2DA5bF,KA+btC,MACSv3B,KAAK20C,KACTjX,KAAK,MAAM19B,KAAKi3C,MAChBvZ,KAAK,MAAM19B,KAAK+0C;;2DAMjBp2C,GAAci4C;QACpB,SAAOA,KAASA,EAAOjF,YAAY3xC,KAAKsyC;;;;;;;;WAUlC3zC,GACNi6B;QAEA,IAAI54B,KAAKm0C,IACP,OAAOtjB,GAAmBU,SAAiB;QAG7C,OADc0kB,GAAmBrd,GAE9Bp3B,IAAIitC,GAAgBjuC,KACpBgG,KAAK0wC;;;;;;;;;;YAkBJ,IAhBqB,SAAnBA,KACAl3C,KAAKo2C,GACHc,EAAerF,kBA1eS,SA6ezB7xC,KAAKm3C,GAAgBD,EAAevF,UAWd;gBACvB,IAAI3xC,KAAKm2C,GAAce,MAAmBl3C,KAAKwyC,gBAC7C,QAAO;gBAGT,KAAKxyC,KAAKm2C,GAAce,IAAiB;oBACvC,KAAKA,EAAgBtF;;;;;;;;;;;;oBAanB,MAAM,IAAI3uC,EACRlB,EAAKW,qBACLqxC;oBAIJ,QAAO;;;YAIX,UAAI/zC,KAAKwyC,mBAAkBxyC,KAAKyyC,iBAIzBiD,GAAoB9c,GACxBwQ,KACA5iC,KAAKgwC,UAwB0Bl1C,MArBHtB,KAAK02C,GAC9BF,GA/hBsB,KAiiBtBz9B,KAAKq+B;gBACL,IAAIp3C,KAAKsyC,aAAa8E,EAAY9E,UAAU;oBAC1C,MAAM+E,KACHr3C,KAAKwyC,kBAAkB4E,EAAY5E,gBAChC8E,KACHt3C,KAAKyyC,gBAAgB2E,EAAY3E,cAC9B8E,IACJv3C,KAAKwyC,mBAAmB4E,EAAY5E;oBACtC,IACE6E,KACCC,KACCC,GAEF,QAAO;;gBAGX,QAAO;;WAKd/wC,KAAKsvC,MACA91C,KAAK40C,cAAckB,KACrB15C,EArkBM,wBAukBJ,UACE05C,IAAkB,OAAO;QAIxBA;;IAIbn3C;;;QAGEqB,KAAKm1C,MAAW,GAEhBn1C,KAAKw3C,MACDx3C,KAAKg3C,OACPh3C,KAAKg3C,GAAwBhgB,UAC7Bh3B,KAAKg3C,KAA0B,OAEjCh3C,KAAKy3C;QACLz3C,KAAK03C,YACC13C,KAAKg1C,eAAe,YAAY,aAAapc,KAC1C54B,KAAK+1C,GAA0Bnd,GAAKpyB,KAAK,MAC9CxG,KAAK23C,GAAqB/e,KAE3B2B,MAAMj9B;YACPlB,EAjmBU,wBAimBQ,8CAA8CkB;YAElE0C,KAAKu0C,GAAS5Z;;;QAId36B,KAAK43C;;;;;WAOCj5C,GACNk5C,GACAC;QAEA,OAAOD,EAAQhyC,OACb+wC,KACE52C,KAAKo2C,GAAYQ,EAAOrE,cAAcuF,OACrC93C,KAAKm3C,GAAgBP,EAAOtE;;;;;;;;WAWnC3zC;QACE,OAAOqB,KAAKg1C,eAAe,oBAAoB,YAAYpc,KAClD8c,GAAoB9c,GACxBwQ,KACA5iC,KAAKqxC,KACJ73C,KAAK02C,GAAoBmB,GA/nBT,MA+nBqCn7C,IACnDq7C,KAAkBA,EAAezF;;IAM3C9P;QACE,OAAOxiC,KAAKm1C;;IAGdx2C,GAAiB8oC;QAKf,OAAOH,GAAuB0Q,GAC5BvQ,GACAznC,KAAKsd,YACLtd,KAAKwzB,IACLxzB,KAAKwnC;;IAIT7oC;QAKE,OAAOqB,KAAKw0C;;IAGd71C;QAKE,OAAOqB,KAAKszB;;IAGd30B;QAKE,OAAOqB,KAAKwzB;;IAGd70B,eACEoN,GACAguB,GACAke;QAIA77C,EA5rBY,wBA4rBM,yBAAyB2P;QAE3C,MAAMmsC,IAAwB,eAATne,IAAsB,aAAa;QAExD,IAAIoe;;;gBAIJ,OAAOn4C,KAAKu0C,GACTS,eAAekD,GAAcxF,IAAY0F,MACxCD,IAAyB,IAAInE,GAC3BoE,GACAp4C,KAAKk1C,KACDl1C,KAAKk1C,GAAe1uC,SACpBqvB,GAAesN;QAGR,wBAATpJ,IAMK/5B,KAAK21C,GAAmBwC,GAC5B3xC,KAAK6xC,OACAA,KAGGr4C,KAAK81C,GAAgBqC,IAE7B3xC,KAAK6xC;YACJ,KAAKA,GAQH,MAPAx7C,EACE,8CAA8CkP,QAEhD/L,KAAK40C,aAAY;YACjB50C,KAAKy2B,GAAMof,GAAiB,MAC1B71C,KAAKo1C,IAAqB,KAEtB,IAAInyC,EACRlB,EAAKW,qBACLuwB;YAGJ,OAAOglB,EAAqBE;WAE7B3xC,KAAKgG,KACGxM,KAAKg2C,GACVmC,GACA3xC,KAAK,MAAMgG,MAGVxM,KAAKs4C,GACVH,GACA3xC,KAAK,MAAMyxC,EAAqBE,MAGrCza,KAAKlxB,MACJ2rC,EAAuBI;QAChB/rC;;;;;;;;IAUL7N,GACNi6B;QAGA,OADcqd,GAAmBrd,GACpBp3B,IAAIitC,GAAgBjuC,KAAKgG,KAAK0wC;YASzC,IAPqB,SAAnBA,KACAl3C,KAAKo2C,GACHc,EAAerF,kBA5vBW,SA+vB3B7xC,KAAKm3C,GAAgBD,EAAevF,aAEX3xC,KAAKm2C,GAAce,QAE1Cl3C,KAAKm0C,MACJn0C,KAAK4xC,2BACJsF,EAAgBtF,0BAEnB,MAAM,IAAI3uC,EACRlB,EAAKW,qBACLqxC;;;;;;WAWFp1C,GACNi6B;QAEA,MAAM4f,IAAa,IAAI/J,GACrBzuC,KAAKsyC,UACLtyC,KAAK4xC,yBACLluC,KAAKC;QAEP,OAAOsyC,GAAmBrd,GAAKkD,IAAI2S,GAAgBjuC,KAAKg4C;;IAG1D75C;QACE,OAAO84B,GAAS2c;;qFAIVz1C,GACNi6B;QAEA,MAAMC,IAAQod,GAAmBrd;QACjC,OAAOC,EAAMr3B,IAAIitC,GAAgBjuC,KAAKgG,KAAK0vC,KACrCl2C,KAAKm2C,GAAcD,MACrB95C,EAvzBQ,wBAuzBU;QACXy8B,EAAM5oB,OAAOw+B,GAAgBjuC,QAE7BqwB,GAAmBU;;iEAMxB5yB,GAAY4zC,GAAsBkG;QACxC,MAAM90C,IAAMD,KAAKC;QAGjB,SAAI4uC,IAFkB5uC,IAAM80C,SAIjBlG,IAHW5uC,OAIpB9G,EACE,kDAAkD01C,OALhC5uC;SAOb;;IAMHhF;QAEc,SAAlBqB,KAAK+V,YACqC,qBAAnC/V,KAAK+V,SAASyoB,qBAErBx+B,KAAK04C,KAA4B;YAC/B14C,KAAKy2B,GAAM0H,GAAiB,OAC1Bn+B,KAAKyyC,eAAkD,cAAnCzyC,KAAK+V,SAAUsoB;YAC5Br+B,KAAK20C;WAIhB30C,KAAK+V,SAASyoB,iBACZ,oBACAx+B,KAAK04C,KAGP14C,KAAKyyC,eAAiD,cAAlCzyC,KAAK+V,SAASsoB;;IAI9B1/B;QACFqB,KAAK04C,OAMP14C,KAAK+V,SAASgpB,oBACZ,oBACA/+B,KAAK04C,KAEP14C,KAAK04C,KAA4B;;;;;;;;;;;WAc7B/5C;;QACuC,oCAAlCqB,KAAK83B,qCAAQ0G,sBACtBx+B,KAAK24C,KAAsB;;;;YAIzB34C,KAAKw3C,MAELx3C,KAAKy2B,GAAM0H,GAAiB,MAGnBn+B,KAAK44C;WAGhB54C,KAAK83B,OAAO0G,iBAAiB,UAAUx+B,KAAK24C;;IAIxCh6C;QACFqB,KAAK24C,OAKP34C,KAAK83B,OAAQiH,oBAAoB,UAAU/+B,KAAK24C,KAChD34C,KAAK24C,KAAsB;;;;;;WASvBh6C,GAAgB2zC;;QACtB;YACE,MAAMuG,IAGE,wBAFN74C,KAAK00C,iCAAYoE,QACf94C,KAAK+2C,GAA6BzE;YAQtC,OANAl2C,EAt6BU,wBAw6BR,WAAWk2C,MACTuG,IAAY,OAAO;YAGhBA;UACP,OAAOv7C;;YAGP,OADAT,EA/6BU,wBA+6BQ,oCAAoCS,KAC/C;;;;;;WAQHqB;QACN,IAAKqB,KAAK00C,IAGV;YACE10C,KAAK00C,GAAWqE,QACd/4C,KAAK+2C,GAA6B/2C,KAAKsyC,WACvCruC,OAAOP,KAAKC;UAEd,OAAOrG;;YAEPT,EAAS,mCAAmCS;;;6DAKxCqB;QACN,IAAKqB,KAAK00C,IAGV;YACE10C,KAAK00C,GAAWoC,WACd92C,KAAK+2C,GAA6B/2C,KAAKsyC;UAEzC,OAAOh1C;;;;IAKHqB,GAA6B2zC;QACnC,OAAO,oBAAiCtyC,KAAKJ,kBAAkB0yC;;;;;;GAOnE,UAAS2D,GACPrd;IAEA,OAAOwS,GAAqBC,GAC1BzS,GACA6V,GAAgB5V;;;;;GAOpB,UAAS6c,GACP9c;IAEA,OAAOwS,GAAqBC,GAC1BzS,GACAgX,GAAiB/W;;;mEAKRwb;IAGX11C,YAA6Bs6B,GAA0BqJ;QAA1BtiC,UAAAi5B,GAC3Bj5B,KAAKmiC,KAAmB,IAAIW,GAAoB9iC,MAAMsiC;;IAGxD3jC,GACEi6B;QAEA,MAAMogB,IAAkBh5C,KAAKi5C,GAAsBrgB;QAEnD,OAD2B54B,KAAKi5B,GAAGigB,KAAiBC,GAAevgB,GACzCpyB,KAAK08B,KAC7B8V,EAAgBxyC,KAAK4yC,KAAYlW,IAAckW;;IAI3Cz6C,GACNi6B;QAEA,IAAIygB,IAAgB;QACpB,OAAOr5C,KAAKqjC,GAAsCzK,GAAKj3B;YACrD03C;WACC7yC,KAAK,MAAM6yC;;IAGhB16C,GACEi6B,GACA1wB;QAEA,OAAOlI,KAAKi5B,GAAGigB,KAAiB9kC,GAAcwkB,GAAK1wB;;IAGrDvJ,GACEi6B,GACA1wB;QAEA,OAAOlI,KAAKs5C,GAAwB1gB,GAAK,CAAC7I,GAAQvlB,MAChDtC,EAAEsC;;IAIN7L,GACEi6B,GACAtuB,GACA9J;QAEA,OAAO0wC,GAAiBtY,GAAKp4B;;IAG/B7B,GACEi6B,GACAtuB,GACA9J;QAEA,OAAO0wC,GAAiBtY,GAAKp4B;;IAG/B7B,GACEi6B,GACA0K,GACAC;QAEA,OAAOvjC,KAAKi5B,GACTigB,KACA1V,GAAc5K,GAAK0K,GAAYC;;IAGpC5kC,GACEi6B,GACAp4B;QAEA,OAAO0wC,GAAiBtY,GAAKp4B;;;;;;;WASvB7B,GACNi6B,GACA7I;QAEA,gBP7jBF6I,GACA7I;YAEA,IAAI9Q,KAAQ;YACZ,OAAOyrB,GAAoB9R,GACxB2gB,GAAchS,KACNkD,GAAyB7R,GAAK2O,GAAQxX,GAAQvpB,KAAKqkC,MACpDA,MACF5rB,KAAQ,IAEH4R,GAAmBU,SAASsZ,MAGtCrkC,KAAK,MAAMyY;SOgjBLu6B,CAAyB5gB,GAAK7I;;IAGvCpxB,GACEi6B,GACA0K;QAEA,MACMmW,IADgBz5C,KAAKi5B,GAAGygB,KACKC,MAE7BxnB,IAA4C;QAClD,IAAIynB,IAAgB;QAsBpB,OApBkB55C,KAAKs5C,GACrB1gB,GACA,CAAC7I,GAAQvlB;YACP,IAAIA,KAAkB84B,GAAY;gBAChC,MAAMjU,IAAIrvB,KAAK65C,GAASjhB,GAAK7I,GAAQvpB,KAAKqzC;oBACxC,KAAKA;;;oBAIH,OAHAD,KAGOH,EAAa5lB,GAAS+E,GAAK7I,GAAQvpB,KAAK,OAC7CizC,EAAa9L,GAAY5d,IAClB+gB,GAAoBlY,GAAK3oB,OAoFvC,EAAC,GAAGw0B,GApFsD1U,EAoF/BrqB;;gBAhF1BysB,EAAS1wB,KAAK4tB;;WAMjB7oB,KAAK,MAAMqqB,GAAmBuB,GAAQD,IACtC3rB,KAAK,MAAMizC,EAAajwC,MAAMovB,IAC9BpyB,KAAK,MAAMozC;;IAGhBj7C,aACEi6B,GACA1jB;QAEA,MAAM0+B,IAAU1+B,EAAW4kC,EAAmBlhB,EAAIqb;QAClD,OAAOj0C,KAAKi5B,GAAGigB,KAAiBa,GAAiBnhB,GAAKgb;;IAGxDj1C,GACEi6B,GACAp4B;QAEA,OAAO0wC,GAAiBtY,GAAKp4B;;;;;;;WASvB7B,GACNi6B,GACA1wB;QAEA,MAAM2wB,IAAQiY,GAAoBlY;QAClC,IACIohB,GADAC,IAAqCpkB,GAAesN;QAExD,OAAOtK,EACJmP,GACC;YACEzoC,OAAO4vC,GAAiB+C;WAE1B,EAAE5nC,GAAUylB,KAAWrqB,MAAAA,GAAM8E,gBAAAA;YACV,MAAbF;;;YAGE2vC,MAAiBpkB,GAAesN,MAClCj7B,EAAE,IAAIzB,EAAYq+B,GAAmBkV,KAAYC;;;;;YAMnDA,OACAD,IAAWt0C;;;YAIXu0C,IAAepkB,GAAesN;WAInC38B,KAAK;;;;YAIAyzC,MAAiBpkB,GAAesN,MAClCj7B,EAAE,IAAIzB,EAAYq+B,GAAmBkV,KAAYC;;;IAKzDt7C,GAAai6B;QACX,OAAO54B,KAAKi5B,GAAGygB,KAAyBQ,GAAQthB;;;;AAmBpD,SAASsY,GACPtY,GACAp4B;IAEA,OAAOswC,GAAoBlY,GAAKkD;;;;;IAXlC,SACEt7B,GACAgK;QAEA,OAAO,IAAI2kC,GAAiB,GAAG1K,GAAmBjkC,EAAIkF,OAAO8E;KAQ3D2vC,CAAY35C,GAAKo4B,EAAIqb;;;;;;aAQTmG,GACdz6C,GACAC;;;;;;IASA,IAAIO,IAAWR,EAAWO;IAK1B,OAJKP,EAAW06C,MACdl6C,KAAY,MAAMR,EAAWQ,WAGxB,eAAeP,IAAiB,MAAMO,IAAW;;;;;;;;;;;ACphC1D,MAAMm6C;IAkDJ37C;;IAEW47C,GACDC,GACRC;QAFSz6C,mBAAAu6C,aACDC;;;;;;;QAnBVx6C,UAAqB,IAAIkL,GAAgCjM;;;QAIzDe,UAA2B,IAAIgB,EAC7B05C,KAAK7yC,EAAe6yC,IACpB7xC;;;;;;QAQF7I,UAA6BmE,EAAgBkB,OAY3CrF,KAAKuzB,KAAgBgnB,EAAYI,GAAiBF,IAClDz6C,KAAK46C,KAAkBL,EAAYb,MACnC15C,KAAKw0C,KAAc+F,EAAYrB,MAC/Bl5C,KAAK66C,KAAiB,IAAIxnB,GACxBrzB,KAAK46C,IACL56C,KAAKuzB,IACLvzB,KAAKu6C,YAAYO;QAEnB96C,KAAKw6C,GAAYO,GAAsB/6C,KAAK66C;;IAG9Cl8C,SAAuB8oC;QACrB,IAAIuT,IAAmBh7C,KAAKuzB,IACxB0nB,IAAoBj7C,KAAK66C;QAE7B,MAAMruC,UAAexM,KAAKu6C,YAAYvF,eACpC,sBACA,YACApc;;;YAGE,IAAIsiB;YACJ,OAAOl7C,KAAKuzB,GACT4nB,GAAsBviB,GACtBpyB,KAAK40C,MACJF,IAAaE,GAEbJ,IAAmBh7C,KAAKu6C,YAAYI,GAAiBlT;;;YAIrDwT,IAAoB,IAAI5nB,GACtBrzB,KAAK46C,IACLI,GACAh7C,KAAKu6C,YAAYO,OAEZE,EAAiBG,GAAsBviB,KAE/CpyB,KAAK60C;gBACJ,MAAMC,IAA6B,IAC7BC,IAA2B;;gBAGjC,IAAIC,IAAcpsC;gBAElB,KAAK,MAAMohB,KAAS0qB,GAAY;oBAC9BI,EAAgB75C,KAAK+uB,EAAMZ;oBAC3B,KAAK,MAAMtP,KAAYkQ,EAAMV,WAC3B0rB,IAAcA,EAAYjtC,IAAI+R,EAAS9f;;gBAI3C,KAAK,MAAMgwB,KAAS6qB,GAAY;oBAC9BE,EAAc95C,KAAK+uB,EAAMZ;oBACzB,KAAK,MAAMtP,KAAYkQ,EAAMV,WAC3B0rB,IAAcA,EAAYjtC,IAAI+R,EAAS9f;;;;gCAM3C,OAAOy6C,EACJQ,GAAa7iB,GAAK4iB,GAClBh1C,KAAKk1C,MACG;oBACLC,IAAAD;oBACAE,IAAAN;oBACAO,IAAAN;;;;QAWd,OAJAv7C,KAAKuzB,KAAgBynB,GACrBh7C,KAAK66C,KAAiBI,GACtBj7C,KAAKw6C,GAAYO,GAAsB/6C,KAAK66C,KAErCruC;;IAGT7N,GAAWmxB;QACT,MAAMhZ,IAAiBxT,EAAUK,OAC3B0L,IAAOygB,EAAU3K,OACrB,CAAC9V,GAAM+gB,MAAM/gB,EAAKd,IAAI6hB,EAAE5vB,MACxB4O;QAGF,IAAI0sC;QAEJ,OAAO97C,KAAKu6C,YACTvF,eAAe,2BAA2B,aAAapc,KAI/C54B,KAAK66C,GAAeY,GAAa7iB,GAAKvpB,GAAM7I,KAAKsK;YACtDgrC,IAAehrC;;;;;;YAOf,MAAM+e,IAA4B;YAElC,KAAK,MAAMvP,KAAYwP,GAAW;gBAChC,MAAMtI,IAAY6C,GAChB/J,GACAw7B,EAAat6C,IAAI8e,EAAS9f;gBAEX,QAAbgnB;;;;gBAIFqI,EAAcpuB,KACZ,IAAIif,GACFJ,EAAS9f,KACTgnB,GACAsE,GAAiBtE,EAAUzI,MAAe,WAC1CuD,GAAaH,QAAO;;YAM5B,OAAOniB,KAAKuzB,GAAcwoB,GACxBnjB,GACA9hB,GACA+Y,GACAC;YAIL4N,KAAKlN;YACJ,MAAM7f,IAAU6f,EAAMwrB,GAAwBF;YAC9C,OAAO;gBAAElsB,SAASY,EAAMZ;gBAASqsB,IAAAtrC;;;;IAIvChS,GACEqxB;QAEA,OAAOhwB,KAAKu6C,YAAYvF,eACtB,qBACA,qBACApc;YACE,MAAMsjB,IAAWlsB,EAAYQ,MAAMnhB,QAC7B8sC,IAAiBn8C,KAAK46C,GAAgBjB,GAAgB;gBAC1DyC,KAAe;;YAEjB,OAAOp8C,KAAKq8C,GACVzjB,GACA5I,GACAmsB,GAEC31C,KAAK,MAAM21C,EAAe3yC,MAAMovB,IAChCpyB,KAAK,MAAMxG,KAAKuzB,GAAc+oB,GAAwB1jB,IACtDpyB,KAAK,MAAMxG,KAAK66C,GAAeY,GAAa7iB,GAAKsjB;;;IAK1Dv9C,GAAYixB;QACV,OAAO5vB,KAAKu6C,YAAYvF,eACtB,gBACA,qBACApc;YACE,IAAI2jB;YACJ,OAAOv8C,KAAKuzB,GACTyV,GAAoBpQ,GAAKhJ,GACzBppB,KAAMgqB,MAhdiB7yB,EAidD,SAAV6yB,IACX+rB,IAAe/rB,EAAMnhB,QACdrP,KAAKuzB,GAAc0W,GAAoBrR,GAAKpI,KAEpDhqB,KAAK,MACGxG,KAAKuzB,GAAc+oB,GAAwB1jB,IAEnDpyB,KAAK,MACGxG,KAAK66C,GAAeY,GAAa7iB,GAAK2jB;;;IAMvD59C;QACE,OAAOqB,KAAKu6C,YAAYvF,eACtB,uCACA,YACApc,KACS54B,KAAKuzB,GAAcipB,GAAgC5jB;;IAKhEj6B;QACE,OAAOqB,KAAKu6C,YAAYvF,eACtB,oCACA,YACApc,KAAO54B,KAAKw0C,GAAYiI,GAA6B7jB;;IAIzDj6B,GAAiBmX;QACf,MAAM4mC,IAAgB5mC,EAAYrL;QAClC,IAAIkyC,IAA2B38C,KAAK48C;QAEpC,OAAO58C,KAAKu6C,YACTvF,eAAe,sBAAsB,qBAAqBpc;YACzD,MAAMujB,IAAiBn8C,KAAK46C,GAAgBjB,GAAgB;gBAC1DyC,KAAe;;;wBAIjBO,IAA2B38C,KAAK48C;YAEhC,MAAMzqB,IAAW;YACjBrc,EAAYnE,GAAc9Q,QAAQ,CAAC0P,GAAQjG;gBACzC,MAAMuyC,IAAgBF,EAAyBn7C,IAAI8I;gBACnD,KAAKuyC,GACH;;;;gCAMF1qB,EAAS1wB,KACPzB,KAAKw0C,GACFsI,GAAmBlkB,GAAKroB,EAAO6B,IAAkB9H,GACjD9D,KAAK,MACGxG,KAAKw0C,GAAYuI,GACtBnkB,GACAroB,EAAO2B,IACP5H;gBAKR,MAAMK,IAAc4F,EAAO5F;;gCAE3B,IAAIA,EAAY6I,MAAwB,GAAG;oBACzC,MAAMwpC,IAAgBH,EACnBI,GAAgBtyC,GAAa+xC,GAC7B5C,EAAmBlhB,EAAIqb;oBAC1B0I,IAA2BA,EAAyBrxC,GAClDhB,GACA0yC;;;oBAMA1C,GAAe4C,GACbL,GACAG,GACAzsC,MAGF4hB,EAAS1wB,KACPzB,KAAKw0C,GAAYuF,GAAiBnhB,GAAKokB;;;YAM/C,IAAIlQ,IAAch+B,MACdquC,IAAc/tC;;;;;YAiElB,IAhEA0G,EAAYjE,GAAgBhR,QAAQ,CAACL,GAAKwP;gBACxCmtC,IAAcA,EAAY5uC,IAAI/N;;;;YAKhC2xB,EAAS1wB,KACP06C,EAAepoB,WAAW6E,GAAKukB,GAAa32C,KAAKs1C;gBAC/ChmC,EAAYjE,GAAgBhR,QAAQ,CAACL,GAAKwP;oBACxC,MAAMotC,IAActB,EAAat6C,IAAIhB;;;;;wCAOnCwP,aAAeiE,MACfjE,EAAI8N,QAAQxZ,QAAQH,EAAgBkB;;;;oBAKpC82C,EAAexO,GAAYntC,GAAKk8C,IAChC5P,IAAcA,EAAYxhC,GAAO9K,GAAKwP,MAEvB,QAAfotC,KACAptC,EAAI8N,QAAQrE,EAAU2jC,EAAYt/B,WAAW,KACG,MAA/C9N,EAAI8N,QAAQrE,EAAU2jC,EAAYt/B,YACjCs/B,EAAY7rC,oBAMd4qC,EAAe1O,GAASz9B,GAAK0sC;oBAC7B5P,IAAcA,EAAYxhC,GAAO9K,GAAKwP,MAEtC5T,EA3jBA,cA6jBE,uCACAoE,GACA,sBACA48C,EAAYt/B,SACZ,mBACA9N,EAAI8N;oBAIJhI,EAAYhE,GAAuBxD,IAAI9N,MACzC2xB,EAAS1wB,KACPzB,KAAKu6C,YAAY/S,GAAkB6V,GACjCzkB,GACAp4B;;kBAYPk8C,EAAcp4C,QAAQH,EAAgBkB,QAAQ;gBACjD,MAAMi4C,IAAsBt9C,KAAKw0C,GAC9BiI,GAA6B7jB,GAC7BpyB,KAAKyrC,KAQGjyC,KAAKw0C,GAAY+I,GACtB3kB,GACAA,EAAIqb,IACJyI;gBAGNvqB,EAAS1wB,KAAK67C;;YAGhB,OAAOzsB,GAAmBuB,GAAQD,GAC/B3rB,KAAK,MAAM21C,EAAe3yC,MAAMovB,IAChCpyB,KAAK,MACGxG,KAAK66C,GAAe7mB,GACzB4E,GACAkU;WAIPpP,KAAKoP,MACJ9sC,KAAK48C,KAAqBD,GACnB7P;;;;;;;;;;;;WAeLnuC,UACNk+C,GACAG,GACAzsC;;QAQA,IANA5S,EACEq/C,EAAcryC,YAAY6I,MAAwB,IAKI,MAApDqpC,EAAclyC,YAAY6I,KAC5B,QAAO;;;;;;gBAWT,IAFEwpC,EAAcvyC,EAAgB+yC,MAC9BX,EAAcpyC,EAAgB+yC,OACfx9C,KAAKy9C,IACpB,QAAO;;;;;;gBAYT,OAHEltC,EAAO2B,GAAelN,OACtBuL,EAAO4B,GAAkBnN,OACzBuL,EAAO6B,GAAiBpN,OACT;;IAGnBrG,SAA6B++C;QAC3B;kBACQ19C,KAAKu6C,YAAYvF,eACrB,0BACA,aACApc,KACS/H,GAAmBhwB,QACxB68C,GACCC,KACQ9sB,GAAmBhwB,QACxB88C,EAAWjoB,IACVl1B,KACCR,KAAKu6C,YAAY/S,GAAkBqM,GACjCjb,GACA+kB,EAAWrzC,UACX9J,IAEJgG,KAAK,MACLqqB,GAAmBhwB,QACjB88C,EAAWhoB,IACVn1B,KACCR,KAAKu6C,YAAY/S,GAAkBsM,GACjClb,GACA+kB,EAAWrzC,UACX9J;UAQhB,OAAOlD;YACP,KAAI49B,GAA4B59B,IAO9B,MAAMA;;;;;YAFNlB,EAjtBQ,cAitBU,wCAAwCkB;;QAM9D,KAAK,MAAMqgD,KAAcD,GAAa;YACpC,MAAMpzC,IAAWqzC,EAAWrzC;YAE5B,KAAKqzC,EAAWzsC,WAAW;gBACzB,MAAMgE,IAAalV,KAAK48C,GAAmBp7C,IAAI8I,IAOzCI,IAA+BwK,EAAWzK,GAC1CmzC,IAAoB1oC,EAAW2oC,GACnCnzC;;gCAEF1K,KAAK48C,KAAqB58C,KAAK48C,GAAmBtxC,GAChDhB,GACAszC;;;;IAMRj/C,GAAkBm/C;QAChB,OAAO99C,KAAKu6C,YAAYvF,eACtB,2BACA,YACApc,WACuBt3B,MAAjBw8C,MACFA,KvBvxBqB;QuByxBhB99C,KAAKuzB,GAAcwqB,GACxBnlB,GACAklB;;IAMRn/C,GAAa6B;QACX,OAAOR,KAAKu6C,YAAYvF,eAAe,iBAAiB,YAAYpc,KAC3D54B,KAAK66C,GAAepmB,GAAYmE,GAAKp4B;;IAIhD7B,GAAemJ;QACb,OAAO9H,KAAKu6C,YACTvF,eAAe,mBAAmB,aAAapc;YAC9C,IAAI1jB;YACJ,OAAOlV,KAAKw0C,GACTwJ,GAAcplB,GAAK9wB,GACnBtB,KAAMy3C,KACDA;;;;YAIF/oC,IAAa+oC,GACNptB,GAAmBU,QAAQrc,MAE3BlV,KAAKw0C,GAAY0J,GAAiBtlB,GAAKpyB,KAAK8D,MACjD4K,IAAa,IAAI7K,GACfvC,GACAwC,oBAEAsuB,EAAIqb;YAECj0C,KAAKw0C,GACT2J,GAAcvlB,GAAK1jB,GACnB1O,KAAK,MAAM0O;WAKvBwoB,KAAKxoB;;;YAGJ,MAAMkpC,IAAmBp+C,KAAK48C,GAAmBp7C,IAC/C0T,EAAW5K;YAcb,QAXuB,SAArB8zC,KACAlpC,EAAWzK,EAAgBgP,EACzB2kC,EAAiB3zC,KACf,OAEJzK,KAAK48C,KAAqB58C,KAAK48C,GAAmBtxC,GAChD4J,EAAW5K,UACX4K,IAEFlV,KAAKq+C,GAAiB/uC,IAAIxH,GAAQoN,EAAW5K;YAExC4K;;;IAIbvW,GACE8zB,GACA3qB;QAEA,MAAMwC,IAAWtK,KAAKq+C,GAAiB78C,IAAIsG;QAC3C,YAAiBxG,MAAbgJ,IACKumB,GAAmBU,QACxBvxB,KAAK48C,GAAmBp7C,IAAI8I,MAGvBtK,KAAKw0C,GAAYwJ,GAAcvrB,GAAa3qB;;IAIvDnJ,SACE2L,GACAg0C;QAEA,MAAMppC,IAAalV,KAAK48C,GAAmBp7C,IAAI8I,IAMzCyvB,IAAOukB,IAA0B,cAAc;QAErD;YACOA,WACGt+C,KAAKu6C,YAAYvF,eAAe,kBAAkBjb,GAAMnB,KACrD54B,KAAKu6C,YAAY/S,GAAkB5yB,aACxCgkB;UAKN,OAAOt7B;YACP,KAAI49B,GAA4B59B,IAW9B,MAAMA;;;;;;YALNlB,EAh2BQ,cAk2BN,gDAAgDkO,MAAahN;;QAOnE0C,KAAK48C,KAAqB58C,KAAK48C,GAAmBnxC,OAAOnB,IACzDtK,KAAKq+C,GAAiBpuC,OAAOiF,EAAYpN;;IAG3CnJ,GACEkS,GACA0tC;QAEA,IAAI7zC,IAA+BvG,EAAgBkB,OAC/Cm5C,IAAapvC;QAEjB,OAAOpP,KAAKu6C,YAAYvF,eAAe,iBAAiB,YAAYpc,KAC3D54B,KAAKg+C,GAAcplB,GAAKhT,GAAc/U,IAC1CrK,KAAK0O;YACJ,IAAIA,GAGF,OAFAxK,IACEwK,EAAWxK,8BACN1K,KAAKw0C,GACTiK,GAA2B7lB,GAAK1jB,EAAW5K,UAC3C9D,KAAKgG;gBACJgyC,IAAahyC;;WAIpBhG,KAAK,MACJxG,KAAKw6C,GAAYzlB,GACf6D,GACA/nB,GACA0tC,IACI7zC,IACAvG,EAAgBkB,OACpBk5C,IAAqBC,IAAapvC,OAGrC5I,KAAK6K,MACG;YAAEA,WAAAA;YAAWqtC,IAAAF;;;IAKpB7/C,GACNi6B,GACA5I,GACAmsB;QAEA,MAAM3rB,IAAQR,EAAYQ,OACpBmuB,IAAUnuB,EAAMnhB;QACtB,IAAIuvC,IAAe/tB,GAAmBU;QAiCtC,OAhCAotB,EAAQ99C,QAAQkvB;YACd6uB,IAAeA,EACZp4C,KAAK,MACG21C,EAAetoB,GAAS+E,GAAK7I,IAErCvpB,KAAM++B;gBACL,IAAIv1B,IAAMu1B;gBACV,MAAMsZ,IAAa7uB,EAAYU,GAAYlvB,IAAIuuB;gBA37BvBpyB,EA67BP,SAAfkhD,MAGG7uC,KAAOA,EAAI8N,QAAQrE,OAAyB,OAC/CzJ,IAAMwgB,EAAMsuB,GAAsB/uB,GAAQ/f,GAAKggB,IAC1ChgB;;;;gBAaHmsC,EAAe1O,GAASz9B,GAAKggB,EAAYS;;YAK5CmuB,EAAap4C,KAAK,MACvBxG,KAAKuzB,GAAc0W,GAAoBrR,GAAKpI;;IAIhD7xB,GAAewjC;QACb,OAAOniC,KAAKu6C,YAAYvF,eACtB,mBACA,qBACApc,KAAOuJ,EAAiB4c,GAAQnmB,GAAK54B,KAAK48C;;;;;;;;;;;;SAmEhCoC,GACd3c,GACA/3B;IAEA,MAAM20C,IAAiBphD,EAAUwkC,IAC3B6c,IAAkBrhD,EACtBohD,EAAezK,KAGX4J,IAAmBa,EAAerC,GAAmBp7C,IAAI8I;IAC/D,OAAI8zC,IACK3sB,QAAQF,QAAQ6sB,EAAiBt2C,UAEjCm3C,EAAe1E,YAAYvF,eAChC,mBACA,YACApc,KACSsmB,EACJ1oC,GAAuBoiB,GAAKtuB,GAC5B9D,KAAK0O,KAAeA,IAAaA,EAAWpN,SAAS;;;;;;;;;;;;;;;;;;;;AAqEzD66B,eAAeE,GACpB/Q;IAEA,IACEA,EAAI5uB,SAASnB,EAAKW,uBAClBovB,EAAIr0B,YAAYw1B,IAIhB,MAAMnB;IAFN11B,EApmCY,cAomCM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA74BpBk+C,SAAsD;;MC1P3C6E;IAAbxgD;;QAEEqB,UAAoB,IAAI0N,GAAU0xC,GAAaC;;QAG/Cr/C,UAAuB,IAAI0N,GAAU0xC,GAAaE;;wEAGlD3gD;QACE,OAAOqB,KAAKu/C,GAAUx+C;;2EAIxBpC,GAAa6B,GAAkBW;QAC7B,MAAMq+C,IAAM,IAAIJ,GAAa5+C,GAAKW;QAClCnB,KAAKu/C,KAAYv/C,KAAKu/C,GAAUhxC,IAAIixC,IACpCx/C,KAAKy/C,KAAez/C,KAAKy/C,GAAalxC,IAAIixC;;0EAI5C7gD,GAAc0Q,GAAsBlO;QAClCkO,EAAKxO,QAAQL,KAAOR,KAAK6zC,GAAarzC,GAAKW;;;;;WAO7CxC,GAAgB6B,GAAkBW;QAChCnB,KAAK0/C,GAAU,IAAIN,GAAa5+C,GAAKW;;IAGvCxC,GAAiB0Q,GAAsBlO;QACrCkO,EAAKxO,QAAQL,KAAOR,KAAK8zC,GAAgBtzC,GAAKW;;;;;WAOhDxC,GAAsBwC;QACpB,MAAMw+C,IAAW,IAAIl5C,EAAY,IAAInB,EAAa,MAC5Cs6C,IAAW,IAAIR,GAAaO,GAAUx+C,IACtC0+C,IAAS,IAAIT,GAAaO,GAAUx+C,IAAK,IACzCkO,IAAsB;QAK5B,OAJArP,KAAKy/C,GAAaK,GAAe,EAACF,GAAUC,KAASL;YACnDx/C,KAAK0/C,GAAUF,IACfnwC,EAAK5N,KAAK+9C,EAAIh/C;YAET6O;;IAGT1Q;QACEqB,KAAKu/C,GAAU1+C,QAAQ2+C,KAAOx/C,KAAK0/C,GAAUF;;IAGvC7gD,GAAU6gD;QAChBx/C,KAAKu/C,KAAYv/C,KAAKu/C,GAAUtvC,OAAOuvC,IACvCx/C,KAAKy/C,KAAez/C,KAAKy/C,GAAaxvC,OAAOuvC;;IAG/C7gD,GAAgBwC;QACd,MAAMw+C,IAAW,IAAIl5C,EAAY,IAAInB,EAAa,MAC5Cs6C,IAAW,IAAIR,GAAaO,GAAUx+C,IACtC0+C,IAAS,IAAIT,GAAaO,GAAUx+C,IAAK;QAC/C,IAAIkO,IAAOD;QAIX,OAHApP,KAAKy/C,GAAaK,GAAe,EAACF,GAAUC,KAASL;YACnDnwC,IAAOA,EAAKd,IAAIixC,EAAIh/C;YAEf6O;;IAGT1Q,GAAY6B;QACV,MAAMg/C,IAAM,IAAIJ,GAAa5+C,GAAK,IAC5Bu/C,IAAW//C,KAAKu/C,GAAUS,GAAkBR;QAClD,OAAoB,SAAbO,KAAqBv/C,EAAI8D,QAAQy7C,EAASv/C;;;;MAIxC4+C;IACXzgD,YACS6B,GACAy/C;QADAjgD,WAAAQ,aACAy/C;;wCAITthD,UAAoBO,GAAoBC;QACtC,OACEsH,EAAYpH,EAAWH,EAAKsB,KAAKrB,EAAMqB,QACvCvB,EAAoBC,EAAK+gD,IAAiB9gD,EAAM8gD;;wCAKpDthD,UAAyBO,GAAoBC;QAC3C,OACEF,EAAoBC,EAAK+gD,IAAiB9gD,EAAM8gD,OAChDx5C,EAAYpH,EAAWH,EAAKsB,KAAKrB,EAAMqB;;;;;;;;;;;;;;;;;;;;;;;UCnHhC0/C;IASXvhD,YAAqB+oC;QAAA1nC,WAAA0nC;;IAErB/oC;QACE,OAAmB,QAAZqB,KAAK0nC;;;;;WAOd/oC;QACE,OAAIqB,KAAK2nC,OACA,SAAS3nC,KAAK0nC,MAEd;;IAIX/oC,QAAQwhD;QACN,OAAOA,EAAUzY,QAAQ1nC,KAAK0nC;;;;8BA1BhBwY,sBAAkB,IAAIA,GAAK;;;AAI3CA,QAAqC,IAAIA,GAAK,2BAC9CA,QAA8B,IAAIA,GAAK;;;;;;;;;;;;;;;;;;MCiC5BE;IAGXzhD,YAAYxB,GAAsBsqC;QAAAznC,YAAAynC,GAFlCznC,YAAO,SAGLA,KAAKqgD,KAAc;;QAEnBrgD,KAAKqgD,GAA2B,gBAAI,YAAUljD;;;;sEAqCrCmjD;IAAb3hD;;;;;;QAMEqB,UAA0D;;IAE1DrB;QACE,OAAO8yB,QAAQF,QAAsB;;IAGvC5yB;IAEAA,GAAkB4hD;QAKhBvgD,KAAKugD,KAAiBA;;QAEtBA,EAAeL,GAAK19C;;IAGtB7D;QAKEqB,KAAKugD,KAAiB;;;;MAIbC;IAwBX7hD,YAAY8hD;;;;;QAnBZzgD,UAAiE;;QAGzDA,mBAAoBkgD,GAAK19C,iBACjCxC,WAAuC;;;;;QAMvCA,UAAuB;;QAGvBA,UAA0D,MAElDA,qBAAe,GAKrBA,KAAK0gD,KAAgB;YACnB1gD,KAAK2gD,MACL3gD,KAAK4gD,cAAc5gD,KAAK6gD,MACxB7gD,KAAK8gD,MAAsB,GACvB9gD,KAAKugD,MACPvgD,KAAKugD,GAAevgD,KAAK4gD;WAI7B5gD,KAAK2gD,KAAe,GAEpB3gD,KAAK+gD,OAAON,EAAaO,aAAa;YAAEC,WAAU;YAE9CjhD,KAAK+gD,OACP/gD,KAAK+gD,KAAKG,qBAAqBlhD,KAAmB;;QAGlDA,KAAK0gD,GAAc,OACnBD,EAAaj/C,MAAMk8B,KACjBqjB;YACE/gD,KAAK+gD,OAAOA,GACR/gD,KAAK0gD;;YAEP1gD,KAAK+gD,KAAKG,qBAAqBlhD,KAAK0gD;WAGxC;;IAON/hD;;;;QASE,MAAMwiD,IAAsBnhD,KAAK2gD,IAC3BS,IAAephD,KAAKohD;QAG1B,OAFAphD,KAAKohD,gBAAe,GAEfphD,KAAK+gD,OAIH/gD,KAAK+gD,KAAKM,SAASD,GAAc1jB,KAAK4jB;;;;QAIvCthD,KAAK2gD,OAAiBQ,KACxB/kD,EACE,+BACA;QAEK4D,KAAKqhD,cAERC,KACF3jD,EACmC,mBAA1B2jD,EAAUC,cAGZ,IAAInB,GAAWkB,EAAUC,aAAavhD,KAAK4gD,gBAE3C,QArBJnvB,QAAQF,QAAQ;;IA2B3B5yB;QACEqB,KAAKohD,gBAAe;;IAGtBziD,GAAkB4hD;QAKhBvgD,KAAKugD,KAAiBA;;QAGlBvgD,KAAK8gD,MACPP,EAAevgD,KAAK4gD;;IAIxBjiD;QAUMqB,KAAK+gD,QACP/gD,KAAK+gD,KAAKS,wBAAwBxhD,KAAmB,KAEvDA,KAAK0gD,KAAgB,MACrB1gD,KAAKugD,KAAiB;;;;;;IAOhB5hD;QACN,MAAM8iD,IAAazhD,KAAK+gD,QAAQ/gD,KAAK+gD,KAAKW;QAK1C,OAJA/jD,EACiB,SAAf8jD,KAA6C,mBAAfA,IAGzB,IAAIvB,GAAKuB;;;;;;;;;;UAoBPE;IAIXhjD,YAAoBijD,GAAoBC;kBAApBD,aAAoBC,GAHxC7hD,YAAO,cACPA,YAAOkgD,GAAK4B;;IAIZC;QACE,MAAMC,IAAwC;YAC5CC,mBAAmBjiD,KAAK6hD;WAEpBK,IAAaliD,KAAK4hD,GAAKb,KAAKoB,GAAgC;QAIlE,OAHID,MACFF,EAAuB,gBAAIE,IAEtBF;;;;;;;;UASEI;IACXzjD,YAAoBijD,GAAoBC;kBAApBD,aAAoBC;;IAExCljD;QACE,OAAO8yB,QAAQF,QAAQ,IAAIowB,GAAgB3hD,KAAK4hD,IAAM5hD,KAAK6hD;;IAG7DljD,GAAkB4hD;;QAEhBA,EAAeL,GAAK4B;;IAGtBnjD;IAEAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;MChLoB0jD;IAkBpB1jD,YACU83B,GACR6rB,GACQC,GACEC,GACFC,GACEtvB;kBALFsD,aAEA8rB,aACEC,aACFC,GACEziD,gBAAAmzB,GAnBJnzB;;;;;;QAMRA,UAAqB,GAErBA,UAAmD,MAC3CA,cAA+C,MAYrDA,KAAKs+B,KAAU,IAAI9H,GAAmBC,GAAO6rB;;;;;;;;WAU/C3jD;QACE,4BACEqB,KAAK4S,0BACL5S,KAAK4S,6BACL5S,KAAK4S;;;;;WAQTjU;QACE,wBAAOqB,KAAK4S;;;;;;;;WAUdjU;0BACMqB,KAAK4S,QAST5S,KAAK+gD,SARH/gD,KAAK0iD;;;;;;;WAiBT/jD;QACMqB,KAAK2iD,cACD3iD,KAAK26B;;;;;;;;;WAYfh8B;QAMEqB,KAAK4S,0BACL5S,KAAKs+B,GAAQxH;;;;;;;;;;;WAafn4B;;;QAGMqB,KAAK4iD,QAA+B,SAAnB5iD,KAAK6iD,OACxB7iD,KAAK6iD,KAAY7iD,KAAKy2B,GAAMc,GAC1Bv3B,KAAKuiD,IAvJW,KAyJhB,MAAMviD,KAAK8iD;;wDAMPnkD,GAAYtC;QACpB2D,KAAK+iD,MACL/iD,KAAKgjD,OAAQC,KAAK5mD;;uFAIZsC;QACN,IAAIqB,KAAK4iD;;;QAGP,OAAO5iD,KAAK26B;;gDAKRh8B;QACFqB,KAAK6iD,OACP7iD,KAAK6iD,GAAU7rB,UACfh3B,KAAK6iD,KAAY;;;;;;;;;;;;;;WAiBblkD,YACNukD,GACAnmD;;QASAiD,KAAK+iD,MACL/iD,KAAKs+B,GAAQtH;;;QAIbh3B,KAAKmjD,wBAEDD;;QAEFljD,KAAKs+B,GAAQxH,UACJ/5B,KAASA,EAAMmG,SAASnB,EAAKU;;QAEtC5F,EAASE,EAAMqG,aACfvG,EACE;QAEFmD,KAAKs+B,GAAQ8kB,QACJrmD,KAASA,EAAMmG,SAASnB,EAAKS;;;QAGtCxC,KAAKyiD,GAAoBY;;QAIP,SAAhBrjD,KAAKgjD,WACPhjD,KAAKsjD,MACLtjD,KAAKgjD,OAAOroB,SACZ36B,KAAKgjD,SAAS;;;QAKhBhjD,KAAK4S,QAAQswC;;cAGPljD,KAAKmzB,SAASowB,GAAQxmD;;;;;WAOpB4B;IAiBFA;QAMNqB,KAAK4S;QAEL,MAAM4wC,IAAsBxjD,KAAKyjD,GAA0BzjD,KAAKmjD,KAG1DA,IAAanjD,KAAKmjD;;gBAExBnjD,KAAKyiD,GAAoBpB,WAAW3jB,KAClCgmB;;;;;YAKM1jD,KAAKmjD,OAAeA;;;;YAItBnjD,KAAK2jD,GAAYD;WAGpB3mD;YACCymD,EAAoB;gBAClB,MAAMI,IAAW,IAAI3gD,EACnBlB,EAAKG,SACL,iCAAiCnF,EAAMU;gBAEzC,OAAOuC,KAAK6jD,GAAkBD;;;;IAM9BjlD,GAAY+kD;QAMlB,MAAMF,IAAsBxjD,KAAKyjD,GAA0BzjD,KAAKmjD;QAEhEnjD,KAAKgjD,SAAShjD,KAAK8jD,GAASJ,IAC5B1jD,KAAKgjD,OAAOe,GAAO;YACjBP,EAAoB,OAKlBxjD,KAAK4S,uBACE5S,KAAKmzB,SAAU4wB;YAG1B/jD,KAAKgjD,OAAOO,GAASxmD;YACnBymD,EAAoB,MACXxjD,KAAK6jD,GAAkB9mD;YAGlCiD,KAAKgjD,OAAOgB,UAAW3nD;YACrBmnD,EAAoB,MACXxjD,KAAKgkD,UAAU3nD;;;IAKpBsC;QAKNqB,KAAK4S,0BAEL5S,KAAKs+B,GAAQc,GAAcuD;YAMzB3iC,KAAK4S,0BACL5S,KAAKmO;;;;IAMTxP,GAAkB5B;;;;;QAahB,OARAX,EAzbY,oBAybM,uBAAqBW,IAEvCiD,KAAKgjD,SAAS,MAMPhjD,KAAK26B,sBAAmC59B;;;;;;;WASzC4B,GACNslD;QAEA,OAAQnjD;YACNd,KAAKy2B,GAAM0H,GAAiB,MACtBn+B,KAAKmjD,OAAec,IACfnjD,OAEP1E,EAldM,oBAodJ;YAEKq1B,QAAQF;;;;;;;;;;;UA0BZ2yB,WAA+B7B;IAK1C1jD,YACE83B,GACA+rB,GACA2B,GACQ7mC,GACR6V;QAEAhwB,MACEszB,0HAGA+rB,GACA2B,GACAhxB;QATMnzB,kBAAAsd;;IAaA3e,GACR+kD;QAEA,OAAO1jD,KAAKwiD,GAAW4B,GACrB,UACAV;;IAIM/kD,UAAU0lD;;QAElBrkD,KAAKs+B,GAAQxH;QAEb,MAAM9hB,IAAcwK,GAAgBxf,KAAKsd,YAAY+mC,IAC/CC,ajCLR/zC;;;;YAKA,MAAM,kBAAkBA,IACtB,OAAOpM,EAAgBkB;YAEzB,MAAM8O,IAAe5D,EAAoB;YACzC,OAAI4D,EAAatB,aAAasB,EAAatB,UAAU/T,SAC5CqF,EAAgBkB,QAEpB8O,EAAamL,WAGXvB,GAAY5J,EAAamL,YAFvBnb,EAAgBkB;SiCRNk/C,CAA0BF;QAC3C,OAAOrkD,KAAKmzB,SAAUqxB,GAAcxvC,GAAasvC;;;;;;;WASnD3lD,GAAMuW;QACJ,MAAMgkB,IAAyB;QAC/BA,EAAQ/4B,WAAW0e,GAAqB7e,KAAKsd,aAC7C4b,EAAQurB,qBjCmXVnnC,GACApI;YAEA,IAAI1I;YACJ,MAAM1E,IAASoN,EAAWpN;YAc1B,OAXE0E,IADErD,GAAiBrB,KACV;gBAAEuJ,WAAWiS,GAAkBhG,GAAYxV;gBAE3C;gBAAE+I,OAAO0S,GAAcjG,GAAYxV;eAG9C0E,EAAOlC,WAAW4K,EAAW5K,UAEzB4K,EAAWvK,YAAY6I,MAAwB,MACjDhH,EAAO7B,cAAcgT,GAAQL,GAAYpI,EAAWvK;YAG/C6B;SiCrYek4C,CAAS1kD,KAAKsd,YAAYpI;QAE9C,MAAMyvC,IAAS7+B,GAAsB9lB,KAAKsd,YAAYpI;QAClDyvC,MACFzrB,EAAQyrB,SAASA,IAGnB3kD,KAAK4kD,GAAY1rB;;;;;WAOnBv6B,GAAQ2L;QACN,MAAM4uB,IAAyB;QAC/BA,EAAQ/4B,WAAW0e,GAAqB7e,KAAKsd,aAC7C4b,EAAQtkB,eAAetK,GACvBtK,KAAK4kD,GAAY1rB;;;;;;;;;;;;;;;;;;;;UAuCR2rB,WAA8BxC;IAOzC1jD,YACE83B,GACA+rB,GACA2B,GACQ7mC,GACR6V;QAEAhwB,MACEszB,sHAGA+rB,GACA2B,GACAhxB;QATMnzB,kBAAAsd,GANVtd,WAA6B;;;;;WAiC7B8kD;QACE,OAAO9kD,KAAK+kD;;;IAIdpmD;QACEqB,KAAK+kD,MAAqB,GAC1B/kD,KAAK8xC,uBAAkBxwC,GACvB6B,MAAMgL;;IAGExP;QACJqB,KAAK+kD,MACP/kD,KAAKglD,GAAe;;IAIdrmD,GACR+kD;QAEA,OAAO1jD,KAAKwiD,GAAW4B,GACrB,SACAV;;IAIM/kD,UAAUsmD;QAQlB;;QANAtnD,IACIsnD,EAAcC,cAGlBllD,KAAK8xC,kBAAkBmT,EAAcC,aAEhCllD,KAAK+kD,IAQH;;;;YAIL/kD,KAAKs+B,GAAQxH;YAEb,MAAMnG,IAAU3N,GACdiiC,EAAcE,cACdF,EAAc/hC,aAEVuN,IAAgB1S,GAAYknC,EAAyB;YAC3D,OAAOjlD,KAAKmzB,SAAUiyB,GAAiB30B,GAAeE;;;QAZtD,OAvqBchzB,GAmqBXsnD,EAAcE,gBAAsD,MAAtCF,EAAcE,aAAarmD,SAG5DkB,KAAK+kD,MAAqB,GACnB/kD,KAAKmzB,SAAUkyB;;;;;;WAqB1B1mD;;;QASE,MAAMu6B,IAAwB;QAC9BA,EAAQ/4B,WAAW0e,GAAqB7e,KAAKsd,aAC7Ctd,KAAK4kD,GAAY1rB;;4EAInBv6B,GAAemxB;QAWb,MAAMoJ,IAAwB;YAC5BgsB,aAAallD,KAAK8xC;YAClBwT,QAAQx1B,EAAUpzB,IAAI4jB,KAAYD,GAAWrgB,KAAKsd,YAAYgD;;QAGhEtgB,KAAK4kD,GAAY1rB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjtBrB,MAAMqsB;IAGJ5mD,YACWwlD,GACA3B,GACAllC;QAETna,SAJSnD,mBAAAmkD,aACA3B,GACAxiD,kBAAAsd,GALXtd,WAAa;;IAUbrB;QAEE,IAAIqB,KAAKwlD,IACP,MAAM,IAAIviD,EACRlB,EAAKW,qBACL;;+DAMN/D,GACE8mD,GACA//C,GACAwzB;QAGA,OADAl5B,KAAK0lD,MACE1lD,KAAKmkD,YACT9C,WACA3jB,KAAKgmB,KACG1jD,KAAKwiD,GAAWmD,GACrBF,GACA//C,GACAwzB,GACAwqB,IAGHnpB,MAAOx9B;YAIN,MAHIA,EAAMmG,SAASnB,EAAKS,mBACtBxC,KAAKmkD,YAAYd,MAEbtmD;;;qFAKZ4B,GACE8mD,GACA//C,GACAwzB;QAGA,OADAl5B,KAAK0lD,MACE1lD,KAAKmkD,YACT9C,WACA3jB,KAAKgmB,KACG1jD,KAAKwiD,GAAWoD,GACrBH,GACA//C,GACAwzB,GACAwqB,IAGHnpB,MAAOx9B;YAIN,MAHIA,EAAMmG,SAASnB,EAAKS,mBACtBxC,KAAKmkD,YAAYd,MAEbtmD;;;IAIZ4B;QACEqB,KAAKwlD,MAAa;;;;;;;;;;;;;;;;;MC/ETK;IAyBXlnD,YACU2+B,GACAwoB;kBADAxoB,aACAwoB;;QAzBF9lD;;;;;;QAORA,UAA8B;;;;;;QAO9BA,UAA0D;;;;;;QAO1DA,WAAoC;;;;;;;;WAcpCrB;QACmC,MAA7BqB,KAAK+lD,OACP/lD,KAAKgmD,6BAMLhmD,KAAKimD,KAAmBjmD,KAAKs9B,GAAW/F,qDA1Dd,KA6DxB,OACEv3B,KAAKimD,KAAmB;QAKxBjmD,KAAKkmD,GACH,8CAGFlmD,KAAKgmD;QAMEv0B,QAAQF;;;;;;;WAYvB5yB,GAAyB5B;kCACnBiD,KAAK4S,QACP5S,KAAKgmD,+BAaLhmD,KAAK+lD;QACD/lD,KAAK+lD,MA/GmB,MAgH1B/lD,KAAKmmD,MAELnmD,KAAKkmD,GACH,mDAC+BnpD,EAAMqG;QAGvCpD,KAAKgmD;;;;;;;;WAYXrnD,IAAIynD;QACFpmD,KAAKmmD,MACLnmD,KAAK+lD,KAAsB,6BAEvBK;;;QAGFpmD,KAAKqmD,MAA4B,IAGnCrmD,KAAKgmD,GAAgBI;;IAGfznD,GAAgBynD;QAClBA,MAAapmD,KAAK4S,UACpB5S,KAAK4S,QAAQwzC,GACbpmD,KAAK8lD,GAAmBM;;IAIpBznD,GAAmC2nD;QACzC,MAAM7oD,IACJ,4CAA4C6oD;QAI1CtmD,KAAKqmD,MACPxpD,EAASY,IACTuC,KAAKqmD,MAA4B,KAEjCjqD,EAxKU,sBAwKQqB;;IAIdkB;QACwB,SAA1BqB,KAAKimD,OACPjmD,KAAKimD,GAAiBjvB,UACtBh3B,KAAKimD,KAAmB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;MCpGjBM;IA4CX5nD;;;;IAIU0jC;;IAEAmkB,GACAlpB,GACRwoB,GACAW;kBALQpkB,aAEAmkB,aACAlpB;;;;;;;;;;;;;;;;;;QAjCVt9B,UAAyC;;;;;;;;;;QAWzCA,UAAwB,IAAI+R,KAK5B/R,UAA8D;;;;;QAM9DA,UAAwB,IAAI0mD,KAe1B1mD,KAAKymD,KAAsBA,GAC3BzmD,KAAKymD,GAAoBE,GAAahlD;YACpC27B,EAAWa,GAAiBwE;;;;gBAItB3iC,KAAK4mD,SACPxqD,EAtGM,eAwGJ;sBAEI4D,KAAK6mD;;YAKjB7mD,KAAK8mD,KAAqB,IAAIjB,GAC5BvoB,GACAwoB;;QAIF9lD,KAAK+mD,cF4CPP,GACA/vB,GACAtD;YAEA,MAAM6zB,IAAgBnpD,EAAU2oD;YAEhC,OADAQ,EAActB,MACP,IAAIxB,GACTztB,GACAuwB,EAAcxE,IACdwE,EAAc7C,aACd6C,EAAc1pC,YACd6V;;;;;;;;;;;;;;;;;GEvDmB8zB,EAAyBjnD,KAAKwmD,IAAWlpB,GAAY;YACtE4pB,IAAQlnD,KAAKmnD,GAAkBxpB,KAAK39B;YACpConD,IAASpnD,KAAKqnD,GAAmB1pB,KAAK39B;YACtCsnD,IAAetnD,KAAKunD,GAAoB5pB,KAAK39B;YAG/CA,KAAKwnD,cFsBPhB,GACA/vB,GACAtD;YAEA,MAAM6zB,IAAgBnpD,EAAU2oD;YAEhC,OADAQ,EAActB,MACP,IAAIb,GACTpuB,GACAuwB,EAAcxE,IACdwE,EAAc7C,aACd6C,EAAc1pC,YACd6V;SEjCmBs0B,CAAyBznD,KAAKwmD,IAAWlpB,GAAY;YACtE4pB,IAAQlnD,KAAK0nD,GAAkB/pB,KAAK39B;YACpConD,IAASpnD,KAAK2nD,GAAmBhqB,KAAK39B;YACtC4nD,IAAqB5nD,KAAK6nD,GAAyBlqB,KAAK39B;YACxD8nD,IAAkB9nD,KAAKolD,GAAiBznB,KAAK39B;;;;;;WAcjDrB;QACE,OAAOqB,KAAK+nD;;kDAIdppD;QAEE,OADAqB,KAAKgoD,GAAc/3C,8BACZjQ,KAAKioD;;IAGNtpD;QACFqB,KAAK4mD,SACH5mD,KAAKkoD,OACPloD,KAAKmoD,OAELnoD,KAAK8mD,GAAmBx3C;;cAIpBtP,KAAKooD;;;;;WAQfzpD;QACEqB,KAAKgoD,GAAcz5C,iCACbvO,KAAKqoD;;QAGXroD,KAAK8mD,GAAmBx3C;;IAGlB3Q;cACAqB,KAAKwnD,GAAYc,cACjBtoD,KAAK+mD,GAAYuB,QAEnBtoD,KAAKuoD,GAAczpD,SAAS,MAC9B1C,EArLU,eAuLR,8BAA8B4D,KAAKuoD,GAAczpD;QAEnDkB,KAAKuoD,KAAgB,KAGvBvoD,KAAKwoD;;IAGP7pD;QACEvC,EAhMY,eAgMM,+BAClB4D,KAAKgoD,GAAcz5C,6BACbvO,KAAKqoD;QACXroD,KAAKymD,GAAoB7N;;;QAIzB54C,KAAK8mD,GAAmBx3C;;;;;WAO1B3Q,OAAOuW;QACDlV,KAAKyoD,GAAcn6C,IAAI4G,EAAW5K;;QAKtCtK,KAAKyoD,GAAcn5C,IAAI4F,EAAW5K,UAAU4K,IAExClV,KAAKkoD;;QAEPloD,KAAKmoD,OACInoD,KAAK+mD,GAAYnE,QAC1B5iD,KAAK0oD,GAAiBxzC;;;;;WAQ1BvW,GAAS2L;QAMPtK,KAAKyoD,GAAcx4C,OAAO3F,IACtBtK,KAAK+mD,GAAYnE,QACnB5iD,KAAK2oD,GAAmBr+C,IAGM,MAA5BtK,KAAKyoD,GAAczjD,SACjBhF,KAAK+mD,GAAYnE,OACnB5iD,KAAK+mD,GAAY6B,OACR5oD,KAAK4mD;;;;QAId5mD,KAAK8mD,GAAmBx3C;;oEAM9B3Q,GAAuB2L;QACrB,OAAOtK,KAAKyoD,GAAcjnD,IAAI8I,MAAa;;oEAI7C3L,GAAuB2L;QACrB,OAAOtK,KAAK6oD,GAAWzyC,GAAuB9L;;;;;WAOxC3L,GAAiBuW;QACvBlV,KAAK8oD,GAAuBzyC,GAA2BnB,EAAW5K,WAClEtK,KAAK+mD,GAAYgC,GAAM7zC;;;;;;WAQjBvW,GAAmB2L;QACzBtK,KAAK8oD,GAAuBzyC,GAA2B/L,IACvDtK,KAAK+mD,GAAYiC,GAAQ1+C;;IAGnB3L;QAMNqB,KAAK8oD,KAAwB,IAAIn1C,GAAsB3T,OACvDA,KAAK+mD,GAAY54C,SACjBnO,KAAK8mD,GAAmBmC;;;;;WAOlBtqD;QACN,OACEqB,KAAK4mD,SACJ5mD,KAAK+mD,GAAYpE,QAClB3iD,KAAKyoD,GAAczjD,OAAO;;IAI9BrG;QACE,OAAmC,MAA5BqB,KAAKgoD,GAAchjD;;IAGpBrG;QACNqB,KAAK8oD,KAAwB;;IAGvBnqD;QACNqB,KAAKyoD,GAAc5nD,QAAQ,CAACqU,GAAY5K;YACtCtK,KAAK0oD,GAAiBxzC;;;IAIlBvW,SAAyB5B;QAU/BiD,KAAKwoD;;QAGDxoD,KAAKkoD,QACPloD,KAAK8mD,GAAmBoC,OAExBlpD,KAAKmoD;;;;QAKLnoD,KAAK8mD,GAAmBx3C;;IAIpB3Q,SACNqW,GACAvK;QAKA;;QAFAzK,KAAK8mD,GAAmBx3C,4BAGtB0F,aAAuBrC,0BACvBqC,EAAYpC,SACZoC,EAAYlC;;;QAIZ;kBACQ9S,KAAKmpD,GAAkBn0C;UAC7B,OAAO1X;YACPlB,EArWQ,eAuWN,oCACA4Y,EAAYnC,UAAUrN,KAAK,MAC3BlI;kBAEI0C,KAAKopD,GAA4B9rD;eAiB3C,IAZI0X,aAAuB3C,KACzBrS,KAAK8oD,GAAuBO,GAAqBr0C,KACxCA,aAAuBvC,KAChCzS,KAAK8oD,GAAuBQ,GAAsBt0C,KAMlDhV,KAAK8oD,GAAuBS,GAAmBv0C;SAG5CvK,EAAgBnG,QAAQH,EAAgBkB,QAC3C;YACE,MAAM4sC,UAAkCjyC,KAAKqiC,GAAWoa;YACpDhyC,EAAgBgP,EAAUw4B,MAA8B;;;kBAGpDjyC,KAAKwpD,GAAmB/+C;UAEhC,OAAOnN;YACPlB,EArYQ,eAqYU,6BAA6BkB,UACzC0C,KAAKopD,GAA4B9rD;;;;;;;;;;;WAcrCqB,SACNrB,GACAqL;QAEA,KAAIuyB,GAA4B59B,IA0B9B,MAAMA;QArBN0C,KAAKgoD,GAAcz5C;;cAGbvO,KAAKqoD,MACXroD,KAAK8mD,GAAmBx3C,8BAEnB3G;;;;QAIHA,IAAK,MAAM3I,KAAKqiC,GAAWoa;;QAI7Bz8C,KAAKs9B,GAAWuY,GAAiBlT;YAC/BvmC,EA5aQ,eA4aU,oCACZuM,KACN3I,KAAKgoD,GAAc/3C;kBACbjQ,KAAKioD;;;;;;WAWTtpD,GAAoBgK;QAC1B,OAAOA,IAAK4xB,MAAMj9B,KAAK0C,KAAKopD,GAA4B9rD,GAAGqL;;;;;;WAQrDhK,GAAmB8L;QAKzB,MAAMqL,IAAc9V,KAAK8oD,GAAuBW,GAC9Ch/C;;;;QAuDF,OAlDAqL,EAAYnE,GAAc9Q,QAAQ,CAAC0P,GAAQjG;YACzC,IAAIiG,EAAO5F,YAAY6I,MAAwB,GAAG;gBAChD,MAAM0B,IAAalV,KAAKyoD,GAAcjnD,IAAI8I;;gCAEtC4K,KACFlV,KAAKyoD,GAAcn5C,IACjBhF,GACA4K,EAAW+nC,GAAgB1sC,EAAO5F,aAAaF;;;;;QAQvDqL,EAAYlE,GAAiB/Q,QAAQyJ;YACnC,MAAM4K,IAAalV,KAAKyoD,GAAcjnD,IAAI8I;YAC1C,KAAK4K;;YAEH;;;wBAKFlV,KAAKyoD,GAAcn5C,IACjBhF,GACA4K,EAAW+nC,GACTtzC,GAAWiB,GACXsK,EAAWzK;;;YAMfzK,KAAK2oD,GAAmBr+C;;;;;YAMxB,MAAMo/C,IAAoB,IAAIr/C,GAC5B6K,EAAWpN,QACXwC,qCAEA4K,EAAW1K;YAEbxK,KAAK0oD,GAAiBgB;YAIjB1pD,KAAK6oD,GAAWc,GAAiB7zC;;2CAIlCnX,SACNqW;QAGA,MAAMjY,IAAQiY,EAAkB;QAChC,KAAK,MAAM1K,KAAY0K,EAAYnC;;QAE7B7S,KAAKyoD,GAAcn6C,IAAIhE,aACnBtK,KAAK6oD,GAAWe,GAAat/C,GAAUvN,IAC7CiD,KAAKyoD,GAAcx4C,OAAO3F,IAC1BtK,KAAK8oD,GAAuBl0C,aAAatK;;;;;;;;;WAa/C3L;QACE,IAAIkrD,IACF7pD,KAAKuoD,GAAczpD,SAAS,IACxBkB,KAAKuoD,GAAcvoD,KAAKuoD,GAAczpD,SAAS,GAAG8wB,W9BjjB7B;Q8BojB3B,MAAO5vB,KAAK8pD,QACV;YACE,MAAMt5B,UAAcxwB,KAAKqiC,GAAW0nB,GAClCF;YAGF,IAAc,SAAVr5B,GAAgB;gBACgB,MAA9BxwB,KAAKuoD,GAAczpD,UACrBkB,KAAKwnD,GAAYoB;gBAEnB;;YAEAiB,IAAuBr5B,EAAMZ,SAC7B5vB,KAAKgqD,GAAmBx5B;UAE1B,OAAOlzB;kBACD0C,KAAKopD,GAA4B9rD;;QAIvC0C,KAAKiqD,QACPjqD,KAAKkqD;;;;;WAQDvrD;QACN,OACEqB,KAAK4mD,QAAmB5mD,KAAKuoD,GAAczpD,SA7jBtB;;;IAkkBzBH;QACE,OAAOqB,KAAKuoD,GAAczpD;;;;;WAOpBH,GAAmB6xB;QAKzBxwB,KAAKuoD,GAAc9mD,KAAK+uB,IAEpBxwB,KAAKwnD,GAAY5E,QAAY5iD,KAAKwnD,GAAY2C,MAChDnqD,KAAKwnD,GAAYxC,GAAex0B,EAAMV;;IAIlCnxB;QACN,OACEqB,KAAK4mD,SACJ5mD,KAAKwnD,GAAY7E,QAClB3iD,KAAKuoD,GAAczpD,SAAS;;IAIxBH;QAKNqB,KAAKwnD,GAAYr5C;;IAGXxP;QACNqB,KAAKwnD,GAAY4C;;IAGXzrD;;QAEN,KAAK,MAAM6xB,KAASxwB,KAAKuoD,IACvBvoD,KAAKwnD,GAAYxC,GAAex0B,EAAMV;;IAIlCnxB,SACN8xB,GACAE;QAQA,MAAMH,IAAQxwB,KAAKuoD,GAAcppB,SAC3ByW,IAAUrlB,GAAoB7M,KAAK8M,GAAOC,GAAeE;cAEzD3wB,KAAKqqD,GAAoB,MAC7BrqD,KAAK6oD,GAAWyB,GAAqB1U;;;cAKjC51C,KAAKooD;;IAGLzpD,SAAyB5B;;;QAY3BA,KAASiD,KAAKwnD,GAAY2C;;cAEtBnqD,KAAKuqD;;;QAKTvqD,KAAKiqD,QACPjqD,KAAKkqD;;IAIDvrD,SAAuB5B;;;QAG7B,I9CznBKgO,GAD6B7H,I8C0nBRnG,EAAMmG,S9CznBDA,MAASnB,EAAKY,S8CynBN;;;YAGrC,MAAM6tB,IAAQxwB,KAAKuoD,GAAcppB;;;;wBAKjCn/B,KAAKwnD,GAAYgD,YAEXxqD,KAAKqqD,GAAoB,MAC7BrqD,KAAK6oD,GAAW4B,GAAkBj6B,EAAMZ,SAAS7yB;;;kBAK7CiD,KAAKooD;;Y9C1oBqBllD;;;;;;;I8CgpB5BvE;QACNqB,KAAKgoD,GAAcz5C,uCACbvO,KAAKqoD,MACXroD,KAAK8mD,GAAmBx3C;QACxBtP,KAAKwnD,GAAYgD,MACjBxqD,KAAK+mD,GAAYyD,MACjBxqD,KAAKgoD,GAAc/3C,0CACbjQ,KAAKioD;;IAGbtpD,SAA6B8oC;QAC3BznC,KAAKs9B,GAAWotB;;;;QAKhBtuD,EA3sBY,eA2sBM,yCAClB4D,KAAKgoD,GAAcz5C;cAEbvO,KAAKqoD,MACXroD,KAAK8mD,GAAmBx3C,oCAClBtP,KAAK6oD,GAAW8B,GAAuBljB,IAE7CznC,KAAKgoD,GAAc/3C;cACbjQ,KAAKioD;;;;WAMbtpD,SAAwBi2C;QAClBA,KACF50C,KAAKgoD,GAAc/3C,mCACbjQ,KAAKioD,QACDrT,MACV50C,KAAKgoD,GAAcz5C;cACbvO,KAAKqoD,MACXroD,KAAK8mD,GAAmBx3C;;;;;;;;;;;;;;;;;;;;;;;SC9vBds7C,GACdhrD,GACA0yC;IAOA,OAAO,qBAA8B1yC,KAAkB0yC;;;;;;;;;;;SAuBzCuY,GACdjrD,GACA6nC,GACA7X;IAEA,IAAIk7B,IAAc,uBAAgClrD,KAAkBgwB;IAMpE,OAJI6X,EAAKE,SACPmjB,KAAe,MAAIrjB,EAAKC,MAGnBojB;;;;;;SAmBOC,GACdnrD,GACA0K;IAEA,OAAO,qBAA8B1K,KAAkB0K;;;;;;;;;;;MCuF5C0gD;IACXrsD,YACW8oC,GACA7X,GACAhd,GACA7V;QAHAiD,YAAAynC,GACAznC,eAAA4vB,GACA5vB,aAAA4S,GACA5S,aAAAjD;;;;;WAYX4B,UACE8oC,GACA7X,GACAzyB;QAEA,MAAM8tD,IAAgB7tD,KAAK8tD,MAAM/tD;QAEjC,IAAIguD,IACuB,mBAAlBF,MAEJ,MADH,EAAC,WAAW,gBAAgB,aAAYtlD,QAAQslD,EAAcr4C,gBAErCtR,MAAxB2pD,EAAcluD,SACkB,mBAAxBkuD,EAAcluD,QAErBquD,SAA6C9pD;QAcjD,OAZI6pD,KAAaF,EAAcluD,UAC7BouD,IACyC,mBAAhCF,EAAcluD,MAAMU,WACS,mBAA7BwtD,EAAcluD,MAAMmG;QACzBioD,MACFC,IAAiB,IAAInoD,EACnBgoD,EAAcluD,MAAMmG,MACpB+nD,EAAcluD,MAAMU,YAKtB0tD,IACK,IAAIH,GACTvjB,GACA7X,GACAq7B,EAAcr4C,OACdw4C,MAGFvuD,EApLU,qBAsLR,0CAA0C+yB,OAAazyB;QAElD;;IAIXwB;QACE,MAAM0sD,IAAwC;YAC5Cz4C,OAAO5S,KAAK4S;YACZ2/B,cAAc7uC,KAAKC;;QAUrB,OAPI3D,KAAKjD,UACPsuD,EAActuD,QAAQ;YACpBmG,MAAMlD,KAAKjD,MAAMmG;YACjBzF,SAASuC,KAAKjD,MAAMU;YAIjBL,KAAKC,UAAUguD;;;;;;;;;MASbC;IACX3sD,YACW2L,GACAsI,GACA7V;QAFAiD,gBAAAsK,GACAtK,aAAA4S,GACA5S,aAAAjD;;;;;WAYX4B,UACE2L,GACAnN;QAEA,MAAMkX,IAAcjX,KAAK8tD,MAAM/tD;QAE/B,IAAIguD,IACqB,mBAAhB92C,MAEJ,MADH,EAAC,eAAe,WAAW,aAAY1O,QAAQ0O,EAAYzB,gBAEpCtR,MAAtB+S,EAAYtX,SACkB,mBAAtBsX,EAAYtX,QAEnBquD,SAA6C9pD;QAcjD,OAZI6pD,KAAa92C,EAAYtX,UAC3BouD,IACuC,mBAA9B92C,EAAYtX,MAAMU,WACS,mBAA3B4W,EAAYtX,MAAMmG;QACvBioD,MACFC,IAAiB,IAAInoD,EACnBoR,EAAYtX,MAAMmG,MAClBmR,EAAYtX,MAAMU,YAKpB0tD,IACK,IAAIG,GACThhD,GACA+J,EAAYzB,OACZw4C,MAGFvuD,EApQU,qBAsQR,wCAAwCyN,OAAcnN;QAEjD;;IAIXwB;QACE,MAAM0V,IAAsC;YAC1CzB,OAAO5S,KAAK4S;YACZ2/B,cAAc7uC,KAAKC;;QAUrB,OAPI3D,KAAKjD,UACPsX,EAAYtX,QAAQ;YAClBmG,MAAMlD,KAAKjD,MAAMmG;YACjBzF,SAASuC,KAAKjD,MAAMU;YAIjBL,KAAKC,UAAUgX;;;;;;;GAiB1B,OAAMk3C;IACJ5sD,YACW2zC,GACA/O;QADAvjC,gBAAAsyC,GACAtyC,uBAAAujC;;;;;WAOX5kC,UACE2zC,GACAn1C;QAEA,MAAMquD,IAAcpuD,KAAK8tD,MAAM/tD;QAE/B,IAAIguD,IACqB,mBAAhBK,KACPA,EAAYjoB,2BAA2BkoB,OAErCC,IAAqBl8C;QAEzB,KAAK,IAAIlR,IAAI,GAAG6sD,KAAa7sD,IAAIktD,EAAYjoB,gBAAgBzkC,UAAUR,GACrE6sD,IAAYlkD,EAAcukD,EAAYjoB,gBAAgBjlC;QACtDotD,IAAqBA,EAAmBn9C,IACtCi9C,EAAYjoB,gBAAgBjlC;QAIhC,OAAI6sD,IACK,IAAII,GAAkBjZ,GAAUoZ,MAEvC7uD,EA1UU,qBA4UR,6CAA6Cy1C,OAAcn1C;QAEtD;;;;;;;;UAUAwuD;IACXhtD,YAAqB2zC,GAA2BsZ;QAA3B5rD,gBAAAsyC,GAA2BtyC,mBAAA4rD;;;;;WAMhDjtD,UAA2BxB;QACzB,MAAMyuD,IAAcxuD,KAAK8tD,MAAM/tD;QAQ/B,OALyB,mBAAhByuD,MAEJ,MADH,EAAC,WAAW,UAAU,YAAWjmD,QAAQimD,EAAYA,gBAErB,mBAAzBA,EAAYtZ,WAGZ,IAAIqZ,GACTC,EAAYtZ,UACZsZ,EAAYA,gBAGd/uD,EA9WU,qBA8WQ,mCAAiCM;QAC5C;;;;;;;;;;;;;;;MAgBA0uD;IAAbltD;QACEqB,uBAAkBwP;;IAElB7Q,GAAe2L;QACbtK,KAAKujC,kBAAkBvjC,KAAKujC,gBAAgBh1B,IAAIjE;;IAGlD3L,GAAkB2L;QAChBtK,KAAKujC,kBAAkBvjC,KAAKujC,gBAAgBtzB,OAAO3F;;;;;WAOrD3L;QACE,MAAMgP,IAA0B;YAC9B41B,iBAAiBvjC,KAAKujC,gBAAgBh+B;YACtCgtC,cAAc7uC,KAAKC;;QAErB,OAAOvG,KAAKC,UAAUsQ;;;;;;;;UASbm+C;IA2BXntD,YACmBm5B,GACArB,GACA72B,GACAmsD,GACjBtR;QAJiBz6C,cAAA83B,aACArB,GACAz2B,sBAAAJ,aACAmsD,GA9BnB/rD,UAA6C;QAC7CA,UAAkE,MAClEA,UAEW,MAKXA,UAAmCA,KAAKgsD,GAAsBruB,KAAK39B,OAKnEA,UAAwB,IAAIkL,GAC1BjM;QAEFe,WAAkB;;;;;QAOlBA,UAAsC;;;QAWpC,MAAMisD,IAAwBrsD,EAAesG,QAC3C,uBACA;QAGFlG,KAAKksD,UAAUlsD,KAAK83B,OAAO2c,cAC3Bz0C,KAAK4gD,cAAcnG,GACnBz6C,KAAKmsD,KAAwBvB,GAC3B5qD,KAAKJ,gBACLI,KAAK+rD;QAEP/rD,KAAKosD;;iBDxXPxsD;YAEA,OAAO,+BAAiCA;;;;;;;;;;;;;;;;;GCsXbysD,EACvBrsD,KAAKJ,iBAEPI,KAAKssD,KAAgBtsD,KAAKssD,GAAchhD,GACtCtL,KAAK+rD,IACL,IAAIF,KAGN7rD,KAAKusD,KAAmB,IAAIr1C,OAC1B,sBAA+B+0C;QAEjCjsD,KAAKwsD,KAAqB,IAAIt1C,OAC5B,wBAAiC+0C,wBAEnCjsD,KAAKysD,KAAmB,IAAIv1C,OAC1B,sBAA+B+0C;QAGjCjsD,KAAK0sD;;iBDlasC9sD;YAC7C,OAAO,4BAA8BA;;;uECiab+sD;SAA+B3sD,KAAKJ;;;;;;;QAQ1DI,KAAK83B,OAAO0G,iBAAiB,WAAWx+B,KAAK4sD;;oFAI/CjuD,UAAmBm5B;QACjB,UAAUA,MAAUA,EAAO2c;;IAG7B91C;;;QAaE,MAAM63C,UAAwBx2C,KAAK6oD,GAAYgE;QAE/C,KAAK,MAAMva,KAAYkE,GAAiB;YACtC,IAAIlE,MAAatyC,KAAK+rD,IACpB;YAGF,MAAMe,IAAc9sD,KAAK84C,QACvB8R,GAA+B5qD,KAAKJ,gBAAgB0yC;YAEtD,IAAIwa,GAAa;gBACf,MAAMtB,IAAcD,GAAkBwB,GACpCza,GACAwa;gBAEEtB,MACFxrD,KAAKssD,KAAgBtsD,KAAKssD,GAAchhD,GACtCkgD,EAAYlZ,UACZkZ;;;QAMRxrD,KAAKgtD;;;QAIL,MAAMC,IAAkBjtD,KAAKksD,QAAQpT,QAAQ94C,KAAK0sD;QAClD,IAAIO,GAAiB;YACnB,MAAMrB,IAAc5rD,KAAKktD,GAA0BD;YAC/CrB,KACF5rD,KAAKmtD,GAAuBvB;;QAIhC,KAAK,MAAMvyB,KAASr5B,KAAKotD,IACvBptD,KAAKgsD,GAAsB3yB;QAG7Br5B,KAAKotD,KAAc;;;QAInBptD,KAAK83B,OAAO0G,iBAAiB,UAAU,MAAMx+B,KAAK44C,OAElD54C,KAAKs1C,MAAU;;IAGjB32C,GAAoB6L;QAClBxK,KAAK+4C,QAAQ/4C,KAAKosD,IAAmBhvD,KAAKC,UAAUmN;;IAGtD7L;QACE,OAAOqB,KAAKqtD,GAA0BrtD,KAAKssD;;IAG7C3tD,GAAoB2L;QAClB,IAAI2U,KAAQ;QAMZ,OALAjf,KAAKssD,GAAczrD,QAAQ,CAACL,GAAKrD;YAC3BA,EAAMomC,gBAAgBj1B,IAAIhE,OAC5B2U,KAAQ;YAGLA;;IAGTtgB,GAAmBixB;QACjB5vB,KAAKstD,GAAqB19B,GAAS;;IAGrCjxB,GACEixB,GACAhd,GACA7V;QAEAiD,KAAKstD,GAAqB19B,GAAShd,GAAO7V;;;;QAK1CiD,KAAKutD,GAAoB39B;;IAG3BjxB,GAAoB2L;QAClB,IAAIkjD,IAA+B;;;gBAInC,IAAIxtD,KAAKytD,GAAoBnjD,IAAW;YACtC,MAAMwiD,IAAc9sD,KAAKksD,QAAQpT,QAC/BiS,GAAuC/qD,KAAKJ,gBAAgB0K;YAG9D,IAAIwiD,GAAa;gBACf,MAAMniB,IAAW2gB,GAAoByB,GACnCziD,GACAwiD;gBAEEniB,MACF6iB,IAAa7iB,EAAS/3B;;;QAQ5B,OAHA5S,KAAK0tD,GAAiBC,GAAerjD,IACrCtK,KAAKgtD,MAEEQ;;IAGT7uD,GAAuB2L;QACrBtK,KAAK0tD,GAAiBE,GAAkBtjD,IACxCtK,KAAKgtD;;IAGPruD,GAAmB2L;QACjB,OAAOtK,KAAK0tD,GAAiBnqB,gBAAgBj1B,IAAIhE;;IAGnD3L,GAAgB2L;QACdtK,KAAK82C,WACHiU,GAAuC/qD,KAAKJ,gBAAgB0K;;IAIhE3L,GACE2L,GACAsI,GACA7V;QAEAiD,KAAK6tD,GAAwBvjD,GAAUsI,GAAO7V;;IAGhD4B,GACE8oC,GACA6T,GACAC;QAEAD,EAAgBz6C,QAAQ+uB;YACtB5vB,KAAKutD,GAAoB39B;YAE3B5vB,KAAK4gD,cAAcnZ,GACnB8T,EAAc16C,QAAQ+uB;YACpB5vB,KAAK8tD,GAAmBl+B;;;IAI5BjxB,GAAeitD;QACb5rD,KAAK+tD,GAAmBnC;;IAG1BjtD;QACMqB,KAAKs1C,OACPt1C,KAAK83B,OAAOiH,oBAAoB,WAAW/+B,KAAK4sD,KAChD5sD,KAAK82C,WAAW92C,KAAKmsD;QACrBnsD,KAAKs1C,MAAU;;IAIX32C,QAAQ6B;QACd,MAAMrD,IAAQ6C,KAAKksD,QAAQpT,QAAQt4C;QAEnC,OADApE,EA5pBY,qBA4pBM,QAAQoE,GAAKrD,IACxBA;;IAGDwB,QAAQ6B,GAAarD;QAC3Bf,EAjqBY,qBAiqBM,OAAOoE,GAAKrD,IAC9B6C,KAAKksD,QAAQnT,QAAQv4C,GAAKrD;;IAGpBwB,WAAW6B;QACjBpE,EAtqBY,qBAsqBM,UAAUoE,IAC5BR,KAAKksD,QAAQpV,WAAWt2C;;IAGlB7B,GAAsB06B;;;QAG5B,MAAM20B,IAAe30B;QACrB,IAAI20B,EAAaC,gBAAgBjuD,KAAKksD,SAAS;YAG7C,IAFA9vD,EA/qBU,qBA+qBQ,SAAS4xD,EAAaxtD,KAAKwtD,EAAajjC,WAEtDijC,EAAaxtD,QAAQR,KAAKmsD,IAK5B,YAJAtvD,EACE;YAMJmD,KAAKy2B,GAAMof,GAAiBlT;gBAC1B,IAAK3iC,KAAKs1C;oBAKV,IAAyB,SAArB0Y,EAAaxtD,KAIjB,IAAIR,KAAKusD,GAAiBvmD,KAAKgoD,EAAaxtD,MAAM;wBAChD,IAA6B,QAAzBwtD,EAAajjC,UAWV;4BACL,MAAMunB,IAAWtyC,KAAKkuD,GACpBF,EAAaxtD;4BAEf,OAAOR,KAAKmuD,GAAuB7b,GAAU;;wBAfZ;4BACjC,MAAMkZ,IAAcxrD,KAAKouD,GACvBJ,EAAaxtD,KACbwtD,EAAajjC;4BAEf,IAAIygC,GACF,OAAOxrD,KAAKmuD,GACV3C,EAAYlZ,UACZkZ;;2BASD,IAAIxrD,KAAKwsD,GAAmBxmD,KAAKgoD,EAAaxtD;wBACnD,IAA8B,SAA1BwtD,EAAajjC,UAAmB;4BAClC,MAAMsjC,IAAmBruD,KAAKsuD,GAC5BN,EAAaxtD,KACbwtD,EAAajjC;4BAEf,IAAIsjC,GACF,OAAOruD,KAAKuuD,GAAyBF;;2BAGpC,IAAIruD,KAAKysD,GAAiBzmD,KAAKgoD,EAAaxtD;wBACjD,IAA8B,SAA1BwtD,EAAajjC,UAAmB;4BAClC,MAAMyjC,IAAsBxuD,KAAKyuD,GAC/BT,EAAaxtD,KACbwtD,EAAajjC;4BAEf,IAAIyjC,GACF,OAAOxuD,KAAK0uD,GAAuBF;;2BAGlC,IAAIR,EAAaxtD,QAAQR,KAAK0sD;wBACnC,IAA8B,SAA1BsB,EAAajjC,UAAmB;4BAClC,MAAM6gC,IAAc5rD,KAAKktD,GACvBc,EAAajjC;4BAEf,IAAI6gC,GACF,OAAO5rD,KAAKmtD,GAAuBvB;;2BAGlC,IAAIoC,EAAaxtD,QAAQR,KAAKosD,IAAmB;wBAKtD,MAAM5hD,IA4NhB,SACEmkD;4BAEA,IAAInkD,IAAiBqrB,GAAesN;4BACpC,IAAiB,QAAbwrB,GACF;gCACE,MAAMC,IAASxxD,KAAK8tD,MAAMyD;gCAh+BrBhxD,EAk+Be,mBAAXixD,IAGTpkD,IAAiBokD;8BACjB,OAAOtxD;gCACPT,EAh+BU,qBAg+BQ,kDAAkDS;;4BAGxE,OAAOkN;;;;;;GA5OwBqkD,EACrBb,EAAajjC;wBAEXvgB,MAAmBqrB,GAAesN,MACpCnjC,KAAK+1B,GAAuBvrB;;uBAhE9BxK,KAAKotD,GAAY3rD,KAAKusD;;;;IAuE9Bc;QACE,OAAO9uD,KAAKssD,GAAc9qD,IAAIxB,KAAK+rD;;IAG7BptD;QACNqB,KAAK+4C,QACH/4C,KAAKmsD,IACLnsD,KAAK0tD,GAAiBqB;;IAIlBpwD,GACNixB,GACAhd,GACA7V;QAEA,MAAMiyD,IAAgB,IAAIhE,GACxBhrD,KAAK4gD,aACLhxB,GACAhd,GACA7V,IAEI+tD,IAAcD,GAClB7qD,KAAKJ,gBACLI,KAAK4gD,aACLhxB;QAEF5vB,KAAK+4C,QAAQ+R,GAAakE,EAAcD;;IAGlCpwD,GAAoBixB;QAC1B,MAAMk7B,IAAcD,GAClB7qD,KAAKJ,gBACLI,KAAK4gD,aACLhxB;QAEF5vB,KAAK82C,WAAWgU;;IAGVnsD,GAAmBitD;QACzB,MAAM7qB,IAAiC;YACrCuR,UAAUtyC,KAAK+rD;YACfH,aAAAA;;QAEF5rD,KAAKksD,QAAQnT,QAAQ/4C,KAAK0sD,IAAgBtvD,KAAKC,UAAU0jC;;IAGnDpiC,GACN2L,GACAsI,GACA7V;QAEA,MAAMkyD,IAAYlE,GAChB/qD,KAAKJ,gBACL0K,IAEI4kD,IAAiB,IAAI5D,GAAoBhhD,GAAUsI,GAAO7V;QAChEiD,KAAK+4C,QAAQkW,GAAWC,EAAeH;;;;;WAOjCpwD,GAA6B6B;QACnC,MAAMu4B,IAAQ/4B,KAAKusD,GAAiBjxC,KAAK9a;QACzC,OAAOu4B,IAAQA,EAAM,KAAK;;;;;WAOpBp6B,GACN6B,GACArD;QAEA,MAAMm1C,IAAWtyC,KAAKkuD,GAA6B1tD;QAEnD,OAAO+qD,GAAkBwB,GAAoBza,GAAUn1C;;;;;WAOjDwB,GACN6B,GACArD;QAEA,MAAM47B,IAAQ/4B,KAAKwsD,GAAmBlxC,KAAK9a,IAGrCovB,IAAU1oB,OAAO6xB,EAAM,KACvBwO,SAAsBjmC,MAAby3B,EAAM,KAAmBA,EAAM,KAAK;QACnD,OAAOiyB,GAAiB+B,GACtB,IAAI7M,GAAK3Y,IACT3X,GACAzyB;;;;;WAQIwB,GACN6B,GACArD;QAEA,MAAM47B,IAAQ/4B,KAAKysD,GAAiBnxC,KAAK9a,IAGnC8J,IAAWpD,OAAO6xB,EAAM;QAC9B,OAAOuyB,GAAoByB,GAAoBziD,GAAUnN;;;;;WAOnDwB,GAA0BxB;QAChC,OAAOwuD,GAAkBoB,GAAoB5vD;;IAGvCwB,SACNssD;QAEA,IAAIA,EAAcxjB,KAAKC,QAAQ1nC,KAAK4gD,YAAYlZ,KAQhD,OAAO1nC,KAAK6oD,GAAYsG,GACtBlE,EAAcr7B,SACdq7B,EAAcr4C,OACdq4C,EAAcluD;QAVdX,EAn4BU,qBAq4BR,2CAAyC6uD,EAAcxjB,KAAKC;;IAY1D/oC,GACNuwD;QAEA,OAAOlvD,KAAK6oD,GAAYuG,GACtBF,EAAe5kD,UACf4kD,EAAet8C,OACfs8C,EAAenyD;;IAIX4B,GACN2zC,GACAkZ;QAEA,MAAM6D,IAAiB7D,IACnBxrD,KAAKssD,GAAchhD,GAAOgnC,GAAUkZ,KACpCxrD,KAAKssD,GAAc7gD,OAAO6mC,IAExBgd,IAAkBtvD,KAAKqtD,GAA0BrtD,KAAKssD,KACtDiD,IAAavvD,KAAKqtD,GAA0BgC,IAE5CG,IAA2B,IAC3BC,IAA6B;QAcnC,OAZAF,EAAW1uD,QAAQyJ;YACZglD,EAAgBhhD,IAAIhE,MACvBklD,EAAa/tD,KAAK6I;YAItBglD,EAAgBzuD,QAAQyJ;YACjBilD,EAAWjhD,IAAIhE,MAClBmlD,EAAehuD,KAAK6I;YAIjBtK,KAAK6oD,GAAY6G,GACtBF,GACAC,GACA/xB,KAAK;YACL19B,KAAKssD,KAAgB+C;;;IAIjB1wD,GAAuBitD;;;;;;QAMzB5rD,KAAKssD,GAAc9qD,IAAIoqD,EAAYtZ,aACrCtyC,KAAK8lD,GAAoB8F,EAAYA;;IAIjCjtD,GACNk5C;QAEA,IAAI8X,IAAgBngD;QAIpB,OAHAqoC,EAAQh3C,QAAQ,CAAC+uD,GAAKzyD;YACpBwyD,IAAgBA,EAAcE,GAAU1yD,EAAMomC;YAEzCosB;;;;MA4BEG;IAAbnxD;QACEqB,UAAqB,IAAI6rD,IACzB7rD,UAA+D,IAC/DA,UAAkE,MAClEA,UAEW;;IAEXrB,GAAmBixB;;;IAInBjxB,GACEixB,GACAhd,GACA7V;;;IAKF4B,GAAoB2L;QAElB,OADAtK,KAAK+vD,GAAWpC,GAAerjD,IACxBtK,KAAKwtD,GAAWljD,MAAa;;IAGtC3L,GACE2L,GACAsI,GACA7V;QAEAiD,KAAKwtD,GAAWljD,KAAYsI;;IAG9BjU,GAAuB2L;QACrBtK,KAAK+vD,GAAWnC,GAAkBtjD;;IAGpC3L,GAAmB2L;QACjB,OAAOtK,KAAK+vD,GAAWxsB,gBAAgBj1B,IAAIhE;;IAG7C3L,GAAgB2L;eACPtK,KAAKwtD,GAAWljD;;IAGzB3L;QACE,OAAOqB,KAAK+vD,GAAWxsB;;IAGzB5kC,GAAoB2L;QAClB,OAAOtK,KAAK+vD,GAAWxsB,gBAAgBj1B,IAAIhE;;IAG7C3L;QAEE,OADAqB,KAAK+vD,KAAa,IAAIlE,IACfp6B,QAAQF;;IAGjB5yB,GACE8oC,GACA6T,GACAC;;;IAKF58C,GAAeitD;;;IAIfjtD;IAEAA,GAAoB6L;;;;;;;;;;;;;;;;;;UClkCTwlD;IACXrxD,YAAmB6B;QAAAR,WAAAQ;;;;MAERyvD;IACXtxD,YAAmB6B;QAAAR,WAAAQ;;;;;;;;UA6BR0vD;IAiBXvxD,YACUkS;;IAEAs/C;QAFAnwD,aAAA6Q,aAEAs/C,GAnBVnwD,UAAsC;;;;;;;QAOtCA,WAAkB;;QAGlBA,UAAyBoP;;QAEzBpP,UAAsBoP,MASpBpP,KAAKowD,KAAgB5hC,GAAmB3d,IACxC7Q,KAAKqwD,KAAc,IAAI5gD,GAAYzP,KAAKowD;;;;;WAO1CE;QACE,OAAOtwD,KAAKmwD;;;;;;;;;;;WAadxxD,GACEqS,GACAu/C;QAEA,MAAMC,IAAYD,IACdA,EAAgBC,KAChB,IAAIlgD,IACFmgD,IAAiBF,IACnBA,EAAgBF,KAChBrwD,KAAKqwD;QACT,IAAIK,IAAiBH,IACjBA,EAAgBt/C,KAChBjR,KAAKiR,IACL0/C,IAAiBF,GACjBG,KAAc;;;;;;;;;QAWlB,MAAMC,IACJ7wD,KAAK6Q,MAAMigD,QAAqBL,EAAezrD,SAAShF,KAAK6Q,MAAMhM,QAC/D4rD,EAAevvB,SACf,MACA6vB,IACJ/wD,KAAK6Q,MAAMmgD,QAAoBP,EAAezrD,SAAShF,KAAK6Q,MAAMhM,QAC9D4rD,EAAex1C,UACf;;QAwFN,IAtFAjK,EAAWhF,GACT,CAACxL,GAAkBywD;YACjB,MAAMC,IAAST,EAAejvD,IAAIhB;YAClC,IAAIgS,IAASy+C,aAAuBl9C,KAAWk9C,IAAc;YACzDz+C,MAQFA,IAASub,GAAa/tB,KAAK6Q,OAAO2B,KAAUA,IAAS;YAGvD,MAAM2+C,MAA4BD,KAC9BlxD,KAAKiR,GAAY3C,IAAI4iD,EAAO1wD,MAE1B4wD,MAA4B5+C,MAC9BA,EAAO4Z;;;YAGNpsB,KAAKiR,GAAY3C,IAAIkE,EAAOhS,QAAQgS,EAAOyW;YAGhD,IAAIooC,KAAgB;;wBAGpB,IAAIH,KAAU1+C,GAAQ;gBACF0+C,EAAOvjD,OAAOrJ,QAAQkO,EAAO7E,UAqBpCwjD,MAA8BC,MACvCZ,EAAUc,MAAM;oBAAE5gD;oBAA2BV,KAAKwC;oBAClD6+C,KAAgB,KArBXrxD,KAAKuxD,GAA4BL,GAAQ1+C,OAC5Cg+C,EAAUc,MAAM;oBACd5gD;oBACAV,KAAKwC;oBAEP6+C,KAAgB,IAGbR,KACC7wD,KAAKowD,GAAc59C,GAAQq+C,KAAkB,KAC9CE,KACC/wD,KAAKowD,GAAc59C,GAAQu+C,KAAmB;;;;gBAKhDH,KAAc;oBAOVM,KAAU1+C,KACpBg+C,EAAUc,MAAM;gBAAE5gD;gBAAwBV,KAAKwC;gBAC/C6+C,KAAgB,KACPH,MAAW1+C,MACpBg+C,EAAUc,MAAM;gBAAE5gD;gBAA0BV,KAAKkhD;gBACjDG,KAAgB,IAEZR,KAAkBE;;;;YAIpBH,KAAc;YAIdS,MACE7+C,KACFm+C,IAAiBA,EAAepiD,IAAIiE,IAElCk+C,IADEU,IACeV,EAAeniD,IAAI/N,KAEnBkwD,EAAezgD,OAAOzP,OAGzCmwD,IAAiBA,EAAe1gD,OAAOzP,IACvCkwD,IAAiBA,EAAezgD,OAAOzP;YAO3CR,KAAK6Q,MAAMigD,QAAqB9wD,KAAK6Q,MAAMmgD,MAC7C,MAAOL,EAAe3rD,OAAOhF,KAAK6Q,MAAY,SAAE;YAC9C,MAAMqgD,IAASlxD,KAAK6Q,MAAMigD,OACtBH,EAAezvB,SACfyvB,EAAe11C;YACnB01C,IAAiBA,EAAe1gD,OAAOihD,EAAQ1wD,MAC/CkwD,IAAiBA,EAAezgD,OAAOihD,EAAQ1wD,MAC/CgwD,EAAUc,MAAM;gBAAE5gD;gBAA0BV;;;QAQhD,OAAO;YACLwhD,IAAab;YACbc,IAAAjB;YACAkB,IAAAd;YACAe,IAAajB;;;IAIT/xD,GACNuyD,GACA1+C;;;;;;;;QASA,OACE0+C,EAAO9kC,MACP5Z,EAAOyW,0BACNzW,EAAO4Z;;;;;;;;;;;;;IAeZztB,GACEqS,GACA4gD,GACAz9C;QAMA,MAAMpD,IAAU/Q,KAAKqwD;QACrBrwD,KAAKqwD,KAAcr/C,EAAWq/C,IAC9BrwD,KAAKiR,KAAcD,EAAWC;;QAE9B,MAAMN,IAAUK,EAAWw/C,GAAUqB;QACrClhD,EAAQ6J,KAAK,CAACs3C,GAAIC,MAsLtB,SAA2BD,GAAgBC;YACzC,MAAMztC,IAAS/T;gBACb,QAAQA;kBACN;oBACE,OAAO;;kBACT;kBAEA;;;;oBAIE,OAAO;;kBACT;oBACE,OAAO;;kBACT;oBACE,OAzdYhT;;;YA6dlB,OAAO+mB,EAAMwtC,KAAMxtC,EAAMytC;;;;;;;;;;;;;;;;;GAvMnBC,EAAkBF,EAAGphD,MAAMqhD,EAAGrhD,SAC9B1Q,KAAKowD,GAAc0B,EAAG9hD,KAAK+hD,EAAG/hD,OAIlChQ,KAAKiyD,GAAkB99C;QACvB,MAAM+9C,IAAeN,IACjB5xD,KAAK4xD,OACL,IAEEO,IADsC,MAA7BnyD,KAAKoyD,GAAeptD,QAAchF,KAAKoG,sCAEhD+K,IAAmBghD,MAAiBnyD,KAAKqyD;QAG/C,IAFAryD,KAAKqyD,KAAYF,GAEM,MAAnBxhD,EAAQ7R,UAAiBqS,GAGtB;YAWL,OAAO;gBACLmzC,UAXyB,IAAI1zC,GAC7B5Q,KAAK6Q,OACLG,EAAWq/C,IACXt/C,GACAJ,GACAK,EAAWC,sBACXkhD,GACAhhD;gDAC+B;gBAI/BmhD,IAAAJ;;;;QAdF,OAAO;YAAEI,IAAAJ;;;;;;WAuBbvzD,GAAuBitD;QACrB,OAAI5rD,KAAKoG,kCAAWwlD;;;;;QAKlB5rD,KAAKoG,MAAU,GACRpG,KAAKgzB,GACV;YACEw+B,IAAaxxD,KAAKqwD;YAClBoB,IAAW,IAAInhD;YACfqhD,IAAa3xD,KAAKiR;YAClBygD,KAAa;;qCAEa,MAIvB;YAAEY,IAAc;;;;;WAOnB3zD,GAAgB6B;;QAEtB,QAAIR,KAAKmwD,GAAiB7hD,IAAI9N;;UAIzBR,KAAKqwD,GAAY/hD,IAAI9N,OAOtBR,KAAKqwD,GAAY7uD,IAAIhB,GAAM4rB;;;;;WAWzBztB,GAAkBwV;QACpBA,MACFA,EAAajC,GAAerR,QAC1BL,KAAQR,KAAKmwD,KAAmBnwD,KAAKmwD,GAAiB5hD,IAAI/N,KAE5D2T,EAAahC,GAAkBtR,QAAQL,UAMvC2T,EAAa/B,GAAiBvR,QAC5BL,KAAQR,KAAKmwD,KAAmBnwD,KAAKmwD,GAAiBlgD,OAAOzP;QAE/DR,KAAKoG,KAAU+N,EAAa/N;;IAIxBzH;;QAEN,KAAKqB,KAAKoG,IACR,OAAO;;;gBAKT,MAAMmsD,IAAoBvyD,KAAKoyD;QAC/BpyD,KAAKoyD,KAAiBhjD,MACtBpP,KAAKqwD,GAAYxvD,QAAQmP;YACnBhQ,KAAKwyD,GAAgBxiD,EAAIxP,SAC3BR,KAAKoyD,KAAiBpyD,KAAKoyD,GAAe7jD,IAAIyB,EAAIxP;;;QAKtD,MAAMmQ,IAAiC;QAWvC,OAVA4hD,EAAkB1xD,QAAQL;YACnBR,KAAKoyD,GAAe9jD,IAAI9N,MAC3BmQ,EAAQlP,KAAK,IAAIwuD,GAAqBzvD;YAG1CR,KAAKoyD,GAAevxD,QAAQL;YACrB+xD,EAAkBjkD,IAAI9N,MACzBmQ,EAAQlP,KAAK,IAAIuuD,GAAmBxvD;YAGjCmQ;;;;;;;;;;;;;;;;;;;;;;IAuBThS,GAA8B8zD;QAC5BzyD,KAAKmwD,KAAmBsC,EAAYjU,IACpCx+C,KAAKoyD,KAAiBhjD;QACtB,MAAM4B,IAAahR,KAAK0yD,GAAkBD,EAAYphD;QACtD,OAAOrR,KAAKgzB,GAAahiB,8BAAsC;;;;;;;;IASjErS;QACE,OAAOiS,GAAa+hD,GAClB3yD,KAAK6Q,OACL7Q,KAAKqwD,IACLrwD,KAAKiR,sBACLjR,KAAKqyD;;;;;;;;ACnYX,MAAMO;IACJj0D;;;;IAISkS;;;;;IAKAvG;;;;;;;IAOAuoD;QAZA7yD,aAAA6Q,GAKA7Q,gBAAAsK,GAOAtK,YAAA6yD;;;;iCAKX,OAAMC;IACJn0D,YAAmB6B;QAAAR,WAAAQ;;;;;;;QAQnBR,WAA4B;;;;;;;;;;;GA8F9B,OAAM+yD;IAyCJp0D,YACS0jC,GACA2wB,GACGxM;;IAEHyM,GACCrS,GACAsS;kBAND7wB,aACA2wB,aACGxM,aAEHyM,GACCjzD,mBAAA4gD,aACAsS;QA/CVlzD,UAAgD,MAEhDA,UAAoB,IAAIgB,EACtBmyD,KAAKtlC,GAAcslC,IACnB3hD,KAEFxR,UAAkB,IAAI+R;;;;;QAKtB/R,UAAkD;;;;;QAKlDA,UAA0B,IAAIkL,GAC5BzE,EAAYpH;;;;;QAMdW,UAAiC,IAAI+R,KACrC/R,UAAoB,IAAIm/C;;QAExBn/C,UAAgC;;QAIhCA,UAAiC,IAAI+R,KACrC/R,UAAiC+yC,GAAkBqgB,MAE3CpzD;;;;QAKRA,eAAwCsB;;IAYxC+xD;QACE,QAAiC,MAA1BrzD,KAAKszD;;IAGd30D,UAAU40D;QAURvzD,KAAKuzD,KAAqBA;;IAG5B50D,aAAakS;QAGX,IAAIvG,GACAsrB;QAHJ51B,KAAKwzD,GAAiB;QAKtB,MAAMC,IAAYzzD,KAAK0zD,GAAkBlyD,IAAIqP;QAC7C,IAAI4iD;;;;;;;QAOFnpD,IAAWmpD,EAAUnpD,UACrBtK,KAAKizD,GAAkBU,GAAoBrpD,IAC3CsrB,IAAe69B,EAAUZ,KAAKe,WACzB;YACL,MAAM1+C,UAAmBlV,KAAKqiC,GAAWwxB,GACvCjuC,GAAc/U,KAGVgP,IAAS7f,KAAKizD,GAAkBU,GACpCz+C,EAAW5K;YAEbA,IAAW4K,EAAW5K,UACtBsrB,UAAqB51B,KAAK8zD,GACxBjjD,GACAvG,GACW,cAAXuV,IAEE7f,KAAK+zD,MACP/zD,KAAKgzD,GAAYgB,OAAO9+C;;QAI5B,OAAO0gB;;;;;WAOTj3B,SACEkS,GACAvG,GACAlE;QAEA,MAAMqsD,UAAoBzyD,KAAKqiC,GAAW4xB,GACxCpjD;mCAC0B,IAEtBgiD,IAAO,IAAI3C,GAAKr/C,GAAO4hD,EAAYjU,KACnC0V,IAAiBrB,EAAKH,GAAkBD,EAAYphD,YACpD8iD,IAA0BniD,GAAaC,GAC3C3H,GACAlE,iCAAWpG,KAAK4rD,cAEZjO,IAAakV,EAAK7/B,GACtBkhC;oCAC4Bl0D,KAAK+zD,IACjCI;QAEFn0D,KAAKo0D,GAAoB9pD,GAAUqzC,EAAWuU;QAO9C,MAAMvkD,IAAO,IAAIilD,GAAU/hD,GAAOvG,GAAUuoD;QAO5C,OANA7yD,KAAK0zD,GAAkBpkD,IAAIuB,GAAOlD,IAC9B3N,KAAKq0D,GAAgB/lD,IAAIhE,KAC3BtK,KAAKq0D,GAAgB7yD,IAAI8I,GAAW7I,KAAKoP,KAEzC7Q,KAAKq0D,GAAgB/kD,IAAIhF,GAAU,EAACuG;QAE/B8sC,EAAW2G;;IAGpB3lD,SAAekS;QACb7Q,KAAKwzD,GAAiB;QAEtB,MAAMC,IAAYzzD,KAAK0zD,GAAkBlyD,IAAIqP,IAQvCyjD,IAAUt0D,KAAKq0D,GAAgB7yD,IAAIiyD,EAAUnpD;;;gBACnD,IAAIgqD,EAAQx1D,SAAS,GAMnB,OALAkB,KAAKq0D,GAAgB/kD,IACnBmkD,EAAUnpD,UACVgqD,EAAQzuD,OAAOstD,MAAM3hD,GAAY2hD,GAAGtiD;aAEtC7Q,KAAK0zD,GAAkBzjD,OAAOY;;gBAKhC,IAAI7Q,KAAK+zD,IAAiB;;;YAGxB/zD,KAAKizD,GAAkBsB,GAAuBd,EAAUnpD;YAC5BtK,KAAKizD,GAAkBxF,GACjDgG,EAAUnpD,mBAIJtK,KAAKqiC,GACRmyB,GAAcf,EAAUnpD,wCAAuC,GAC/DozB,KAAK;gBACJ19B,KAAKizD,GAAkBwB,GAAgBhB,EAAUnpD,WACjDtK,KAAKgzD,GAAY0B,GAASjB,EAAUnpD,WACpCtK,KAAK20D,GAAuBlB,EAAUnpD;eAEvCiwB,MAAMsI;eAGX7iC,KAAK20D,GAAuBlB,EAAUnpD,iBAChCtK,KAAKqiC,GAAWmyB,GACpBf,EAAUnpD;sCACmB;;IAKnC3L,YAAY6xB,GAAmBokC;QAC7B50D,KAAKwzD,GAAiB;QAEtB;YACE,MAAMhnD,UAAexM,KAAKqiC,GAAWwyB,GAAWrkC;YAChDxwB,KAAKizD,GAAkBnF,GAAmBthD,EAAOojB,UACjD5vB,KAAK80D,GAAoBtoD,EAAOojB,SAASglC,UACnC50D,KAAK+0D,GAAgCvoD,EAAOmE,WAC5C3Q,KAAKgzD,GAAY5K;UACvB,OAAO9qD;;;YAGP,MAAMP,IAAQsjC,GAA6B/iC,GAAG;YAC9Cs3D,EAAapjC,OAAOz0B;;;IAIxB4B,SAAuBmX;QACrB9V,KAAKwzD,GAAiB;QACtB;YACE,MAAM7iD,UAAgB3Q,KAAKqiC,GAAWsnB,GAAiB7zC;;wBAEvDA,EAAYnE,GAAc9Q,QAAQ,CAACsT,GAAc7J;gBAC/C,MAAM0qD,IAAkBh1D,KAAKi1D,GAA+BzzD,IAC1D8I;gBAEE0qD;;;gBA7YRr3D,EAiZQwW,EAAajC,GAAelN,OAC1BmP,EAAahC,GAAkBnN,OAC/BmP,EAAa/B,GAAiBpN,QAC9B,IAGAmP,EAAajC,GAAelN,OAAO,IACrCgwD,EAAgBE,MAAmB,IAC1B/gD,EAAahC,GAAkBnN,OAAO,IAzZvDrH,EA2ZUq3D,EAAgBE,MAGT/gD,EAAa/B,GAAiBpN,OAAO,MA9ZtDrH,EAgaUq3D,EAAgBE;gBAGlBF,EAAgBE,MAAmB;sBAMnCl1D,KAAK+0D,GAAgCpkD,GAASmF;UACpD,OAAO/Y;kBACD8lC,GAAyB9lC;;;IAInC4B,GACEitD,GACAuJ;;;;;QAMA,IACGn1D,KAAK+zD,8BAAmBoB,MACvBn1D,KAAK+zD,oCAAmBoB,GAC1B;YACAn1D,KAAKwzD,GAAiB;YACtB,MAAM4B,IAAmB;YACzBp1D,KAAK0zD,GAAkB7yD,QAAQ,CAACgQ,GAAO4iD;gBACrC,MAAM9V,IAAa8V,EAAUZ,KAAKwC,GAAuBzJ;gBAKrDjO,EAAW2G,YACb8Q,EAAiB3zD,KAAKk8C,EAAW2G;gBAGrCtkD,KAAKuzD,GAAoB+B,GAAoB1J,IAC7C5rD,KAAKuzD,GAAoB/O,GAAc4Q,IACvCp1D,KAAK4rD,cAAcA,GACf5rD,KAAK+zD,MACP/zD,KAAKizD,GAAkBsC,GAAe3J;;;IAK5CjtD,SAAmB2L,GAAoBwnB;QACrC9xB,KAAKwzD,GAAiB;;QAGtBxzD,KAAKizD,GAAkBuC,GAAiBlrD,GAAU,YAAYwnB;QAE9D,MAAMkjC,IAAkBh1D,KAAKi1D,GAA+BzzD,IAAI8I,IAC1DmrD,IAAWT,KAAmBA,EAAgBx0D;QACpD,IAAIi1D,GAAU;;;;;;;YAQZ,IAAI5jD,IAAkB,IAAI3G,GACxBzE,EAAYpH;YAEdwS,IAAkBA,EAAgBvG,GAChCmqD,GACA,IAAIxhD,GAAWwhD,GAAUtxD,EAAgBkB;YAE3C,MAAMyM,IAAyB1C,KAAiBb,IAAIknD,IAC9Cp8B,IAAQ,IAAI3nB,GAChBvN,EAAgBkB;iCACK,IAAI0M;oCACD,IAAIrE,GAAoBzO,IAChD4S,GACAC;kBAGI9R,KAAK2pD,GAAiBtwB;;;;;;YAO5Br5B,KAAK01D,KAA0B11D,KAAK01D,GAAwBjqD,OAC1DgqD,IAEFz1D,KAAKi1D,GAA+BhlD,OAAO3F,IAC3CtK,KAAK21D;qBAEC31D,KAAKqiC,GACRmyB,GAAclqD,kCAAwC,GACtDozB,KAAK,MAAM19B,KAAK20D,GAAuBrqD,GAAUwnB,IACjDyI,MAAMsI;;IAIblkC,SACEi3D;QAEA51D,KAAKwzD,GAAiB;QAEtB,MAAM5jC,IAAUgmC,EAAoBplC,MAAMZ;QAE1C;YACE,MAAMjf,UAAgB3Q,KAAKqiC,GAAWwzB,GACpCD;;;;;wBAOF51D,KAAK81D,GAAoBlmC,cAAoB,OAC7C5vB,KAAK+1D,GAA8BnmC,IAEnC5vB,KAAKizD,GAAkB+C,GAAoBpmC,GAAS;kBAC9C5vB,KAAK+0D,GAAgCpkD;UAC3C,OAAO5T;kBACD8lC,GAAyB9lC;;;IAInC4B,SACEixB,GACA7yB;QAEAiD,KAAKwzD,GAAiB;QAEtB;YACE,MAAM7iD,UAAgB3Q,KAAKqiC,GAAW4zB,GAAYrmC;;;;;wBAMlD5vB,KAAK81D,GAAoBlmC,GAAS7yB,IAClCiD,KAAK+1D,GAA8BnmC,IAEnC5vB,KAAKizD,GAAkB+C,GAAoBpmC,GAAS,YAAY7yB,UAC1DiD,KAAK+0D,GAAgCpkD;UAC3C,OAAO5T;kBACD8lC,GAAyB9lC;;;IAInC4B,SAAoCmyB;QAC7B9wB,KAAKgzD,GAAYpM,QACpBxqD,EA5gBU,cA8gBR;QAKJ;YACE,MAAM85D,UAAuBl2D,KAAKqiC,GAAWma;YAC7C,KlCpkByB,MkCokBrB0Z;;YAGF,YADAplC,EAASS;YAIX,MAAM4kC,IAAYn2D,KAAKo2D,GAAuB50D,IAAI00D,MAAmB;YACrEC,EAAU10D,KAAKqvB,IACf9wB,KAAKo2D,GAAuB9mD,IAAI4mD,GAAgBC;UAChD,OAAO74D;YACP,MAAM8tD,IAAiB/qB,GACrB/iC,GACA;YAEFwzB,EAASU,OAAO45B;;;;;;WAQZzsD,GAA8BixB;SACnC5vB,KAAKo2D,GAAuB50D,IAAIouB,MAAY,IAAI/uB,QAAQiwB;YACvDA,EAASS;YAGXvxB,KAAKo2D,GAAuBnmD,OAAO2f;;uFAI7BjxB,GAAwC03D;QAC9Cr2D,KAAKo2D,GAAuBv1D,QAAQs1D;YAClCA,EAAUt1D,QAAQiwB;gBAChBA,EAASU,OAAO,IAAIvuB,EAAelB,EAAKE,WAAWo0D;;YAIvDr2D,KAAKo2D,GAAuBE;;IAGtB33D,GACNixB,GACAkB;QAEA,IAAIylC,IAAev2D,KAAKw2D,GAAsBx2D,KAAK4gD,YAAY6V;QAC1DF,MACHA,IAAe,IAAIrrD,GACjBjM,KAGJs3D,IAAeA,EAAajrD,GAAOskB,GAASkB,IAC5C9wB,KAAKw2D,GAAsBx2D,KAAK4gD,YAAY6V,QAAWF;;;;;WAOzD53D,GAAoBixB,GAAkB7yB;QACpC,IAAIw5D,IAAev2D,KAAKw2D,GAAsBx2D,KAAK4gD,YAAY6V;;;gBAI/D,IAAIF,GAAc;YAChB,MAAMzlC,IAAWylC,EAAa/0D,IAAIouB;YAC9BkB,MAKE/zB,IACF+zB,EAASU,OAAOz0B,KAEhB+zB,EAASS,WAEXglC,IAAeA,EAAa9qD,OAAOmkB,KAErC5vB,KAAKw2D,GAAsBx2D,KAAK4gD,YAAY6V,QAAWF;;;IAI3D53D,GAAuB2L,GAAkBvN,IAAsB;QAC7DiD,KAAKizD,GAAkBsB,GAAuBjqD;QAQ9C,KAAK,MAAMuG,KAAS7Q,KAAKq0D,GAAgB7yD,IAAI8I,IAC3CtK,KAAK0zD,GAAkBzjD,OAAOY,IAC1B9T,KACFiD,KAAKuzD,GAAoBmD,GAAa7lD,GAAO9T;QAMjD,IAFAiD,KAAKq0D,GAAgBpkD,OAAO3F,IAExBtK,KAAK+zD,IAAiB;YACN/zD,KAAK22D,GAAkBC,GAAsBtsD,GACrDzJ,QAAQ40D;gBACKz1D,KAAK22D,GAAkB9rB,GAAY4qB;;gBAGtDz1D,KAAK62D,GAAkBpB;;;;IAMvB92D,GAAkB6B;;;QAGxB,MAAMs2D,IAAgB92D,KAAK01D,GAAwBl0D,IAAIhB;QACjC,SAAlBs2D,MAKJ92D,KAAKgzD,GAAY0B,GAASoC,IAC1B92D,KAAK01D,KAA0B11D,KAAK01D,GAAwBjqD,OAAOjL,IACnER,KAAKi1D,GAA+BhlD,OAAO6mD,IAC3C92D,KAAK21D;;IAGPh3D,GACE2L,GACA4nD;QAEA,KAAK,MAAM6E,KAAe7E,GACxB,IAAI6E,aAAuB/G,IACzBhwD,KAAK22D,GAAkB9iB,GAAakjB,EAAYv2D,KAAK8J,IACrDtK,KAAKg3D,GAAiBD,SACjB,IAAIA,aAAuB9G,IAAsB;YACtD7zD,EA7pBQ,cA6pBU,kCAAkC26D,EAAYv2D,MAChER,KAAK22D,GAAkB7iB,GAAgBijB,EAAYv2D,KAAK8J;YACnCtK,KAAK22D,GAAkB9rB,GAC1CksB,EAAYv2D;;YAIZR,KAAK62D,GAAkBE,EAAYv2D;eAGrCjD;;IAKEoB,GAAiBo4D;QACvB,MAAMv2D,IAAMu2D,EAAYv2D;QACnBR,KAAK01D,GAAwBl0D,IAAIhB,OACpCpE,EA/qBU,cA+qBQ,4BAA4BoE,IAC9CR,KAAKi3D,GAAyBx1D,KAAKjB;QACnCR,KAAK21D;;;;;;;;;WAYDh3D;QACN,MACEqB,KAAKi3D,GAAyBn4D,SAAS,KACvCkB,KAAK01D,GAAwB1wD,OAAOhF,KAAKkzD,MACzC;YACA,MAAM1yD,IAAMR,KAAKi3D,GAAyB93B,SACpC23B,IAAgB92D,KAAKk3D,GAAuB1wD;YAClDxG,KAAKi1D,GAA+B3lD,IAClCwnD,GACA,IAAIhE,GAAgBtyD,KAEtBR,KAAK01D,KAA0B11D,KAAK01D,GAAwBpqD,GAC1D9K,GACAs2D,IAEF92D,KAAKgzD,GAAYgB,OACf,IAAI3pD,GACFub,GAAcgH,GAAgBpsB,EAAIkF,QAClCoxD,6BAEAjhC,GAAesN;;;;IAOvBxkC;QACE,OAAOqB,KAAK01D;;;IAId/2D;QACE,OAAOqB,KAAKi3D;;IAGdt4D,SACEgS,GACAmF;QAEA,MAAMqhD,IAA2B,IAC3BC,IAA2C,IAC3CC,IAAyC;QAE/Cr3D,KAAK0zD,GAAkB7yD,QAAQ,CAACc,GAAG8xD;YACjC4D,EAAiB51D,KACfgwB,QAAQF,UACLmM,KAAK;gBACJ,MAAMw2B,IAAiBT,EAAUZ,KAAKH,GAAkB/hD;gBACxD,OAAKujD,EAAetD,KAMb5wD,KAAKqiC,GACT4xB,GAAaR,EAAU5iD,kCAAiC,GACxD6sB,KAAK,EAAGrsB,WAAAA,OACAoiD,EAAUZ,KAAKH,GACpBrhD,GACA6iD,MAVGA;;;;2BAcVx2B,KAAMw2B;gBACL,MAAM//C,IACJ2B,KAAeA,EAAYnE,GAAcnQ,IAAIiyD,EAAUnpD,WACnDqzC,IAAa8V,EAAUZ,KAAK7/B,GAChCkhC;4CAC4Bl0D,KAAK+zD,IACjC5/C;gBAMF,IAJAnU,KAAKo0D,GACHX,EAAUnpD,UACVqzC,EAAWuU,KAETvU,EAAW2G,UAAU;oBACnBtkD,KAAK+zD,MACP/zD,KAAKizD,GAAkBuC,GACrB/B,EAAUnpD,UACVqzC,EAAW2G,SAASpzC,YAAY,gBAAgB;oBAIpDimD,EAAS11D,KAAKk8C,EAAW2G;oBACzB,MAAMtzC,IAAaykB,GAAiB6hC,GAClC7D,EAAUnpD,UACVqzC,EAAW2G;oBAEb8S,EAAqB31D,KAAKuP;;;kBAM9BygB,QAAQE,IAAI0lC,IAClBr3D,KAAKuzD,GAAoB/O,GAAc2S,UACjCn3D,KAAKqiC,GAAWk1B,GAAuBH;;IAG/Cz4D,GAAiB64D;IAOjB74D,SAA6B8oC;QAG3B,KAFqBznC,KAAK4gD,YAAYt8C,QAAQmjC,IAE7B;YACfrrC,EA5yBU,cA4yBQ,0BAA0BqrC,EAAKgvB;YAEjD,MAAMjqD,UAAexM,KAAKqiC,GAAWo1B,GAAiBhwB;YACtDznC,KAAK4gD,cAAcnZ;;YAGnBznC,KAAK03D,GACH;;YAGF13D,KAAKizD,GAAkBwE,GACrBhwB,GACAj7B,EAAO8uC,IACP9uC,EAAO+uC,WAEHv7C,KAAK+0D,GAAgCvoD,EAAOkvC;;;IAItD/8C,GAAuB2L;QACrB,MAAM0qD,IAAkBh1D,KAAKi1D,GAA+BzzD,IAAI8I;QAChE,IAAI0qD,KAAmBA,EAAgBE,IACrC,OAAO9lD,KAAiBb,IAAIymD,EAAgBx0D;QACvC;YACL,IAAIm3D,IAASvoD;YACb,MAAMklD,IAAUt0D,KAAKq0D,GAAgB7yD,IAAI8I;YACzC,KAAKgqD,GACH,OAAOqD;YAET,KAAK,MAAM9mD,KAASyjD,GAAS;gBAC3B,MAAMb,IAAYzzD,KAAK0zD,GAAkBlyD,IAAIqP;gBAK7C8mD,IAASA,EAAO9H,GAAU4D,EAAUZ,KAAK+E;;YAE3C,OAAOD;;;;;;;;;AAiCbh1B,eAAek1B,GACbhP,GACA4K;IAEA,MAAMqE,IAAiBj6D,EAAUgrD,IAC3B4J,UAAoBqF,EAAez1B,GAAW4xB,GAClDR,EAAU5iD;+BACgB,IAEtB+kB,IAAe69B,EAAUZ,KAAKkF,GAClCtF;IAQF,OANIqF,EAAe/D,MACjB+D,EAAe1D,GACbX,EAAUnpD,UACVsrB,EAAas8B,KAGVt8B;;;;gCAKF+M;eAAewsB,GACpBtG,GACAj5B,GACAooC,GACAj7D;IAEA,MAAM+6D,IAAiBj6D,EAAUgrD;IACjCiP,EAAetE,GAAiB;IAChC,MAAMniD;;;aXsDNgxB,GACAzS;QAEA,MAAMqvB,IAAiBphD,EAAUwkC,IAC3B41B,IAAoBp6D,EACxBohD,EAAe1rB;QAGjB,OAAO0rB,EAAe1E,YAAYvF,eAChC,6BACA,YACApc,KACSq/B,EAAkBC,GAAmBt/B,GAAKhJ,GAASppB,KAAK6I,KACzDA,IACK4vC,EAAepE,GAAeY,GACnC7iB,GACAvpB,KAGKwhB,GAAmBU,QAAiC;;oCWzE3C4mC;KACtBL,EAAez1B,IACfzS;IAGgB,SAAdve,KAYe,cAAf2mD;;;;UAIIF,EAAe9E,GAAY5K,OACT,mBAAf4P,KAAgD,eAAfA;;;IAG1CF,EAAehC,GAAoBlmC,GAAS7yB,KAAgB,gBXyD9DslC,GACAzS;QAE0B/xB,EACxBA,EAAUwkC,GAA4B9O,IAGtB4W,GAAyBva;;oCW/DzCwoC;KAAkCN,EAAez1B,IAAYzS,MAE7DryB,WAGIu6D,EAAe/C,GAAgC1jD;;;;;;;;IAlBnDjV,EA95BY,cA85BM,0CAA0CwzB;;;;gCAuBzD+S;eAAe01B,GACpBxP,GACAjU;IAEA,MAAMkjB,IAAiBj6D,EAAUgrD;IACjC,KAAkB,MAAdjU,MAA0D,MAApCkjB,EAAexE,IAA2B;;;;;;;QAOlE,MAAM3D,IAAgBmI,EAAe7E,GAAkBqF,MACjDC,UAAsBC,GAC1BV,GACAnI,EAAcpqD;QAGhBuyD,EAAexE,MAAmB,SAC5BwE,EAAe9E,GAAYqF,IAAkB;QACnD,KAAK,MAAMnjD,KAAcqjD,GACvBT,EAAe9E,GAAYgB,OAAO9+C;WAE/B,KAAkB,MAAd0/B,MAA2D,MAApCkjB,EAAexE,IAA4B;QAC3E,MAAM3D,IAA4B;QAElC,IAAItgC,IAAIoC,QAAQF;QAChBumC,EAAezD,GAAgBxzD,QAAQ,CAACc,GAAG2I;YACrCwtD,EAAe7E,GAAkBwF,GAAmBnuD,KACtDqlD,EAAcluD,KAAK6I,KAEnB+kB,IAAIA,EAAEqO,KAAK,OACTo6B,EAAenD,GAAuBrqD,IAC/BwtD,EAAez1B,GAAWmyB,GAC/BlqD;0CAC6B,MAInCwtD,EAAe9E,GAAY0B,GAASpqD;kBAEhC+kB,SAEAmpC,GACJV,GACAnI;;QAUN,SAA6B9G;YAC3B,MAAMiP,IAAiBj6D,EAAUgrD;YACjCiP,EAAe7C,GAA+Bp0D,QAAQ,CAACc,GAAG2I;gBACxDwtD,EAAe9E,GAAY0B,GAASpqD;gBAEtCwtD,EAAenB,GAAkB+B,MACjCZ,EAAe7C,KAAiC,IAAIljD,KAIpD+lD,EAAepC,KAA0B,IAAIxqD,GAC3CzE,EAAYpH;;;;;;;;;;;wCAlBZs5D;SAAoBb,IACpBA,EAAexE,MAAmB,SAC5BwE,EAAe9E,GAAYqF,IAAkB;;;;AA8BvD11B,eAAe61B,GACb3P,GACAlzC,GACAijD;IAEA,MAAMd,IAAiBj6D,EAAUgrD,IAC3B0P,IAA8B,IAC9BnD,IAAmC;IACzC,KAAK,MAAM9qD,KAAYqL,GAAS;QAC9B,IAAIT;QACJ,MAAMo/C,IAAUwD,EAAezD,GAAgB7yD,IAAI8I;QAEnD,IAAIgqD,KAA8B,MAAnBA,EAAQx1D,QAAc;;;;;YAKnCoW,UAAmB4iD,EAAez1B,GAAWwxB,GAC3CjuC,GAAc0uC,EAAQ;YAGxB,KAAK,MAAMzjD,KAASyjD,GAAS;gBAC3B,MAAMb,IAAYqE,EAAepE,GAAkBlyD,IAAIqP,IAMjD8sC,UAAmBka,GACvBC,GACArE;gBAEE9V,EAAW2G,YACb8Q,EAAiB3zD,KAAKk8C,EAAW2G;;eAGhC;;;YAOL,MAAMx8C,UAAek3C,GAAgB8Y,EAAez1B,IAAY/3B;YAEhE4K,UAAmB4iD,EAAez1B,GAAWwxB,GAAe/rD,UACtDgwD,EAAehE,GACnB+E,OACAvuD;0BACa;;QAIjBiuD,EAAc92D;;IAIhB,OADAq2D,EAAevE,GAAoB/O,GAAc4Q,IAC1CmD;;;;;;;;;;;;;gCAcT;SAASM,GAAwB/wD;IAC/B,OAAO+d,GACL/d,EAAOpC,MACPoC,EAAOP,iBACPO,EAAON,SACPM,EAAOL,SACPK,EAAOjD,yBAEPiD,EAAOJ,SACPI,EAAOH;;;;;SAMKklD,GAAiBhE;IAC/B,MAAMiP,IAAiBj6D,EAAUgrD;IACjC,OX5GwBhrD,EACtBA,EW2GqCi6D,EAAez1B,IX3GdkY,aAGjBsS;;;;gCW6GlBlqB;eAAeysB,GACpBvG,GACAv+C,GACAsI,GACA7V;IAEA,MAAM+6D,IAAiBj6D,EAAUgrD;IACjC,IAAIiP,EAAexE;;;IAGjBl3D,EA5mCY,cA4mCM,uDAIpB,IAAI07D,EAAezD,GAAgB/lD,IAAIhE,IACrC,QAAQsI;MACN,KAAK;MACL,KAAK;QAAe;YAClB,MAAMjC,mBX1FZ0xB;gBAEA,MAAM4c,IAAiBphD,EAAUwkC,IAC3By2B,IAA0Bj7D,EAC9BohD,EAAerE;gBAGjB,OAAOqE,EAAe1E,YACnBvF,eAAe,4BAA4B,YAAYpc,KACtDkgC,EAAwBC,GACtBngC,GACAqmB,EAAe+Z,KAGlBt7B,KAAK,EAAGwP,IAAAJ,GAAaxtB,UAAAA,QACpB2/B,EAAe+Z,KAA6B15C;gBACrCwtB;;;;;;;4CW0EiBisB;aAAsBjB,EAAez1B,KACrD42B,IAAyBvnD,GAAYwnD,GACzC5uD,GACU,cAAVsI;kBAEIklD,EAAe/C,GACnBpkD,GACAsoD;YAEF;;;MAEF,KAAK;cACGnB,EAAez1B,GAAWmyB,GAC9BlqD;uCAC8B,IAEhCwtD,EAAenD,GAAuBrqD,GAAUvN;QAChD;;MAEF;QACEQ;;;;qEAMDolC,gBAAe+sB,GACpB7G,GACAva,GACA6qB;IAEA,MAAMrB,IAAiBj6D,EAAUgrD;IACjC,IAAKiP,EAAexE,IAApB;QAIA,KAAK,MAAMhpD,KAAYgkC,GAAO;YAC5B,IAAIwpB,EAAezD,GAAgB/lD,IAAIhE,IAAW;;gBAEhDlO,EA3pCU,cA2pCQ,qCAAqCkO;gBACvD;;YAGF,MAAMxC,UAAek3C,GAAgB8Y,EAAez1B,IAAY/3B,IAE1D4K,UAAmB4iD,EAAez1B,GAAWwxB,GAAe/rD;kBAC5DgwD,EAAehE,GACnB+E,GAAwB/wD,IACxBoN,EAAW5K;0BACE,IAEfwtD,EAAe9E,GAAYgB,OAAO9+C;;QAGpC,KAAK,MAAM5K,KAAY6uD;;;QAGhBrB,EAAezD,GAAgB/lD,IAAIhE;;cAKlCwtD,EAAez1B,GAClBmyB,GAAclqD,kCAAwC,GACtDozB,KAAK;YACJo6B,EAAe9E,GAAY0B,GAASpqD,IACpCwtD,EAAenD,GAAuBrqD;WAEvCiwB,MAAMsI;;;;;;;;;;;;;;;;;;;;;;;GChvCb,OAAMu2B;IAANz6D;QACEqB,eAAqCsB,GACrCtB,iBAA6B;;;;;;;;UAgBlBq5D;IAUX16D,YAAoBkqD;kBAAAA,GATpB7oD,UAAkB,IAAIgB,EACpBmyD,KAAKtlC,GAAcslC,IACnB3hD,KAGMxR;QAERA,UAAwD,IAAI0mD,KAG1D1mD,KAAK6oD,GAAWyQ,UAAUt5D;;IAG5BrB,aAAaw0B;QACX,MAAMtiB,IAAQsiB,EAAStiB;QACvB,IAAI0oD,KAAc,GAEdC,IAAYx5D,KAAKs0D,GAAQ9yD,IAAIqP;QAMjC,IALK2oD,MACHD,KAAc,GACdC,IAAY,IAAIJ,KAGdG,GACF;YACEC,EAAUC,WAAiBz5D,KAAK6oD,GAAWmL,OAAOnjD;UAClD,OAAOvT;YACP,MAAM8tD,IAAiB/qB,GACrB/iC,GACA,4BAA4BwwB,GAAeqF,EAAStiB;YAGtD,YADAsiB,EAASumC,QAAQtO;;QAKrBprD,KAAKs0D,GAAQhlD,IAAIuB,GAAO2oD,IACxBA,EAAUG,UAAUl4D,KAAK0xB;;QAGLA,EAASkiC,GAAuBr1D,KAAK4rD;QAMzD,IAAI4N,EAAUC,IAAU;YACFtmC,EAASymC,GAAeJ,EAAUC,OAEpDz5D,KAAK65D;;;IAKXl7D,SAAew0B;QACb,MAAMtiB,IAAQsiB,EAAStiB;QACvB,IAAIipD,KAAa;QAEjB,MAAMN,IAAYx5D,KAAKs0D,GAAQ9yD,IAAIqP;QACnC,IAAI2oD,GAAW;YACb,MAAMl7D,IAAIk7D,EAAUG,UAAUh0D,QAAQwtB;YAClC70B,KAAK,MACPk7D,EAAUG,UAAUj4D,OAAOpD,GAAG,IAC9Bw7D,IAA4C,MAA/BN,EAAUG,UAAU76D;;QAIrC,IAAIg7D,GAEF,OADA95D,KAAKs0D,GAAQrkD,OAAOY,IACb7Q,KAAK6oD,GAAW6L,GAAS7jD;;IAIpClS,GAAco7D;QACZ,IAAIC,KAAc;QAClB,KAAK,MAAMP,KAAYM,GAAW;YAChC,MAAMlpD,IAAQ4oD,EAAS5oD,OACjB2oD,IAAYx5D,KAAKs0D,GAAQ9yD,IAAIqP;YACnC,IAAI2oD,GAAW;gBACb,KAAK,MAAMrmC,KAAYqmC,EAAUG,WAC3BxmC,EAASymC,GAAeH,OAC1BO,KAAc;gBAGlBR,EAAUC,KAAWA;;;QAGrBO,KACFh6D,KAAK65D;;IAITl7D,GAAakS,GAAc9T;QACzB,MAAMy8D,IAAYx5D,KAAKs0D,GAAQ9yD,IAAIqP;QACnC,IAAI2oD,GACF,KAAK,MAAMrmC,KAAYqmC,EAAUG,WAC/BxmC,EAASumC,QAAQ38D;;;gBAMrBiD,KAAKs0D,GAAQrkD,OAAOY;;IAGtBlS,GAAoBitD;QAClB5rD,KAAK4rD,cAAcA;QACnB,IAAIoO,KAAc;QAClBh6D,KAAKs0D,GAAQzzD,QAAQ,CAACc,GAAG63D;YACvB,KAAK,MAAMrmC,KAAYqmC,EAAUG;;YAE3BxmC,EAASkiC,GAAuBzJ,OAClCoO,KAAc;YAIhBA,KACFh6D,KAAK65D;;IAITl7D,GAA2Bs7D;QACzBj6D,KAAKk6D,GAAyB3rD,IAAI0rD;;;QAGlCA,EAASzzD;;IAGX7H,GAA8Bs7D;QAC5Bj6D,KAAKk6D,GAAyBjqD,OAAOgqD;;;IAI/Bt7D;QACNqB,KAAKk6D,GAAyBr5D,QAAQo5D;YACpCA,EAASzzD;;;;;;;;;;UAsBF2zD;IAaXx7D,YACWkS,GACDupD,GACRjuC;QAFSnsB,aAAA6Q,aACDupD;;;;;QAVVp6D,WAA6B,GAI7BA,UAAoC,MAE5BA,6CAONA,KAAKmsB,UAAUA,KAAW;;;;;;;WAS5BxtB,GAAe07D;QAMb,KAAKr6D,KAAKmsB,QAAQmuC,wBAAwB;;YAExC,MAAMtpD,IAAmC;YACzC,KAAK,MAAM8C,KAAaumD,EAAKrpD,iCACvB8C,EAAUpD,QACZM,EAAWvP,KAAKqS;YAGpBumD,IAAO,IAAIzpD,GACTypD,EAAKxpD,OACLwpD,EAAKvpD,MACLupD,EAAKtpD,IACLC,GACAqpD,EAAKppD,IACLopD,EAAKnpD,WACLmpD,EAAKlpD;4CAC0B;;QAGnC,IAAI6oD,KAAc;QAYlB,OAXKh6D,KAAKu6D,KAKCv6D,KAAKw6D,GAAiBH,OAC/Br6D,KAAKo6D,GAAc5zD,KAAK6zD,IACxBL,KAAc,KANVh6D,KAAKy6D,GAAwBJ,GAAMr6D,KAAK4rD,iBAC1C5rD,KAAK06D,GAAkBL;QACvBL,KAAc,IAOlBh6D,KAAKq6D,KAAOA,GACLL;;IAGTr7D,QAAQ5B;QACNiD,KAAKo6D,GAAcr9D,MAAMA;;qDAI3B4B,GAAuBitD;QACrB5rD,KAAK4rD,cAAcA;QACnB,IAAIoO,KAAc;QASlB,OAPEh6D,KAAKq6D,OACJr6D,KAAKu6D,MACNv6D,KAAKy6D,GAAwBz6D,KAAKq6D,IAAMzO,OAExC5rD,KAAK06D,GAAkB16D,KAAKq6D,KAC5BL,KAAc;QAETA;;IAGDr7D,GACN07D,GACAzO;;QAQA,KAAKyO,EAAKnpD,WACR,QAAO;;;gBAKT,MAAMypD,gCAAc/O;;;gBAGpB,SAAI5rD,KAAKmsB,QAAQyuC,OAAyBD,QASlCN,EAAKvpD,KAAK/P,mCAAa6qD;;;IAGzBjtD,GAAiB07D;;;;;QAKvB,IAAIA,EAAKrpD,WAAWlS,SAAS,GAC3B,QAAO;QAGT,MAAM+7D,IACJ76D,KAAKq6D,MAAQr6D,KAAKq6D,GAAK9oD,qBAAqB8oD,EAAK9oD;QACnD,UAAI8oD,EAAKlpD,OAAoB0pD,OACoB,MAAxC76D,KAAKmsB,QAAQmuC;;;;;IAShB37D,GAAkB07D;QAKxBA,IAAOzpD,GAAa+hD,GAClB0H,EAAKxpD,OACLwpD,EAAKvpD,MACLupD,EAAKppD,IACLopD,EAAKnpD,YAEPlR,KAAKu6D,MAAqB,GAC1Bv6D,KAAKo6D,GAAc5zD,KAAK6zD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;UCzSfS;IAGXn8D,GAAsBk8C;QACpB76C,KAAK+6D,KAAqBlgB;;IAG5Bl8C,GACE8zB,GACA5hB,GACAnG,GACA8zC;;;;QAUA,OAAI3tC,EAAMmqD,QAMNtwD,EAA6BpG,QAAQH,EAAgBkB,SALhDrF,KAAKi7D,GAA0BxoC,GAAa5hB,KAS9C7Q,KAAK+6D,GAAoBtf,GAAahpB,GAAa+rB,GAAYh4C,KACpE6K;YACE,MAAM6pD,IAAkBl7D,KAAKm7D,GAAWtqD,GAAOQ;YAE/C,QACGR,EAAMigD,QAAqBjgD,EAAMmgD,SAClChxD,KAAK4wD,GACH//C,EAAM2b,IACN0uC,GACA1c,GACA9zC,KAGK1K,KAAKi7D,GAA0BxoC,GAAa5hB,MAGjD3U,OAAiBK,EAASC,SAC5BJ,EACE,wBACA,yDACAsO,EAA6BtH,YAC7B0qB,GAAejd;YAMZ7Q,KAAK+6D,GAAoBhmC,GAC9BtC,GACA5hB,GACAnG,GACAlE,KAAK40D;;;;YAILF,EAAgBr6D,QAAQmP;gBACtBorD,IAAiBA,EAAe9vD,GAAO0E,EAAIxP,KAAKwP;gBAE3CorD;;;;;+EAOPz8D,GACNkS,GACAQ;;;QAIA,IAAI2jB,IAAe,IAAItnB,GAAoB8gB,GAAmB3d;QAM9D,OALAQ,EAAUxQ,QAAQ,CAACc,GAAGknB;YAChBA,aAAoB9U,MAAYga,GAAald,GAAOgY,OACtDmM,IAAeA,EAAazmB,IAAIsa;YAG7BmM;;;;;;;;;;;;WAcDr2B,GACN6tB,GACA6uC,GACA7c,GACA8c;;;QAIA,IAAI9c,EAAWx5C,SAASq2D,EAAsBr2D,MAC5C,QAAO;;;;;;;;;gBAWT,MAAMu2D,wBACJ/uC,IACI6uC,EAAsBn6B,SACtBm6B,EAAsBpgD;QAC5B,SAAKsgD,MAKHA,EAAehqD,oBACfgqD,EAAez9C,QAAQrE,EAAU6hD,KAA4B;;IAIzD38D,GACN8zB,GACA5hB;QAUA,OARI3U,OAAiBK,EAASC,SAC5BJ,EACE,wBACA,gDACA0xB,GAAejd;QAIZ7Q,KAAK+6D,GAAoBhmC,GAC9BtC,GACA5hB,GACA1M,EAAgBkB;;;;;;;;;;;;;;;;;;;UChLTm2D;IAaX78D,YACmB60B,GACAgU;kBADAhU,aACAgU;;;;;QAVnBxnC,UAAyC;;QAGzCA,UAA+B;;QAG/BA,UAA+B,IAAI0N,GAAU0xC,GAAaC;;IAO1D1gD,GAAW8zB;QACT,OAAO5B,GAAmBU,QAAsC,MAA9BvxB,KAAKuzB,GAAcz0B;;IAGvDH,GACE8zB,GACA3b,GACA+Y,GACAC;QAIA,MAAMF,IAAU5vB,KAAKipC;QAGrB,IAFAjpC,KAAKipC,MAEDjpC,KAAKuzB,GAAcz0B,SAAS,GAAG;YACnBkB,KAAKuzB,GAAcvzB,KAAKuzB,GAAcz0B,SAAS;;QAO/D,MAAM0xB,IAAQ,IAAIb,GAChBC,GACA9Y,GACA+Y,GACAC;QAEF9vB,KAAKuzB,GAAc9xB,KAAK+uB;;QAGxB,KAAK,MAAMlQ,KAAYwP,GACrB9vB,KAAKy7D,KAAuBz7D,KAAKy7D,GAAqBltD,IACpD,IAAI6wC,GAAa9+B,EAAS9f,KAAKovB,KAGjC5vB,KAAKwzB,GAAaqV,GAChBpW,GACAnS,EAAS9f,IAAIkF,KAAKke;QAItB,OAAOiN,GAAmBU,QAAQf;;IAGpC7xB,GACE8zB,GACA7C;QAEA,OAAOiB,GAAmBU,QAAQvxB,KAAK07D,GAAkB9rC;;IAG3DjxB,GACE8zB,GACA7C;QAEA,MAAMqZ,IAAcrZ,IAAU,GAIxB+rC,IAAW37D,KAAK47D,GAAe3yB,IAC/B1pC,IAAQo8D,IAAW,IAAI,IAAIA;;;gBACjC,OAAO9qC,GAAmBU,QACxBvxB,KAAKuzB,GAAcz0B,SAASS,IAAQS,KAAKuzB,GAAch0B,KAAS;;IAIpEZ;QACE,OAAOkyB,GAAmBU,QACM,MAA9BvxB,KAAKuzB,GAAcz0B,UrCnFM,IqCmF2BkB,KAAKipC,KAAc;;IAI3EtqC,GACE8zB;QAEA,OAAO5B,GAAmBU,QAAQvxB,KAAKuzB,GAAc3uB;;IAGvDjG,GACE8zB,GACAC;QAEA,MAAMvkB,IAAQ,IAAIixC,GAAa1sB,GAAa,IACtCxtB,IAAM,IAAIk6C,GAAa1sB,GAAaxrB,OAAO4gC,oBAC3Ct7B,IAA0B;QAchC,OAbAxM,KAAKy7D,GAAqB3b,GAAe,EAAC3xC,GAAOjJ,KAAMs6C;YAKrD,MAAMhvB,IAAQxwB,KAAK07D,GAAkBlc,EAAIS;YAKzCzzC,EAAO/K,KAAK+uB;YAGPK,GAAmBU,QAAQ/kB;;IAGpC7N,GACE8zB,GACAI;QAEA,IAAI8W,IAAiB,IAAIj8B,GAAkBzO;QAe3C,OAbA4zB,EAAahyB,QAAQ6xB;YACnB,MAAMvkB,IAAQ,IAAIixC,GAAa1sB,GAAa,IACtCxtB,IAAM,IAAIk6C,GAAa1sB,GAAaxrB,OAAO4gC;YACjD9nC,KAAKy7D,GAAqB3b,GAAe,EAAC3xC,GAAOjJ,KAAMs6C;gBAMrD7V,IAAiBA,EAAep7B,IAAIixC,EAAIS;;YAIrCpvB,GAAmBU,QAAQvxB,KAAK67D,GAAoBlyB;;IAG7DhrC,GACE8zB,GACA5hB;;;QAQA,MAAMirD,IAASjrD,EAAMnL,MACf+mC,IAA8BqvB,EAAOh9D,SAAS;;;;;QAMpD,IAAIi9D,IAAYD;QACXr1D,EAAY2C,EAAc2yD,OAC7BA,IAAYA,EAAU59C,MAAM;QAG9B,MAAMhQ,IAAQ,IAAIixC,GAAa,IAAI34C,EAAYs1D,IAAY;;;gBAI3D,IAAIpyB,IAAiB,IAAIj8B,GAAkBzO;QAmB3C,OAjBAe,KAAKy7D,GAAqB5lD,GAAa2pC;YACrC,MAAMwc,IAAaxc,EAAIh/C,IAAIkF;YAC3B,SAAKo2D,EAAOxzC,EAAW0zC;;;;;;YAQjBA,EAAWl9D,WAAW2tC,MACxB9C,IAAiBA,EAAep7B,IAAIixC,EAAIS,OAEnC;WAER9xC,IAEI0iB,GAAmBU,QAAQvxB,KAAK67D,GAAoBlyB;;IAGrDhrC,GAAoBqrC;;;QAG1B,MAAMx9B,IAA0B;QAOhC,OANAw9B,EAASnpC,QAAQ+uB;YACf,MAAMY,IAAQxwB,KAAK07D,GAAkB9rC;YACvB,SAAVY,KACFhkB,EAAO/K,KAAK+uB;YAGThkB;;IAGT7N,GACE8zB,GACAjC;QAvMQ7yB,EA4MS,MAFEqC,KAAKi8D,GAAuBzrC,EAAMZ,SAAS,aAK9D5vB,KAAKuzB,GAAc4L;QAEnB,IAAI+8B,IAAal8D,KAAKy7D;QACtB,OAAO5qC,GAAmBhwB,QAAQ2vB,EAAMV,WAAYxP;YAClD,MAAMk/B,IAAM,IAAIJ,GAAa9+B,EAAS9f,KAAKgwB,EAAMZ;YAEjD,OADAssC,IAAaA,EAAWjsD,OAAOuvC,IACxBx/C,KAAKwnC,GAAkB4C,GAC5B3X,GACAnS,EAAS9f;WAEVgG,KAAK;YACNxG,KAAKy7D,KAAuBS;;;IAIhCv9D,GAAyBixB;;;IAIzBjxB,GACEi6B,GACAp4B;QAEA,MAAMg/C,IAAM,IAAIJ,GAAa5+C,GAAK,IAC5Bu/C,IAAW//C,KAAKy7D,GAAqBzb,GAAkBR;QAC7D,OAAO3uB,GAAmBU,QAAQ/wB,EAAI8D,QAAQy7C,KAAYA,EAASv/C;;IAGrE7B,GACEi6B;QAQA,OANI54B,KAAKuzB,GAAcz0B,QAMhB+xB,GAAmBU;;;;;;;;;WAWpB5yB,GAAuBixB,GAAkB7jB;QAM/C,OALc/L,KAAK47D,GAAehsC;;;;;;;;;;WAiB5BjxB,GAAeixB;QACrB,IAAkC,MAA9B5vB,KAAKuzB,GAAcz0B;;QAErB,OAAO;;;;;gBAQT,OAAO8wB,IADc5vB,KAAKuzB,GAAc,GAAG3D;;;;;WAQrCjxB,GAAkBixB;QACxB,MAAMrwB,IAAQS,KAAK47D,GAAehsC;QAClC,IAAIrwB,IAAQ,KAAKA,KAASS,KAAKuzB,GAAcz0B,QAC3C,OAAO;QAKT,OAFckB,KAAKuzB,GAAch0B;;;;;;;;;;;;;;;;;;;UC9RxB48D;;;;;IAWXx9D,YACmB60B,GACA4oC;kBADA5oC,aACA4oC;;QAXXp8D,YAPD,IAAIkL,GACTzE,EAAYpH;;QASNW,YAAO;;;;;;;WAiBPrB,GACN8zB,GACAziB,GACAsP;QAOA,MAAM9e,IAAMwP,EAAIxP,KACVugC,IAAQ/gC,KAAK8Q,KAAKtP,IAAIhB,IACtB+sC,IAAexM,IAAQA,EAAM/7B,OAAO,GACpCq3D,IAAcr8D,KAAKo8D,GAAMpsD;QAU/B,OARAhQ,KAAK8Q,OAAO9Q,KAAK8Q,KAAKxF,GAAO9K,GAAK;YAChCurC,IAAe/7B;YACfhL,MAAMq3D;YACN/8C,UAAAA;YAGFtf,KAAKgF,QAAQq3D,IAAc9uB,GAEpBvtC,KAAKwzB,GAAaqV,GACvBpW,GACAjyB,EAAIkF,KAAKke;;;;;;;WAULjlB,GAAY+zB;QAClB,MAAMqO,IAAQ/gC,KAAK8Q,KAAKtP,IAAIkxB;QACxBqO,MACF/gC,KAAK8Q,OAAO9Q,KAAK8Q,KAAKrF,OAAOinB,IAC7B1yB,KAAKgF,QAAQ+7B,EAAM/7B;;IAIvBrG,GACE8zB,GACAC;QAEA,MAAMqO,IAAQ/gC,KAAK8Q,KAAKtP,IAAIkxB;QAC5B,OAAO7B,GAAmBU,QAAQwP,IAAQA,EAAMxO,KAAgB;;IAGlE5zB,WACE8zB,GACAI;QAEA,IAAIlC,IAAU5hB;QAKd,OAJA8jB,EAAahyB,QAAQ6xB;YACnB,MAAMqO,IAAQ/gC,KAAK8Q,KAAKtP,IAAIkxB;YAC5B/B,IAAUA,EAAQrlB,GAAOonB,GAAaqO,IAAQA,EAAMxO,KAAgB;YAE/D1B,GAAmBU,QAAQZ;;IAGpChyB,GACE8zB,GACA5hB,GACAujB;QAMA,IAAIzD,IAAU1hB;;;gBAId,MAAM6sD,IAAS,IAAIr1D,EAAYoK,EAAMnL,KAAKyY,MAAM,MAC1Cm+C,IAAWt8D,KAAK8Q,KAAK9C,GAAgB8tD;QAC3C,MAAOQ,EAASruD,QAAW;YACzB,OAAMzN,KACJA,GACArD,QAAO4uC,IAAExZ,GAAajT,UAAEA,MACtBg9C,EAASpuD;YACb,KAAK2C,EAAMnL,KAAK4iB,EAAW9nB,EAAIkF,OAC7B;YAEE4Z,EAAS7F,EAAU2a,MAAkB,KAIvC7B,aAAyBxe,MACzBga,GAAald,GAAO0hB,OAEpB5B,IAAUA,EAAQrlB,GAAOinB,EAAc/xB,KAAK+xB;;QAGhD,OAAO1B,GAAmBU,QAAQZ;;IAGpChyB,GACE8zB,GACAvqB;QAEA,OAAO2oB,GAAmBhwB,QAAQb,KAAK8Q,MAAOtQ,KAAqB0H,EAAE1H;;IAGvE7B,GAAgBwtB;;;QAKd,OAAO,IAAIgwC,GAA0B9pC,GAA2BryB;;IAGlErB,GAAQi6B;QACN,OAAO/H,GAAmBU,QAAQvxB,KAAKgF;;;;;;GAMzCm3D,SAA4C,cAAc9pC;IACxD1zB,YAA6B2uC;QAC3BnqC,mBAD2BmqC;;IAInB3uC,GACR8zB;QAEA,MAAMN,IAA4C;QAUlD,OATAnyB,KAAK2Q,GAAQ9P,QAAQ,CAACL,GAAKwP;YACrBA,IACFmiB,EAAS1wB,KACPzB,KAAKstC,GAAcG,GAAShb,GAAaziB,GAAKhQ,KAAKsf,aAGrDtf,KAAKstC,GAAcK,GAAYntC;YAG5BqwB,GAAmBuB,GAAQD;;IAG1BxzB,GACR8zB,GACAC;QAEA,OAAO1yB,KAAKstC,GAAczZ,GAASpB,GAAaC;;IAGxC/zB,GACR8zB,GACAI;QAEA,OAAO7yB,KAAKstC,GAAcvZ,WAAWtB,GAAaI;;;;;;;;;;;;;;;;;;;;MCjM3C0pC;IAyBX59D,YAA6B47C;QAAAv6C,mBAAAu6C;;;;QArB7Bv6C,UAAkB,IAAIgB,EACpB05C,KAAK7yC,EAAe6yC,IACpB7xC;;QAIM7I,iCAA4BmE,EAAgBkB;;QAE5CrF,uBAA4B;;QAEpCA,UAAsD;;;;;QAKtDA,UAAqB,IAAIm/C,IAEjBn/C,mBAAc,GAEtBA,UAA4B+yC,GAAkBypB;;IAI9C79D,GACEi6B,GACA1wB;QAGA,OADAlI,KAAK2V,GAAQ9U,QAAQ,CAACc,GAAGuT,MAAehN,EAAEgN,KACnC2b,GAAmBU;;IAG5B5yB,GACE8zB;QAEA,OAAO5B,GAAmBU,QAAQvxB,KAAKiyC;;IAGzCtzC,GACE8zB;QAEA,OAAO5B,GAAmBU,QAAQvxB,KAAKy8D;;IAGzC99D,GACE8zB;QAGA,OADAzyB,KAAK+xC,kBAAkB/xC,KAAKmzC,GAAkB3sC,QACvCqqB,GAAmBU,QAAQvxB,KAAK+xC;;IAGzCpzC,GACE8zB,GACAuf,GACAC;QAQA,OANIA,MACFjyC,KAAKiyC,4BAA4BA,IAE/BD,IAA8BhyC,KAAKy8D,OACrCz8D,KAAKy8D,KAAwBzqB;QAExBnhB,GAAmBU;;IAGpB5yB,GAAeuW;QACrBlV,KAAK2V,GAAQrG,IAAI4F,EAAWpN,QAAQoN;QACpC,MAAM5K,IAAW4K,EAAW5K;QACxBA,IAAWtK,KAAK+xC,oBAClB/xC,KAAKmzC,KAAoB,IAAIJ,GAAkBzoC,IAC/CtK,KAAK+xC,kBAAkBznC,IAErB4K,EAAW1K,iBAAiBxK,KAAKy8D,OACnCz8D,KAAKy8D,KAAwBvnD,EAAW1K;;IAI5C7L,GACE8zB,GACAvd;QAQA,OAFAlV,KAAKszC,GAAep+B,IACpBlV,KAAKkjC,eAAe,GACbrS,GAAmBU;;IAG5B5yB,GACE8zB,GACAvd;QAOA,OADAlV,KAAKszC,GAAep+B,IACb2b,GAAmBU;;IAG5B5yB,GACE8zB,GACAvd;QAUA,OAHAlV,KAAK2V,GAAQ1F,OAAOiF,EAAWpN,SAC/B9H,KAAKk8D,GAAWtF,GAAsB1hD,EAAW5K,WACjDtK,KAAKkjC,eAAe;QACbrS,GAAmBU;;IAG5B5yB,GACE8zB,GACA6Q,GACAC;QAEA,IAAIhjC,IAAQ;QACZ,MAAMm8D,IAA4C;QAalD,OAZA18D,KAAK2V,GAAQ9U,QAAQ,CAACL,GAAK0U;YAEvBA,EAAW1K,kBAAkB84B,KACgB,SAA7CC,EAAgB/hC,IAAI0T,EAAW5K,cAE/BtK,KAAK2V,GAAQ1F,OAAOzP,IACpBk8D,EAASj7D,KACPzB,KAAKwzC,GAA8B/gB,GAAavd,EAAW5K;YAE7D/J;YAGGswB,GAAmBuB,GAAQsqC,GAAUl2D,KAAK,MAAMjG;;IAGzD5B,GACE8zB;QAEA,OAAO5B,GAAmBU,QAAQvxB,KAAKkjC;;IAGzCvkC,GACE8zB,GACA3qB;QAEA,MAAMoN,IAAalV,KAAK2V,GAAQnU,IAAIsG,MAAW;QAC/C,OAAO+oB,GAAmBU,QAAQrc;;IAGpCvW,GACEi6B,GACAvpB,GACA/E;QAGA,OADAtK,KAAKk8D,GAAWS,GAActtD,GAAM/E,IAC7BumB,GAAmBU;;IAG5B5yB,GACEi6B,GACAvpB,GACA/E;QAEAtK,KAAKk8D,GAAWU,GAAiBvtD,GAAM/E;QACvC,MAAMk9B,IAAoBxnC,KAAKu6C,YAAY/S,IACrCrV,IAA4C;QAMlD,OALIqV,KACFn4B,EAAKxO,QAAQL;YACX2xB,EAAS1wB,KAAK+lC,EAAkB4C,GAAwBxR,GAAKp4B;YAG1DqwB,GAAmBuB,GAAQD;;IAGpCxzB,GACEi6B,GACAtuB;QAGA,OADAtK,KAAKk8D,GAAWtF,GAAsBtsD,IAC/BumB,GAAmBU;;IAG5B5yB,GACEi6B,GACAtuB;QAEA,MAAMuyD,IAAe78D,KAAKk8D,GAAWY,GAAgBxyD;QACrD,OAAOumB,GAAmBU,QAAQsrC;;IAGpCl+D,GACEi6B,GACAp4B;QAEA,OAAOqwB,GAAmBU,QAAQvxB,KAAKk8D,GAAWrxB,GAAYrqC;;;;;;;;;;;;;;;;;;;;;;;;MCtLrDu8D;;;;;;;IAwBXp+D,YACEq+D;QAhBFh9D,UAAkE,IAGlEA,UAAkC,IAAI61B,GAAe,IAErD71B,WAAmB,GAajBA,KAAKm1C,MAAW,GAChBn1C,KAAKwnC,KAAoBw1B,EAAyBh9D;QAClDA,KAAKw0C,KAAc,IAAI+nB,GAAkBv8D;QAGzCA,KAAKwzB,KAAe,IAAIya,IACxBjuC,KAAKszB,KAAsB,IAAI6oC,GAC7Bn8D,KAAKwzB,IAJQxjB,KACbhQ,KAAKwnC,GAAkBy1B,GAAajtD;;IAQxCrR;QACE,OAAO8yB,QAAQF;;IAGjB5yB;;QAGE,OADAqB,KAAKm1C,MAAW,GACT1jB,QAAQF;;IAGjBiR;QACE,OAAOxiC,KAAKm1C;;IAGdx2C;;;IAIAA;;;IAIAA;QACE,OAAOqB,KAAKwzB;;IAGd70B,GAAiB8oC;QACf,IAAIhR,IAAQz2B,KAAKk9D,GAAez1B,EAAKgvB;QAQrC,OAPKhgC,MACHA,IAAQ,IAAI+kC,GACVx7D,KAAKwzB,IACLxzB,KAAKwnC,KAEPxnC,KAAKk9D,GAAez1B,EAAKgvB,QAAWhgC,IAE/BA;;IAGT93B;QACE,OAAOqB,KAAKw0C;;IAGd71C;QACE,OAAOqB,KAAKszB;;IAGd30B,eACEoN,GACAguB,GACAke;QAIA77C,EAjGY,qBAiGM,yBAAyB2P;QAC3C,MAAM6sB,IAAM,IAAIukC,GAAkBn9D,KAAKk1C,GAAe1uC;QAEtD,OADAxG,KAAKwnC,GAAkB41B,MAChBnlB,EAAqBrf,GACzBpyB,KAAKgG,KACGxM,KAAKwnC,GACT61B,GAAuBzkC,GACvBpyB,KAAK,MAAMgG,IAEfyrB,KACAyF,KAAKlxB,MACJosB,EAAI2f;QACG/rC;;IAIb7N,GACE8zB,GACAjyB;QAEA,OAAOqwB,GAAmBysC,GACxB78D,OAAO+X,OAAOxY,KAAKk9D,IAAgBxgE,IAAI+5B,KAAS,MAC9CA,EAAMoU,GAAYpY,GAAajyB;;;;;;;UAU1B28D,WAA0BjqC;IACrCv0B,YAAqBs1C;QACnB9wC,mBADmB8wC;;;;MAWVspB;IAMX5+D,YAAqC47C;QAAAv6C,mBAAAu6C;;QAJrCv6C,UAA4C,IAAIm/C;;QAEhDn/C,UAAsD;;IAItDrB,UAAe47C;QACb,OAAO,IAAIgjB,GAAoBhjB;;IAGjCijB;QACE,IAAKx9D,KAAKy9D,IAGR,OAAOz9D,KAAKy9D;QAFZ,MApLqDlgE;;IA0LzDoB,GACEi6B,GACAtuB,GACA9J;QAIA,OAFAR,KAAK09D,GAAoB7pB,GAAarzC,GAAK8J,IAC3CtK,KAAK29D,GAAkB1tD,OAAOzP,IACvBqwB,GAAmBU;;IAG5B5yB,GACEi6B,GACAtuB,GACA9J;QAIA,OAFAR,KAAK09D,GAAoB5pB,GAAgBtzC,GAAK8J,IAC9CtK,KAAK29D,GAAkBpvD,IAAI/N,IACpBqwB,GAAmBU;;IAG5B5yB,GACEi6B,GACAp4B;QAGA,OADAR,KAAK29D,GAAkBpvD,IAAI/N,IACpBqwB,GAAmBU;;IAG5B5yB,aACEi6B,GACA1jB;QAEiBlV,KAAK09D,GAAoB9G,GACxC1hD,EAAW5K,UAEJzJ,QAAQL,KAAOR,KAAK29D,GAAkBpvD,IAAI/N;QACnD,MAAM6wC,IAAQrxC,KAAKu6C,YAAYrB;QAC/B,OAAO7H,EACJoN,GAA2B7lB,GAAK1jB,EAAW5K,UAC3C9D,KAAK6I;YACJA,EAAKxO,QAAQL,KAAOR,KAAK29D,GAAkBpvD,IAAI/N;WAEhDgG,KAAK,MAAM6qC,EAAMqC,GAAiB9a,GAAK1jB;;IAG5CvW;QACEqB,KAAKy9D,KAAqB,IAAI/W;;IAGhC/nD,GACEi6B;;QAGA,MACM6gB,IADQz5C,KAAKu6C,YAAYb,KACJC;QAC3B,OAAO9oB,GAAmBhwB,QACxBb,KAAK29D,IACJn9D,KACQR,KAAK49D,GAAahlC,GAAKp4B,GAAKgG,KAAKo3D;YACjCA,KACHnkB,EAAa9L,GAAYntC;YAI/BgG,KAAK,OACLxG,KAAKy9D,KAAqB,MACnBhkB,EAAajwC,MAAMovB;;IAI9Bj6B,GACEi6B,GACAp4B;QAEA,OAAOR,KAAK49D,GAAahlC,GAAKp4B,GAAKgG,KAAKo3D;YAClCA,IACF59D,KAAK29D,GAAkB1tD,OAAOzP,KAE9BR,KAAK29D,GAAkBpvD,IAAI/N;;;IAKjC7B,GAAaqR;;QAEX,OAAO;;IAGDrR,GACNi6B,GACAp4B;QAEA,OAAOqwB,GAAmBysC,GAAG,EAC3B,MACEzsC,GAAmBU,QAAQvxB,KAAK09D,GAAoB7yB,GAAYrqC,KAClE,MAAMR,KAAKu6C,YAAYrB,KAAiBrO,GAAYjS,GAAKp4B,IACzD,MAAMR,KAAKu6C,YAAYf,GAAyB5gB,GAAKp4B;;;;;;;;;;;;;;;;;;;;;;;;UCtR9Cq9D;IAQXl/D,YAAYlC;QACVuD,KAAK89D,KAASrhE,EAAKqhE,IACnB99D,KAAK+9D,KAAUthE,EAAKshE;;IAGtBp/D,GAAOmyB;QAEL9wB,KAAKg+D,KAAgBltC;;IAGvBnyB,GAAQmyB;QAEN9wB,KAAKi+D,KAAiBntC;;IAGxBnyB,UAAUmyB;QAER9wB,KAAKk+D,KAAmBptC;;IAG1BnyB;QACEqB,KAAK+9D;;IAGPp/D,KAAKtC;QACH2D,KAAK89D,GAAOzhE;;IAGdsC;QAKEqB,KAAKg+D;;IAGPr/D,GAAYmzB;QAKV9xB,KAAKi+D,GAAensC;;IAGtBnzB,GAActC;QAKZ2D,KAAKk+D,GAAiB7hE;;;;;;;;;;;;;;;;;;;GC1D1B,OAOM8hE,KAAkC;IAExCC,mBAA4C;IAC5CC,QAAiC;IACjCC,UAAmC;;;;;;;UCoBtBC;;;;;;IDNX5/D,YAA6B6/D;kBAAAA,GAC3Bx+D,KAAKL,IAAa6+D,EAAa7+D;QAC/B,MAAMof,IAAQy/C,EAAa1+D,MAAM,UAAU;QAC3CE,KAAKy+D,KAAU1/C,IAAQ,QAAQy/C,EAAa3+D,MAC5CG,KAAK0+D,KACH,cACA1+D,KAAKL,EAAWO,YAChB,gBACAF,KAAKL,EAAWQ,WAChB;;IAGJxB,GACE8mD,GACA//C,GACAi5D,GACAjb;QAEA,MAAMkb,IAAM5+D,KAAK6+D,GAAQpZ,GAAS//C;QAClCtJ,EA5CY,kBA4CM,aAAawiE,GAAKD;QAEpC,MAAM3c,IAAU;QAGhB,OAFAhiD,KAAK8+D,GAAwB9c,GAAS0B,IAE/B1jD,KAAK++D,GAA6BtZ,GAASmZ,GAAK5c,GAAS2c,GAAKjhC,KACnEshC,MACE5iE,EAnDQ,kBAmDU,cAAc4iE;QACzBA,IAERltC;YAUC,MATA90B,EAvDQ,kBAyDHyoD,IAAH,wBACA3zB,GACA,SACA8sC,GACA,YACAD;YAEI7sC;;;IAKZnzB,GACE8mD,GACA//C,GACAwzB,GACAwqB;;;QAIA,OAAO1jD,KAAK2lD,GAAuBF,GAAS//C,GAAMwzB,GAASwqB;;;;;WAYnD/kD,GACRqjD,GACA0B;QAUA,IARA1B,EAAQ,uBA/EoB;;;;;QAqF5BA,EAAQ,kBAAkB,cAEtB0B,GACF,KAAK,MAAMub,KAAUvb,EAAMrD,IACrBqD,EAAMrD,GAAY1/C,eAAes+D,OACnCjd,EAAQid,KAAUvb,EAAMrD,GAAY4e;;IAgBpCtgE,GAAa8mD,GAAiB//C;QACpC,MAAMw5D,IAAaf,GAAqB1Y;QAKxC,OAAO,GAAGzlD,KAAKy+D,SAA8B/4D,KAAQw5D;;;;;;;;;;;;;;;;;;;IC5FvDvgE,YAAYwgE;QACVh8D,MAAMg8D,IACNn/D,KAAKD,mBAAmBo/D,EAAKp/D;;IAGrBpB,GACR8mD,GACAmZ,GACA5c,GACAod;QAEA,OAAO,IAAI3tC,QAAQ,CAACF,GAAyBC;YAC3C,MAAM6tC,IAAM,IAAIC;YAChBD,EAAIE,WAAWC,EAAUC,UAAU;gBACjC;oBACE,QAAQJ,EAAIK;sBACV,KAAKC,EAAUC;wBACb,MAAMC,IAAOR,EAAIS;wBACjB1jE,EA3BE,cA2BgB,iBAAiBgB,KAAKC,UAAUwiE,KAClDtuC,EAAQsuC;wBACR;;sBACF,KAAKF,EAAUI;wBACb3jE,EA/BE,cA+BgB,UAAUqpD,IAAU,gBACtCj0B,EACE,IAAIvuB,EAAelB,EAAKK,mBAAmB;wBAE7C;;sBACF,KAAKu9D,EAAUK;wBACb,MAAMngD,IAASw/C,EAAIY;wBAQnB,IAPA7jE,EAtCE,cAwCA,UAAUqpD,IAAU,yBACpB5lC,GACA,kBACAw/C,EAAIa;wBAEFrgD,IAAS,GAAG;4BACd,MAAMsgD,IAAiBd,EAAIS,kBACxB/iE;4BACH,IACIojE,KACAA,EAActgD,UACdsgD,EAAc1iE,SAChB;gCACA,MAAM2iE,a3DmN2BvgD;oCACjD,MAAMwgD,IAAcxgD,EAAOygD,cAAcp6D,QAAQ,KAAK;oCACtD,OAAOzF,OAAO+X,OAAOzW,GAAM4D,QAAQ06D,MAAwB,IACtDA,IACDt+D,EAAKG;iC2DvNkCq+D,CACzBJ,EAActgD;gCAEhB2R,EACE,IAAIvuB,EACFm9D,GACAD,EAAc1iE;mCAIlB+zB,EACE,IAAIvuB,EACFlB,EAAKG,SACL,kCAAkCm9D,EAAIY;;;;wBAO5CzuC,EACE,IAAIvuB,EAAelB,EAAKgB,aAAa;wBAGzC;;sBACF;wBACExF;;;oBAYJnB,EA3FM,cA2FY,UAAUqpD,IAAU;;;YAI1C,MAAM+a,IAAgBpjE,KAAKC,UAAU+hE;YACrCC,EAAIpc,KAAK2b,GAAK,QAAQ4B,GAAexe,GA5FlB;;;IAgGvBrjD,GACE8mD,GACA/B;QAEA,MAAM+c,IAAW,EACfzgE,KAAKy+D,IACL,KAxGqB,iCA0GrB,KACAhZ,GACA,cAEIib,IAAsBC,KACtBznC,IAA6B;;;YAGjC0nC,oBAAoB;YACpBC,oBAAoB;YACpBC,kBAAkB;;;gBAGhB3gE,UAAU,YAAYH,KAAKL,EAAWO,uBAAuBF,KAAKL,EAAWQ;;YAE/E4gE,cAAa;YACbC,yBAAwB;YACxBC,uBAAuB;;;;;;;gBAOrBC,gCAAgC;;YAElCnhE,kBAAkBC,KAAKD;;QAGzBC,KAAK8+D,GAAwB5lC,EAA2B,oBAAEwqB;;;;;;;;;;;;;;;;QAoBvDyd,OACAC,OACAC,OACAC,OACAC,OACAC,QAEDtoC,EAAQuoC,4BAA4B;QAGtC,MAAM7C,IAAM6B,EAASj7D,KAAK;QAC1BpJ,EAxKY,cAwKM,0BAA0BwiE,GAAK1lC;QACjD,MAAMwoC,IAAUhB,EAAoBiB,iBAAiB/C,GAAK1lC;;;;;;gBAO1D,IAAI0oC,KAAS,GAKTC,KAAS;;;;gBAEb,MAAMC,IAAe,IAAIjE,GAAwB;YAC/CkE,IAAS1lE;gBACFwlE,IASHzlE,EAlMM,cAkMY,6CAA6CC,MAR1DulE,MACHxlE,EA3LI,cA2Lc;gBAClBslE,EAAQvoC,QACRyoC,KAAS,IAEXxlE,EA/LM,cA+LY,uBAAuBC,IACzCqlE,EAAQze,KAAK5mD;;YAKjB2lE,IAAS,MAAMN,EAAQ/mC;YAOnBsnC,IAAuB,CAC3BvxD,GACA5P;;;YAIA4gE,EAAQ1N,OAAOtjD,GAAOwxD;gBACpB;oBACEphE,EAAGohE;kBACH,OAAO5kE;oBACP6/B,WAAW;wBACT,MAAM7/B;uBACL;;;;;;;;gBAuFT,OAlFA2kE,EAAqBE,EAAW3C,UAAU4C,MAAM;YACzCP,KACHzlE,EA/NQ,cA+NU;YAItB6lE,EAAqBE,EAAW3C,UAAU6C,OAAO;YAC1CR,MACHA,KAAS,GACTzlE,EAtOQ,cAsOU,gCAClB0lE,EAAaQ;YAIjBL,EAA4BE,EAAW3C,UAAU1iE,OAAOg1B;YACjD+vC,MACHA,KAAS,GACT7kE,EA9OQ,cA8OS,iCAAiC80B,IAClDgwC,EAAaQ,GACX,IAAIr/D,EACFlB,EAAKgB,aACL;YAaRk/D,EACEE,EAAW3C,UAAU+C,SACrBlmE;;YACE,KAAKwlE,GAAQ;gBACX,MAAMW,IAAUnmE,EAAKsR,KAAK;gBA/PvBhQ,IAgQU6kE;;;;;;gBAMb,MAAMC,IAA2CD,GAC3CzlE,IACJ0lE,EAAe1lE,wBACd0lE,EAAqC,iCAAI1lE;gBAC5C,IAAIA,GAAO;oBACTX,EA/QI,cA+Qc,8BAA8BW;;oBAEhD,MAAM8iB,IAAiB9iB,EAAM8iB;oBAC7B,IAAI3c,a3DtNqB2c;;;wBAGnC,MAAM3c,IAAgB4H,GAAQ+U;wBAC9B,SAAave,MAAT4B,GAIJ,OAAO8H,GAAmB9H;qB2D8MLw/D,CAAqB7iD,IAC5BpiB,IAAUV,EAAMU;yBACP6D,MAAT4B,MACFA,IAAOnB,EAAKe,UACZrF,IACE,2BACAoiB,IACA,mBACA9iB,EAAMU;;oBAGVokE,KAAS,GACTC,EAAaQ,GAAY,IAAIr/D,EAAeC,GAAMzF,KAClDikE,EAAQ/mC;uBAERv+B,EAjSI,cAiSc,wBAAwBomE,IAC1CV,EAAaa,GAAcH;;YAMnCrlC,WAAW;;;;;YAKT2kC,EAAac;WACZ,IACId;;;;;;;;;;;;;;;;;;;;;;;;;MClUEe;IAOXlkE;QANAqB,UAA4C,MAC1CA,KAAK8iE,MACP9iE,UAA8C,MAC5CA,KAAK+iE,MACP/iE,UAAmD,IAGjDA,KAAKgjE;;IAGPrkE,GAAYmyB;QACV9wB,KAAKm2D,GAAU10D,KAAKqvB;;IAGtBnyB;QACEm5B,OAAOiH,oBAAoB,UAAU/+B,KAAKijE,KAC1CnrC,OAAOiH,oBAAoB,WAAW/+B,KAAKkjE;;IAGrCvkE;QACNm5B,OAAO0G,iBAAiB,UAAUx+B,KAAKijE,KACvCnrC,OAAO0G,iBAAiB,WAAWx+B,KAAKkjE;;IAGlCvkE;QACNvC,EA/BY,uBA+BM;QAClB,KAAK,MAAM00B,KAAY9wB,KAAKm2D,IAC1BrlC;;IAIInyB;QACNvC,EAtCY,uBAsCM;QAClB,KAAK,MAAM00B,KAAY9wB,KAAKm2D,IAC1BrlC;;;;;IAOJnyB;QACE,OACoB,sBAAXm5B,eACqBx2B,MAA5Bw2B,OAAO0G,yBACwBl9B,MAA/Bw2B,OAAOiH;;;;;;;;;;;;;;;;;;;UC3DAokC;IACXxkE,GAAYmyB;;;IAIZnyB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;SCHcykE,GAAczjE;IAC5B,OAAO,IAAIud,GAAoBvd,yBAAiC;;;;;;;;;;;;;;;;;;GC0ClE,OAAM0jE,KACJ;;;;;UAsCWC;IAOX3kE,iBAAiB4kE;QACfvjE,KAAKizD,KAAoBjzD,KAAKwjE,GAAwBD,IACtDvjE,KAAKu6C,cAAcv6C,KAAKyjE,GAAkBF,UACpCvjE,KAAKu6C,YAAYpsC;QACvBnO,KAAK0jE,KAAc1jE,KAAK2jE,GAAiCJ,IACzDvjE,KAAKqiC,KAAariC,KAAK4jE,GAAiBL;;IAG1C5kE,GACE4kE;QAEA,OAAO;;IAGT5kE,GAAiB4kE;;QACf,OxBs5BFhpB,IwBr5BIv6C,KAAKu6C,axBs5BTC,IwBr5BI,IAAIsgB,IxBs5BRrgB,IwBr5BI8oB,EAAI9oB,IxBu5BD,IAAIH,GAAeC,GAAaC,GAAaC;YAJpDF,GACAC,GACAC;;IwBj5BA97C,GAAkB4kE;QAChB,IAAIA,EAAIM,GAAoBC,IAC1B,MAAM,IAAI7gE,EACRlB,EAAKW,qBACL2gE;QAGJ,OAAO,IAAItG,GAAkBQ,GAAoBwG;;IAGnDplE,GAAwB4kE;QACtB,OAAO,IAAIzT;;IAGbnxD;QACMqB,KAAK0jE,MACP1jE,KAAK0jE,GAAYpb,cAEbtoD,KAAKizD,GAAkBra,YACvB54C,KAAKu6C,YAAY3B;;IAGzBj6C,iBACEgB,GACAC;QAEA,MAAM,IAAIqD,EACRlB,EAAKW,qBACL2gE;;;;;;UAQOW,WAA0CV;IAMrD3kE,iBAAiB4kE;cACTpgE,MAAM8gE,WAAWV,UxB29BpB5gC,eACLN;YAEA,MAAM4c,IAAiBphD,EAAUwkC,IAC3By2B,IAA0Bj7D,EAC9BohD,EAAerE;YAGjB,OAAOqE,EAAe1E,YACnBvF,eACC,8CACA,YACApc,KAAOkgC,EAAwBoL,GAAgBtrC,IAEhD8E,KAAKpe;gBACJ2/B,EAAe+Z,KAA6B15C;;SwBz+BxC6kD,CAAsCnkE,KAAKqiC;;IAGnD1jC,GACE4kE;QAEA,MAAMphC,IAAmBniC,KAAKu6C,YAAY/S,GACvCrF;QACH,OAAO,IAAID,GAAaC,GAAkBohC,EAAIjmC;;IAGhD3+B,GAAkB4kE;QAMhB,MAAM3jE,IAAiBw6C,GACrBmpB,EAAI/E,GAAa7+D,GACjB4jE,EAAI/E,GAAa5+D,iBAEb0d,IAAa8lD,GAAcG,EAAI/E,GAAa7+D;QAClD,OAAO,IAAIyrC,GACTm4B,EAAIM,GAAoBO,iBACxBxkE,GACA2jE,EAAIjxB,UACJ7Q,GAAU4iC,GAAcd,EAAIM,GAAoBS,iBAChDf,EAAIjmC,IACJF,MACA3I,MACAnX,GACAtd,KAAKizD,IACLsQ,EAAIM,GAAoB1vB;;IAI5Bx1C,GAAwB4kE;QACtB,OAAO,IAAIzT;;IAGbnxD,iBACEgB,GACAC;QAEA,OzBolCG+iC,eACL/iC;YAEA,KAAK63B,GAAS2c,MACZ,OAAO3iB,QAAQF;YAEjB,MAAM+iB,IAAS10C,IA5rCY;kBA6rCrB63B,GAASxnB,OAAOqkC;;;;;;;;;;;;;;;;;GyB3lCbiwB,EACLnqB,GAAuBz6C,GAAYC;;;;;;;;;;;UAa5B4kE,WAAyCR;IACpDrlE,YACmB8lE;QAEjBthE,mBAFiBshE;;IAKnB9lE,iBAAiB4kE;cACTpgE,MAAM8gE,WAAWV,UAEjBvjE,KAAKykE,GAAwBR,WAAWjkE,MAAMujE;QACpD,MAAM1a,IAAa7oD,KAAKykE,GAAwB5b;QAE5C7oD,KAAKizD,cAA6BnH,OACpC9rD,KAAKizD,GAAkBpK,KAAa;YAClC6b,IAAiBvV,GAAgBxxB,KAAK,MAAMkrB;YAC5C8b,IAAkBvV,GAAiBzxB,KAAK,MAAMkrB;YAC9C+b,IAA0BlV,GAAyB/xB,KACjD,MACAkrB;YAEFgc,IAAkBhY,GAAiBlvB,KAAK,MAAMkrB;iBAE1C7oD,KAAKizD,GAAkB9kD;;;cAKzBnO,KAAKu6C,YAAYuqB,GAAwBniC,MAAMiS;kBAC7CyjB,GACJr4D,KAAKykE,GAAwB5b,IAC7BjU,IAEE50C,KAAK0jE,OACH9uB,MAAc50C,KAAK0jE,GAAYpuB,KACjCt1C,KAAK0jE,GAAYv1D,MAAMnO,KAAKqiC,MAClBuS,KACV50C,KAAK0jE,GAAYpb;;;IAMzB3pD,GAAwB4kE;QACtB,IACEA,EAAIM,GAAoBC,MACxBP,EAAIM,GAAoBO,iBACxB;YACA,MAAMtsC,IAASsF;YACf,KAAK0uB,GAA4B1X,GAAYtc,IAC3C,MAAM,IAAI70B,EACRlB,EAAKc,eACL;YAGJ,MAAMjD,IAAiBw6C,GACrBmpB,EAAI/E,GAAa7+D,GACjB4jE,EAAI/E,GAAa5+D;YAEnB,OAAO,IAAIksD,GACTh0B,GACAyrC,EAAIjmC,IACJ19B,GACA2jE,EAAIjxB,UACJixB,EAAI9oB;;QAGR,OAAO,IAAIqV;;;;;;;UAQFiV;IAQXpmE,iBACEqmE,GACAzB;QAEIvjE,KAAKqiC,OAMTriC,KAAKqiC,KAAa2iC,EAAyB3iC,IAC3CriC,KAAKizD,KAAoB+R,EAAyB/R,IAClDjzD,KAAKwmD,KAAYxmD,KAAKilE,GAAgB1B,IACtCvjE,KAAKgzD,KAAchzD,KAAKklE,GAAkB3B;QAC1CvjE,KAAK6oD,KAAa7oD,KAAKmlE,GAAiB5B,IACxCvjE,KAAKolE,KAAeplE,KAAKqlE,GAAmB9B,IAE5CvjE,KAAKizD,GAAkBnN,KAAqB8F,KAC1C5rD,KAAK6oD,GAAWwM,GACdzJ;QAIJ5rD,KAAKgzD,GAAYnK,KAAa7oD,KAAK6oD,UAE7B7oD,KAAKgzD,GAAY7kD,eACjBnO,KAAKgzD,GAAYqF,GAAkBr4D,KAAK6oD,GAAWkL;;IAG3Dp1D,GAAmB4kE;QACjB,OAAO,IAAIlK,GAAar5D,KAAK6oD;;IAG/BlqD,GAAgB4kE;QACd,MAAMjmD,IAAa8lD,GAAcG,EAAI/E,GAAa7+D,IAC5C6iD,KCvUoBgc,IDuUO+E,EAAI/E,ICtUhC,IAAID,GAAqBC;YADJA;yEDwU1B,gBnB1NFra,GACA3B,GACAllC;YAEA,OAAO,IAAIioC,GAAcpB,GAAa3B,GAAYllC;SmBsNzCgoD,CAAa/B,EAAIpf,aAAa3B,GAAYllC;;IAGnD3e,GAAkB4kE;QAChB,OAAO,IAAIhd,GACTvmD,KAAKqiC,IACLriC,KAAKwmD,IACL+c,EAAIjmC,IACJsuB,KACE5rD,KAAK6oD,GAAWwM,GACdzJ,yBC5UJiX,GAA2BzuB,OACtB,IAAIyuB,KAEJ,IAAIM;;IDgVbxkE,GAAiB4kE;QACf,gBb0jBFlhC,GACA2wB,GACAxM;;QAEAyM,GACArS,GACAsS,GACAte;YAEA,MAAMiU,IAAa,IAAIkK,GACrB1wB,GACA2wB,GACAxM,GACAyM,GACArS,GACAsS;YAKF,OAHIte,MACFiU,EAAWyK,MAAmB,IAEzBzK;Sa9kBE0c,CACLvlE,KAAKqiC,IACLriC,KAAKgzD,IACLhzD,KAAKwmD,IACLxmD,KAAKizD,IACLsQ,EAAI9oB,IACJ8oB,EAAIrQ,KACHqQ,EAAIM,GAAoBC,OACtBP,EAAIM,GAAoBO;;IAI/BzlE;QACE,OAAOqB,KAAKgzD,GAAYpa;;;;;;;;;;;;;;;;;;;aE3VZ4sB,GAAkBlpE;;;;;IAChC,OAOF,SAA8BA,GAAcmpE;QAC1C,IAAmB,mBAARnpE,KAA4B,SAARA,GAC7B,QAAO;QAGT,MAAMopE,IAASppE;QACf,KAAK,MAAMqpE,KAAUF,GACnB,IAAIE,KAAUD,KAAoC,qBAAnBA,EAAOC,IACpC,QAAO;QAGX,QAAO;;;;;;;;;;;;;;;;;;;;;;GAlBAC,EAAqBtpE,GAAK,EAAC,QAAQ,SAAS;;;MCbxCupE;IAOXlnE,YAAoBs7D;QAAAj6D,gBAAAi6D;;;;;QAFZj6D,cAAQ;;IAIhBrB,KAAKxB;QACC6C,KAAKi6D,SAASzzD,QAChBxG,KAAK8lE,GAAc9lE,KAAKi6D,SAASzzD,MAAMrJ;;IAI3CwB,MAAM5B;QACAiD,KAAKi6D,SAASl9D,QAChBiD,KAAK8lE,GAAc9lE,KAAKi6D,SAASl9D,OAAOA,KAExCgpE,QAAQhpE,MAAM,wCAAwCA;;IAI1D4B;QACEqB,KAAKgmE,SAAQ;;IAGPrnE,GAAiBsnE,GAA+B5sC;QACjDr5B,KAAKgmE,SACR7oC,WAAW;YACJn9B,KAAKgmE,SACRC,EAAa5sC;WAEd;;;;;;;;;;;;;;;;;;;;;;;;;;aCnBO6sC,GAAeC,GAAsB1pE;IACnD,IAAoB,MAAhBA,EAAKqC,QACP,MAAM,IAAImE,EACRlB,EAAKI,kBACL,YAAYgkE,yDAEVC,GAAa3pE,EAAKqC,QAAQ,cAC1B;;;;;;;;;aAYQunE,GACdF,GACA1pE,GACA6pE;IAEA,IAAI7pE,EAAKqC,WAAWwnE,GAClB,MAAM,IAAIrjE,EACRlB,EAAKI,kBACL,YAAYgkE,kBACVC,GAAaE,GAAc,cAC3B,2BACAF,GAAa3pE,EAAKqC,QAAQ,cAC1B;;;;;;;;;;aAaQynE,GACdJ,GACA1pE,GACA+pE;IAEA,IAAI/pE,EAAKqC,SAAS0nE,GAChB,MAAM,IAAIvjE,EACRlB,EAAKI,kBACL,YAAYgkE,2BACVC,GAAaI,GAAiB,cAC9B,2BACAJ,GAAa3pE,EAAKqC,QAAQ,cAC1B;;;;;;;;;;aAaQ2nE,GACdN,GACA1pE,GACA+pE,GACAE;IAEA,IAAIjqE,EAAKqC,SAAS0nE,KAAmB/pE,EAAKqC,SAAS4nE,GACjD,MAAM,IAAIzjE,EACRlB,EAAKI,kBACL,YAAYgkE,wBAAmCK,WAC1CE,IAAH,qCACAN,GAAa3pE,EAAKqC,QAAQ,cAC1B;;;;;;;;;;;SA6BQ6nE,GACdR,GACAz1D,GACAyV,GACAygD;IAEAC,GAAaV,GAAcz1D,GAASo2D,GAAQ3gD,KAAX,aAAiCygD;;;;;;aAOpDG,GACdZ,GACAz1D,GACAyV,GACAygD;SAEiBtlE,MAAbslE,KACFD,GAAgBR,GAAcz1D,GAAMyV,GAAUygD;;;;;;aAQlCI,GACdb,GACAz1D,GACAu2D,GACAL;IAEAC,GAAaV,GAAcz1D,GAASu2D,IAAH,WAAwBL;;;;;;aAO3CM,GACdf,GACAz1D,GACAu2D,GACAL;SAEiBtlE,MAAbslE,KACFI,GAAkBb,GAAcz1D,GAAMu2D,GAAYL;;;SA+BtCO,GACdhB,GACAc,GACAG,GACAR,GACAS;SAEiB/lE,MAAbslE,cAjCJT,GACAc,GACAG,GACAR,GACAS;QAEA,MAAMT,aAAoBnb,QACxB,MAAM,IAAIxoD,EACRlB,EAAKI,kBACL,YAAYgkE,oBAA+Bc,0CACHK,GAAiBV;QAI7D,KAAK,IAAItoE,IAAI,GAAGA,IAAIsoE,EAAS9nE,UAAUR,GACrC,KAAK+oE,EAAUT,EAAStoE,KACtB,MAAM,IAAI2E,EACRlB,EAAKI,kBACL,YAAYgkE,oBAA+Bc,oBACvBG,6BAA2C9oE,YACrDgpE,GAAiBV,EAAStoE;KAcxCipE,CACEpB,GACAc,GACAG,GACAR,GACAS;;;;;;;;;;SAoCUG,GACdrB,GACAsB,GACAR,GACAS,GACAC;SAEcrmE,MAAVomE,cAlCJvB,GACAsB,GACAR,GACAS,GACAC;QAEA,MAAMC,IAAgC;QAEtC,KAAK,MAAMljD,KAAOijD,GAAU;YAC1B,IAAIjjD,MAAQgjD,GACV;YAEFE,EAAoBnmE,KAAK6lE,GAAiB5iD;;QAG5C,MAAMmjD,IAAoBP,GAAiBI;QAC3C,MAAM,IAAIzkE,EACRlB,EAAKI,kBACL,iBAAiB0lE,0BAA0C1B,mBACrDc,0BAAmCW,EAAoBpiE,KAAK;KAgBlEsiE,CACE3B,GACAsB,GACAR,GACAS,GACAC;;;;;;;;;;;aAcUI,GACd5B,GACA6B,GACA7hD,GACAygD;IAEA,KAAKoB,EAAM9/C,KAAKC,KAAWA,MAAYy+C,IACrC,MAAM,IAAI3jE,EACRlB,EAAKI,kBACL,iBAAiBmlE,GAAiBV,2BAC7BT,eAA0BW,GAAQ3gD,qCAC1B6hD,EAAMxiE,KAAK;IAG5B,OAAOohE;;;uDA8BT,UAASC,GACPV,GACAz1D,GACA+2D,GACAC;IAEA,IAAIO,KAAQ;IASZ,IAPEA,IADW,aAATv3D,IACMw3D,GAAcR,KACJ,uBAATh3D,IACgB,mBAAVg3D,KAAgC,OAAVA,WAEtBA,MAAUh3D;KAGtBu3D,GAAO;QACV,MAAME,IAAcb,GAAiBI;QACrC,MAAM,IAAIzkE,EACRlB,EAAKI,kBACL,YAAYgkE,oBAA+BsB,mBACxB/2D,kBAAqBy3D;;;;;;;aAS9BD,GAAcR;IAC5B,OACmB,mBAAVA,KACG,SAAVA,MACCjnE,OAAO2nE,eAAeV,OAAWjnE,OAAOC,aACN,SAAjCD,OAAO2nE,eAAeV;;;oFAKZJ,GAAiBI;IAC/B,SAAcpmE,MAAVomE,GACF,OAAO;IACF,IAAc,SAAVA,GACT,OAAO;IACF,IAAqB,mBAAVA,GAIhB,OAHIA,EAAM5oE,SAAS,OACjB4oE,IAAWA,EAAMxiC,UAAU,GAAG,MAAtB;IAEH9nC,KAAKC,UAAUqqE;IACjB,IAAqB,mBAAVA,KAAuC,oBAAVA,GAC7C,OAAO,KAAKA;IACP,IAAqB,mBAAVA,GAAoB;QACpC,IAAIA,aAAiBjc,OACnB,OAAO;QACF;YACL,MAAM4c;;qBAe2BX;gBACrC,IAAIA,EAAM5pE,aAAa;oBACrB,MACM6yB,IADgB,4BACQrV,KAAKosD,EAAM5pE,YAAYsF;oBACrD,IAAIutB,KAAWA,EAAQ7xB,SAAS,GAC9B,OAAO6xB,EAAQ;;gBAGnB,OAAO;;8DAvBsB23C;YACzB,OAAID,IACK,YAAYA,aAEZ;;;IAGN,OAAqB,qBAAVX,IACT,eAnYDnqE;;;SAsZMgrE,GACdpC,GACAhgD,GACAygD;IAEA,SAAiBtlE,MAAbslE,GACF,MAAM,IAAI3jE,EACRlB,EAAKI,kBACL,YAAYgkE,wBAAmCW,GAAQ3gD;;;;;;aAU7CqiD,GACdrC,GACAh6C,GACAs8C;IAEA5nE,EAAQsrB,GAA0B,CAAC3rB,GAAKmB;QACtC,IAAI8mE,EAAY9iE,QAAQnF,KAAO,GAC7B,MAAM,IAAIyC,EACRlB,EAAKI,kBACL,mBAAmB3B,yBAA2B2lE,6BAE5CsC,EAAYjjE,KAAK;;;;;;;aAUXkjE,GACdvC,GACAz1D,GACAyV,GACAygD;IAEA,MAAMuB,IAAcb,GAAiBV;IACrC,OAAO,IAAI3jE,EACTlB,EAAKI,kBACL,YAAYgkE,oBAA+BW,GAAQ3gD,uBAC7BzV,kBAAqBy3D;;;SAI/BQ,GACdxC,GACAhgD,GACAxZ;IAEA,IAAIA,KAAK,GACP,MAAM,IAAI1J,EACRlB,EAAKI,kBACL,YAAYgkE,oBAA+BW,GACzC3gD,oDACiDxZ;;;2DAMzD,UAASm6D,GAAQ8B;IACf,QAAQA;MACN,KAAK;QACH,OAAO;;MACT,KAAK;QACH,OAAO;;MACT,KAAK;QACH,OAAO;;MACT;QACE,OAAOA,IAAM;;;;;;GAOnB,UAASxC,GAAawC,GAAa3iE;IACjC,OAAO,GAAG2iE,KAAO3iE,OAAiB,MAAR2iE,IAAY,KAAK;;;;;;;;;;;;;;;;;;;oECze7C,UAASC;IACP,IAA0B,sBAAfzqE,YACT,MAAM,IAAI6E,EACRlB,EAAKc,eACL;;;;;;;;;UAsBOimE;IAKXnqE,YAAYoqE;QAEV/oE,KAAKgpE,KAAcD;;IAGrBpqE,wBAAwB8K;QACtB48D,GAA0B,yBAAyB4C,WAAW,IAC9DtC,GAAgB,yBAAyB,UAAU,GAAGl9D;QAEtD;YACE,OAAO,IAAIq/D,GAAKn/D,GAAWgS,iBAAiBlS;UAC5C,OAAOnM;YACP,MAAM,IAAI2F,EACRlB,EAAKI,kBACL,kDAAkD7E;;;IAKxDqB,sBAAsBkL;QAGpB,IAFAw8D,GAA0B,uBAAuB4C,WAAW,IAC5DJ,QACMh/D,aAAiBzL,aACrB,MAAMsqE,GAAkB,uBAAuB,cAAc,GAAG7+D;QAElE,OAAO,IAAIi/D,GAAKn/D,GAAWiS,eAAe/R;;IAG5ClL;QAGE,OAFA0nE,GAA0B,iBAAiB4C,WAAW,IAE/CjpE,KAAKgpE,GAAYluD;;IAG1Bnc;QAGE,OAFA0nE,GAA0B,qBAAqB4C,WAAW,IAC1DJ,MACO7oE,KAAKgpE,GAAYprD;;IAG1Bjf;QACE,OAAO,kBAAkBqB,KAAK8a,aAAa;;IAG7Cnc,QAAQ0B;QACN,OAAOL,KAAKgpE,GAAY1kE,QAAQjE,EAAM2oE;;;;;;;;;;;;;;;;;;;;;;;;;;UCpEpBE;IAIpBvqE,YAAYwqE;kBF2FZhD,GACAhpE,GACAkG,GACA+lE;YAEA,MAAMjsE,aAAiBsuD,UAAUtuD,EAAM2B,SAASsqE,GAC9C,MAAM,IAAInmE,EACRlB,EAAKI,kBACL,YAAYgkE,oBAA+B9iE,6CAEtC+iE,GAAagD,GAAqB,aAArC;SEpGJC,CACE,aACAF,GACA,cACA;QAGF,KAAK,IAAI7qE,IAAI,GAAGA,IAAI6qE,EAAWrqE,UAAUR,GAEvC,IADAqoE,GAAgB,aAAa,UAAUroE,GAAG6qE,EAAW7qE,KACxB,MAAzB6qE,EAAW7qE,GAAGQ,QAChB,MAAM,IAAImE,EACRlB,EAAKI,kBACL;QAMNnC,KAAKspE,KAAgB,IAAIC,EAAkBJ;;;;;;;;UASlCpjE,WAAkBmjE;;;;;;;IAO7BvqE,eAAewqE;QACbhmE,MAAMgmE;;IAGRxqE;;;;;;;QAOE,OAAO,IAAIoH,GAAUwjE,EAAkBl8C,IAAW5nB;;IAGpD9G,QAAQ0B;QACN,MAAMA,aAAiB0F,KACrB,MAAM2iE,GAAkB,WAAW,aAAa,GAAGroE;QAErD,OAAOL,KAAKspE,GAAchlE,QAAQjE,EAAMipE;;;;;;GAO5C,OAAME,KAAW,IAAItyD,OAAO;;;;;;;;;;;;;;;;;;;;;;;;;MC5DNuyD;IAAtB9qE;;QAKEqB,UAA6CA;;;;MAOlC0pE,WAA6BD;IACxC9qE,YAAqBgrE;QACnBxmE,mBADmBwmE;;IAIrBhrE,GAAkBirE;QAChB,yBAAIA,EAAQC,IAIL,yBAAID,EAAQC,KAMXD,EAAQE,GACT9pE,KAAK2pE,KAAR,6DAKIC,EAAQE,GACT9pE,KAAK2pE,KAAR;;;QAIJ,OAlBEC,EAAQ/oD,GAAUpf,KAAKmoE,EAAa,OAkB/B;;IAGTjrE,QAAQ0B;QACN,OAAOA,aAAiBqpE;;;;;;;;;;;;;;;;;;;GAoB5B,UAASK,GACPC,GACAJ,GACAK;IAEA,OAAO,IAAIC,GACT;QACEC;QACAC,IAAWR,EAAQS,SAASC;QAC5BC,YAAYP,EAAWL;QACvBa,IAAAP;OAEFL,EAAQjqE,GACRiqE,EAAQtsD,YACRssD,EAAQa;;;MAICC,WAAsCjB;IACjD9qE,YAAqBgrE;QACnBxmE,mBADmBwmE;;IAIrBhrE,GAAkBirE;QAChB,OAAO,IAAI9mD,GAAe8mD,EAAa,MAAE,IAAI1oD;;IAG/CviB,QAAQ0B;QACN,OAAOA,aAAiBqqE;;;;MAIfC,WAAiClB;IAC5C9qE,YACWgrE,GACQiB;QAEjBznE,mBAHSwmE,aACQiB;;IAKnBjsE,GAAkBirE;QAChB,MAAMiB,IAAed,GACnB/pE,MACA4pE;oBACW,IAEPkB,IAAiB9qE,KAAK4qE,GAAUluE,IACpCyrB,KAAW4iD,GAAU5iD,GAAS0iD,KAE1BG,IAAa,IAAI3pD,GAA6BypD;QACpD,OAAO,IAAIhoD,GAAe8mD,EAAQlkE,MAAOslE;;IAG3CrsE,QAAQ0B;;QAEN,OAAOL,SAASK;;;;MAIP4qE,WAAkCxB;IAC7C9qE,YAAqBgrE,GAA8BiB;QACjDznE,mBADmBwmE,aAA8BiB;;IAInDjsE,GAAkBirE;QAChB,MAAMiB,IAAed,GACnB/pE,MACA4pE;oBACW,IAEPkB,IAAiB9qE,KAAK4qE,GAAUluE,IACpCyrB,KAAW4iD,GAAU5iD,GAAS0iD,KAE1BG,IAAa,IAAIxpD,GAA8BspD;QACrD,OAAO,IAAIhoD,GAAe8mD,EAAQlkE,MAAOslE;;IAG3CrsE,QAAQ0B;;QAEN,OAAOL,SAASK;;;;MAIP6qE,WAAuCzB;IAClD9qE,YAAqBgrE,GAAsCwB;QACzDhoE,mBADmBwmE,aAAsCwB;;IAI3DxsE,GAAkBirE;QAChB,MAAMwB,IAAmB,IAAI1pD,GAC3BkoD,EAAQtsD,YACRE,GAASosD,EAAQtsD,YAAYtd,KAAKmrE;QAEpC,OAAO,IAAIroD,GAAe8mD,EAAa,MAAEwB;;IAG3CzsE,QAAQ0B;;QAEN,OAAOL,SAASK;;;;0DAKEgrE,WAAmB5B;IAEvC9qE;QACEwE;;IAGFxE;QAEE,OADAunE,GAAe,qBAAqB+C,YAC7B,IAAIqC,GACT,IAAI5B,GAAqB;;IAI7B/qE;QAEE,OADAunE,GAAe,8BAA8B+C,YACtC,IAAIqC,GACT,IAAIZ,GAA8B;;IAItC/rE,qBAAqB4iB;;;QAInB,OAHAglD,GAA4B,yBAAyB0C,WAAW,IAGzD,IAAIqC,GACT,IAAIX,GAAyB,yBAAyBppD;;IAI1D5iB,sBAAsB4iB;;;QAIpB,OAHAglD,GAA4B,0BAA0B0C,WAAW,IAG1D,IAAIqC,GACT,IAAIL,GAA0B,0BAA0B1pD;;IAI5D5iB,iBAAiBgO;QAGf,OAFAg6D,GAAgB,wBAAwB,UAAU,GAAGh6D,IACrD05D,GAA0B,wBAAwB4C,WAAW;QACtD,IAAIqC,GACT,IAAIJ,GAA+B,wBAAwBv+D;;;;;;;;;;;;GAcjE,OAAM2+D,WAA2BD;IAG/B1sE,YAAqB4sE;QACnBpoE,mBADmBooE,GAEnBvrE,KAAK2pE,KAAc4B,EAAU5B;;IAG/BhrE,GAAkBirE;QAChB,OAAO5pE,KAAKurE,GAAUC,GAAkB5B;;IAG1CjrE,QAAQ0B;QACN,OAAMA,aAAiBirE,MAGhBtrE,KAAKurE,GAAUjnE,QAAQjE,EAAMkrE;;;;;;;;;;;;;;;;;;;;;;;UCzP3BE;IAMX9sE,YAAYoZ,GAAkBC;QAI5B,IAHAquD,GAA0B,YAAY4C,WAAW,IACjDtC,GAAgB,YAAY,UAAU,GAAG5uD,IACzC4uD,GAAgB,YAAY,UAAU,GAAG3uD;SACpC0zD,SAAS3zD,MAAaA,KAAY,MAAMA,IAAW,IACtD,MAAM,IAAI9U,EACRlB,EAAKI,kBACL,4DAA4D4V;QAGhE,KAAK2zD,SAAS1zD,MAAcA,KAAa,OAAOA,IAAY,KAC1D,MAAM,IAAI/U,EACRlB,EAAKI,kBACL,+DAA+D6V;QAInEhY,KAAK2rE,KAAO5zD,GACZ/X,KAAK4rE,KAAQ5zD;;;;WAMfD;QACE,OAAO/X,KAAK2rE;;;;WAMd3zD;QACE,OAAOhY,KAAK4rE;;IAGdjtE,QAAQ0B;QACN,OAAOL,KAAK2rE,OAAStrE,EAAMsrE,MAAQ3rE,KAAK4rE,OAAUvrE,EAAMurE;;;;;WAO1DjtE,EAAW0B;QACT,OACEpB,EAAoBe,KAAK2rE,IAAMtrE,EAAMsrE,OACrC1sE,EAAoBe,KAAK4rE,IAAOvrE,EAAMurE;;;;;;;;;;;;;;;;;;;GC5B5C,OAAMC,KAAuB;;;;;;;UAqBhBC;IACXntE,YACWotE,GACAC,GACAC;kBAFAF,aACAC,aACAC;;;;4EAKAC;IACXvtE,YACWgP,GACAkT,GACAG;QAFAhhB,YAAA2N,aACAkT,GACA7gB,uBAAAghB;;IAGXriB,GAAY6B,GAAkBwhB;QAC5B,MAAM8N,IAAY;QAWlB,OAVuB,SAAnB9vB,KAAK6gB,KACPiP,EAAUruB,KACR,IAAIif,GAAclgB,GAAKR,KAAK2N,MAAM3N,KAAK6gB,IAAWmB,MAGpD8N,EAAUruB,KAAK,IAAI8e,GAAY/f,GAAKR,KAAK2N,MAAMqU;QAE7ChiB,KAAKghB,gBAAgBliB,SAAS,KAChCgxB,EAAUruB,KAAK,IAAIqf,GAAkBtgB,GAAKR,KAAKghB,mBAE1C8O;;;;gFAKEq8C;IACXxtE,YACWgP,GACAkT,GACAG;QAFAhhB,YAAA2N,aACAkT,GACA7gB,uBAAAghB;;IAGXriB,GAAY6B,GAAkBwhB;QAC5B,MAAM8N,IAAY,EAChB,IAAIpP,GAAclgB,GAAKR,KAAK2N,MAAM3N,KAAK6gB,IAAWmB;QAKpD,OAHIhiB,KAAKghB,gBAAgBliB,SAAS,KAChCgxB,EAAUruB,KAAK,IAAIqf,GAAkBtgB,GAAKR,KAAKghB;QAE1C8O;;;;AAyBX,SAASs8C,GAAQvC;IACf,QAAQA;MACN;;cACA;;cACA;QACE,QAAO;;MACT;MACA;QACE,QAAO;;MACT;QACE,MA9HCtsE;;;;uEA8JM2sE;;;;;;;;;;;;;;;;;;;IAqBXvrE,YACW0rE,GACA1qE,GACA2d,GACAmtD,GACTzpD,GACAH;QALS7gB,gBAAAqqE,YACA1qE,GACAK,kBAAAsd,GACAtd,iCAAAyqE;;;aAMenpE,MAApB0f,KACFhhB,KAAKqsE,MAEPrsE,KAAKghB,kBAAkBA,KAAmB,IAC1ChhB,KAAK6gB,KAAYA,KAAa;;IAGhCnb;QACE,OAAO1F,KAAKqqE,SAAS3kE;;IAGvBykE;QACE,OAAOnqE,KAAKqqE,SAASR;;6EAIvBlrE,GAAY2tE;QACV,OAAO,IAAIpC,mCACJlqE,KAAKqqE,WAAaiC,IACvBtsE,KAAKL,GACLK,KAAKsd,YACLtd,KAAKyqE,2BACLzqE,KAAKghB,iBACLhhB,KAAK6gB;;IAITliB,GAAqB2J;;QACnB,MAAMikE,kBAAYvsE,KAAK0F,mCAAMyY,MAAM7V,IAC7BshE,IAAU5pE,KAAKwsE,GAAY;YAAE9mE,MAAM6mE;YAAW/B,KAAc;;QAElE,OADAZ,EAAQ6C,GAAoBnkE,IACrBshE;;IAGTjrE,GAAyB2J;;QACvB,MAAMikE,kBAAYvsE,KAAK0F,mCAAMyY,MAAM7V,IAC7BshE,IAAU5pE,KAAKwsE,GAAY;YAAE9mE,MAAM6mE;YAAW/B,KAAc;;QAElE,OADAZ,EAAQyC,MACDzC;;IAGTjrE,GAAqBY;;;QAGnB,OAAOS,KAAKwsE,GAAY;YAAE9mE,WAAMpE;YAAWkpE,KAAc;;;IAG3D7rE,GAAYs/B;QACV,OAAO6rC,GACL7rC,GACAj+B,KAAKqqE,SAASE,YACdvqE,KAAKqqE,SAASqC,OAAgB,GAC9B1sE,KAAK0F,MACL1F,KAAKqqE,SAASC;;sFAKlB3rE,SAASwiB;QACP,YACgE7f,MAA9DtB,KAAK6gB,GAAU9H,KAAKzQ,KAAS6Y,EAAUmH,EAAWhgB,YAG5ChH,MAFNtB,KAAKghB,gBAAgBjI,KAAKgI,KACxBI,EAAUmH,EAAWvH,EAAUzY;;IAK7B3J;;;QAGN,IAAKqB,KAAK0F,MAGV,KAAK,IAAIpH,IAAI,GAAGA,IAAI0B,KAAK0F,KAAK5G,QAAQR,KACpC0B,KAAKysE,GAAoBzsE,KAAK0F,KAAKlE,IAAIlD;;IAInCK,GAAoBmG;QAC1B,IAAuB,MAAnBA,EAAQhG,QACV,MAAMkB,KAAK8pE,GAAY;QAEzB,IAAIsC,GAAQpsE,KAAK6pE,OAAegC,GAAqB7lE,KAAKlB,IACxD,MAAM9E,KAAK8pE,GAAY;;;;;;;UAShB6C;IAGXhuE,YACmBgB,GACA8qE,GACjBntD;iBAFiB3d,GACAK,iCAAAyqE,GAGjBzqE,KAAKsd,aAAaA,KAAc8lD,GAAczjE;;qDAIhDhB,GACEkrE,GACAU,GACAD,GACAoC,KAAe;QAEf,OAAO,IAAIxC,GACT;YACEC,IAAAN;YACAU,YAAAA;YACAH,IAAAE;YACA5kE,MAAMK,EAAU6Y;YAChB4rD,KAAc;YACdoC,IAAAF;WAEF1sE,KAAKL,GACLK,KAAKsd,YACLtd,KAAKyqE;;;;uDAMKoC,GACdC,GACAvC,GACAD,GACA5C,GACAgF,GACAvgD,IAAgC;IAEhC,MAAMy9C,IAAUkD,EAAeC,GAC7B5gD,EAAQ6gD,SAAS7gD,EAAQ8gD,+CAGzB1C,GACAD,GACAoC;IAEFQ,GAAoB,uCAAuCtD,GAASlC;IACpE,MAAMyF,IAAaC,GAAY1F,GAAOkC;IAEtC,IAAI/oD,GACAG;IAEJ,IAAImL,EAAQ6gD,OACVnsD,IAAY,IAAI8B,GAAUinD,EAAQ/oD,KAClCG,IAAkB4oD,EAAQ5oD,sBACrB,IAAImL,EAAQ8gD,aAAa;QAC9B,MAAMI,IAAmC;QAEzC,KAAK,MAAMC,KAAqBnhD,EAAQ8gD,aAAa;YACnD,IAAI9rD;YAEJ,IAAImsD,aAA6BpE,IAC/B/nD,IAAYmsD,EAAkBhE,SACzB;gBAAA,IAAiC,mBAAtBgE,GAOhB,MApWD/vE;gBA8VC4jB,IAAYosD,GACVhD,GACA+C,GACAhD;;YAMJ,KAAKV,EAAQz5B,SAAShvB,IACpB,MAAM,IAAIle,EACRlB,EAAKI,kBACL,UAAUgf;YAITqsD,GAAkBH,GAAqBlsD,MAC1CksD,EAAoB5rE,KAAK0f;;QAI7BN,IAAY,IAAI8B,GAAU0qD,IAC1BrsD,IAAkB4oD,EAAQ5oD,gBAAgBnb,OAAOkb,KAC/CF,EAAW4sD,GAAO1sD,EAAUzY;WAG9BuY,IAAY,MACZG,IAAkB4oD,EAAQ5oD;IAG5B,OAAO,IAAIkrD,GACT,IAAI/sD,GAAYguD,IAChBtsD,GACAG;;;yDAKY0sD,GACdZ,GACAvC,GACAD,GACA5C;IAEA,MAAMkC,IAAUkD,EAAeC,oBAE7BxC,GACAD;IAEF4C,GAAoB,uCAAuCtD,GAASlC;IAEpE,MAAMiG,IAA8B,IAC9BR,IAAa,IAAI1iD;IACvB5pB,EAAQ6mE,GAAwB,CAAClnE,GAAKrD;QACpC,MAAMuI,IAAO6nE,GAAgChD,GAAY/pE,GAAK8pE,IAExDsD,IAAehE,EAAQiE,GAAyBnoE;QACtD,IACEvI,aAAiBssE,MACjBtsE,EAAMouE,cAAqB7B;;QAG3BiE,EAAelsE,KAAKiE,SACf;YACL,MAAMooE,IAAc/C,GAAU5tE,GAAOywE;YAClB,QAAfE,MACFH,EAAelsE,KAAKiE,IACpBynE,EAAW79D,IAAI5J,GAAMooE;;;IAK3B,MAAMC,IAAO,IAAIprD,GAAUgrD;IAC3B,OAAO,IAAIxB,GACTgB,EAAWziD,MACXqjD,GACAnE,EAAQ5oD;;;wEAKIgtD,GACdlB,GACAvC,GACAD,GACAhiE,GACAnL,GACA8wE;IAEA,MAAMrE,IAAUkD,EAAeC,oBAE7BxC,GACAD,IAEIj7D,IAAO,EAAC6+D,GAAsB3D,GAAYjiE,GAAOgiE,MACjD9xD,IAAS,EAACrb;IAEhB,IAAI8wE,EAAoBnvE,SAAS,KAAM,GACrC,MAAM,IAAImE,EACRlB,EAAKI,kBACL,YAAYooE;IAKhB,KAAK,IAAIjsE,IAAI,GAAGA,IAAI2vE,EAAoBnvE,QAAQR,KAAK,GACnD+Q,EAAK5N,KACHysE,GACE3D,GACA0D,EAAoB3vE,MAGxBka,EAAO/W,KAAKwsE,EAAoB3vE,IAAI;IAGtC,MAAMqvE,IAA8B,IAC9BR,IAAa,IAAI1iD;;;IAIvB,KAAK,IAAInsB,IAAI+Q,EAAKvQ,SAAS,GAAGR,KAAK,KAAKA,GACtC,KAAKkvE,GAAkBG,GAAgBt+D,EAAK/Q,KAAK;QAC/C,MAAMoH,IAAO2J,EAAK/Q,IACZnB,IAAQqb,EAAOla,IACfsvE,IAAehE,EAAQiE,GAAyBnoE;QACtD,IACEvI,aAAiBssE,MACjBtsE,EAAMouE,cAAqB7B;;QAG3BiE,EAAelsE,KAAKiE,SACf;YACL,MAAMooE,IAAc/C,GAAU5tE,GAAOywE;YAClB,QAAfE,MACFH,EAAelsE,KAAKiE,IACpBynE,EAAW79D,IAAI5J,GAAMooE;;;IAM7B,MAAMC,IAAO,IAAIprD,GAAUgrD;IAC3B,OAAO,IAAIxB,GACTgB,EAAWziD,MACXqjD,GACAnE,EAAQ5oD;;;;;;;;;aAWImtD,GACdrB,GACAvC,GACA7C,GACA0G,KAAc;IAYd,OANerD,GAAUrD,GAJToF,EAAeC,GAC7BqB,+CACA7D;;;;;;;;;;;aAoBYQ,GACdrD,GACAkC;IAEA,IAAIyE,GAAoB3G,IAEtB,OADAwF,GAAoB,4BAA4BtD,GAASlC,IAClD0F,GAAY1F,GAAOkC;IACrB,IAAIlC,aAAiB+B;;;;;;;;;;IAO1B,OA2EJ,SACEtsE,GACAysE;;QAGA,KAAKwC,GAAQxC,EAAQC,KACnB,MAAMD,EAAQE,GACT3sE,EAAMwsE,KAAT;QAGJ,KAAKC,EAAQlkE,MACX,MAAMkkE,EAAQE,GACT3sE,EAAMwsE,KAAT;QAIJ,MAAM1oD,IAAiB9jB,EAAMquE,GAAkB5B;QAC3C3oD,KACF2oD,EAAQ5oD,gBAAgBvf,KAAKwf;;;;;;GA9F7BqtD,EAAwB5G,GAAOkC,IACxB;IAQP;;;IAJIA,EAAQlkE,QACVkkE,EAAQ/oD,GAAUpf,KAAKmoE,EAAQlkE,OAG7BgiE,aAAiBjc,OAAO;;;;;;;QAO1B,IACEme,EAAQS,SAASJ,gCACjBL,EAAQC,IAER,MAAMD,EAAQE,GAAY;QAE5B,OA+BN,SAAoBjgE,GAAkB+/D;YACpC,MAAMpxD,IAAsB;YAC5B,IAAI+1D,IAAa;YACjB,KAAK,MAAMxtC,KAASl3B,GAAO;gBACzB,IAAI2kE,IAAczD,GAChBhqC,GACA6oC,EAAQ6E,GAAqBF;gBAEZ,QAAfC;;;gBAGFA,IAAc;oBAAE5nD,WAAW;oBAE7BpO,EAAO/W,KAAK+sE,IACZD;;YAEF,OAAO;gBAAEh2D,YAAY;oBAAEC,QAAAA;;;SA/CZk2D,CAAWhH,GAAoBkC;;IAEtC,OA+EN,SACEzsE,GACAysE;QAEA,IAAc,SAAVzsE,GACF,OAAO;YAAEypB,WAAW;;QACf,IAAqB,mBAAVzpB,GAChB,OAAOqgB,GAASosD,EAAQtsD,YAAYngB;QAC/B,IAAqB,oBAAVA,GAChB,OAAO;YAAEka,cAAcla;;QAClB,IAAqB,mBAAVA,GAChB,OAAO;YAAEyZ,aAAazZ;;QACjB,IAAIA,aAAiBuG,MAAM;YAChC,MAAMU,IAAYd,EAAUqrE,SAASxxE;YACrC,OAAO;gBACLma,gBAAgBmG,GAAYmsD,EAAQtsD,YAAYlZ;;;QAE7C,IAAIjH,aAAiBmG,GAAW;;;;YAIrC,MAAMc,IAAY,IAAId,EACpBnG,EAAMoG,SACiC,MAAvChF,KAAKC,MAAMrB,EAAMqG,cAAc;YAEjC,OAAO;gBACL8T,gBAAgBmG,GAAYmsD,EAAQtsD,YAAYlZ;;;QAE7C,IAAIjH,aAAiBsuE,IAC1B,OAAO;YACL3zD,eAAe;gBACbC,UAAU5a,EAAM4a;gBAChBC,WAAW7a,EAAM6a;;;QAGhB,IAAI7a,aAAiB2rE,IAC1B,OAAO;YAAE8F,YAAYjxD,GAAQisD,EAAQtsD,YAAYngB;;QAC5C,IAAIA,aAAiB2uE,IAAsB;YAChD,MAAM+C,IAASjF,EAAQjqE,GACjBmvE,IAAU3xE,EAAM4uE;YACtB,KAAK+C,EAAQxqE,QAAQuqE,IACnB,MAAMjF,EAAQE,GAEV,sCAAGgF,EAAQ5uE,aAAa4uE,EAAQ3uE,uCAChB0uE,EAAO3uE,aAAa2uE,EAAO1uE;YAGjD,OAAO;gBACLyX,gBAAgBqG,GACd9gB,EAAM4uE,MAAenC,EAAQjqE,GAC7BxC,EAAM6uE,GAAKtmE;;;QAGV,SAAcpE,MAAVnE,KAAuBysE,EAAQa,2BACxC,OAAO;QAEP,MAAMb,EAAQE,GACZ,8BAA4BxC,GAAiBnqE;;;;;;;;GAxItC4xE,EAAiBrH,GAAOkC;;;AAKrC,SAASwD,GACP9wE,GACAstE;IAEA,MAAMjzD,IAA0B;IAiBhC,OAfI5V,EAAQzE;;;IAGNstE,EAAQlkE,QAAQkkE,EAAQlkE,KAAK5G,SAAS,KACxC8qE,EAAQ/oD,GAAUpf,KAAKmoE,EAAQlkE,QAGjC7E,EAAQvE,GAAK,CAACkE,GAAakkB;QACzB,MAAMopD,IAAc/C,GAAUrmD,GAAKklD,EAAQoF,GAAqBxuE;QAC7C,QAAfstE,MACFn3D,EAAOnW,KAAOstE;QAKb;QAAEp3D,UAAU;YAAEC,QAAAA;;;;;AA0HvB,SAAS03D,GAAoB3G;IAC3B,SACmB,mBAAVA,KACG,SAAVA,KACEA,aAAiBjc,SACjBic,aAAiBhkE,QACjBgkE,aAAiBpkE,KACjBokE,aAAiB+D,MACjB/D,aAAiBoB,MACjBpB,aAAiBoE,MACjBpE,aAAiB+B;;;AAIvB,SAASyD,GACPzvE,GACAmsE,GACAlC;IAEA,KAAK2G,GAAoB3G,OAAWQ,GAAcR,IAAQ;QACxD,MAAMS,IAAcb,GAAiBI;QACrC,MAAoB,gBAAhBS,IAEIyB,EAAQE,GAAYrsE,IAAU,sBAE9BmsE,EAAQE,GAAYrsE,IAAU,MAAM0qE;;;;;;aAQhC+F,GACd3D,GACA7kE,GACA4kE;IAEA,IAAI5kE,aAAgBwjE,IAClB,OAAOxjE,EAAK4jE;IACP,IAAoB,mBAAT5jE,GAChB,OAAO6nE,GAAgChD,GAAY7kE;IAGnD,MAAMokE,GADU,6DAGdS;yBACoB;qBACRjpE,GACZgpE;;;;;;;;;;aAaUiD,GACdhD,GACA7kE,GACA4kE;IAEA;QACE,gBHxsBmC5kE;YAErC,IADcA,EAAKupE,OAAOzF,OACb,GACX,MAAM,IAAIvmE,EACRlB,EAAKI,kBACL,uBAAuBuD;YAI3B;gBACE,OAAO,IAAIK,MAAaL,EAAKE,MAAM;cACnC,OAAOtI;gBACP,MAAM,IAAI2F,EACRlB,EAAKI,kBACL,uBAAuBuD;;SG0rBlBwpE,CAAuBxpE,GAAM4jE;MACpC,OAAOhsE;QAEP,MAAMwsE,IAgDY/sE,IAjDWO,cAkDPI,QAAQX,EAAMU,UAAUV,EAAMqG,YA/ClDmnE;6BACoB;yBACRjpE,GACZgpE;;;;;;IA2CN,IAAsBvtE;;;AAtCtB,SAAS+sE,GACP7rC,GACAssC,GACAmC,GACAhnE,GACA4kE;IAEA,MAAM6E,IAAUzpE,MAASA,EAAK3E,KACxBquE,SAA4B9tE,MAAdgpE;IACpB,IAAI7sE,IAAU,YAAY8sE;IACtBmC,MACFjvE,KAAW,2BAEbA,KAAW;IAEX,IAAI0qE,IAAc;IAalB,QAZIgH,KAAWC,OACbjH,KAAe,WAEXgH,MACFhH,KAAe,eAAaziE,IAE1B0pE,MACFjH,KAAe,kBAAgBmC;IAEjCnC,KAAe,MAGV,IAAIllE,EACTlB,EAAKI,kBACL1E,IAAUwgC,IAASkqC;;;AAavB,SAASqF,GAAkB30D,GAAuBC;IAChD,OAAOD,EAASqP,KAAKpmB,KAAKA,EAAEwC,QAAQwU;;;;;;;;;;;;;;;;;;;;;;UCh0BzBu2D;IAoBX1wE,YAAoB6nD;kBAAAA;;QAlBpBxmD,UAAuB,IAAI+R,KACnB/R,iBAAwB,IAChCA,WAAoB;;;;;QAMpBA,UAAgD;;;;;;;QAQhDA,UAAwC,IAAI0mD;;IAI5C/nD,SAAa0Q;QAGX,IAFArP,KAAKsvE,MAEDtvE,KAAK8vB,UAAUhxB,SAAS,GAC1B,MAAM,IAAImE,EACRlB,EAAKI,kBACL;QAGJ,MAAM2O,U7BkFH6xB,eACL6jB,GACAn3C;YAEA,MAAM23C,IAAgBnpD,EAAU2oD,IAC1B9gD,IAAOmZ,GAAqBmoC,EAAc1pC,cAAc,cACxD4b,IAAU;gBACd7nB,WAAWhC,EAAK3S,IAAImF,KAAK0c,GAAOyoC,EAAc1pC,YAAYzb;eAEtDm9D,UAAiBhY,EAAcpB,GAGnC,qBAAqBlgD,GAAMwzB,IAEvBpoB,IAAO,IAAIiB;YACjBitD,EAASn+D,QAAQke;gBACf,MAAM/O,IAAMgP,GAAkBgoC,EAAc1pC,YAAYyB;gBACxDjO,EAAKxB,IAAIU,EAAIxP,IAAI4C,YAAY4M;;YAE/B,MAAMxD,IAA0B;YAMhC,OALA6C,EAAKxO,QAAQL;gBACX,MAAMwP,IAAMc,EAAKtP,IAAIhB,EAAI4C;gBAjIczF,IAkI1BqS,IACbxD,EAAO/K,KAAKuO;gBAEPxD;S6B3Gc+iE,CAA2BvvE,KAAKwmD,IAAWn3C;QAQ9D,OAPAyB,EAAKjQ,QAAQmP;YACPA,aAAeiE,MAAcjE,aAAe+D,KAC9C/T,KAAKwvE,GAAcx/D,KAEnBzS;YAGGuT;;IAGTnS,IAAI6B,GAAkBmN;QACpB3N,KAAKyvE,MAAM9hE,EAAK+hE,GAAYlvE,GAAKR,KAAKgiB,GAAaxhB,MACnDR,KAAK2vE,GAAYphE,IAAI/N;;IAGvB7B,OAAO6B,GAAkBmN;QACvB;YACE3N,KAAKyvE,MAAM9hE,EAAK+hE,GAAYlvE,GAAKR,KAAK4vE,GAAsBpvE;UAC5D,OAAOlD;YACP0C,KAAK6vE,KAAiBvyE;;QAExB0C,KAAK2vE,GAAYphE,IAAI/N;;IAGvB7B,OAAO6B;QACLR,KAAKyvE,MAAM,EAAC,IAAIhvD,GAAejgB,GAAKR,KAAKgiB,GAAaxhB,QACtDR,KAAK2vE,GAAYphE,IAAI/N;;IAGvB7B;QAGE,IAFAqB,KAAKsvE,MAEDtvE,KAAK6vE,IACP,MAAM7vE,KAAK6vE;QAEb,MAAMC,IAAY9vE,KAAK+vE;;gBAEvB/vE,KAAK8vB,UAAUjvB,QAAQyf;YACrBwvD,EAAU7/D,OAAOqQ,EAAS9f,IAAI4C;;;;QAIhC0sE,EAAUjvE,QAAQ,CAACc,GAAG+D;YACpB,MAAMlF,IAAM,IAAIiG,EAAYnB,EAAaoB,EAAWhB;YACpD1F,KAAK8vB,UAAUruB,KAAK,IAAIqgB,GAAethB,GAAKR,KAAKgiB,GAAaxhB;kB7ByB7DmiC,eACL6jB,GACA12B;YAEA,MAAMk3B,IAAgBnpD,EAAU2oD,IAC1B9gD,IAAOmZ,GAAqBmoC,EAAc1pC,cAAc,cACxD4b,IAAU;gBACdosB,QAAQx1B,EAAUpzB,IAAI0zB,KAAK/P,GAAW2mC,EAAc1pC,YAAY8S;;kBAE5D42B,EAAcrB,GAAU,UAAUjgD,GAAMwzB;S6BhCtC82C,CAAgBhwE,KAAKwmD,IAAWxmD,KAAK8vB,YAC3C9vB,KAAKiwE,MAAY;;IAGXtxE,GAAcqR;QACpB,IAAIkgE;QAEJ,IAAIlgE,aAAe+D,IACjBm8D,IAAalgE,EAAI8N,cACZ;YAAA,MAAI9N,aAAeiE,KAIxB,MAvGI1W;;YAqGJ2yE,IAAa/rE,EAAgBkB;;QAK/B,MAAM8qE,IAAkBnwE,KAAK+vE,GAAavuE,IAAIwO,EAAIxP,IAAI4C;QACtD,IAAI+sE;YACF,KAAKD,EAAW5rE,QAAQ6rE;;YAEtB,MAAM,IAAIltE,EACRlB,EAAKY,SACL;eAIJ3C,KAAK+vE,GAAazgE,IAAIU,EAAIxP,IAAI4C,YAAY8sE;;;;;WAQtCvxE,GAAa6B;QACnB,MAAMsd,IAAU9d,KAAK+vE,GAAavuE,IAAIhB,EAAI4C;QAC1C,QAAKpD,KAAK2vE,GAAYrhE,IAAI9N,MAAQsd,IACzBwE,GAAapD,WAAWpB,KAExBwE,GAAaC;;;;WAOhB5jB,GAAsB6B;QAC5B,MAAMsd,IAAU9d,KAAK+vE,GAAavuE,IAAIhB,EAAI4C;;;gBAG1C,KAAKpD,KAAK2vE,GAAYrhE,IAAI9N,MAAQsd,GAAS;YACzC,IAAIA,EAAQxZ,QAAQH,EAAgBkB;;;;;;;;;;YAYlC,MAAM,IAAIpC,EACRlB,EAAKI,kBACL;;wBAIJ,OAAOmgB,GAAapD,WAAWpB;;;;QAI/B,OAAOwE,GAAaH,QAAO;;IAIvBxjB,MAAMmxB;QACZ9vB,KAAKsvE,MACLtvE,KAAK8vB,YAAY9vB,KAAK8vB,UAAUzK,OAAOyK;;IAGjCnxB;;;;;;;;;;;;;;;;;;;;;;;MCzKGyxE;IAIXzxE,YACmB2+B,GACAkpB,GACA6pB,GACA5yC;kBAHAH,aACAkpB,GACAxmD,sBAAAqwE,aACA5yC,GAPnBz9B,UAPkB,GAgBhBA,KAAKs+B,KAAU,IAAI9H,GACjBx2B,KAAKs9B;;oEAMT3+B;QACEqB,KAAKswE;;IAGC3xE;QACNqB,KAAKs+B,GAAQc,GAAcuD;YACzB,MAAMlQ,IAAc,IAAI48C,GAAYrvE,KAAKwmD,KACnC9pB,IAAc18B,KAAKuwE,GAAqB99C;YAC1CiK,KACFA,EACGgB,KAAKlxB;gBACJxM,KAAKs9B,GAAWa,GAAiB,MACxB1L,EACJ+9C,SACA9yC,KAAK;oBACJ19B,KAAKy9B,GAASlM,QAAQ/kB;mBAEvB+tB,MAAMk2C;oBACLzwE,KAAK0wE,GAAuBD;;eAInCl2C,MAAMo2C;gBACL3wE,KAAK0wE,GAAuBC;;;;IAM9BhyE,GAAqB8zB;QAC3B;YACE,MAAMiK,IAAc18B,KAAKqwE,eAAe59C;YACxC,QACE1rB,EAAkB21B,MACjBA,EAAYnC,SACZmC,EAAYgB,OAORhB,KALL18B,KAAKy9B,GAASjM,OACZ9zB,MAAM;YAED;UAGT,OAAOX;;YAGP,OADAiD,KAAKy9B,GAASjM,OAAOz0B,IACd;;;IAIH4B,GAAuB5B;QACzBiD,KAAK4wE,KAAU,KAAK5wE,KAAK6wE,GAA4B9zE,MACvDiD,KAAK4wE,MAAW,GAChB5wE,KAAKs9B,GAAWa,GAAiB,OAC/Bn+B,KAAKswE,MACE7+C,QAAQF,eAGjBvxB,KAAKy9B,GAASjM,OAAOz0B;;IAIjB4B,GAA4B5B;QAClC,IAAmB,oBAAfA,EAAMsG,MAA0B;;;YAGlC,MAAMH,IAAQnG,EAAyBmG;YACvC,OACW,cAATA,KACS,0BAATA,MACC6H,GAAiB7H;;QAGtB,QAAO;;;;;;;;;;;;;;;;;;;;;;;;;MC1CE4tE;IA8BXnyE,YACUwlD;;;;;;;;;IASA7mB;QATAt9B,mBAAAmkD,aASA7mB,GArBOt9B,gBAAWtB,EAAOqyE;;;;;;;QASnC/wE,UAAsC,IAAIs2B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;WAuD1C33B,MACE6/D,GACAwG,GACAP,GACAZ;QAEA7jE,KAAKgxE,MAELhxE,KAAKw+D,KAAeA;;;;;;QAQpB,MAAMyS,IAAoB,IAAI36C;QAE9B,IAAI46C,KAAc;;;;QA2BlB,OA1BAlxE,KAAKmkD,YAAYgtB,GAAkB1pC;YACjC,KAAKypC,GAKH,OAJAA,KAAc,GAEd90E,EAlIQ,mBAkIU,uBAAuBqrC,EAAKC,MAEvC1nC,KAAKoxE,GACVpM,GACAP,GACAZ,GACAp8B,GACAwpC,GACAvzC,KAAK19B,KAAKqxE,GAAmB9/C,SAASvxB,KAAKqxE,GAAmB7/C;YAEhExxB,KAAKs9B,GAAWuY,GAAiB,MAC/B71C,KAAKgzD,GAAYrI,GAAuBljB;;;QAM9CznC,KAAKs9B,GAAWa,GAAiB,MAAMn+B,KAAKqxE,GAAmB96C,UAKxD06C,EAAkB16C;;kFAI3B53B;QAEE,OADAqB,KAAKgxE,MACEhxE,KAAKs9B,GAAWsB,QAAQ,OAC7B5+B,KAAKu6C,YAAY+2B,IAAkB,IAC5BtxE,KAAKgzD,GAAYjL;;;;;;;;;;;;;;;;;;;;;;;WA0BpBppD,SACNqmE,GACAP,GACAZ,GACAp8B,GACAwpC;QAEA;YACE,MAAMM,IAAyB;gBAC7BC,IAAYxxE,KAAKs9B;gBACjBm0C,IAAczxE,KAAKw+D;gBACnBlsB,UAAUtyC,KAAKsyC;gBACf6R,aAAankD,KAAKmkD;gBAClButB,IAAajqC;gBACbkqC,IAvMwC;gBAwMxCC,IAAA/N;;kBAGImB,EAAyBf,WAAWsN,UACpC9M,EAAwBR,WAC5Be,GACAuM,IAGFvxE,KAAKu6C,cAAcyqB,EAAyBzqB;YAC5Cv6C,KAAKizD,KAAoB+R,EAAyB/R,IAClDjzD,KAAKqiC,KAAa2iC,EAAyB3iC,IAC3CriC,KAAK0jE,KAAcsB,EAAyBtB,IAC5C1jE,KAAKwmD,KAAYie,EAAwBje,IACzCxmD,KAAKgzD,KAAcyR,EAAwBzR;YAC3ChzD,KAAK6oD,KAAa4b,EAAwB5b,IAC1C7oD,KAAK6xE,KAAWpN,EAAwBW;;;YAIxCplE,KAAKu6C,YAAYu3B,GAA2BnvC;sBACpC3iC,KAAK+xE;gBAGbd,EAAkB1/C;UAClB,OAAOx0B;;YAMP;;;YAHAk0E,EAAkBz/C,OAAOz0B,KAGpBiD,KAAKgyE,GAAYj1E,IACpB,MAAMA;YAOR,OALAgpE,QAAQ7oE,KACN,+EAEEH;YAEGiD,KAAKoxE,GACV,IAAI9N,IACJ,IAAIyB,IACJ;gBAAEkN,KAAS;eACXxqC,GACAwpC;;;;;;WASEtyE,GAAY5B;QAClB,OAAmB,oBAAfA,EAAMsG,OAENtG,EAAMmG,SAASnB,EAAKW,uBACpB3F,EAAMmG,SAASnB,EAAKc,kBAGE,sBAAjBqvE,gBACPn1E,aAAiBm1E;;;;QAhQc,OA6Q7Bn1E,EAAMmG,QA9QgB,OA+QtBnG,EAAMmG;;;QAhRsB,OAmR5BnG,EAAMmG;;;;;WAWJvE;QACN,IAAIqB,KAAKs9B,GAAW60C,IAClB,MAAM,IAAIlvE,EACRlB,EAAKW,qBACL;;qFAMN/D;QAEE,OADAqB,KAAKgxE,MACEhxE,KAAKs9B,GAAWsB,QAAQ,OAC7B5+B,KAAKu6C,YAAY+2B,IAAkB,IAC5BtxE,KAAKgzD,GAAYof;;IAI5BzzE;QACE,OAAOqB,KAAKs9B,GAAW+0C,GAA2B1vC;;YAE5C3iC,KAAK0jE,MACP1jE,KAAK0jE,GAAYpb,cAGbtoD,KAAKgzD,GAAYpa,YACjB54C,KAAKizD,GAAkBra,YACvB54C,KAAKu6C,YAAY3B;;;;YAKvB54C,KAAKmkD,YAAYmuB;;;;;;;WASrB3zE;QACEqB,KAAKgxE;QAEL,MAAMvzC,IAAW,IAAInH;QAIrB,OAHAt2B,KAAKs9B,GAAWa,GAAiB,MACxBn+B,KAAK6oD,GAAW0pB,GAA8B90C,KAEhDA,EAASlH;;IAGlB53B,OACEkS,GACAsb,GACA8tC;QAEAj6D,KAAKgxE;QACL,MAAMwB,IAAkB,IAAI3M,GAAc5L,IACpC9mC,IAAW,IAAIgnC,GAActpD,GAAO2hE,GAAiBrmD;QAE3D,OADAnsB,KAAKs9B,GAAWa,GAAiB,MAAMn+B,KAAK6xE,GAAS7d,OAAO7gC,KACrD;YACLq/C,EAAgBC,MAChBzyE,KAAKs9B,GAAWa,GAAiB,MAAMn+B,KAAK6xE,GAASnd,GAASvhC;;;IAIlEx0B,SACEoxB;QAIA,OAFA/vB,KAAKgxE,YACChxE,KAAKqxE,GAAmB96C,SAmL3BoM,eACLrF,GACA+E,GACAtS;YAEA,MAAM0N,IAAW,IAAInH;YA2BrB,aA1BMgH,EAAWsB,QAAQ+D;gBACvB;oBACE,MAAM9Z,UAAiBwZ,EAAWqwC,GAAa3iD;oBAC3ClH,aAAoB9U,KACtB0pB,EAASlM,QAAQ1I,KACRA,aAAoB5U,KAC7BwpB,EAASlM,QAAQ,QAEjBkM,EAASjM,OACP,IAAIvuB,EACFlB,EAAKgB,aACL;kBAON,OAAOzF;oBACP,MAAM8tD,IAAiB/qB,GACrB/iC,GACA,2BAA2ByyB;oBAE7B0N,EAASjM,OAAO45B;;gBAGb3tB,EAASlH;;;;;GAlNPo8C,EACL3yE,KAAKs9B,IACLt9B,KAAKqiC,IACLtS;;IAIJpxB,SACE6B,GACA2rB;QAIA,OAFAnsB,KAAKgxE,YACChxE,KAAKqxE,GAAmB96C,kBA8MhC+G,GACA8nC,GACA5kE,GACA2rB;YAEA,MAAM3f,IAAS,IAAI8pB,IACbo+B,IAAWke,GACft1C,GACA8nC,GACAx4C,GAAgBpsB,EAAIkF,OACpB;gBACE40D,yBAAwB;gBACxBuY,KAAuB;eAEzB;gBACErsE,MAAO6zD;;;oBAGL3F;oBAEA,MAAMvyC,IAASk4C,EAAKvpD,KAAKxC,IAAI9N;qBACxB2hB,KAAUk4C,EAAKnpD;;;;;;;;oBAQlB1E,EAAOglB,OACL,IAAIvuB,EACFlB,EAAKgB,aACL,4DAIJof,KACAk4C,EAAKnpD,aACLib,KACmB,aAAnBA,EAAQgpC,SAER3oD,EAAOglB,OACL,IAAIvuB,EACFlB,EAAKgB,aACL,gLAWJyJ,EAAO+kB,QAAQ8oC;;gBAGnBt9D,OAAOO,KAAKkP,EAAOglB,OAAOl0B;;YAG9B,OAAOkP,EAAO+pB;SA1QLu8C,CACL9yE,KAAKs9B,IACLt9B,KAAK6xE,IACLrxE,GACA2rB;;IAIJxtB,SAAiCkS;QAG/B,OAFA7Q,KAAKgxE,YACChxE,KAAKqxE,GAAmB96C,SAmQ3BoM,eACLrF,GACA+E,GACAxxB;YAEA,MAAM4sB,IAAW,IAAInH;YAsBrB,aArBMgH,EAAWsB,QAAQ+D;gBACvB;oBACE,MAAM8vB,UAAoBpwB,EAAW4xB,GACnCpjD;+CAC0B,IAEtBgiD,IAAO,IAAI3C,GAAKr/C,GAAO4hD,EAAYjU,KACnC0V,IAAiBrB,EAAKH,GAAkBD,EAAYphD,YACpDssC,IAAakV,EAAK7/B,GACtBkhC;iDAC4B;oBAE9Bz2B,EAASlM,QAAQosB,EAAoB;kBACrC,OAAOrgD;oBACP,MAAM8tD,IAAiB/qB,GACrB/iC,GACA,4BAA4BuT;oBAE9B4sB,EAASjM,OAAO45B;;gBAGb3tB,EAASlH;;;;;GA7RPw8C,EACL/yE,KAAKs9B,IACLt9B,KAAKqiC,IACLxxB;;IAIJlS,SACEkS,GACAsb;QAIA,OAFAnsB,KAAKgxE,YACChxE,KAAKqxE,GAAmB96C,kBAyRhC+G,GACA8nC,GACAv0D,GACAsb;YAEA,MAAM3f,IAAS,IAAI8pB,IACbo+B,IAAWke,GACft1C,GACA8nC,GACAv0D,GACA;gBACEypD,yBAAwB;gBACxBuY,KAAuB;eAEzB;gBACErsE,MAAM89C;;;oBAGJoQ,KAEIpQ,EAASpzC,aAAaib,KAA8B,aAAnBA,EAAQgpC,SAC3C3oD,EAAOglB,OACL,IAAIvuB,EACFlB,EAAKgB,aACL,mLAOJyJ,EAAO+kB,QAAQ+yB;;gBAGnBvnD,OAAOO,KAAKkP,EAAOglB,OAAOl0B;;YAG9B,OAAOkP,EAAO+pB;;;;;;;;;;;;;;;;;;;;;GA7TLy8C,EACLhzE,KAAKs9B,IACLt9B,KAAK6xE,IACLhhE,GACAsb;;IAIJxtB,MAAMmxB;QACJ9vB,KAAKgxE;QACL,MAAMvzC,IAAW,IAAInH;QAIrB,OAHAt2B,KAAKs9B,GAAWa,GAAiB,MAC/Bn+B,KAAK6oD,GAAW4mB,MAAM3/C,GAAW2N,KAE5BA,EAASlH;;IAGlB53B;QACE,OAAOqB,KAAKw+D,GAAa7+D;;IAG3BhB,GAA2Bs7D;QACzBj6D,KAAKgxE;QACL,MAAMwB,IAAkB,IAAI3M,GAAc5L;QAI1C,OAHAj6D,KAAKs9B,GAAWa,GAAiBwE,YAC/B3iC,KAAK6xE,GAASoB,GAA2BT,KAEpC;YACLA,EAAgBC,MAChBzyE,KAAKs9B,GAAWa,GAAiBwE,YAC/B3iC,KAAK6xE,GAASqB,GAA8BV;;;IAKlDW;;;;QAIE,OAAOnzE,KAAKs9B,GAAW60C;;;;;;;;;;;;;;;;WAkBzBxzE,YACE0xE;QAEArwE,KAAKgxE;QACL,MAAMvzC,IAAW,IAAInH;QAUrB,OATAt2B,KAAKs9B,GAAWa,GAAiB,OAC/B,IAAIiyC,GACFpwE,KAAKs9B,IACLt9B,KAAKwmD,IACL6pB,GACA5yC,GACA21C,OACK3hD,QAAQF;QAEVkM,EAASlH;;;;SAqCJq8C,GACdt1C,GACA+1C,GACAxiE,GACAsb,GACA8tC;IAEA,MAAMuY,IAAkB,IAAI3M,GAAc5L,IACpC9mC,IAAW,IAAIgnC,GAActpD,GAAO2hE,GAAiBrmD;IAE3D,OADAmR,EAAWa,GAAiB,MAAMk1C,EAAYrf,OAAO7gC,KAC9C;QACLq/C,EAAgBC,MAChBn1C,EAAWa,GAAiB,MAAMk1C,EAAY3e,GAASvhC;;;;MC5gB9CmgD;IACX30E,YACmBgB,GACA4zE,GACAC,GACAC;iBAHA9zE,GACAK,6BAAAuzE,aACAC,aACAC;;IAKnB90E,GAAaxB;QACX,QAAQga,GAAUha;UAChB;YACE,OAAO;;UACT;YACE,OAAOA,EAAMka;;UACf;YACE,OAAOQ,GAAgB1a,EAAM+a,gBAAgB/a,EAAMgc;;UACrD;YACE,OAAOnZ,KAAK0zE,GAAiBv2E,EAAqB;;UACpD;YACE,OAAO6C,KAAK2zE,GAAuBx2E;;UACrC;YACE,OAAOA,EAAMyZ;;UACf;YACE,OAAO,IAAIkyD,GAAKpxD,GAAoBva,EAAiB;;UACvD;YACE,OAAO6C,KAAK4zE,GAAiBz2E,EAAqB;;UACpD;YACE,OAAO6C,KAAK6zE,GAAgB12E,EAAoB;;UAClD;YACE,OAAO6C,KAAK8zE,GAAa32E,EAAiB;;UAC5C;YACE,OAAO6C,KAAK+zE,GAAc52E,EAAe;;UAC3C;YACE,MA3DRI;;;IA+DUoB,GAAc+X;QACpB,MAAMlK,IAAiC;QAIvC,OAHA3L,EAAQ6V,EAASC,UAAU,IAAI,CAACnW,GAAKrD;YACnCqP,EAAOhM,KAAOR,KAAKg0E,GAAa72E;YAE3BqP;;IAGD7N,GAAgBxB;QACtB,OAAO,IAAIsuE,GACT5zD,GAAgB1a,EAAM4a,WACtBF,GAAgB1a,EAAM6a;;IAIlBrZ,GAAa4Z;QACnB,QAAQA,EAAWC,UAAU,IAAI9b,IAAIS,KAAS6C,KAAKg0E,GAAa72E;;IAG1DwB,GAAuBxB;QAC7B,QAAQ6C,KAAKwzE;UACX,KAAK;YACH,MAAMtsD,apE1BE+sD,EAAiB92E;gBAC/B,MAAM+pB,IAAgB/pB,EAAMuZ,SAAUC,OAA0B;gBAEhE,OAAIF,GAAkByQ,KACb+sD,EAAiB/sD,KAEnBA;aoEoBqB+sD,CAAiB92E;YACvC,OAAqB,QAAjB+pB,IACK,OAEFlnB,KAAKg0E,GAAa9sD;;UAC3B,KAAK;YACH,OAAOlnB,KAAK0zE,GAAiB78D,GAAkB1Z;;UACjD;YACE,OAAO;;;IAILwB,GAAiBxB;QACvB,MAAM+2E,IAAkBn9D,GAAmB5Z,IACrCiH,IAAY,IAAId,EACpB4wE,EAAgB3wE,SAChB2wE,EAAgBl9D;QAElB,OAAIhX,KAAKuzE,wBACAnvE,IAEAA,EAAU+vE;;IAIbx1E,GACN0E;QAEA,MAAM+wE,IAAe9uE,EAAaoB,EAAWrD;QA3FrC1F,EA6FN2gB,GAAoB81D;QAGtB,MAAMz0E,IAAa,IAAIM,EAAWm0E,EAAa5yE,IAAI,IAAI4yE,EAAa5yE,IAAI,KAClEhB,IAAM,IAAIiG,EAAY2tE,EAAaztE,EAAS;QAclD,OAZKhH,EAAW2E,QAAQtE,KAAKL;;QAE3B9C,EACE,YAAY2D,gEAEPb,EAAWO,aAAaP,EAAWQ,gGAEzBH,KAAKL,EAAWO,aAAaF,KAAKL,EAAWQ;QAKzDH,KAAKyzE,GAAiBjzE;;;;;;;;;;;;;;;;;;;;uBC5CjC;MAWa6zE,KAAuB5yC,GAAUQ;;;;;;;AAyB9C,MAAMqyC;IAmBJ31E,YAAY0rE;;QACV,SAAsB/oE,MAAlB+oE,EAASxqE,MAAoB;YAC/B,SAAqByB,MAAjB+oE,EAASvqE,KACX,MAAM,IAAImD,EACRlB,EAAKI,kBACL;YAGJnC,KAAKH,OA/DU,4BAgEfG,KAAKF,OA/DS;eAiEdknE,GAAkB,YAAY,oBAAoB,QAAQqD,EAASxqE,OACnEG,KAAKH,OAAOwqE,EAASxqE,MAErBqnE,GAA0B,YAAY,WAAW,OAAOmD,EAASvqE;QACjEE,KAAKF,oBAAMuqE,EAASvqE;QA0DtB,IAxDA0oE,GAAoB,YAAY6B,GAAU,EACxC,QACA,OACA,eACA,yBACA,kBACA,gCACA;QAGFnD,GACE,YACA,UACA,eACAmD,EAASlmB,cAEXnkD,KAAKmkD,cAAckmB,EAASlmB;QAE5B+iB,GACE,YACA,WACA,yBACAmD,EAASkJ,wBAGXrM,GACE,YACA,WACA,6BACAmD,EAASI;;;SAK4B,MAAnCJ,EAASkJ,wBACX12E,EACE,6FAG0C,MAAnCwtE,EAASkJ,yBAClB12E,EACE;QAIJmD,KAAKuzE,sCACHlJ,EAASkJ;QACXvzE,KAAKyqE,0CACHJ,EAASI;QAEXvD,GACE,YACA,UACA,kBACAmD,EAAS/F,sBAEqBhjE,MAA5B+oE,EAAS/F,gBACXtkE,KAAKskE,iBAAiB7iC,GAAUO,SAC3B;YACL,IACEqoC,EAAS/F,mBAAmB+P,MAC5BhK,EAAS/F,iBAAiB7iC,GAAU8yC,IAEpC,MAAM,IAAItxE,EACRlB,EAAKI,kBACL,qCAAmCs/B,GAAU8yC;YAG/Cv0E,KAAKskE,iBAAiB+F,EAAS/F;;QAInC4C,GACE,YACA,WACA,gCACAmD,EAASmK;QAEXx0E,KAAKD,iCACHsqE,EAASmK;;IAGb71E,QAAQ0B;QACN,OACEL,KAAKH,SAASQ,EAAMR,QACpBG,KAAKF,QAAQO,EAAMP,OACnBE,KAAKuzE,0BAA0BlzE,EAAMkzE,yBACrCvzE,KAAKmkD,gBAAgB9jD,EAAM8jD,eAC3BnkD,KAAKskE,mBAAmBjkE,EAAMikE,kBAC9BtkE,KAAKD,qBAAqBM,EAAMN,oBAChCC,KAAKyqE,8BAA8BpqE,EAAMoqE;;;;;;UAQlCgK;;;;IA2BX91E,YACE+1E,GACAj0B,GACQk0B,IAAsD,IAAIrR,IAC1DsR,IAA2B,IAAI7P;QAEvC,cAHQ4P,aACAC,GAxBV50E,UAAoD;;;QAapDA,UAAkB,IAAIo+B,IA8QtBp+B,gBAAW;YACTiQ,QAAQ0yB;;;gBAGN3iC,KAAK60E,YACC70E,KAAK80E,GAAkB/C;;WAtQyB,mBAA5C2C,EAAgCvoD,SAAsB;;;YAGhE,MAAM4oD,IAAML;YACZ10E,KAAKg1E,KAAeD,GACpB/0E,KAAK+rE,KAAc0I,GAAUQ,GAAkBF,IAC/C/0E,KAAKk1E,KAAkBH,EAAI1xE,MAC3BrD,KAAKm1E,KAAe,IAAI30B,GAA4BC;eAC/C;YACL,MAAM20B,IAAWV;YACjB,KAAKU,EAASl1E,WACZ,MAAM,IAAI+C,EACRlB,EAAKI,kBACL;YAIJnC,KAAK+rE,KAAc,IAAI9rE,EAAWm1E,EAASl1E,WAAWk1E,EAASj1E;;YAE/DH,KAAKk1E,KAAkB,aACvBl1E,KAAKm1E,KAAe,IAAI70B;;QAG1BtgD,KAAKq1E,KAAY,IAAIf,GAAkB;;IAGzCgB;QAYE,OAPKt1E,KAAKu1E;;QAERv1E,KAAKu1E,KAAkB,IAAI5I,GACzB3sE,KAAK+rE,IACL/rE,KAAKq1E,GAAU5K,6BAGZzqE,KAAKu1E;;IAGd52E,SAAS62E;QACPnP,GAA0B,sBAAsB4C,WAAW,IAC3DtC,GAAgB,sBAAsB,UAAU,GAAG6O;QAEnD,MAAMC,IAAc,IAAInB,GAAkBkB;QAC1C,IAAIx1E,KAAK80E,OAAqB90E,KAAKq1E,GAAU/wE,QAAQmxE,IACnD,MAAM,IAAIxyE,EACRlB,EAAKW,qBACL;QAMJ1C,KAAKq1E,KAAYI,QACen0E,MAA5Bm0E,EAAYtxB,gBACdnkD,KAAKm1E,cnC9BThxB;YAEA,KAAKA,GACH,OAAO,IAAI7D;YAGb,QAAQ6D,EAAYzzC;cAClB,KAAK;gBACH,MAAMkmC,IAASuN,EAAYvN;;gCAW3B,OATAj5C,IAEsB,mBAAXi5C,KACI,SAAXA,MACAA,EAAa,SACbA,EAAa,KAAmC;gBAI7C,IAAIwL,GACTxL,GACAuN,EAAYtC,MAAgB;;cAGhC,KAAK;gBACH,OAAOsC,EAAYvN;;cAErB;gBACE,MAAM,IAAI3zC,EACRlB,EAAKI,kBACL;;;;;;;;;;;;;;;;;;GmCAkBuzE,EAAwBD,EAAYtxB;;IAI5DxlD;QAEE,OADAqB,KAAK60E,MACE70E,KAAK80E,GAAkB/sB;;IAGhCppD;QAEE,OADAqB,KAAK60E,MACE70E,KAAK80E,GAAkB1C;;IAGhCzzE,kBAAkB0rE;;QAChB,IAAIrqE,KAAK80E,IACP,MAAM,IAAI7xE,EACRlB,EAAKW,qBACL;QAMJ,IAAI0hE,KAAkB,GAClBuR,KAA6B;QAEjC,IAAItL,WAC8C/oE,MAA5C+oE,EAASuL,kCACX/4E,EACE;QAGJunE,gCACEiG,EAASjG,uCACTiG,EAASuL;QAGXD,MAA6BtL,EAASsL,8BAClCtL,EAASsL,4BAGTvR,KAAmBuR,IACrB,MAAM,IAAI1yE,EACRlB,EAAKI,kBACL;QAKN,OAAOnC,KAAK61E,GACV71E,KAAK20E,IACL30E,KAAK40E,IACL;YACE3C,KAAS;YACT3N,gBAAgBtkE,KAAKq1E,GAAU/Q;YAC/BF,iBAAAA;YACA0R,IAAgBH;;;IAKtBh3E;QACE,SAC4B2C,MAA1BtB,KAAK80E,OACJ90E,KAAK80E,GAAiBiB,IAEvB,MAAM,IAAI9yE,EACRlB,EAAKW,qBACL;QAKJ,MAAM+6B,IAAW,IAAInH;QAYrB,OAXAt2B,KAAKg2E,GAAOC,GAAkCtzC;YAC5C;sBACQ3iC,KAAK20E,GAA0BuB,iBACnCl2E,KAAK+rE,IACL/rE,KAAKk1E,KAEPz3C,EAASlM;cACT,OAAOj0B;gBACPmgC,EAASjM,OAAOl0B;;YAGbmgC,EAASlH;;IAGlB53B;QAEE,OADCqB,KAAK+0E,IAAqBoB,uBAAuB,cAC3Cn2E,KAAK8C,SAASmN;;IAGvBmmE;QAEE,OADAp2E,KAAK60E,MACE70E,KAAK80E,GAAkBiB;;IAGhCp3E;QAEE,OADAqB,KAAK60E,MACE70E,KAAK80E,GAAkBuB;;IAKhC13E,kBAAkB23E;QAGhB,IAFAt2E,KAAK60E,MAEDrP,GAAkB8Q,IACpB,OAAOt2E,KAAK80E,GAAkB7B,GAC5BqD;QAEG;YACL3P,GAAgB,+BAA+B,YAAY,GAAG2P;YAC9D,MAAMrc,IAAkC;gBACtCzzD,MAAM8vE;;YAER,OAAOt2E,KAAK80E,GAAkB7B,GAA2BhZ;;;IAI7Dt7D;QAYE,OAXKqB,KAAK80E;;;QAGR90E,KAAK61E,GACH,IAAIvS,IACJ,IAAIyB,IACJ;YACEkN,KAAS;YAIRjyE,KAAK80E;;IAGNn2E;QACN,OAAO,IAAIe,EACTM,KAAK+rE,IACL/rE,KAAKk1E,IACLl1E,KAAKq1E,GAAUx1E,MACfG,KAAKq1E,GAAUv1E,KACfE,KAAKq1E,GAAUt1E;;IAIXpB,GACNqmE,GACAP,GACAZ;QASA,MAAMrF,IAAex+D,KAAKu2E;QAI1B,OAFAv2E,KAAK80E,KAAmB,IAAIhE,GAAgB9wE,KAAKm1E,IAAcn1E,KAAKg2E,KAE7Dh2E,KAAK80E,GAAiB3mE,MAC3BqwD,GACAwG,GACAP,GACAZ;;IAIIllE,UAAyBo2E;QAC/B,IAs+Dcz4E,IAt+DAy4E,EAAI5oD,SAs+DS3rB,IAt+DA,cAu+DtBC,OAAOC,UAAUC,eAAeC,KAAKtE,GAAKkE,IAt+D7C,MAAM,IAAIyC,EACRlB,EAAKI,kBACL;QAm+DR,IAAkB7F,GAAakE;;;;;;;;;;;;;;;;WA/9D3B,MAAMN,IAAY60E,EAAI5oD,QAAQjsB;QAC9B,KAAKA,KAAkC,mBAAdA,GACvB,MAAM,IAAI+C,EACRlB,EAAKI,kBACL;QAGJ,OAAO,IAAIlC,EAAWC;;IAGxB60E;QACE,KAAK/0E,KAAKg1E,IACR,MAAM,IAAI/xE,EACRlB,EAAKW,qBACL;QAIJ,OAAO1C,KAAKg1E;;IAYdr2E,WAAW63E;QAIT,OAHAnQ,GAA0B,wBAAwB4C,WAAW,IAC7DtC,GAAgB,wBAAwB,oBAAoB,GAAG6P;QAC/Dx2E,KAAK60E,MACE,IAAI4B,GACTnxE,EAAaoB,EAAW8vE,IACxBx2E;yBACiB;;IAIrBrB,IAAI63E;QAIF,OAHAnQ,GAA0B,iBAAiB4C,WAAW,IACtDtC,GAAgB,iBAAiB,oBAAoB,GAAG6P;QACxDx2E,KAAK60E,MACE6B,GAAkBC,GACvBrxE,EAAaoB,EAAW8vE,IACxBx2E;yBACiB;;IAIrBrB,gBAAgBiI;QAQd,IAPAy/D,GAA0B,6BAA6B4C,WAAW,IAClEtC,GACE,6BACA,oBACA,GACA//D;QAEEA,EAAajB,QAAQ,QAAQ,GAC/B,MAAM,IAAI1C,EACRlB,EAAKI,kBACL,0BAA0ByE;QAK9B,OADA5G,KAAK60E,MACE,IAAI+B,YlF1Y4BhwE;YACzC,OAAO,IAAI0lB,GAAUhnB,EAAasZ,KAAahY;SkF0Y3CiwE,CAA2BjwE,IAC3B5G;yBACiB;;IAIrBrB,eACE0xE;QAIA,OAFAhK,GAA0B,4BAA4B4C,WAAW,IACjEtC,GAAgB,4BAA4B,YAAY,GAAG0J;QACpDrwE,KAAK60E,KAAyBpiD,YAClCA,KACQ49C,EAAe,IAAIhB,GAAYrvE,MAAMyyB;;IAKlD9zB;QAGE,OAFAqB,KAAK60E,MAEE,IAAIiC,GAAW92E;;IAGxB7D;QACE,QAAQD;UACN,KAAKK,EAASC;YACZ,OAAO;;UACT,KAAKD,EAASO;YACZ,OAAO;;UACT,KAAKP,EAASw6E;YACZ,OAAO;;UACT,KAAKx6E,EAASU;YACZ,OAAO;;UACT,KAAKV,EAASy6E;YACZ,OAAO;;UACT,KAAKz6E,EAAS06E;YACZ,OAAO;;UACT;;YAEE,OAAO;;;IAIbt4E,mBAAmBu4E;YjG7nBOC;QiG8nBxB9Q,GAA0B,yBAAyB4C,WAAW,IAC9DlB,GACE,eACA,EAAC,SAAS,SAAS,UAAU,QAAQ,QAAQ,aAC7C,GACAmP;QjGnoBsBC,IiGqoBZD,GjGpoBdl7E,EAAUo7E,YAAYD;;;;IiGyoBtBx4E;QACE,OAAOqB,KAAKq1E,GAAU9B;;;;;;UAOblE;IACX1wE,YACU04E,GACAC;kBADAD,aACAC;;IAGV34E,IACE44E;QAEAlR,GAA0B,mBAAmB4C,WAAW;QACxD,MAAMzpB,IAAMg4B,GACV,mBACAD,GACAv3E,KAAKq3E;QAEP,OAAOr3E,KAAKs3E,GACTG,GAAO,EAACj4B,EAAIwsB,MACZtuC,KAAM5sB;YACL,KAAKA,KAAwB,MAAhBA,EAAKhS,QAChB,OA3qBkBvB;YA6qBpB,MAAMyS,IAAMc,EAAK;YACjB,IAAId,aAAeiE,IACjB,OAAO,IAAIyjE,GACT13E,KAAKq3E,IACL73B,EAAIwsB,IACJ;8BACiB;qCACO,GACxBxsB,EAAIysB;YAED,IAAIj8D,aAAe+D,IACxB,OAAO,IAAI2jE,GACT13E,KAAKq3E,IACL73B,EAAIwsB,IACJh8D;8BACiB;qCACO,GACxBwvC,EAAIysB;YAGN,MAjsBkB1uE;;;IA8sB1BoB,IACE44E,GACAp6E,GACAgvB;QAEAs6C,GAA4B,mBAAmBwC,WAAW,GAAG;QAC7D,MAAMzpB,IAAMg4B,GACV,mBACAD,GACAv3E,KAAKq3E;QAEPlrD,IAAUwrD,GAAmB,mBAAmBxrD;QAChD,MAAMyrD,IAAiBC,GACrBr4B,EAAIysB,IACJ9uE,GACAgvB,IAEIyiC,IAASie,GACb7sE,KAAKq3E,GAAWS,IAChB,mBACAt4B,EAAIwsB,IACJ4L,GACmB,SAAnBp4B,EAAIysB,IACJ9/C;QAGF,OADAnsB,KAAKs3E,GAAahoE,IAAIkwC,EAAIwsB,IAAMpd,IACzB5uD;;IAaTrB,OACE44E,GACAQ,GACA56E,MACG8wE;QAEH,IAAIzuB,GACAoP;QAoCJ,OAjC+B,mBAAtBmpB,KACPA,aAA6BC,MAE7BzR,GAA4B,sBAAsB0C,WAAW;QAC7DzpB,IAAMg4B,GACJ,sBACAD,GACAv3E,KAAKq3E,KAEPzoB,IAASof,GACPhuE,KAAKq3E,GAAWS,IAChB,sBACAt4B,EAAIwsB,IACJ+L,GACA56E,GACA8wE,OAGF5H,GAA0B,sBAAsB4C,WAAW;QAC3DzpB,IAAMg4B,GACJ,sBACAD,GACAv3E,KAAKq3E,KAEPzoB,IAAS8e,GACP1tE,KAAKq3E,GAAWS,IAChB,sBACAt4B,EAAIwsB,IACJ+L;QAIJ/3E,KAAKs3E,GAAa92D,OAAOg/B,EAAIwsB,IAAMpd,IAC5B5uD;;IAGTrB,OAAO44E;QACLlR,GAA0B,sBAAsB4C,WAAW;QAC3D,MAAMzpB,IAAMg4B,GACV,sBACAD,GACAv3E,KAAKq3E;QAGP,OADAr3E,KAAKs3E,GAAarnE,OAAOuvC,EAAIwsB,KACtBhsE;;;;MAIE82E;IAIXn4E,YAAoB04E;kBAAAA,GAHpBr3E,UAAqB,IACrBA,WAAqB;;IAUrBrB,IACE44E,GACAp6E,GACAgvB;QAEAs6C,GAA4B,kBAAkBwC,WAAW,GAAG,IAC5DjpE,KAAKi4E;QACL,MAAMz4B,IAAMg4B,GACV,kBACAD,GACAv3E,KAAKq3E;QAEPlrD,IAAUwrD,GAAmB,kBAAkBxrD;QAC/C,MAAMyrD,IAAiBC,GACrBr4B,EAAIysB,IACJ9uE,GACAgvB,IAEIyiC,IAASie,GACb7sE,KAAKq3E,GAAWS,IAChB,kBACAt4B,EAAIwsB,IACJ4L,GACmB,SAAnBp4B,EAAIysB,IACJ9/C;QAKF,OAHAnsB,KAAKk4E,KAAal4E,KAAKk4E,GAAW7yD,OAChCupC,EAAO8gB,GAAYlwB,EAAIwsB,IAAM1pD,GAAaC,QAErCviB;;IAaTrB,OACE44E,GACAQ,GACA56E,MACG8wE;QAIH,IAAIzuB,GACAoP;QAsCJ,OAzCA5uD,KAAKi4E,MAM0B,mBAAtBF,KACPA,aAA6BC,MAE7BzR,GAA4B,qBAAqB0C,WAAW;QAC5DzpB,IAAMg4B,GACJ,qBACAD,GACAv3E,KAAKq3E,KAEPzoB,IAASof,GACPhuE,KAAKq3E,GAAWS,IAChB,qBACAt4B,EAAIwsB,IACJ+L,GACA56E,GACA8wE,OAGF5H,GAA0B,qBAAqB4C,WAAW;QAC1DzpB,IAAMg4B,GACJ,qBACAD,GACAv3E,KAAKq3E,KAEPzoB,IAAS8e,GACP1tE,KAAKq3E,GAAWS,IAChB,qBACAt4B,EAAIwsB,IACJ+L;QAIJ/3E,KAAKk4E,KAAal4E,KAAKk4E,GAAW7yD,OAChCupC,EAAO8gB,GAAYlwB,EAAIwsB,IAAM1pD,GAAaH,QAAO,MAE5CniB;;IAGTrB,OAAO44E;QACLlR,GAA0B,qBAAqB4C,WAAW,IAC1DjpE,KAAKi4E;QACL,MAAMz4B,IAAMg4B,GACV,qBACAD,GACAv3E,KAAKq3E;QAKP,OAHAr3E,KAAKk4E,KAAal4E,KAAKk4E,GAAW7yD,OAChC,IAAI5E,GAAe++B,EAAIwsB,IAAM1pD,GAAaC,QAErCviB;;IAGTrB;QAGE,OAFAqB,KAAKi4E,MACLj4E,KAAKm4E,MAAa,GACdn4E,KAAKk4E,GAAWp5E,SAAS,IACpBkB,KAAKq3E,GAAWxC,KAAyBpF,MAAMzvE,KAAKk4E,MAGtDzmD,QAAQF;;IAGT5yB;QACN,IAAIqB,KAAKm4E,IACP,MAAM,IAAIl1E,EACRlB,EAAKW,qBACL;;;;;;UAUKg0E,WACH5K;IAIRntE,YACSqtE,GACEoM,GACAnM;QAET9oE,MAAMi1E,EAAUrM,IAAaC,GAAMC,cAJ5BD,GACEhsE,iBAAAo4E,aACAnM,GAGTjsE,KAAK80E,KAAmB90E,KAAKo4E,UAAUvD;;IAGzCl2E,UACE+G,GACA0yE,GACAC;QAEA,IAAI3yE,EAAK5G,SAAS,KAAM,GACtB,MAAM,IAAImE,EACRlB,EAAKI,kBAGH,6FAAGuD,EAAKD,WAAyBC,EAAK5G;QAG5C,OAAO,IAAI43E,GAAkB,IAAIjwE,EAAYf,IAAO0yE,GAAWC;;IAGjEl3E;QACE,OAAOnB,KAAKgsE,GAAKtmE,KAAKme;;IAGxBJ;QACE,OAAO,IAAIgzD,GACTz2E,KAAKgsE,GAAKtmE,KAAKke,KACf5jB,KAAKo4E,WACLp4E,KAAKisE;;IAITvmE;QACE,OAAO1F,KAAKgsE,GAAKtmE,KAAKD;;IAGxB9G,WACE63E;QASA,IAPAnQ,GAA0B,gCAAgC4C,WAAW,IACrEtC,GACE,gCACA,oBACA,GACA6P;SAEGA,GACH,MAAM,IAAIvzE,EACRlB,EAAKI,kBACL;QAGJ,MAAMuD,IAAOJ,EAAaoB,EAAW8vE;QACrC,OAAO,IAAIC,GACTz2E,KAAKgsE,GAAKtmE,KAAKyY,MAAMzY,IACrB1F,KAAKo4E;yBACY;;IAIrBz5E,QAAQ0B;QACN,MAAMA,aAAiBq2E,KACrB,MAAMhO,GAAkB,WAAW,qBAAqB,GAAGroE;QAE7D,OACEL,KAAKo4E,cAAc/3E,EAAM+3E,aACzBp4E,KAAKgsE,GAAK1nE,QAAQjE,EAAM2rE,OACxBhsE,KAAKisE,OAAe5rE,EAAM4rE;;IAM9BttE,IAAIxB,GAAuBgvB;QACzBs6C,GAA4B,yBAAyBwC,WAAW,GAAG,IACnE98C,IAAUwrD,GAAmB,yBAAyBxrD;QACtD,MAAMyrD,IAAiBC,GACrB73E,KAAKisE,IACL9uE,GACAgvB,IAEIyiC,IAASie,GACb7sE,KAAKo4E,UAAUN,IACf,yBACA93E,KAAKgsE,IACL4L,GACoB,SAApB53E,KAAKisE,IACL9/C;QAEF,OAAOnsB,KAAK80E,GAAiBrF,MAC3B7gB,EAAO8gB,GAAY1vE,KAAKgsE,IAAM1pD,GAAaC;;IAU/C5jB,OACEo5E,GACA56E,MACG8wE;QAEH,IAAIrf;QAyBJ,OAtB+B,mBAAtBmpB,KACPA,aAA6BC,MAE7BzR,GAA4B,4BAA4B0C,WAAW;QACnEra,IAASof,GACPhuE,KAAKo4E,UAAUN,IACf,4BACA93E,KAAKgsE,IACL+L,GACA56E,GACA8wE,OAGF5H,GAA0B,4BAA4B4C,WAAW;QACjEra,IAAS8e,GACP1tE,KAAKo4E,UAAUN,IACf,4BACA93E,KAAKgsE,IACL+L,KAIG/3E,KAAK80E,GAAiBrF,MAC3B7gB,EAAO8gB,GAAY1vE,KAAKgsE,IAAM1pD,GAAaH,QAAO;;IAItDxjB;QAEE,OADA0nE,GAA0B,4BAA4B4C,WAAW,IAC1DjpE,KAAK80E,GAAiBrF,MAAM,EACjC,IAAIhvD,GAAezgB,KAAKgsE,IAAM1pD,GAAaC;;IAuB/C5jB,cAAclC;;QACZgqE,GACE,gCACAwC,WACA,GACA;QAEF,IAAI98C,IAAyB;YAC3BmuC,yBAAwB;WAEtBge,IAAU;QAEa,mBAAlB77E,EAAK67E,MACX9S,GAAkB/oE,EAAK67E,QAExBnsD,IAAU1vB,EAAK67E,IACf9P,GAAoB,gCAAgCr8C,GAAS,EAC3D;QAEF+6C,GACE,gCACA,WACA,0BACA/6C,EAAQmuC;QAEVge;QAGF,MAAMC,IAAkB;YACtBje,wBAAwBnuC,EAAQmuC;;QAGlC,IAAIkL,GAAkB/oE,EAAK67E,KAAW;YACpC,MAAME,IAAe/7E,EAAK67E;YAG1B77E,EAAK67E,mBAAWE,EAAahyE,mCAAMm3B,KAAK66C,IACxC/7E,EAAK67E,IAAU,mBAAKE,EAAaz7E,oCAAO4gC,KAAK66C;YAC7C/7E,EAAK67E,IAAU,mBAAKE,EAAaC,uCAAU96C,KAAK66C;eAEhD7R,GACE,gCACA,YACA2R,GACA77E,EAAK67E,KAEPvR,GACE,gCACA,YACAuR,IAAU,GACV77E,EAAK67E,IAAU;QAEjBvR,GACE,gCACA,YACAuR,IAAU,GACV77E,EAAK67E,IAAU;QAInB,MAAMre,IAA0C;YAC9CzzD,MAAM89C;gBACA7nD,EAAK67E,MACN77E,EAAK67E,GACJt4E,KAAK04E,GAAsBp0B;;YAIjCvnD,OAAON,EAAK67E,IAAU;YACtBG,UAAUh8E,EAAK67E,IAAU;;QAG3B,OAAOt4E,KAAK80E,GAAiB9gB,OAC3BpnC,GAAgB5sB,KAAKgsE,GAAKtmE,OAC1B6yE,GACAte;;IAIJt7D,IAAIwtB;QACFs6C,GAA4B,yBAAyBwC,WAAW,GAAG,IACnE0P,GAAmB,yBAAyBxsD;QAE5C,MAAMysD,IAAkB54E,KAAKo4E,UAAUvD;QACvC,OAAI1oD,KAA8B,YAAnBA,EAAQgpC,SACdyjB,EACJC,GAA0B74E,KAAKgsE,IAC/BtuC,KACC1tB,KACE,IAAI0nE,GACF13E,KAAKo4E,WACLp4E,KAAKgsE,IACLh8D;wBACe,GACfA,aAAe+D,MAAW/D,EAAIoc,IAC9BpsB,KAAKisE,OAIN2M,EACJE,GAA+B94E,KAAKgsE,IAAM7/C,GAC1CuR,KAAK4mB,KAAYtkD,KAAK04E,GAAsBp0B;;IAInD3lD,cACE05E;QAEA,OAAO,IAAI3B,GAAqB12E,KAAKgsE,IAAMhsE,KAAKo4E,WAAWC;;;;;WAOrD15E,GAAsB2lD;QAK5B,MAAMt0C,IAAMs0C,EAASxzC,KAAKtP,IAAIxB,KAAKgsE;QAEnC,OAAO,IAAI0L,GACT13E,KAAKo4E,WACLp4E,KAAKgsE,IACLh8D,GACAs0C,EAASpzC,WACTozC,EAAS/yC,kBACTvR,KAAKisE;;;;MAKE8M;IACXp6E,YACW4S,GACAL;QADAlR,wBAAAuR,GACAvR,iBAAAkR;;IAGXvS,QAAQ0B;QACN,OACEL,KAAKuR,qBAAqBlR,EAAMkR,oBAChCvR,KAAKkR,cAAc7Q,EAAM6Q;;;;MAWlBwmE;IAEX/4E,YACU04E,GACArL,GACDgN,GACCC,GACAC,GACSjN;kBALToL,aACArL,aACDgN,aACCC,aACAC,aACSjN;;IAGnBttE,KAAKwtB;QAGH,IAFAs6C,GAA4B,yBAAyBwC,WAAW,GAAG,IACnE98C,IAAUgtD,GAAwB,yBAAyBhtD;QACtDnsB,KAAKg5E,IAEH;;;YAGL,IAAIh5E,KAAKisE,IAAY;gBACnB,MAAM3nB,IAAW,IAAI80B,GACnBp5E,KAAKq3E,IACLr3E,KAAKgsE,IACLhsE,KAAKg5E,IACLh5E,KAAKi5E,IACLj5E,KAAKk5E;iCACY;gBAEnB,OAAOl5E,KAAKisE,GAAWoN,cAAc/0B,GAAUn4B;;YAS/C,OAPuB,IAAImnD,GACzBtzE,KAAKq3E,GAAWtL,IAChB/rE,KAAKq3E,GAAWiC,MAChBntD,EAAQotD,oBAAoB,QAC5B/4E,KACE,IAAIk2E,GAAkBl2E,GAAKR,KAAKq3E,qBAA6B,OAE3CrD,GAAah0E,KAAKg5E,GAAU/yC;;;IAKxDtnC,IACEwiB,GACAgL;QAIA,IAFAs6C,GAA4B,wBAAwBwC,WAAW,GAAG,IAClE98C,IAAUgtD,GAAwB,wBAAwBhtD;QACtDnsB,KAAKg5E,IAAW;YAClB,MAAM77E,IAAQ6C,KAAKg5E,GAChBrrE,OACArF,MACC4lE,GAAsB,wBAAwB/sD,GAAWnhB,KAAKgsE;YAElE,IAAc,SAAV7uE,GAAgB;gBAOlB,OANuB,IAAIm2E,GACzBtzE,KAAKq3E,GAAWtL,IAChB/rE,KAAKq3E,GAAWiC,MAChBntD,EAAQotD,oBAAoB,QAC5B/4E,KAAO,IAAIk2E,GAAkBl2E,GAAKR,KAAKq3E,IAAYr3E,KAAKisE,KAEpC+H,GAAa72E;;;;IAMzCgE;QACE,OAAOnB,KAAKgsE,GAAKtmE,KAAKme;;IAGxB27B;QACE,OAAO,IAAIk3B,GACT12E,KAAKgsE,IACLhsE,KAAKq3E,IACLr3E,KAAKisE;;IAIT9pD;QACE,OAA0B,SAAnBniB,KAAKg5E;;IAGdruC;QACE,OAAO,IAAIouC,GAAiB/4E,KAAKk5E,IAAmBl5E,KAAKi5E;;IAG3Dt6E,QAAQ0B;QACN,MAAMA,aAAiBq3E,KACrB,MAAMhP,GAAkB,WAAW,oBAAoB,GAAGroE;QAE5D,OACEL,KAAKq3E,OAAeh3E,EAAMg3E,MAC1Br3E,KAAKi5E,OAAe54E,EAAM44E,MAC1Bj5E,KAAKgsE,GAAK1nE,QAAQjE,EAAM2rE,QACJ,SAAnBhsE,KAAKg5E,KACkB,SAApB34E,EAAM24E,KACNh5E,KAAKg5E,GAAU10E,QAAQjE,EAAM24E,QACjCh5E,KAAKisE,OAAe5rE,EAAM4rE;;;;MAKnBmN,WACH1B;IAER/4E,KAAKwtB;QAMH,OALahpB,MAAMwK,KAAKwe;;;;SASZqtD,GACd3oE,GACA05D,GACAkP,GACA95E,GACAwhB,GACAxY,GACAxL;IAEA,IAAI6sE;IACJ,IAAI7oD,EAAUsL,KAAc;QAC1B,8CAAI9jB,uDAAkCA,GACpC,MAAM,IAAI1F,EACRlB,EAAKI,kBACL,qCAAqCwG;QAGlC,sBAAIA,+BAAsBA,GAAwB;YACvD+wE,GAAkCv8E,GAAOwL;YACzC,MAAMgxE,IAA6B;YACnC,KAAK,MAAMphE,KAAcpb,GACvBw8E,EAAcl4E,KAAKm4E,GAAqBj6E,GAAYkR,GAAO0H;YAE7DyxD,IAAa;gBAAEzxD,YAAY;oBAAEC,QAAQmhE;;;eAErC3P,IAAa4P,GAAqBj6E,GAAYkR,GAAO1T;6BAIrDwL,+BACAA,uDACAA,KAEA+wE,GAAkCv8E,GAAOwL;IAE3CqhE,IAAamE,GACXsL,GACAlP,GACAptE;yCACmBwL,+BAAsBA;IAG7C,MAAM9C,IAASygB,GAAYC,OAAOpF,GAAWxY,GAAIqhE;IAEjD,OA+RF,SAA2Bn5D,GAAsBhL;QAG/C,IAAIA,EAAO6mB,MAAgB;YACzB,MAAMmtD,IAAgBhpE,EAAMqc;YAC5B,IAAsB,SAAlB2sD,MAA2BA,EAAcv1E,QAAQuB,EAAOyC,QAC1D,MAAM,IAAIrF,EACRlB,EAAKI,kBAGH,wIAA2B03E,EAAcz2E,oBAChCyC,EAAOyC,MAAMlF;YAI5B,MAAM+pB,IAAoBtc,EAAMuc;YACN,SAAtBD,KACF2sD,GAAkCjpE,GAAOhL,EAAOyC,OAAO6kB;;QAI3D,MAAM4sD,IAAgBlpE,EAAMmpE;;;;;;;;;;;;;QArD9B,SAAwBrxE;YACtB,QAAQA;cACN;gBACE,OAAO;;cACT;gBACE,OAAO;;cAKT;gBACE,OAAO;;cACT;gBACE,OAAO;;cAMT;gBACE,OAAO;;cAOT;gBACE,OAAO;;SAyBoCsxE,CAAep0E,EAAO8C;QACrE,IAAsB,SAAlBoxE;;QAEF,MAAIA,MAAkBl0E,EAAO8C,KACrB,IAAI1F,EACRlB,EAAKI,kBAEH,gDAAI0D,EAAO8C,GAAGvF,yBAGZ,IAAIH,EACRlB,EAAKI,kBACL,kCAAkC0D,EAAO8C,GAAGvF,6BACjC22E,EAAc32E;KAlU/B82E,CAAkBrpE,GAAOhL,IAClBA;;;SAGOs0E,GACdtpE,GACAsQ,GACAqD;IAEA,IAAsB,SAAlB3T,EAAMnJ,SACR,MAAM,IAAIzE,EACRlB,EAAKI,kBACL;IAIJ,IAAoB,SAAhB0O,EAAMlJ,OACR,MAAM,IAAI1E,EACRlB,EAAKI,kBACL;IAIJ,MAAMqF,IAAU,IAAI+d,GAAQpE,GAAWqD;IAEvC,OA+SF,SAA4B3T,GAAsBrJ;QAChD,IAAqC,SAAjCqJ,EAAMuc,MAAiC;;YAEzC,MAAMH,IAAkBpc,EAAMqc;YACN,SAApBD,KACF6sD,GAAkCjpE,GAAOoc,GAAiBzlB,EAAQc;;KArTtE8xE,CAAmBvpE,GAAOrJ,IACnBA;;;;;;;;;;;;;;;;;;;AAwIT,SAASoyE,GACPj6E,GACAkR,GACAwpE;IAEA,IAA+B,mBAApBA,GAA8B;QACvC,IAAwB,OAApBA,GACF,MAAM,IAAIp3E,EACRlB,EAAKI,kBACL;QAIJ,KAAK0qB,GAAuBhc,OAA4C,MAAlCwpE,EAAgB10E,QAAQ,MAC5D,MAAM,IAAI1C,EACRlB,EAAKI,kBAGH,mHAAIk4E;QAGV,MAAM30E,IAAOmL,EAAMnL,KAAKyY,MAAM7Y,EAAaoB,EAAW2zE;QACtD,KAAK5zE,EAAY2C,EAAc1D,IAC7B,MAAM,IAAIzC,EACRlB,EAAKI,kBAGH,4IAAQuD,uDAA0DA,EAAK5G;QAG7E,OAAO+c,GAASlc,GAAY,IAAI8G,EAAYf;;IACvC,IAAI20E,aAA2BvO,IACpC,OAAOjwD,GAASlc,GAAY06E,EAAgBrO;IAE5C,MAAM,IAAI/oE,EACRlB,EAAKI,kBACL,mIAEKmlE,GAAiB+S,KAApB;;;;;;GASR,UAASX,GACPv8E,GACAm9E;IAEA,KAAK7uB,MAAM3vC,QAAQ3e,MAA2B,MAAjBA,EAAM2B,QACjC,MAAM,IAAImE,EACRlB,EAAKI,kBAEH,qDAAIm4E,EAASl3E;IAGnB,IAAIjG,EAAM2B,SAAS,IACjB,MAAM,IAAImE,EACRlB,EAAKI,kBACL,mBAAmBm4E,EAASl3E;IAIhC,sBAAIk3E,uDAA4BA,GAA0C;QACxE,IAAIn9E,EAAMwI,QAAQ,SAAS,GACzB,MAAM,IAAI1C,EACRlB,EAAKI,kBACL,mBAAmBm4E,EAASl3E;QAIhC,IAAIjG,EAAM0I,OAAOsiB,KAAWjhB,OAAOmR,MAAM8P,IAAUrpB,SAAS,GAC1D,MAAM,IAAImE,EACRlB,EAAKI,kBACL,mBAAmBm4E,EAASl3E;;;;AAqGpC,SAAS02E,GACPS,GACAC,GACAhzE;IAEA,KAAKA,EAAQlD,QAAQk2E,IACnB,MAAM,IAAIv3E,EACRlB,EAAKI,kBAEH,yFAA+Bq4E,EAAWp3E,yCACbo3E,EAAWp3E,8EAExBoE,EAAQpE;;;SAKhBq3E,GACd5pE;IAEA,IAAIA,EAAMmgD,QAAqD,MAAjCngD,EAAM0b,GAAgBztB,QAClD,MAAM,IAAImE,EACRlB,EAAKc,eACL;;;MAKO+zE;IACXj4E,YACS+7E,GACEtC,GACUnM;kBAFZyO,GACE16E,iBAAAo4E,aACUnM;;IAGrBttE,MACE2J,GACAqyE,GACAx9E;;QAMA,IAAIwL;QACJ,IALA09D,GAA0B,eAAe4C,WAAW,IACpDV,GAAgB,eAAe,GAAGprE,IAIP,aAAtBw9E,KAAyD,SAAtBA,GACtChyE,IAAKgyE,QACA;YAYLhyE,IAAKo/D,GAAmB,eAVG,gPAUgC,GAAG4S;;QAGhE,MAAMx5D,IAAY+sD,GAAsB,eAAe5lE,IACjDzC,IAAS2zE,GACbx5E,KAAK06E,IACL,eACA16E,KAAKo4E,UAAUN,IACf93E,KAAKo4E,UAAUrM,IACf5qD,GACAxY,GACAxL;QAEF,OAAO,IAAIy5E,YlF/+CsB/lE,GAAchL;YAcjD,MAAM+0E,IAAa/pE,EAAMpJ,QAAQ4d,OAAO,EAACxf;YACzC,OAAO,IAAIymB,GACTzb,EAAMnL,MACNmL,EAAMtJ,iBACNsJ,EAAM0b,GAAgB3nB,SACtBg2E,GACA/pE,EAAMhM,OACNgM,EAAM2b,IACN3b,EAAMnJ,SACNmJ,EAAMlJ;SkFy9CJkzE,CAAqB76E,KAAK06E,IAAQ70E,IAClC7F,KAAKo4E,WACLp4E,KAAKisE;;IAITttE,QACE2J,GACAwyE;QASA,IAAIt2D;QACJ,IARAiiD,GAA4B,iBAAiBwC,WAAW,GAAG,IAC3DlC,GACE,iBACA,oBACA,GACA+T;aAGmBx5E,MAAjBw5E,KAA+C,UAAjBA,GAChCt2D,gCACK;YAAA,IAAqB,WAAjBs2D,GAGT,MAAM,IAAI73E,EACRlB,EAAKI,kBACL,mDAAmD24E;YAJrDt2D;;QAQF,MAAMrD,IAAY+sD,GAAsB,iBAAiB5lE,IACnDd,IAAU2yE,GAAgBn6E,KAAK06E,IAAQv5D,GAAWqD;QACxD,OAAO,IAAIoyD,YlFp/CuB/lE,GAAcrJ;;YAMlD,MAAMuzE,IAAalqE,EAAM0b,GAAgBlH,OAAO,EAAC7d;YACjD,OAAO,IAAI8kB,GACTzb,EAAMnL,MACNmL,EAAMtJ,iBACNwzE,GACAlqE,EAAMpJ,QAAQ7C,SACdiM,EAAMhM,OACNgM,EAAM2b,IACN3b,EAAMnJ,SACNmJ,EAAMlJ;SkFs+CJqzE,CAAsBh7E,KAAK06E,IAAQlzE,IACnCxH,KAAKo4E,WACLp4E,KAAKisE;;IAITttE,MAAMgO;QAIJ,OAHA05D,GAA0B,eAAe4C,WAAW,IACpDtC,GAAgB,eAAe,UAAU,GAAGh6D,IAC5Cg8D,GAAuB,eAAe,GAAGh8D;QAClC,IAAIiqE,GACTnpD,GAAeztB,KAAK06E,IAAQ/tE,qBAC5B3M,KAAKo4E,WACLp4E,KAAKisE;;IAITttE,YAAYgO;QAIV,OAHA05D,GAA0B,qBAAqB4C,WAAW,IAC1DtC,GAAgB,qBAAqB,UAAU,GAAGh6D;QAClDg8D,GAAuB,qBAAqB,GAAGh8D,IACxC,IAAIiqE,GACTnpD,GAAeztB,KAAK06E,IAAQ/tE,oBAC5B3M,KAAKo4E,WACLp4E,KAAKisE;;IAITttE,QACEs8E,MACGtkE;QAEH4vD,GAA4B,iBAAiB0C,WAAW;QACxD,MAAMt7C,IAAQ3tB,KAAKk7E,GACjB,iBACAD,GACAtkE;qBACY;QAEd,OAAO,IAAIigE,GACTlpD,GAAiB1tB,KAAK06E,IAAQ/sD,IAC9B3tB,KAAKo4E,WACLp4E,KAAKisE;;IAITttE,WACEs8E,MACGtkE;QAEH4vD,GAA4B,oBAAoB0C,WAAW;QAC3D,MAAMt7C,IAAQ3tB,KAAKk7E,GACjB,oBACAD,GACAtkE;qBACY;QAEd,OAAO,IAAIigE,GACTlpD,GAAiB1tB,KAAK06E,IAAQ/sD,IAC9B3tB,KAAKo4E,WACLp4E,KAAKisE;;IAITttE,UACEs8E,MACGtkE;QAEH4vD,GAA4B,mBAAmB0C,WAAW;QAC1D,MAAMt7C,IAAQ3tB,KAAKk7E,GACjB,mBACAD,GACAtkE;qBACY;QAEd,OAAO,IAAIigE,GACThpD,GAAe5tB,KAAK06E,IAAQ/sD,IAC5B3tB,KAAKo4E,WACLp4E,KAAKisE;;IAITttE,MACEs8E,MACGtkE;QAEH4vD,GAA4B,eAAe0C,WAAW;QACtD,MAAMt7C,IAAQ3tB,KAAKk7E,GACjB,eACAD,GACAtkE;qBACY;QAEd,OAAO,IAAIigE,GACThpD,GAAe5tB,KAAK06E,IAAQ/sD,IAC5B3tB,KAAKo4E,WACLp4E,KAAKisE;;IAITttE,QAAQ0B;QACN,MAAMA,aAAiBu2E,KACrB,MAAMlO,GAAkB,WAAW,SAAS,GAAGroE;QAEjD,OACEL,KAAKo4E,cAAc/3E,EAAM+3E,aACzB5mE,GAAYxR,KAAK06E,IAAQr6E,EAAMq6E,OAC/B16E,KAAKisE,OAAe5rE,EAAM4rE;;IAI9BttE,cACE05E;QAEA,OAAO,IAAIzB,GAAS52E,KAAK06E,IAAQ16E,KAAKo4E,WAAWC;;0EAI3C15E,GACN4rE,GACA0Q,GACAtkE,GACAuP;QAGA,IADAqiD,GAAgBgC,GAAY,GAAG0Q,IAC3BA,aAAsBvD,IAExB,OADArR,GAA0BkE,GAAY,EAAC0Q,MAAetkE,KAAS,aAjhBnE9F,GACAlR,GACA4qE,GACAv6D,GACAkW;YAEA,KAAKlW,GACH,MAAM,IAAI/M,EACRlB,EAAKM,WACL,yDACKkoE,IAAH;YAIN,MAAM4Q,IAA0B;;;;;;;;wBAShC,KAAK,MAAM3zE,KAAWslB,GAAajc,IACjC,IAAIrJ,EAAQc,MAAMmkB,KAChB0uD,EAAW15E,KAAKoa,GAASlc,GAAYqQ,EAAIxP,YACpC;gBACL,MAAMrD,IAAQ6S,EAAI1H,MAAMd,EAAQc;gBAChC,IAAImO,GAAkBtZ,IACpB,MAAM,IAAI8F,EACRlB,EAAKI,kBACL,iGAEEqF,EAAQc,QAFV;gBAMG,IAAc,SAAVnL,GAEJ;oBACL,MAAMmL,IAAQd,EAAQc,MAAM7C;oBAC5B,MAAM,IAAIxC,EACRlB,EAAKI,kBAEH,+FAAiCmG;;gBANrC6yE,EAAW15E,KAAKtE;;YAYtB,OAAO,IAAIipB,GAAM+0D,GAAYj1D;;;;GAgelBk1D,EACLp7E,KAAK06E,IACL16E,KAAKo4E,UAAUrM,IACfxB,GACA0Q,EAAWjC,IACX9yD;QAEG;YACL,MAAMm1D,IAAY,EAACJ,IAAY51D,OAAO1O;YACtC,gBAleJ9F,GACAlR,GACA85E,GACAlP,GACA/xD,GACA0N;;gBAGA,MAAM1e,IAAUqJ,EAAM0b;gBACtB,IAAI/T,EAAO1Z,SAAS0I,EAAQ1I,QAC1B,MAAM,IAAImE,EACRlB,EAAKI,kBACL,kCAAkCooE;gBAMtC,MAAM4Q,IAA0B;gBAChC,KAAK,IAAI78E,IAAI,GAAGA,IAAIka,EAAO1Z,QAAQR,KAAK;oBACtC,MAAMg9E,IAAW9iE,EAAOla;oBAExB,IADyBkJ,EAAQlJ,GACZgK,MAAMmkB,KAAc;wBACvC,IAAwB,mBAAb6uD,GACT,MAAM,IAAIr4E,EACRlB,EAAKI,kBAEH,uDAAGooE,yBAAkC+Q;wBAG3C,KAAKzuD,GAAuBhc,OAAqC,MAA3ByqE,EAAS31E,QAAQ,MACrD,MAAM,IAAI1C,EACRlB,EAAKI,kBAEH,yGAAuBooE,yCACnB+Q;wBAGV,MAAM51E,IAAOmL,EAAMnL,KAAKyY,MAAM7Y,EAAaoB,EAAW40E;wBACtD,KAAK70E,EAAY2C,EAAc1D,IAC7B,MAAM,IAAIzC,EACRlB,EAAKI,kBAEH,+GAA+CooE,kDAClB7kE;wBAInC,MAAMlF,IAAM,IAAIiG,EAAYf;wBAC5By1E,EAAW15E,KAAKoa,GAASlc,GAAYa;2BAChC;wBACL,MAAM+6E,IAAUpN,GAAgBsL,GAAYlP,GAAY+Q;wBACxDH,EAAW15E,KAAK85E;;;gBAIpB,OAAO,IAAIn1D,GAAM+0D,GAAYj1D;aA0alBs1D,CACLx7E,KAAK06E,IACL16E,KAAKo4E,UAAUrM,IACf/rE,KAAKo4E,UAAUN,IACfvN,GACA8Q,GACAn1D;;;IAwBNvnB,cAAclC;;QACZgqE,GAA4B,oBAAoBwC,WAAW,GAAG;QAC9D,IAAI98C,IAAyB,IACzBmsD,IAAU;QAkBd,IAhB2B,mBAAlB77E,EAAK67E,MACX9S,GAAkB/oE,EAAK67E,QAExBnsD,IAAU1vB,EAAK67E,IACf9P,GAAoB,oBAAoBr8C,GAAS,EAC/C;QAEF+6C,GACE,oBACA,WACA,0BACA/6C,EAAQmuC;QAEVge,MAGE9S,GAAkB/oE,EAAK67E,KAAW;YACpC,MAAME,IAAe/7E,EAAK67E;YAG1B77E,EAAK67E,mBAAWE,EAAahyE,mCAAMm3B,KAAK66C,IACxC/7E,EAAK67E,IAAU,mBAAKE,EAAaz7E,oCAAO4gC,KAAK66C;YAC7C/7E,EAAK67E,IAAU,mBAAKE,EAAaC,uCAAU96C,KAAK66C;eAEhD7R,GAAgB,oBAAoB,YAAY2R,GAAS77E,EAAK67E,KAC9DvR,GACE,oBACA,YACAuR,IAAU,GACV77E,EAAK67E,IAAU;QAEjBvR,GACE,oBACA,YACAuR,IAAU,GACV77E,EAAK67E,IAAU;QAInB,MAAMre,IAA0C;YAC9CzzD,MAAM89C;gBACA7nD,EAAK67E,MACN77E,EAAK67E,GACJ,IAAImD,GACFz7E,KAAKo4E,WACLp4E,KAAK06E,IACLp2B,GACAtkD,KAAKisE;;YAKblvE,OAAON,EAAK67E,IAAU;YACtBG,UAAUh8E,EAAK67E,IAAU;;QAG3BmC,GAAyCz6E,KAAK06E;QAE9C,OADwB16E,KAAKo4E,UAAUvD,KAChB7gB,OAAOh0D,KAAK06E,IAAQvuD,GAAS8tC;;IAGtDt7D,IAAIwtB;QACFs6C,GAA4B,aAAawC,WAAW,GAAG,IACvD0P,GAAmB,aAAaxsD,IAChCsuD,GAAyCz6E,KAAK06E;QAE9C,MAAM9B,IAAkB54E,KAAKo4E,UAAUvD;QACvC,QAAQ1oD,KAA8B,YAAnBA,EAAQgpC,SACvByjB,EAAgB8C,GAA2B17E,KAAK06E,MAChD9B,EAAgB+C,GAAgC37E,KAAK06E,IAAQvuD,IAC/DuR,KACA28B,KACE,IAAIohB,GAAcz7E,KAAKo4E,WAAWp4E,KAAK06E,IAAQrgB,GAAMr6D,KAAKisE;;;;MAKrDwP;IAOX98E,YACmB04E,GACAuE,GACAC,GACA5P;kBAHAoL,aACAuE,aACAC,aACA5P,GATnBjsE,UAAoE,MACpEA,UAA+D;QAU7DA,KAAK2qC,WAAW,IAAIouC,GAClB8C,EAAUtqE,kBACVsqE,EAAU3qE;;IAIdJ;QACE,MAAMtE,IAAoD;QAE1D,OADAxM,KAAKa,QAAQmP,KAAOxD,EAAO/K,KAAKuO,KACzBxD;;IAGTqe;QACE,OAAO7qB,KAAK67E,GAAU/qE,KAAK/P;;IAG7BiE;QACE,OAAOhF,KAAK67E,GAAU/qE,KAAK9L;;IAG7BrG,QACEmyB,GACAgrD;QAEArV,GAA4B,yBAAyBwC,WAAW,GAAG,IACnEtC,GAAgB,yBAAyB,YAAY,GAAG71C;QACxD9wB,KAAK67E,GAAU/qE,KAAKjQ,QAAQmP;YAC1B8gB,EAASlwB,KACPk7E,GACA97E,KAAK+7E,GACH/rE,GACAhQ,KAAK2qC,SAASz5B,WACdlR,KAAK67E,GAAU5qE,GAAY3C,IAAI0B,EAAIxP;;;IAM3CqQ;QACE,OAAO,IAAI+lE,GAAM52E,KAAK47E,IAAgB57E,KAAKq3E,IAAYr3E,KAAKisE;;IAG9DttE,WACEwtB;QAEIA,MACFq8C,GAAoB,4BAA4Br8C,GAAS,EACvD,6BAEF+6C,GACE,4BACA,WACA,0BACA/6C,EAAQmuC;QAIZ,MAAMA,OACJnuC,MAAWA,EAAQmuC;QAGrB,IAAIA,KAA0Bt6D,KAAK67E,GAAUzqE,IAC3C,MAAM,IAAInO,EACRlB,EAAKI,kBACL;QAiBJ,OAXGnC,KAAKg8E,MACNh8E,KAAKi8E,OAAyC3hB,MAE9Ct6D,KAAKg8E;;;;;;;;;;;iBAsNT13B,GACAgW,GACA+d;YAWA,IAAI/zB,EAASvzC,GAAQhQ,KAAW;;;gBAG9B,IAAIm7E,GACA38E,IAAQ;gBACZ,OAAO+kD,EAAStzC,WAAWtU,IAAI6T;oBAC7B,MAAMP,IAAMqoE,EACV9nE,EAAOP,KACPs0C,EAASpzC,WACTozC,EAASrzC,GAAY3C,IAAIiC,EAAOP,IAAIxP;oBAWtC,OADA07E,IAAU3rE,EAAOP,KACV;wBACLU,MAAM;wBACNV,KAAAA;wBACAmsE,WAAW;wBACXC,UAAU78E;;;;YAGT;;;gBAGL,IAAI88E,IAAe/3B,EAASvzC;gBAC5B,OAAOuzC,EAAStzC,WACbnL,OACC0K,KAAU+pD,0BAA0B/pD,EAAOG,MAE5ChU,IAAI6T;oBACH,MAAMP,IAAMqoE,EACV9nE,EAAOP,KACPs0C,EAASpzC,WACTozC,EAASrzC,GAAY3C,IAAIiC,EAAOP,IAAIxP;oBAEtC,IAAI27E,KAAY,GACZC,KAAY;oBAUhB,yBATI7rE,EAAOG,SACTyrE,IAAWE,EAAa12E,QAAQ4K,EAAOP,IAAIxP,MAE3C67E,IAAeA,EAAapsE,OAAOM,EAAOP,IAAIxP;wCAE5C+P,EAAOG,SACT2rE,IAAeA,EAAa9tE,IAAIgC,EAAOP,MACvCosE,IAAWC,EAAa12E,QAAQ4K,EAAOP,IAAIxP,OAEtC;wBAAEkQ,MAAM4rE,GAAiB/rE,EAAOG;wBAAOV,KAAAA;wBAAKmsE,UAAAA;wBAAUC,UAAAA;;;;SAvRzCG,CACpBv8E,KAAK67E,IACLvhB,GACAt6D,KAAK+7E,GAAsBp+C,KAAK39B,QAElCA,KAAKi8E,KAAuC3hB,IAGvCt6D,KAAKg8E;;kEAIdr9E,QAAQ0B;QACN,MAAMA,aAAiBo7E,KACrB,MAAM/S,GAAkB,WAAW,iBAAiB,GAAGroE;QAGzD,OACEL,KAAKq3E,OAAeh3E,EAAMg3E,MAC1B7lE,GAAYxR,KAAK47E,IAAgBv7E,EAAMu7E,OACvC57E,KAAK67E,GAAUv3E,QAAQjE,EAAMw7E,OAC7B77E,KAAKisE,OAAe5rE,EAAM4rE;;IAItBttE,GACNqR,GACAkB,GACAK;QAEA,OAAO,IAAI6nE,GACTp5E,KAAKq3E,IACLrnE,EAAIxP,KACJwP,GACAkB,GACAK,GACAvR,KAAKisE;;;;MAKEwK,WAAwDG;IAEnEj4E,YACW69E,GACTpE,GACAnM;QAGA,IADA9oE,MAAMypB,GAAgB4vD,IAAQpE,GAAWnM,cAJhCuQ,GAKLA,EAAM19E,SAAS,KAAM,GACvB,MAAM,IAAImE,EACRlB,EAAKI,kBAGH,gGAAGq6E,EAAM/2E,WAAyB+2E,EAAM19E;;IAKhDqC;QACE,OAAOnB,KAAK06E,GAAOh1E,KAAKme;;IAG1BJ;QACE,MAAMuiB,IAAahmC,KAAK06E,GAAOh1E,KAAKke;QACpC,OAAIoiB,EAAWjlC,MACN,OAEA,IAAI21E,GACT,IAAIjwE,EAAYu/B,IAChBhmC,KAAKo4E;yBACY;;IAKvB1yE;QACE,OAAO1F,KAAK06E,GAAOh1E,KAAKD;;IAG1B9G,IAAI63E;QACF/P,GAA4B,2BAA2BwC,WAAW,GAAG;;;QAG5C,MAArBA,UAAUnqE,WACZ03E,IAAa93E,EAAOqyE,MAEtBpK,GACE,2BACA,oBACA,GACA6P;QAEF,MAAM9wE,IAAOJ,EAAaoB;QAC1B,OAAOgwE,GAAkBC,GACvB32E,KAAK06E,GAAOh1E,KAAKyY,MAAMzY,IACvB1F,KAAKo4E,WACLp4E,KAAKisE;;IAITttE,IAAIxB;QACFkpE,GAA0B,2BAA2B4C,WAAW;QAIhEtC,GAAgB,2BAA2B,UAAU,GAH9B3mE,KAAKisE,KACxBjsE,KAAKisE,GAAWwQ,YAAYt/E,KAC5BA;QAEJ,MAAMu/E,IAAS18E,KAAKgQ;QACpB,OAAO0sE,EAAOptE,IAAInS,GAAOugC,KAAK,MAAMg/C;;IAGtC/9E,cACE05E;QAEA,OAAO,IAAI5B,GAAuBz2E,KAAKw8E,IAAOx8E,KAAKo4E,WAAWC;;;;AAIlE,SAASV,GACPpN,GACAp+C;IAEA,SAAgB7qB,MAAZ6qB,GACF,OAAO;QACL6gD,QAAO;;IAeX,IAXAxE,GAAoB+B,GAAYp+C,GAAS,EAAC,SAAS,kBACnD+6C,GAA0BqD,GAAY,WAAW,SAASp+C,EAAQ6gD,QAClE7F,GACEoD,GACA,eACA,2BACAp+C,EAAQ8gD,aACR9kD,KACqB,mBAAZA,KAAwBA,aAAmB6vD;SAG1B12E,MAAxB6qB,EAAQ8gD,oBAA+C3rE,MAAlB6qB,EAAQ6gD,OAC/C,MAAM,IAAI/pE,EACRlB,EAAKI,kBACL,sCAAsCooE;IAK1C,OAAOp+C;;;AAGT,SAASgtD,GACP5O,GACAp+C;IAEA,YAAgB7qB,MAAZ6qB,IACK,MAGTq8C,GAAoB+B,GAAYp+C,GAAS,EAAC,uBAC1Cq7C,GACE+C,GACA,GACA,oBACAp+C,EAAQotD,kBACR,EAAC,YAAY,YAAY;IAEpBptD;;;AAGT,SAASwsD,GACPpO,GACAp+C;IAEA46C,GAAwBwD,GAAY,UAAU,GAAGp+C,IAC7CA,MACFq8C,GAAoB+B,GAAYp+C,GAAS,EAAC,aAC1Cq7C,GACE+C,GACA,GACA,UACAp+C,EAAQgpC,QACR,EAAC,WAAW,UAAU;;;AAK5B,SAASqiB,GACPjN,GACAgN,GACAa;IAEA,IAAMb,aAAuBzL,IAEtB;QAAA,IAAIyL,EAAYa,cAAcA,GACnC,MAAM,IAAIn1E,EACRlB,EAAKI,kBACL;QAGF,OAAOo1E;;IAPP,MAAM7O,GAAkB6B,GAAY,qBAAqB,GAAGgN;;;AA4FhE,SAAS+E,GAAiB5rE;IACxB,QAAQA;MACN;QACE,OAAO;;MACT;MACA;QACE,OAAO;;MACT;QACE,OAAO;;MACT;QACE,OA/8EsBnT;;;;;;;;;;;;aA49EZs6E,GACdQ,GACAl7E,GACAgvB;IAEA,IAAIyrD;;;;IAaJ,OAPIA,IALAS,IACElsD,MAAYA,EAAQ6gD,SAAS7gD,EAAQ8gD,eAIrBoL,EAAkBoE,YAAYt/E,GAAOgvB,KAEtCksD,EAAUoE,YAAYt/E,KAGxBA;IAEZy6E;;;AC/9ET,MAAM+E,KAAqB;IACzBlI,WAAAA;IACAhJ,UAAAA;IACAnoE,WAAAA;IACAwlE,MAAAA;iBACAuG;IACAyH,YAAAA;IACAJ,mBAAAA;IACAgB,kBAAAA;IACAd,OAAAA;IACAwC,uBAAAA;IACAqC,eAAAA;IACAhF,qBAAAA;eACA1wE;IACAslE,YAAAA;IACA+L,aAAa3C,GAAU2C;IACvB/C,sBAAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;SCtBcuI,GAAkBC;cDiChCC,GACAC;QAKCD,EAAgCh6E,SAASk6E,kBACxC,IAAIC,EACF,aACAC;YACE,MAAMnI,IAAMmI,EAAUC,YAAY,OAAOn8B;YACzC,OAAO+7B,EAAiBhI,GAAKmI,EAAUC,YAAY;kCAGrDC,kCAAqBT;KC9CzBU,CAAqBR,GAAU,CAAC9H,GAAKh0B;QACnC,MAAM0jB,IAA0B,IAAIM,IAC9BC,IAA2B,IAAIR,GACnCC;QAEF,OAAO,IAAIgQ,GACTM,GACAh0B,GACAikB,GACAP;QAGJoY,EAASS,iDAA+B;;;AAG1CV,GAAkBE;;"}